# Extraction: SOURCE-20260125-342

**Source**: `SOURCE-20260125-youtube-lecture-machine_learning_street_talk-if_you_can_t_see_inside_how_do_you_know_it_s_thinking_dr_jef.md`
**Atoms extracted**: 9
**Categories**: claim, concept, praxis_hook

---

## Claim (4)

### ATOM-SOURCE-20260125-342-0001
**Lines**: 16-18
**Context**: hypothesis / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.40, actionability=0.10, epistemic_stability=0.50

> From a purely mathematical perspective, there is no structural difference between an agent and a rock, as both execute policies that map inputs to outputs.

### ATOM-SOURCE-20260125-342-0004
**Lines**: 27-28
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.60

> The best approach to the Black Box Problem of Agency is to identify which model provides the simplest explanation for observed behavior.

### ATOM-SOURCE-20260125-342-0006
**Lines**: 36-38
**Context**: hypothesis / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.70, actionability=0.10, epistemic_stability=0.40

> The complex, non-smooth nature of olfactory space may have driven the evolution of the associative cortex and planning abilities in the brain.

### ATOM-SOURCE-20260125-342-0008
**Lines**: 44-47
**Context**: rebuttal / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.50, actionability=0.20, epistemic_stability=0.50

> AI safety concerns should focus less on rogue superintelligences and more on humans becoming 'reward function selectors' who merely approve or reject AI outputs.

## Concept (4)

### ATOM-SOURCE-20260125-342-0002
**Lines**: 18-21
**Context**: hypothesis / claim
**Tension**: novelty=0.70, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.20, epistemic_stability=0.60

> The distinction between an agent and a rock lies in the sophistication of internal computations, specifically whether the system engages in planning and counterfactual reasoning, or if it merely acts as a lookup table.

### ATOM-SOURCE-20260125-342-0003
**Lines**: 24-27
**Context**: consensus / claim
**Tension**: novelty=0.50, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.70

> The Black Box Problem of Agency refers to the difficulty of determining whether a system is truly planning or just executing a pre-computed response, a question that is nearly impossible to answer from external observation.

### ATOM-SOURCE-20260125-342-0005
**Lines**: 30-33
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.70

> Energy-Based Models (EBMs) differ from standard neural networks because EBMs optimize both weights and internal states, whereas traditional networks only optimize weights.

### ATOM-SOURCE-20260125-342-0007
**Lines**: 40-42
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.60, actionability=0.50, epistemic_stability=0.60

> Yann LeCun's Joint Embedding Prediction Architecture (JEPA) suggests that learning in latent space, rather than predicting every pixel, is key to more robust AI representations.

## Praxis Hook (1)

### ATOM-SOURCE-20260125-342-0009
**Lines**: 47-50
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.60, actionability=0.80, epistemic_stability=0.50

> A proposed solution for AI safety is to use inverse reinforcement learning to derive AI goals from observed human behavior, then make small perturbations rather than naive commands like 'end world hunger'.
