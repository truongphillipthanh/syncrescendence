# 10 Years Building Vertical Software: My Perspective on the Selloff
(Description: Large title graphic displaying "VERTICAL SOFTWARE, ARE WE COOKED?" in blue outlined block letters on a white background)
In the past few weeks, nearly $1 trillion was wiped from software and services stocks. FactSet dropped from a $20B peak to under $8B. S&P Global lost 30% in weeks. Thomson Reuters shed almost half its market cap in a year. The S&P 500 Software & Services Index, 140 companies, fell 20% year to date.
Last week, Anthropic released industry-specific plugins for Claude's Cowork which is an AI agent designed specifically for knowledge workers that can autonomously handle complex research, analysis, and document workflows.
Wall Street called it a panic. I've spent the last decade building vertical SaaS. First @Doctrine, now the largest legal information platform in Europe (competing with LexisNexis, Westlaw etc) and then @fintool, an AI-powered equity research platform in the US that competes with Bloomberg, FactSet, and S&P Global today.
I built the kind of software that LLMs are now threatening. And I'm now building the kind of software that's doing the threatening. I've been on both sides of this disruption.
Here's what I see: LLMs are systematically dismantling the moats that made vertical software defensible. But not all of them. The result is a redrawing of what makes vertical software valuable and the multiple it deserves.
In this article:
- The ten moats that made vertical software defensible, and what LLMs do to each
- Why the market selloff is structurally justified but temporally exaggerated
- What the real threat actually is (it's not what you think)
- What replaces vertical software
- What comes next for the vertical software industry
## The Ten Moats of Vertical Software (and What LLMs Do to Each)
Vertical software is software built for a specific industry. Bloomberg for finance. LexisNexis for legal. Epic for healthcare. Procore for construction. Veeva for life sciences, etc.
These companies share a defining characteristic: they charge a lot and customers rarely leave. FactSet charges $15,000+ per user per year. Bloomberg Terminal costs $25,000 per seat. LexisNexis charges law firms thousands per month. And retention rates hover around 95%.
I would say that there are ten distinct moats. LLMs are attacking some of them while leaving others intact. Understanding which is which is the entire game.
### 1. Learned Interfaces → Destroyed
A Bloomberg Terminal user has spent years learning keyboard shortcuts, function codes, and navigation patterns. GP, FLDS, GIP, FA, BQ. These aren't intuitive. They're a language. And once you speak it fluently, switching to another platform means becoming illiterate again.
I've heard it countless times. "We're a FactSet shop." "We're a Lexis firm." "We're a Bloomberg house." These aren't statements about data quality or feature sets. They're statements about software muscle memory. People have spent a decade learning the tool. That investment isn't transferable.
This was the most under-appreciated moat. Knowledge workers pay to not relearn a workflow they've spent a decade mastering. The interface IS a big part of the value prop.
I lived this at Doctrine. We had a team of designers and a small army of customer success managers whose entire job was onboarding lawyers onto our interface. Every UI change was a project: user research, design sprints, careful rollouts, handholding. We'd spend weeks on a faceted search filter redesign because lawyers had built muscle memory around the old one. The interface wasn't a feature. It was the product. And maintaining it was one of our biggest cost centers.
At Fintool, we have no onboarding. No CSMs teaching people how to navigate the product. Our users type what they want in plain English and get an answer. There is no interface to learn because it's all chat. That entire cost center, the designers, the CSMs, the UI change management, it just doesn't exist. The chat interface absorbed all those scaffoldings.
LLMs collapse all proprietary interfaces into one Chat.
(Description: Diagram comparing two scenarios side by side. Left box labeled "Years to master / $25K per seat / High switching cost" with vertical lines separating columns. Right box labeled "Zero learning curve / Switching cost: zero")
Consider what a financial analyst does today on a Bloomberg Terminal. They navigate to the equity screening function. Set parameters using specialized syntax. Export results. Switch to the DCF model builder. Input assumptions. Run sensitivity analysis. Export to Excel. Build a presentation.
Each step requires learned interface knowledge. Each step reinforces switching costs.
Now consider what the same analyst does with an LLM agent:
"Show me all software companies with over $1B market cap, P/E under 30, and revenue growing over 20% year over year. Build a DCF model for the top 5. Run sensitivity analysis on discount rate and terminal growth."
Three sentences. No keyboard shortcuts. No function codes. No navigation. The user doesn't even know which data provider the LLM queried. They don't care.
When the interface is a natural language conversation, years of muscle memory become worthless. The switching cost that justified $25K per seat per year dissolves. For many vertical software companies, the interface was most of the value. The underlying data was licensed, public, or semi-commoditized. What justified premium pricing was the workflow built on top of that data. That's over.
### 2. Custom Workflows and Business Logic → Vaporized
Vertical software encodes how an industry actually works. A legal research platform doesn't just store case law. It encodes citational networks, Shepardize signals, headnote taxonomies, and the specific way a litigation associate builds a brief.
This business logic took years to build. It reflects thousands of conversations with domain experts. When I built Doctrine, the hardest part wasn't the technology. It was understanding how lawyers actually work: how they research case law, how they draft documents, how they build a litigation strategy from intake to trial. Encoding that understanding into working software was a huge part of what made vertical software valuable—and defensible.
LLMs turn all of this into a markdown file.
This is the most under appreciated shift and I think the most devastating long-term.
Traditional vertical software encodes business logic in code. Thousands of if/then branches, validation rules, compliance checks, approval workflows. Hardcoded by engineers over years... and not just any engineers. You need software engineers who actually understand the domain, which is rare. Finding someone who can write production code AND understands how a litigation workflow actually functions, or how a DCF model should be structured, is incredibly hard. Modifying this business logic required development cycles, QA, deployment.
Let me give you a concrete example from my own experience.
At Doctrine, we built a legal research workflow that helped lawyers find relevant case law for a given legal question. The system needed to understand the legal domain (civil vs. criminal vs. administrative), parse the question into searchable concepts, query across multiple court databases, rank results by relevance and authority, and present them with proper citational context. Building this took a team of engineers and legal experts over several years. The business logic was spread across thousands of lines of Python, custom ranking algorithms, and hand-tuned relevance models. Every modification required engineering sprints, code review, testing, and deployment.
At Fintool, we have a DCF valuation skill. It tells an LLM agent how to do a discounted cash flow analysis: which data to gather, how to calculate WACC by industry, what assumptions to validate, how to run sensitivity analysis, when to add back stock-based compensation. It's a markdown file. Writing it took a week. Updating it takes minutes. A portfolio manager who's done 500 DCF valuations can encode their entire methodology without writing a single line of code.
Years of engineering versus one week of writing. That's the shift.
And it's not just speed. The markdown skill is better in important ways. It's readable by anyone. It's auditable. It can be customized per user (our customers write their own skills). And it gets better automatically as the underlying model improves, without us touching a line of code.
Business logic is migrating from code written by specialized engineers to markdown files that anyone with domain expertise can write. The accumulated business logic that took vertical software companies a decade to build can now be replicated in weeks. The workflow moat is eroding very fast.
### 3. Public Data Access → Commoditized
A massive portion of vertical software's value proposition was making hard-to-access data easy to query. FactSet makes SEC filings searchable. LexisNexis makes case law searchable. These are genuine services. SEC filings are technically public, but try reading a 200-page 10-K in raw HTML. The structure is inconsistent across companies. The accounting terminology is dense. Extracting the actual numbers you need requires parsing nested tables, following footnote references, reconciling restated figures.
Before LLMs, accessing this public data required specialized software and significant engineering scaffolding. Companies like FactSet built thousands of parsers, one for each filing type, each company's idiosyncratic formatting. Armies of engineers maintained these parsers as formats changed. The code to turn a raw SEC filing into queryable data was a genuine competitive advantage.
At Doctrine, this was also a lot of work. We built NLP pipelines for different case laws: named entity recognition to extract judges, courts, legal concepts. Dedicated ML models to classify decisions by legal domain. Custom parsers for every court, each with its own formatting quirks. We had engineers who spent years building and maintaining this scaffolding. It was genuinely impressive technology, and it was a real moat because replicating it meant years of work.
At Fintool, we built none of that. Zero NER. Zero custom parsers. Zero industry-specific classifiers. Why? Because frontier models already know how to navigate a 10-K. They know that Home Depot's ticker is HD. They understand the difference between GAAP and non-GAAP revenue. They can parse a nested table of segment disclosures without being taught the schema. The parsing infrastructure that took Doctrine years to build is now a commodity capability that comes free with the model.
LLMs make this trivial. Frontier models already know how to parse SEC filings from their training data. They understand the structure of a 10-K, where to find revenue recognition policies, how to reconcile GAAP and non-GAAP figures. You don't need to build a parser. The model IS the parser. Feed it a 10-K and it can answer any question about it. Feed it the entire corpus of federal case law and it can find relevant precedent.
The parsing, structuring, and querying that vertical software spent decades building is now a commodity capability baked into the foundation models themselves. The data isn't worthless. But the "making it searchable" layer, which is where a lot of the value and pricing power lived, is collapsing.
### 4. Talent Scarcity → Inverted
Building vertical software requires people who understand both the domain and the technology. Finding an engineer who can write production code AND understands how credit derivatives are structured is extremely rare. This scarcity created a natural barrier to entry that historically limited the number of serious competitors in any vertical.
LLMs flip this moat entirely.
At Doctrine, hiring was brutal. We didn't just need good engineers. We needed engineers who could understand legal reasoning: how precedent works, how jurisdictions interact, what grounds for appeal to the supreme court look like. These people barely existed. So we built our own. Every week, we held internal lectures where lawyers taught engineers how the legal system actually worked. It took months before a new engineer was productive. The talent scarcity was a genuine barrier, not just for us, but for anyone trying to compete with us.
At Fintool, we don't do any of that. Our domain experts (portfolio managers, analysts) write their methodology directly into markdown skill files. They don't need to learn Python. They don't need to understand APIs. They write in plain English what a good DCF analysis looks like, and the LLM executes it. The engineering is handled by the model. The domain expertise, which was always the abundant resource, can now become software directly without the engineering bottleneck.
LLMs make the engineering trivially accessible, which means the scarce resource (domain expertise) is suddenly abundant in its ability to become software. This is why the barrier to entry collapses so dramatically.
### 5. Bundling → Weakened
Vertical software companies expand by bundling adjacent capabilities. Bloomberg started with market data, then added messaging, news, analytics, trading, and compliance. Each new module increases switching costs because customers now depend on the entire ecosystem, not just one product. S&P Global's acquisition of IHS Markit for $44B was exactly this strategy. The bundle becomes the moat.
At Doctrine, bundling was the growth strategy. We started with case law search, then added legislation, then legal news, then alerts, then document analysis. Each module had its own UI, its own onboarding, its own customer workflows. We built elaborate dashboards where lawyers could configure watchlists, set up automated alerts on specific legal topics, manage their research folders. Every feature meant more design work, more engineering, more UI surface area. The bundle kept customers locked in because they'd built their entire workflow around our ecosystem.
LLM agents break the bundling moat because the agent IS the bundle.
(Description: Two-box diagram comparison. Left box labeled "TRADITIONAL BUNDLE" shows "Bloomberg" with list of capabilities: Market Data, News, Analytics, Messaging, Trading, and "One monolithic bundle". Right box labeled "AGENT AS BUNDLE" shows "AI Agent" with routing logic: "Data --> Vendor A, News --> Vendor B, Anal. --> Vendor C, Trading --> Vendor D" followed by "Picks best per task, Cheapest provider wins")
At Fintool, alerts are a prompt. Watchlists are a prompt. Portfolio screening is a prompt. There's no separate module for each. There's no UI to maintain. A customer says "alert me when any company in my portfolio mentions tariff risk in an earnings call" and it just works. The agent orchestrates across ten different specialized tools in a single workflow. It can pull market data from one source, news from another, run analytics through a third, and compile the results. The user never knows or cares that five different services were queried.
When the integration layer moves from the software vendor to the AI agent, the incentive to buy a bundle evaporates. Why pay Bloomberg's premium for the entire suite when an agent can cherry-pick the best (or cheapest) provider for each capability?
This doesn't mean bundling is dead overnight. The operational complexity of managing ten vendor relationships versus one is real. But the directional pressure is clear: agents make unbundling viable in ways that weren't possible before.
### 6. Private and Proprietary Data → Stronger
Some vertical software companies own or license data that doesn't exist anywhere else. Bloomberg collects real-time pricing data from trading desks worldwide. S&P Global owns credit ratings and proprietary analytics. Dun & Bradstreet maintains business credit files on 500M+ entities. This data was collected over decades, often through exclusive relationships. You can't just scrape it. You can't recreate it.
If your data genuinely cannot be replicated, LLMs make it MORE valuable, not less.
Bloomberg's real-time pricing data from trading desks? Can't be scraped. Can't be synthesized. Can't be licensed from a third party. In an LLM world, this data becomes the scarce input that every agent needs. Bloomberg's pricing power on proprietary data may actually increase.