{"atom_id": "ATOM-SOURCE-20260121-x-article-natolambert-get_good_at_agents-0001", "source_id": "SOURCE-20260121-x-article-natolambert-get_good_at_agents", "category": "claim", "content": "Software engineering is going to look very different by the end of 2026 due to advancements in AI, specifically tools like Claude Code.", "line_start": 5, "line_end": 6, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.7, 0.2, 0.4], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260121-x-article-natolambert-get_good_at_agents-0002", "source_id": "SOURCE-20260121-x-article-natolambert-get_good_at_agents", "category": "praxis_hook", "content": "To effectively work with AI agents, one should avoid micromanaging them, assigning them too small tasks, and instead focus on more open-ended, ambitious, and asynchronous approaches.", "line_start": 10, "line_end": 14, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.3, 0.1, 0.5, 0.8, 0.5], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260121-x-article-natolambert-get_good_at_agents-0003", "source_id": "SOURCE-20260121-x-article-natolambert-get_good_at_agents", "category": "prediction", "content": "The future direction of working with agents will involve humans working less, spending more time cultivating peace, and directing agents to do most of the hard work.", "line_start": 16, "line_end": 18, "chaperone": {"context_type": "speculation", "argument_role": "claim", "tension_vector": [0.7, 0.2, 0.1, 0.8, 0.6, 0.3], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260121-x-article-natolambert-get_good_at_agents-0004", "source_id": "SOURCE-20260121-x-article-natolambert-get_good_at_agents", "category": "claim", "content": "Working with AI agents like Claude Code represents a larger shift in work style than the previous era of chat-based AI assistants like ChatGPT.", "line_start": 20, "line_end": 21, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.6, 0.3, 0.5], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260121-x-article-natolambert-get_good_at_agents-0005", "source_id": "SOURCE-20260121-x-article-natolambert-get_good_at_agents", "category": "claim", "content": "AI agents push humans up the organizational chart, requiring engineers to learn system design and researchers to learn lab management.", "line_start": 24, "line_end": 25, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.5, 0.1, 0.7, 0.4, 0.5], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260121-x-article-natolambert-get_good_at_agents-0006", "source_id": "SOURCE-20260121-x-article-natolambert-get_good_at_agents", "category": "claim", "content": "The author's role is shifting from using power tools to directing an 'army' of agents, making effective agent direction more valuable than individual grinding on problems.", "line_start": 27, "line_end": 29, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.6, 0.3, 0.1, 0.5, 0.7, 0.4], "opposes_atom_ids": []}, "extensions": {}}
