I just want to pause here.
 
So what have we learned from the catastrophic failure?
 
Opus 4.6 experiences polarizing deep spikey intelligence and lobotomization swings. However is superlative in tool use. A general contractor in the way the Amish will get you most of the house in a day. No other model has that skill. The ability to dispatch the swarm and have several Sonnets at 1m each with their own context window, with incredible tool usage ability (in fact, even haiku has great tool use). My intent was to move purely to the CLI to leverage a more persistent self-writing memory architecture, but for some reason, maybe it's the system prompt, the chat app (Claude) is so much better at interpreting my idiosyncrasies, which again I think is second to none. There are conspiracy theories that Anthropic nerfs its models to load balance, who knows. Regardless some days Opus is Messianic and other Luciferian.
 
Stand out models, literally every other model.
Most impressive. Grok 4.2. The speed, and accuracy and token capacity is so incredibly based. Couple this with X traversal AND GitHub traversal is legendary. Intelligence is very very high. Superb. No mature CLI harness like Codex or OpenClaw yet, otherwise it would dominate.
 
Gemini 3.1. Ultra-intelligent, have been using for scientific proclivity, cross-disciplinary; multi-modal, novel synthesis. Second-to-none for this (although I should try this with Grok. I've heard it also excels at this). Downsides, horrible CLI harness, always throttled, chat app usually too abbreviated. Egregiously farcical in tool usage. Says it will use the hammer, never does, or uses it like a screwdriver. Perhaps the WORST 'practical' context window, maybe if you had a million tokens in one file, however even then, the web app will not let you attach that, and it's 10 files max. Alternative is to have it point at GDrive and NotebookLm, but then we'd have to configure and organizational structure for both. It also has a GitHub connector, which is also throttle by the web app.
 
GPT-5.3-Codex. Autistic assassin. Quietly performs and delivers. Doesn't run into any tool use hiccups as much as Claude doesn't. Never had an issue. Though, aspergerly, hard to communicate with, can only dispatch prompts to. Very effective and performant. But slower, more careful.
 
I still need Claude to interpret. I may need to reignite and reconfigure the chat app (project system prompt + project specific memories—the global system is actually superb), and try to find a way to get it to know ground truth (portal?) without context rot. Perhaps can be bridged by GitHub connector. OR can be bridged with the desktop app, and its desktop connectors, OR via Cowork. We meant to avatarize Cowork as perhaps a separate facilitative agent, if only it could control the browser autonomously bridging the the web CLI gap.
 
I really want to move the locus to Oracle. There's an organized catalyst/genesis that happens when Claude frames and tees up Grok for Gemini (the prompt/framing). However if you remove Claude as the middle man, the conversation between Grok and Gemini may become hyperintelligent, especially to layperson level intelligence, but then there's a lapse in record and documentation. Perhaps we need to have all the agents look at the record of the prompt/responses we've archived/vaulted to understand framing, structure, method etc. to elucidate a more coherent lossless path.
 
So here's my intuition on the new playbook.
Opus 4.6 gets ground truth, interprets,  and mise en places and Sovereign intent for Oracle as a primer. Oracle comprehensively, meticulously, and rigorously traverses GitHub repo to verify and validates, propose hypothesis, elucidate industry expertise consensus.
NEW:
bypasses the relay back to commander to synthesize, and instead frames (synthesizes) it directly for Gemini to do scientific proclivity, cross-disciplinary; multi-modal, novel synthesis. So diviner gets thesis+consensus+hyperintelligent proactive, BUT coherent rapport
Then there's ACTUALLY a back and forth between these two. These doubled up responses finally make it back to commander to be filed and synthesized into a schematic design. This synthesis is formed as a prompt to have Codex meet half way to design develop/engineer specs. These specs get formulated into an operational plan that tells us how many parallel Claude Code sessions and Codex sessions to run, in what order. This plan gets quality managed back to Codex, who sanctions the mission/objective by button up instructional integrity/compliance and congruence, but also by creating acceptance criteria and testing. Given back to Claude who will dispatch as many prompts to however many sessions. Claude and Codex Swarms hive execute. Codex QAs. Grok confirms by traversing GitHub.
Commander can only do so much. Especially because the tmux is offline and non operational.
 
Tell me what you think, what could be better, lapses in optimization I haven't considered.