https://www.youtube.com/watch?v=1u2DkoqEfhk
Francois Chollet + Mike Knoop | ARC Prize @ MIT
3,250 views  Oct 24, 2025
ARC Prize Co-Founders, Francois Chollet & Mike Knoop, share a fireside chat around ARC-AGI-3 and measuring intelligence

Francois Chollet: https://fchollet.com/
Mike Knoop: https://mikeknoop.com/

Learn more about ARC Prize - ARCPrize.org
Play the games - three.arcprize.org
Learn more about ARC-AGI-3: https://arcprize.org/arc-agi/3/

MIT Department of Brain and Cognitive Sciences: https://bcs.mit.edu/

---

0:08
I want to invite uh Francois Shallay and
0:09
Mike Canupe up to the stage right now
0:11
who are going to be doing a fireside
0:12
chat.
0:13
Thank you, Greg. Great kickoff and uh
0:16
thank you everyone for hosting us. So uh
0:18
yeah, Francois, exactly one year ago,
0:21
welcome back to MIT. Exactly one year
0:22
ago, we're here on the Ark Prize
0:24
University Tour.
0:25
Yeah. Yeah, it's been a while. We were
0:27
here promoting arc prize arcgi you know
0:31
one of our main goals was to sort of
0:33
inspire folks to work on new ideas
0:35
towards AGI and I think you know we have
0:38
our own and one of the big updates since
0:40
last year was as Josh alluded to we
0:43
created our own intelligent science lab
0:44
it's called India and uh we also are
0:47
using ARC as our one of our northstar
0:49
metrics I think to get there we're
0:51
trying to build the top program
0:53
synthesis talent team industry right now
0:55
I think we've got a claim that we've got
0:56
some of those sunks. Uh, by the way, we
0:58
are hiring. So, if you're in, if you're
0:59
a builder and you're interested in
1:00
program synthesis, you should come talk
1:01
to us. But we're starting to make real
1:02
progress over the last few months. I
1:04
think sort of some of the ideas we have,
1:05
you know, of merging deep learning and
1:06
program synthesis together towards ARK1
1:09
and AR2. And hopefully sometime soon
1:10
we'll start looking at V3. This question
1:12
that Greg asked, I think is a really
1:14
common one that we got with V1 and V2 a
1:16
lot. I'm curious to get your take here
1:18
with V3, which is that, okay, you guys
1:22
have now three versions of the
1:23
benchmark. They all have AGI in the
1:25
name. if we can make progress and we can
1:27
beat V1, V2 and V3 here, do we have AGI
1:30
or and if not if that's not a binary
1:33
what does it mean exactly? Can you help
1:35
us kind of like map out what what does
1:37
it mean to make progress against ARK 1 2
1:38
and 3?
1:39
Right. So first of all, you know, as
1:42
Greg stated, uh, with V3, just like with
1:44
V1 and V2, we're not making the claim
1:47
that this is an asset test for whether
1:49
we have a GI or not. Like solving V1,
1:52
solving V2, solving V3 does not
1:54
necessarily mean it's not sufficient
1:55
condition to say that we have a GI.
1:58
That's not the purpose of the benchmark.
2:00
Now, if you look at what it would take
2:02
uh to solve V3, like especially compared
2:04
to V1 and V2, we adding a few uh really
2:06
important abilities. uh we're adding the
2:08
ability to uh discover goals like
2:10
acquire your own goals from your own
2:13
experience do temporal planning and of
2:15
course you know interactive learning uh
2:18
with v1 v2 you are just doing passive uh
2:20
model feeding you are looking at the
2:22
data trying to come up with model to
2:24
explain it here you have to collect your
2:26
own data by interacting with environment
2:28
so what it would mean to create a system
2:31
that could do these things at human
2:34
level uh information efficiency human
2:36
level action efficiency where it means
2:38
you're really good at, you know, agentic
2:40
interactive learning in novel
2:42
environments. You're really efficient at
2:43
it. To me, that's basically a microagg.
2:47
These are the properties you would want
2:48
to see in an AGI system, but on a very
2:51
small scale. So, why very small scale?
2:53
Because these games are really simple.
2:55
They're really easy. Like any one of you
2:56
in this room could just go and play them
2:58
and you would do really well, right? It
3:01
doesn't take you know super intelligence
3:03
and they're also just in term of um
3:06
complexity size like bit count these are
3:08
tiny games right very small environment
3:10
very small per perceptual space and
3:13
you're playing them on very short time
3:14
scales like you're learning across a few
3:17
minutes but of course as a human level
3:20
uh general intelligence you're actually
3:22
learning throughout your entire life
3:24
with an enormous perceptual space and
3:26
you're learning tasks that are
3:28
incredibly complex. So there's a very
3:30
very long distance from these sort of
3:32
like micro environments to the real
3:35
world. But the properties we're trying
3:37
to measure are the same like can you
3:39
efficiently interact with the world
3:41
discover its underlying principles and
3:44
make sense of it and and and act on it
3:46
shape it. It's the same principles but
3:48
but on a tiny scale. So the idea that if
3:51
you manage to crack AR 3 the right way
3:54
you know with with an efficient system
3:56
without taking any shortcut without
3:57
brute force ideally your solution can be
4:01
just scaled up and you would get
4:03
something very similar to a but the
4:04
solution itself would not be instantly
4:07
uh at the very least it would not be
4:08
human level there's this uh big debate
4:11
going on right now on Twitter inspired
4:13
by Rich Sutton's interview with Daresh
4:15
that got published this week on whether
4:17
LM are sufficient
4:19
as a substrate to produce systems that
4:22
look like humans. I'm curious your take
4:26
as a substrate in order to do lifelong
4:29
continual learning like you just said in
4:31
order to beat V3.
4:32
I would say LM alone definitely not. An
4:35
LLM is basically a way to acquire and
4:39
encode uh programs. I mean, yeah, it's
4:43
basically a repository for a bunch of
4:45
reusable vector programs. And the way
4:47
you acquire them is via uh cryonian
4:50
descent on human data, right? And that's
4:54
not what AGI is. It could be a component
4:56
of FGI. I think it could be the the sort
4:58
of like memory component, the knowledge
5:00
and skill representation component, but
5:03
the the defining characteristic of
5:06
general intelligence is how efficiently
5:08
you acquire your skills and your
5:10
knowledge. basically how efficiently you
5:11
extract information from the world from
5:13
your experience and turn it into these
5:16
programs that should generalize as as
5:18
well as possible and that's not what LLM
5:21
do I mean in the in the LLM world the
5:23
algorithm that's playing this role it's
5:25
just cry and descent and cry descent is
5:26
you know four maybe five orders of
5:29
magnitude less efficient than human
5:31
intelligence at skill acquisition so
5:33
this is not what we're looking for so
5:34
Adams could be part of the solution but
5:36
they are definitely not on their own the
5:38
solution
5:39
there was Another um really common thing
5:41
when we launched arc prize last year
5:43
very common point of critique or
5:45
feedback was the reason we haven't
5:46
really made progress LMS haven't made
5:48
progress on on ARC is because it's a
5:50
visual benchmark you need some sort of
5:53
visual progress in order to make you
5:54
know progress here. I think there's
5:55
pretty strong evidence now that's not
5:57
the case given sort of the reasoning
5:58
models in in sort of December. Curious
6:00
how you look at V3 though. Do you think
6:02
that we need sort of more advancements
6:03
or breakthroughs towards the perception
6:05
side in order to beat V3 or is this
6:06
still fundamentally a program synthesis
6:08
benchmark in your eyes? Yeah, I think
6:09
it's fundamentally a reasoning
6:11
benchmark. It's not a visual perception
6:12
benchmark at all. In fact, it was
6:15
designed this way just like V1 and V2.
6:16
We were trying to remove the need for
6:19
perception because perception was sort
6:20
of like getting in the way of measuring
6:23
what we cared about, which was uh
6:25
efficient generalization, effectively
6:26
efficient skill acquisition in V1, V2,
6:29
and even V3. The data like the the game
6:32
state is already in a format that can be
6:34
processed by a computer. Like it's
6:36
already effectively in token form. You
6:38
can put it in an NLM, you can put it in
6:40
a in a program engine just like we do.
6:43
There's no need for a vision module. And
6:45
what we saw on on V1, V2, and I'm sure
6:48
we are going to uh keep seeing the same
6:50
pattern this as well is that vision
6:52
enabled models like VLMs did actually
6:54
significantly worse than pure sequence
6:56
like text models. And the reason why is
6:59
because you can treat like these 2D
7:01
grids as sequences and you're not really
7:03
losing any information. It's the same
7:04
information. Now, if you wanted to have
7:06
a native understanding of 2D space, you
7:09
can also rewire a transformer to give it
7:12
a native understanding of of grids
7:14
instead of sequences. Of course, if you
7:16
do that, you would have to pre-train it
7:17
on grid data, which is not widely
7:19
available. So, it will not work very
7:20
well. And in practice, all the
7:22
state-of-the-art models you're seeing on
7:23
ARC V1, V2, the pure sequence models
7:26
usually trained on on code and so on. So
7:29
yeah, it's definitely not a perception
7:30
problem at all and perception is not an
7:32
obstacle to make real progress on these
7:34
benchmarks
7:35
like uh related to that uh you know a
7:37
lot of the solutions dark 2024 really
7:39
relied on a lot of data augmentation
7:41
techniques. Do you think that that is
7:43
going to be an important thing in order
7:44
to solve V3 as well is to take these and
7:47
do lots of games that look like V3 in
7:49
order to beat it.
7:50
I don't think so. And um in practice, if
7:52
you look at humans, humans who have
7:54
played a lot of games, they might be
7:56
doing a little bit better than other
7:58
people on these games, but it's not a
8:00
lot. And even people who don't play
8:02
games at all can still beat these games,
8:04
right? They can they can still get gro
8:06
how they work. And so that tells you
8:08
that it's not it's not really a matter
8:09
of practicing. It's not a benchmark
8:11
that's measuring an acquired skill. It's
8:13
really measuring your ability to figure
8:16
out something new on your own
8:18
interactively on the fly. Since we've
8:20
been talking about the game design,
8:21
let's switch over because I think that's
8:22
this is one of my favorite parts of my
8:23
job right now is every Wednesday for a
8:25
few hours we get to like play games and
8:27
give feed. It's a little grueling
8:28
sometimes. You know, not all the games
8:30
are good yet, but yeah, literally, you
8:32
know, we're sort of paid to play games.
8:34
I think collectively we've probably
8:35
played over a hundred of them uh and
8:37
given feedback. Do you want to talk a
8:38
little bit about some of the common
8:39
feedback we're finding and sort of
8:40
playing these early preview games and
8:41
giving feedback to the game design team?
8:43
Yeah, we have the most productive uh
8:45
game design studio in the world. It's
8:48
already
8:49
over 100 games in less than a year. So,
8:52
it's actually very fun like making games
8:54
like small games at scale and play
8:57
testing them because you start uh really
8:59
thinking deep about things like what
9:02
makes a game fun for instance you try
9:04
you try to come up with a theory of fun
9:06
to reverse engineer what makes a good
9:08
game. So one thing we've observed is the
9:11
most fun you're having is when the game
9:13
the environment is trying to maximize
9:16
the rate at which you're learning. In
9:18
order to be fun the game should offer
9:20
some kind of challenge, right? It should
9:23
be something you have to figure out
9:24
something you cannot already do. If you
9:26
just recognize what you have to do and
9:28
you do it, then it's very boring. It's
9:30
very it's very repetitive. You're just
9:31
in execution mode. So it should have
9:33
some kind of challenge, some kind of a
9:34
novelty element. It should surprise you
9:36
in some way. But at the same time, it
9:38
should be tractable. It should not be
9:40
too challenging or too novel because
9:42
then you would just get stuck. You'd not
9:44
be able to make sense of it. So for the
9:46
game to be really fun, you need to keep
9:48
your learning rate in this sweet spot
9:50
where it's challenging but just to the
9:53
right amount. It's challenging enough
9:55
that you overcome the challenge and you
9:57
learn in the process and you grow in the
9:59
process. And establishing this sense of
10:01
of progression, of growth is also very
10:04
important. And it's not just in
10:06
polishing your skill at playing the
10:07
game. It's also that the game itself
10:09
should you know directly convey a sense
10:11
of progression like for instance a
10:13
forance progression. As you play the
10:15
game you should be getting more powerful
10:17
in some way. You should you know have
10:19
more things you can do more actions and
10:21
the way you would do it is you know you
10:22
introduce new game dynamics as the game
10:25
goes on and you don't master them and
10:27
then you use them and it opens up you
10:29
know new possibilities in the later
10:30
levels. So yeah, I think this is really
10:32
like the the essence of of fun. It's
10:34
it's to to maximize your learning rate
10:37
and create this sense of of growth and
10:39
progression. Another thing that's uh
10:41
that's interesting is how challenging it
10:44
is to make games like this that are
10:47
still easy to play for humans given that
10:49
we're in a setting where there are no
10:50
instructions whatsoever. You're not told
10:52
anything. In fact, there's also like no
10:54
text for instance, no text labels in the
10:57
games and so on. You cannot leverage any
10:59
acquired knowledge to play them. They're
11:02
completely new. You can only bring to
11:04
the games like core knowledge prior. And
11:07
it's very easy to end up with games that
11:09
are too difficult. Not too difficult
11:11
because the game mechanics are too
11:13
complex, but just because they're not
11:15
learnable enough. And we had to put a
11:17
lot of work into, you know, really
11:19
deliberately crafting the early levels
11:22
of a game to make it as learnable as
11:24
possible. like only introducing one
11:26
concept at a time. Uh making sure the
11:28
the controls are discoverable. One issue
11:30
we had uh early on is u players would
11:33
often you know fail to complete the game
11:36
not because they could not you know
11:37
understand because they could not
11:39
discover the controls right they would
11:40
try to the arrow keys for instance would
11:43
not do anything and because it was a
11:45
game where you were supposed to click on
11:47
things they would never try to click on
11:48
things. So we we had to iterate a lot on
11:51
on the control UI and we ended up with
11:53
something that's a lot more
11:54
discoverable.
11:55
We uh in a lot of my user testing I
11:58
think there's an interesting tension
11:58
here between easy for humans hard for AI
12:00
and this concept of fun. Some of the
12:02
most fun that I've heard from folks and
12:04
myself is playing games where it's not
12:06
immediately obvious until you explore a
12:08
little bit and then there's an aha
12:09
moment and that aha moment actually
12:10
significantly increases your fun. Um so
12:12
this suits the swap between not being
12:14
too obvious on the level one but still
12:15
within sort of easy discovery. uh I
12:18
think in the first couple levels maybe
12:20
why do we care about arc being fun you
12:22
know this this was this was a very
12:23
unique design goal I think you had in
12:25
mind for v1 and v2 as well you know most
12:27
benchmarks don't especially a benchmarks
12:29
don't optimize for fun why is this an
12:31
important thing that arc has this like
12:32
in the acceptance criteria
12:34
I think in a on a very basic way the
12:37
benchmark will be more successful if
12:38
it's fun if it's catchy if people
12:40
actually enjoy interacting with it enjoy
12:42
playing the games it will catch on more
12:44
people will be be attracted to it more
12:46
people will want to work on it.
12:48
The human story like inspiring.
12:50
Exactly. It it needs to be it needs to
12:52
be catchy as a cultural artifact, not
12:54
just as a as a scientific artifact. And
12:57
also I think that in order to make
12:59
progress towards the GI we need to do a
13:01
lot of thinking about how humans play
13:04
these games and uh in order to get this
13:06
data like the human testing data for
13:08
instance or just your own human
13:10
introspection perception like as you
13:12
play the games you ask how you're
13:14
figuring things out. What's your
13:15
strategy? to try to leverage meta
13:17
cognition to produce uh um AGI insights.
13:21
In order to to do that, the games need
13:23
to be fun. They should not be boring. If
13:25
they're boring, you're not going to want
13:26
to play them. And human testers, they're
13:28
they're not going to give it their best.
13:29
All right. So, last question. Looking
13:31
towards the future. So, even beyond V3,
13:33
we've already started having
13:34
conversations about V4, V5, whatever,
13:37
even at lunch today. Uh what what are
13:38
your maybe like hopes and dreams for
13:41
what's not captured on this slide? What
13:42
are the other interesting things that
13:44
you can envision that we might want to
13:45
test for capabilities wise in future AI
13:48
systems?
13:49
Right. So, I think V3 has uh basically
13:51
the right ingredients like on the-fly
13:54
learning uh interactive learning, goal
13:57
acquisition, but at a very small scale.
13:59
So for instance, this sort of
14:01
interactive learning is not really what
14:02
you would call continual learning
14:04
because even though there is a
14:05
curriculum in each game, it's at the
14:07
scale of 5 minutes of play. And as
14:10
humans, you know, we we're doing
14:11
continual learning over decades. And so
14:13
I think an obvious thing would just be
14:15
to take the same ingredients and scale
14:17
them up. Have much more complex
14:19
environments instead of just having, you
14:21
know, 150 uh study games have endless
14:24
novelty like have the have the game
14:26
environment actually be more like a a
14:28
living thing, an intelligent thing with
14:30
maybe other agents that you compete
14:32
with, that you collaborate with. And we
14:36
should try to measure the development of
14:38
an agent not over 5 minutes but over
14:41
years of game time. hopefully not real
14:44
time, right? And uh I think in order to
14:46
build an environment that would be this
14:48
ambitious, you kind of need to already
14:51
be making progress towards the GI
14:53
because such an environment you it will
14:55
be an environment that actually adapts
14:56
to the player as the player adapts to
14:59
the environment as the as the player
15:00
learns to play the game and and you know
15:02
interact with with the agents that
15:04
inhabit the game and so on. And so that
15:06
is an intelligent artifact that is
15:08
already a proto AGI. And I'm a big
15:10
believer in co-evolving the solution
15:13
like AGI itself and the benchmark that
15:16
you're using as your target. And I think
15:19
progress towards AGI will help us create
15:21
this next generation benchmark that will
15:23
in turn help us make faster progress
15:25
towards uh higher levels of AGI.
15:28
Great. All right. Well, while we're
15:30
getting set up for the first speaker, uh
15:31
let's do two questions. Maybe we'll do
15:32
one from this side of the room and one
15:34
from this side of the room. Is there a
15:35
microphone to you want to pass down?
15:38
I I haven't looked at all the games
15:40
available, but they're all in a way 2D
15:42
and the status can be frozen between
15:45
turns essentially. Does the intelligence
15:48
or the learning acquisition u skills?
15:52
Would you expect them to translate to a
15:54
3D environment or in a game where you
15:58
don't have this sequence of turns, but
16:00
it's rather a little more fluid or maybe
16:02
there's a physics engine that is a
16:04
little more continuous in time. Right?
16:06
So the the fact that uh the the game
16:09
frame is a grid of pixel is not really
16:12
important. You could treat it as a
16:13
sequence. Uh it could be 3D, it could be
16:15
4D, it fundamentally doesn't matter.
16:17
It's just a set of discrete symbols with
16:20
discrete properties. they just happen to
16:22
be organized as as a 2D grid. It's
16:24
fundamentally not important. So what
16:26
what you bring up though about the fact
16:28
that this is effectively stepbystate
16:31
environment where you have to take an
16:33
action to get in the next state that's
16:35
definitely super different from like
16:36
real time cons environment. I do think
16:40
yeah if uh if you make a really good uh
16:42
V3 uh solver you could put it on robot
16:45
in principle it's not the only thing you
16:48
would need right you would also need a
16:50
perception system to you know this
16:53
continuous live data into high level
16:56
discrete concepts that the the arc
16:58
solver could process you would also need
17:01
uh probably you know a longer term sort
17:03
of like planning engine to make use of
17:05
the model produced by the arc solver but
17:07
fundamentally I think yeah you would be
17:08
making prog as well as you know real
17:09
world applications.
17:10
This was a really intentional design
17:12
choice right for V3 as well not to
17:13
stress test perception but to challenge
17:15
the reasoning aspect of it. We
17:16
deliberately did not want uh games where
17:20
time gaps were an element of game play
17:22
because we are not trying to for
17:24
instance be there are many games that
17:27
are challenging for humans not through
17:30
understanding what's going on in the
17:31
game but just through execution
17:33
difficulty like timing difficulty for
17:35
instance and we deliberately did not
17:37
want to get into that because this
17:38
actually not intelligence.
17:40
Cool. One more question over here.
17:42
This is great. I'm really glad you guys
17:43
are doing this. I have a really broad
17:44
conceptual question.
17:46
What is the distribution of skills over
17:48
which you expect an intelligent agent to
17:50
generalize?
17:51
Distribution of skills as in the kind of
17:53
abilities.
17:54
Yeah. So acquisition efficiency.
17:56
Yeah. So you said skill acquis
17:57
acquisition efficiency. That's your
17:58
definition of intelligence. And so you
18:00
built some set of games, right? And then
18:02
you have test games and you want the
18:04
intelligent agent to an intelligent
18:06
agent to generalize to those test games,
18:08
right? So what is the distribution that
18:12
is implied by that test set that you
18:13
want to generalize over? implicitly uh
18:16
there is no distribution like for arc v1
18:18
and arc v2 what makes a valid arc task
18:22
is that humans can solve it that's the
18:25
only constraint that we have and and it
18:27
should not it should not leverage any
18:29
acquired knowledge only only core
18:30
knowledge so anything you can build with
18:33
only core knowledge that the human can
18:35
do is in distribution and there's no
18:38
other more narrow definition of our
18:41
distribution
18:41
so so the definition of the distribution
18:43
is the set of things or the distribution
18:44
of task task that humans can solve
18:46
efficiently. Is that correct?
18:47
Yeah. Which is basically infinite.
18:49
Okay. But it's not a uniform
18:50
distribution over all possible tasks. I
18:52
I guess what I'm driving at is what do
18:54
you mean exactly by general
18:56
intelligence? Right? Because it sounds
18:57
like what you're defining is actually
18:58
human intelligence, not general.
18:59
Yeah, that's right. Because this is, you
19:01
know, human intelligence is the only
19:03
proof of existence we have of of a GI.
19:06
But what is general about human
19:07
intelligence? Human intelligence is not
19:09
general. I mean, you could actually
19:10
argue on the basis of no free lunch that
19:12
there's no such thing as general.
19:13
general in the sense that when we are
19:15
showing human testers any of these games
19:17
they're looking at the game for the very
19:18
first time and they can't figure it out
19:21
and the space of games you could give
19:23
them that they could figure out is
19:24
infinite and extremely diverse. So it's
19:26
general in that sense it may not be
19:28
universal. I'm sure there are many tasks
19:30
that you could show human they could not
19:32
figure it out but still the space of
19:34
task that they can figure out is vastly
19:37
larger than what Frontier can
19:39
actually exist for that too with V2. We
19:41
made tasks in V2 that were too hard for
19:42
humans,
19:42
right? So, so it's it's it's big, but
19:44
it's not general in the sense that it
19:46
can do anything.
19:47
So, we're not targeting universal
19:49
intelligence, which would be any task
19:51
whatsoever. Yeah, we are talking human
19:54
uh general intelligence. That's right.
19:55
All right, let's wrap up there. Thank
19:56
you, Franis. Thank you. Let's hear it
19:58
for Mike and Francois.