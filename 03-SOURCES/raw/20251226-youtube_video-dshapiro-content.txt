http://youtube.com/watch?v=jKM_5A8-oKg
The next step towards AGI
19,570 views  Dec 26, 2025
Check out my Patreon community for exclusive Discord server! Links on main channel page.

---

0:00
Good morning everybody. I hope you had a
0:03
decent enough Christmas. So today I want
0:05
to talk about uh this kind of we'll call
0:09
it a scaling paradox. But you know
0:11
people have been saying you know scaling
0:13
is giving out and LLMs are hitting a
0:14
wall for a while now. But despite that
0:17
the objective measurements continue to
0:19
improve. So when we look at actual
0:21
capability it continues to scale
0:23
disproportionate to the rest of the
0:25
scaling law returns. Now, this is not
0:28
just data and compute and test time
0:30
compute. It really just it doesn't make
0:33
any sense that we're not really able to
0:35
predict how much additional capability
0:38
gets added despite the diminishing
0:40
returns of traditional scaling laws. So,
0:43
let's unpack this and figure out kind of
0:46
what's going on. Now, at the beginning,
0:49
the narrative was simply scale is all
0:51
you need. You look at GPT2 to 3 to 4.
0:55
each time it gets about 10 times or
0:57
sorry 100 times bigger um or I guess
1:00
this is a 10x increase this was about a
1:02
100x increase. So the the whole idea was
1:05
that proportional improvements in
1:07
capability from scaling inputs on a
1:09
fixed transformer architecture. So the
1:11
curve was relatively consistent more
1:13
data more compute better performance. Um
1:17
and so this has been kind of the the
1:19
name of the game for a while. uh
1:21
parameter count and compute budgets
1:22
became the primary metrics of progress.
1:25
That is kind of what we know and
1:26
understand.
1:28
Now, however, when we look at kind of
1:32
the the the two things that people are
1:34
saying and there's there's the objective
1:37
uh both are objectively true, but
1:38
they're mutually incompatible. So, we
1:40
need to figure out like how and why. So,
1:42
scaling is hitting a wall. Prominent
1:44
voices argue the original paradigm is
1:45
yielding diminishing returns. Gary
1:47
Marcus in 2022 said deep learning is
1:50
hitting a wall. Obviously, that didn't
1:52
age very well. Um, and then I set even
1:55
said highlighted the need to overcome
1:56
peak data emphasizing we have but one
1:58
internet. The technical claim returns
2:00
from simply adding parameters and data
2:02
to vanilla transformers are diminishing.
2:04
That is objectively true. Now, however,
2:08
capability is still accelerating despite
2:11
the diminishing returns over here. So
2:13
objective real world benchmarks show
2:14
that whatever what AI systems can do is
2:17
improving faster than ever. Machine
2:18
autonomy is improving at a logarithmic
2:20
exponential rate according to MER. New
2:23
reasoning benchmarks are being saturated
2:25
in months rather than years namely arc
2:28
AGI just as one uh exemplar of that
2:31
trend. So then the question is how are
2:33
both of these true and what does it mean
2:35
for the future of artificial
2:36
intelligence.
2:38
So first uh here is kind of the curve of
2:41
meter. Uh so long-term trend the length
2:43
of tasks achieves uh achieves achieved
2:46
by generalist agents uh can complete has
2:48
been doubling approximately every seven
2:50
months for the past 6 years. However,
2:52
recently it accelerated to just every
2:54
four months. This came 3 years after
2:58
Gary Marcus said you know it's it's
3:00
hitting a wall. So where was the wall?
3:02
Where was the wall on machine autonomy?
3:05
Right? Where was the wall when when you
3:07
know Gondor called for aid? Sorry, wrong
3:09
fandom. Anyways, you get the idea. This
3:12
I've talked about this and people have
3:14
talked about the meter and so you're
3:15
like, well, this is something else
3:16
entirely, you know, but it's like is it
3:19
really something different when we're
3:20
looking at the actual capabilities of a
3:22
model, which when you look at the
3:25
behavior of it, the actual capability of
3:26
the model, that's more important than
3:28
whatever scale alone gives you, which is
3:31
utility. So the utility is accelerating
3:34
faster than you know whatever underlying
3:38
uh predictions happen from just scale
3:40
alone. So utility is accelerating
3:42
regardless of what scale is doing. Now
3:45
another example is benchmarks. So
3:46
reasoning benchmarks are saturating at a
3:48
stunning pace. The story of ARGI prize
3:51
illustrates the disconnect between
3:52
scaling debates and real world problem
3:54
solving progress. Now, ARC AGI is not a
3:56
real world problem, but the fact of the
3:58
matter is it took 4 years to go from 0%
4:01
to 5%. And then it took months to go
4:04
from 5% to near saturation. So, they had
4:06
to release ARC AGI 1, then ARC AGI 2,
4:10
and now they're already working on ARC
4:11
AGI 3. This was supposed to be a grand
4:15
challenge. This was supposed to be a
4:17
challenge that was going to take years
4:19
or decades to saturate, but now they're
4:21
already working on the third version,
4:22
saying, "Oh, it's going to get harder
4:23
and harder." Um, and ARGA3 apparently is
4:26
going to be interactive, meaning it's
4:27
not just a static puzzle to solve. It's
4:30
going to be something that reacts as you
4:32
interact with it. I don't know the full
4:33
details yet, but that's that's what the
4:35
rumors show. So, they keep having to
4:37
move the goalposts on the benchmarks.
4:38
And of course, this is just one
4:40
benchmark. This is just one example.
4:42
We've seen plenty of benchmarks where
4:43
they're like, "Oh, well, we saturated
4:45
that benchmark. We're going to need
4:46
another one." Um, and as those
4:48
benchmarks continue to saturate, the
4:50
models continue to get more and more
4:52
useful and better at coding and better
4:53
at agentic control and that sort of
4:55
thing. So, where's the wall? There's no
4:58
actual wall in terms of actual
5:00
performance or actual utility. That's
5:03
the real big question. So, the paradox
5:05
resolves when we stop conflating one
5:07
scaling vector with the entire
5:09
capability frontier. People are really
5:12
committing a category error here. The
5:14
flattening of one curve such as vanilla
5:16
pre-training is being mistaken for a
5:18
slowdown in overall AI progress. The
5:20
capability frontier is being pushed
5:22
forward by multiple simultaneous
5:23
research programs. So test time compute
5:26
scaling which is chain of thought,
5:28
search tool use, architectural
5:30
innovation such as mixture of expert
5:32
experts and SSM. I'm not really sure
5:34
what the SSMs are. Um it just got
5:36
stuffed into the into all of my
5:37
research. uh agent scaffolding and tool
5:40
use, post-training improvements, better
5:43
training recipes such as uh RLHF, DPO,
5:47
synthetic data, selfplay, all of those
5:49
things. So when they say scaling is dead
5:51
and scaling is all you need, crowds are
5:53
both missing the point. Progress is an
5:55
empirical question and the empirical
5:57
trend is a function of all of these
5:58
vectors combined. It's not just one
6:01
thing. Cuz I mean, remember when when
6:03
they released GPT4 and everyone's like,
6:06
"Wow, what's the secret sauce?" And Sam
6:07
Alman literally said it's not one thing,
6:09
it's like hundreds of little
6:10
improvements. So it's it's not just that
6:12
you have to throw more data at it and
6:14
more compute at it. That was, you know,
6:16
kind of the top line, but there's
6:18
hundreds, literally hundreds, if not
6:20
thousands of other improvements that you
6:22
can use to increase the utility and
6:25
capability of models beyond just a
6:27
single scaling vector. So even with all
6:31
of this, however, this is kind of what
6:33
what the purpose of the video is.