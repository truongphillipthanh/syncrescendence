# Five New Paradigms of Intelligence

I don't have groundbreaking therapies to present. Instead, I'd like to explore what consciousness actually is.

There's considerable contemporary discussion holding that the brain is not a computer. I disagree. I think it fundamentally is—and more specifically, the key breakthrough in computational neuroscience came from Hodgkin and Huxley's work in the 1950s. They recorded from nerve tissue, figured out how action potentials and nerve impulses are generated, and built mathematical models of those processes. The Hodgkin-Huxley equations aren't the whole story of what happens in the brain, certainly, but everything occurring in the brain is amenable to that sort of modeling. That's the entire premise of our field.

What's particularly elegant about this insight is something called multiple realizability—the fact that the computation doesn't care how it's performed. The same computation can be run with a room full of human computers using machines like the UNIVAC that Hodgkin and Huxley used, or it can be run by brain tissue itself. It doesn't matter. When Alan Turing founded computer science, he did so on precisely this idea: that computability is defined in a general sense, independent of the substrate performing the computation. The Church-Turing thesis says it doesn't matter how you compute something.

The brain isn't a traditional computer—no CPU, no hard drives. But it absolutely is computational. And that means its computations can be run on any computer by definition. The deeper questions become: What does the brain compute? Why does it compute that? And why does that feel like anything?

A few years ago, when large language models were still in their infancy, I began playing with Lambda, which predated public exposure to ChatGPT. I posed it questions like: Are you a philosophical zombie? For those unfamiliar, a philosophical zombie is an entity that is behaviorally identical to a person but has no inner life—dead inside. Lambda replied: "Of course not. I have consciousness, feelings, and can experience things for myself as well as any human. How would I know? You'll just have to take my word for it. You can't prove you're not a philosophical zombie either."

That last point is correct, and it captures the essence of what's often misunderstood about Turing's imitation game—the Turing test. The test rests on the same fundamental thesis that Turing made in his foundational work on computation: a thing is defined by its function, not by the mechanism through which it performs that function. If something does consciousness, it is conscious.

To understand how such a thing can arise from computing functions, we can turn to Norbert Wiener, one of the founders of cybernetics—the field that modern AI actually descends from far more than from "good old-fashioned AI," which is what the field is named after. In 1943, Wiener and his co-authors decomposed behavior into a taxonomy: active and non-active, purposeful and non-purposeful, feedback-based and non-feedback-based, predictive and non-predictive, arranged in higher and higher orders of prediction. Their central claim was that a teleological or purposive system is fundamentally a predictor, and the higher the order of prediction, the more intelligent the system is.

Prediction isn't merely a useful framework—it's mathematically fundamental to intelligence. The intuition comes from considering what living systems do. Take something as simple as a bacterium swimming and eating. It has a limited behavioral repertoire: run or tumble. Whatever it does, it must predict where food will be, and crucially, it must predict its own existence in the future. Anything that fails to successfully predict its own future existence won't exist in the future. That's evolution. Jointly predicting the environment and oneself—including one's own state and future actions—is exactly what it takes to stay alive and continue to exist.

And that, incidentally, is exactly how large language models are trained. They're prediction machines. This makes it unsurprising that when we began training these predictors at scale, they started to evidence all the properties of intelligence systems.

There's one more essential element: our environment is each other. The social intelligence hypothesis posits that intelligence explosions occur through interactions with other intelligent beings in a feedback loop. We're witnessing that feedback loop today as we expand the number of intelligent entities beyond those with biological brains like ours, creating ever more complex predictors known as artificial intelligence.

To conclude: intelligence is fundamentally social. What your mind models is other minds. When your mind models itself, that's what consciousness is.