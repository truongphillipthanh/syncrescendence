Understanding human-AI collaboration requires experiencing it in safe, explorable spaces where different configurations can be tested without permanent consequences. The Symbiosis Simulator creates these spaces through a remarkably simple principle: model the field of interaction, not the entities themselves.

**Agents and Fields**

The simulator consists of only two elements: agents (human-AI pairs with specific characteristics) and fields (the spaces where they interact). Rather than trying to model the enormous complexity of human cognition or AI architecture, it focuses on what happens in the space between them. Like physicists who study electromagnetic fields rather than individual electrons, we study the patterns that emerge from interaction rather than the impossibly complex entities doing the interacting.

Each agent is defined by its position in six dimensions: how it distributes agency (who decides?), coupling intimacy (how close is the connection?), cognitive architecture (what kind of thinking?), temporal binding (what rhythm of interaction?), embodiment (how physically integrated?), and information flow (how does data move?). Any collaboration pattern can be mapped to a point in this six-dimensional space.

**Interaction Dynamics**

When agents meet in the field, they don't simply exchange information—they create interference patterns, standing waves, resonances and dissonances. The field itself has properties: viscosity (how hard is it to change?), conductivity (how easily does information flow?), memory (does the field remember previous interactions?), and turbulence (how chaotic or ordered?).

These dynamics generate the phenomena we care about: Does the collaboration enhance both parties or diminish one? Does it preserve sovereignty or create dependency? Does it generate genuine novelty or mere recombination? The answers emerge from how agents and field interact rather than from predetermined rules.

**Testing Without Risk**

The simulator's power lies in exploration without consequence. You can test extreme configurations: What happens with total AI control? With complete human override authority? With perfectly balanced partnership? You can stress-test configurations: How does this collaboration pattern handle sudden AI failure? Value misalignment? Cognitive overwhelm? You can explore evolution: How do patterns change over extended interaction? What stable configurations emerge? What leads to collapse?

Each simulation generates phenomenological data—not numbers but experiences. Users report that certain configurations "feel" sustainable while others create immediate discomfort. Some patterns generate creative explosion followed by burnout; others maintain steady but uninspiring productivity. The simulator helps develop intuition for collaboration dynamics before committing to them in reality.

**Emergence Observatory**

Perhaps most importantly, the simulator reveals emergent properties—phenomena that arise from interaction but couldn't be predicted from components. Sometimes a configuration that seems limiting on paper generates unexpected creativity. Sometimes apparently beneficial augmentations create subtle sovereignty erosion only visible over time. The simulator becomes an observatory for watching consciousness patterns emerge, stabilize, and evolve.