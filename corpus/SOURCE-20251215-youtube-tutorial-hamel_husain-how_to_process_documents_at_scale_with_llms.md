# How to Process Documents at Scale with LLMs

**Channel**: Hamel Husain
**Published**: 2025-12-15
**Duration**: 1h 14m 17s
**URL**: https://www.youtube.com/watch?v=t6r4U0SlnPc

## Description (no transcript available)

Join the AI Evals Course starting March 16, 2026: https://maven.com/parlance-labs/evals?promoCode=tf-yt-c4

Watch Shreya Shankar and I break down five years of groundbreaking work that's changing how we process documents with AI. This isn't your typical academic research,  Shreya builds working software that solves real problems for public defenders, legal teams, and companies processing millions of documents.

I've always been impressed by how Shreya's work bridges the gap between research and production. Her papers look like startup pitch decks because they include working software, user studies, and solutions to actual pain points. In this session, she reveals the DocETL framework that's now shipping in Databricks, BigQuery, and Snowflake.

You'll learn why traditional databases fail on unstructured data, how semantic operators actually work at scale, and the optimization techniques that cut LLM costs by 4x while improving quality.

Timestamps:
00:00 Why You Should Pay Attention to Shreya
01:39 Data Systems: A Computing Success Story
02:24 The Unstructured Data Problem
04:00 What Are Semantic Operators?
09:11 DocETL Framework Explained
12:06 Real-World Use Cases
19:14 Making It Scale: Optimization
26:48 Task Decomposition Deep Dive
31:33 The Graph Database Question
38:06 Multi-Hop Reasoning Solutions
46:24 Cost vs Quality Tradeoffs
55:14 Why LLM Judges Fall Short
1:07:40 When NOT to Use Graph Databases
1:10:19 Handling Multi-Hop Queries
1:12:58 Future: Multimodal Data

What You'll Learn:
- Why data systems need semantic operators for unstructured data
- The DocETL framework: Map, Reduce, Filter operations in natural language
- How to process documents at scale without burning your budget on LLM calls
- When graph databases actually make sense (spoiler: rarely)
- Multi-hop reasoning across document chunks without RAG chaos
- Optimization techniques that reduce costs 4x while improving accuracy
- Real applications: analyzing court transcripts for bias, processing legal contracts
- Why LLM judges aren't the answer and what works instead

Key Technical Insights:
- DocWrangler: interactive interface for AI-powered data wrangling
- Task decomposition and agent synthesis for complex pipelines
- Confidence-based task cascading using log probabilities
- The truth about graph databases (most teams are using them wrong)
- How semantic operators are shipping across major databases

Resources Mentioned:
- Annotated Notes & Slides from this video: https://hamel.dev/notes/llm/data-processing/shreya-data-processing.html
- DocETL Framework - https://github.com/ucbepic/docetl
- AI Evals Course - https://parlance-labs.com/education/
- Shreya's Research Portfolio - https://www.shreya-shankar.com/
- Palimpsest & Lotus - Stanford/MIT semantic operator systems

Follow Shreya:
Website ► https://www.shreya-shankar.com/
Twitter ► https://twitter.com/sh_reya
LinkedIn ► https://www.linkedin.com/in/shreyashankar/

Follow Me:
YouTube ► https://www.youtube.com/@hamelhusain7140
LinkedIn ► https://www.linkedin.com/in/hamelhusain/
X ► https://twitter.com/HamelHusain
