---
id: SOURCE-20260209-104
platform: youtube
format: lecture
cadence: evergreen
value_modality: audio_primary
signal_tier: tactical
status: raw
chain: null
topics:
  - "real"
  - "time"
  - "speech"
  - "edge"
  - "llamafarm"
creator: "LlamaFarm"
guest: null
title: "Real-Time Speech-to-Speech AI at the Edge with LlamaFarm"
url: "https://www.youtube.com/watch?v=OQ2K54cju_A"
date_published: 2026-02-09
date_processed: 2026-02-22
date_integrated: null
processing_function: transcribe_youtube
integrated_into: []
duration: "10m 24s"
has_transcript: no
synopsis: "Real-Time Speech-to-Speech AI at the Edge with LlamaFarm by LlamaFarm. A lecture covering real, time, speech."
key_insights: []
visual_notes: null
teleology: implement
notebooklm_category: ai-engineering
aliases:
  - "Real-Time Speech-to-Speech AI at"
  - "Real-Time Speech-to-Speech AI at the Edge"
---

# Real-Time Speech-to-Speech AI at the Edge with LlamaFarm

**Channel**: LlamaFarm
**Published**: 2026-02-09
**Duration**: 10m 24s
**URL**: https://www.youtube.com/watch?v=OQ2K54cju_A

## Description (no transcript available)

Running a full speech-to-speech pipeline (ASR, LLM, and TTS) entirely on local hardware, no cloud APIs required.

In this talk, I walk through building a real-time voice-to-voice AI system using LlamaFarm, an open-source tool for deploying local LLMs with simple YAML configuration. We cover the full pipeline: automatic speech recognition, LLM processing via llama.cpp or transformers, and text-to-speech output â€” all running at the edge.

LlamaFarm is open source â€” check it out and contribute:
ðŸ”— https://github.com/llama-farm/llamafarm

Sales Agent demo repo: https://github.com/llama-farm/sales-agent
