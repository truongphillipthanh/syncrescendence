---
id: [[CANON-30400]]
name: Agentic Architecture
tier: lattice
chain: intelligence
celestial_type: comet
volatility_band: moderate
sn_version: 2.0
parent: CANON-30000
requires: ['CANON-30000', 'CANON-30460']
entities: ['Agenticness Spectrum (CON)', 'Three-Layer Architecture (STR)', 'CoALA Framework (STR)', 'Human Agency Scale (MET)', 'Five Core Orchestration Patterns (STR)', 'Memory Taxonomy (STR)', 'Defense-in-Depth (PROTO)', 'CLASSic Evaluation Framework (MET)', 'Gen AI Paradox (CON)']
original_words: 2822
compressed_words: 712
compression_ratio: 3.96
dropped: ['rhetorical elaboration', 'extended examples restating points', 'historical context without operational impact', 'stylistic prose and epigraphs', 'detailed table formatting where substance captured', 'narrative transitions']
---

# Κ-30400: Agentic Architecture (SN)

PASS Canon30400AgenticArchitecture:
    sutra: "Agents are architectural patterns; October 2025 marked transition from experimental to production systems at scale."
    gloss:
        Agentic AI @term: orchestrated multi-agent systems with measured autonomy, dynamic decomposition, persistent shared memory, and dedicated orchestration. Foundation models (GPT-4, Claude) are reactive cognitive engines; AI agents add task-specific bounded autonomy; agentic AI adds multi-agent collaboration.
        
        Position in Intelligence Chain: CANON-30000 (substrate), CANON-30100 (ASA), CANON-30200 (positioning), CANON-30300 (tech stack), CANON-30400 (this document—architecture).
        
        Status: Infrastructure production-ready; challenges persist (51-72% unsafe behavior, 90% 30-day failure without proper orchestration, evaluation benchmarks ≠ production performance, organizational readiness constraint).
end

PASS IntelligenceChainComet:
    sutra: "Comet designation reflects quarterly refresh cadence and moderate volatility in agentic systems evolution."
    gloss:
        Tier: lattice. Chain: intelligence. Volatility band: moderate. Status: partial operational. Celestial type: comet indicating active but volatile domain. Three evolutionary stages: generative AI (foundation models, reactive, stateless), AI agent (single entity with tool use and rudimentary memory), agentic AI (orchestrated multi-agent with shared memory). Refresh cadence: quarterly reflecting rapid iteration.
end

PASS Purpose:
    sutra: "Provide definitive Syncrescendence guide to agentic AI architecture enabling autonomous cognitive operation at Fortune 500 scale."
    gloss:
        October 2025 transition marked production-grade agent systems handling mission-critical workflows. Document establishes definitional landscape, architectural foundations, cognitive architectures, multi-agent orchestration, memory systems, safety frameworks, production deployment patterns, framework landscape, and definitive synthesis. Nine parts plus satellites, practitioner validations, timeline calibration, and version history.
end

TERM PartIDefinitionalLandscape:
    sutra: "Three evolutionary stages and agenticness spectrum define modern agent taxonomy across modality, autonomy, complexity, environment."
    gloss:
        @agenticness_spectrum @term: four-dimensional measure across modality (text to physical actuation), autonomy (human-in-loop to fully autonomous), complexity (single-step to recursive decomposition), environment (sandboxed to full production).
        
        Defining characteristics: autonomy (pursue goals independently), tool use (execute through APIs/code/databases), memory (persistent context and learning), planning (multi-step decomposition), adaptation (improve from feedback).
        
        @human_agency_scale @term: five levels of human involvement. Dominant finding (45.2%): equal partnership preferred—agents augment rather than replace. This challenges automation-first narratives in favor of human-agent collaboration.
end

PASS 11ThreeEvolutionaryStages:
    sutra: "Three stages distinguish generative AI (reactive foundation models) from AI agents (bounded autonomy) from agentic AI (orchestrated multi-agent)."
    gloss:
        Generative AI: input-driven stateless foundation models (GPT-4, Claude). Cognitive engine without autonomy.
        
        AI Agent: modular single-entity LLM system with measured autonomy, task-specificity, tool use, rudimentary memory.
        
        Agentic AI: orchestrated multi-agent system with multi-agent collaboration, dynamic decomposition, persistent shared memory, dedicated orchestration layer. This represents operational emergence.
end

PASS 12TheAgenticnessSpectrum:
    sutra: "Four-dimensional spectrum measures agents across modality, autonomy, complexity, and environmental constraint."
    gloss:
        @agenticness_spectrum @term organizes measurement across:
        
        Modality: text-only to multimodal perception to physical actuation.
        Autonomy: human-in-loop confirmation to bounded independent operation to fully autonomous execution.
        Complexity: single-step procedures to multi-phase campaigns to recursive decomposition.
        Environment: sandboxed simulation to constrained production access to full production modification.
        
        No single number captures agenticness; multidimensional assessment required. Spectrum enables precise capability articulation.
end

PASS 13DefiningCharacteristics:
    sutra: "Modern agents exhibit autonomy, tool use, memory, planning, and adaptation across operational contexts."
    gloss:
        @autonomy @term: pursue goals independently; take initiative toward objectives without continuous human prompting.
        
        @tool_use @term: execute actions through APIs, code execution, databases, file systems—grounding in external systems.
        
        @memory @term: maintain persistent context across sessions; remember past events; learn from feedback; enables coherence.
        
        @planning @term: decompose goals into actionable steps; multi-step reasoning; explicit strategy formation.
        
        @adaptation @term: learn from experience; improve strategies; adjust heuristics based on feedback and results.
        
        These five characteristics distinguish agents from stateless language models.
end

PASS 14HumanAgencyScale:
    sutra: "Five-level human involvement scale shows 45.2% workforce preference for equal partnership over automation."
    gloss:
        @human_agency_scale @term: Level 1 (full automation) to Level 5 (human essential every step). Research validation across workforce preferences revealed Level 3 (equal partnership) as dominant at 45.2% prevalence.
        
        Key finding: Collaborative augmentation preferred over replacement. Agents positioned as augmentation improve adoption, retention, and outcomes. Pure automation creates resistance and value misalignment.
        
        Strategic implication: Market success requires human-in-loop architectures, not displacement.
end

PASS PartIiArchitecturalFoundations:
    sutra: "Three-layer architecture (orchestration, execution, infrastructure) with design principles (event-driven, federated, capability-based, streaming)."
    gloss:
        @three_layer_architecture @term:
        
        Layer 1—Orchestration: command center for monitoring and steering; agent registry managing capabilities and team formation; learning pipeline ingesting feedback; strategic coordination and human oversight.
        
        Layer 2—Execution: network of specialized agents executing tasks; dynamic topology (hierarchies, peer-to-peer); standardized communication protocols; persistent local state.
        
        Layer 3—Infrastructure: state stores (centralized or federated); message queues; external service integrations (MCP-compliant); observability, logging, security.
        
        This layering enables independent scaling and governance.
end

NORM 22DesignPrinciples:
    sutra: "Five design principles (event-driven autonomy, federated state, capability-based access, streaming processing, documentation as code) govern architecture."
    gloss:
        @event_driven_autonomy @term REQUIRED: subscribe to event streams; act when conditions met; proactive rather than reactive request-response.
        
        @federated_state @term REQUIRED: distributed knowledge; eventual consistency; async propagation; responsive and scalable.
        
        @capability_based_access @term REQUIRED: fine-grained permission tokens; scoped and time-limited; dynamic delegation.
        
        @streaming_processing @term REQUIRED: real-time data flow; minimal latency; continuous adaptation.
        
        @documentation_as_code @term REQUIRED: SOPs become executable specifications; natural language compiles to state machines.
        
        These five principles are architectural commitments, not guidelines.
end

PASS 23AutonomyalignmentTension:
    sutra: "Bounded autonomy, progressive trust, and reversible delegation resolve autonomy-alignment tension through staged capability expansion."
    gloss:
        @bounded_autonomy @term: clear operational perimeters; independent judgment within bounds; hard constraints on prohibited actions.
        
        @progressive_trust @term: capability expansion based on demonstrated reliability; apprenticeship model; earn autonomy in stages; new capabilities unlock with proven accuracy.
        
        @reversible_delegation @term: human oversight can reclaim control at any level; emergency stop mechanisms always available; escalation pathways maintained.
        
        This philosophical commitment enables both autonomous operation and human control simultaneously. Trust is earned through demonstrated performance, not granted by default.
end

PASS PartIiiCognitiveArchitectures:
    sutra: "CoALA framework (Cognitive Architectures for Language Agents) organizes modular components: perception, memory, planning, action, learning."
    gloss:
        @coala_framework @term: five modular components:
        
        Perception: ingest multimodal data (text, images, APIs, user interactions).
        Memory: store, retain, retrieve across timescales and formats.
        Planning: decompose goals into actionable steps; formulate coherent plans.
        Action: execute through tools, APIs, response generation.
        Learning: evaluate performance; correct errors; improve strategies.
        
        This modularity enables component substitution and independent optimization while maintaining system coherence.
end

PASS 32ReasoningPatterns:
    sutra: "ReAct (+34% ALFWorld), Reflexion, Tree-of-Thoughts, Extended CoT (~83% AIME), HTN Planning each enable different problem classes and scales."
    gloss:
        @react @term: reason + act interleave with observation; +34% ALFWorld, +10% WebShop; general tasks.
        
        @reflexion @term: self-correction loop with episodic memory; verbal reinforcement learning; iterative improvement.
        
        @tree_of_thoughts @term: parallel exploration with self-evaluation; +8% NATURAL PLAN; complex problem-solving.
        
        @extended_cot @term: multi-stage internal reasoning; ~83% AIME; mathematical proof.
        
        @htn_planning @term: hierarchical task decomposition; hybrid with LLM flexibility; complex multi-step workflows.
        
        Reasoning pattern selection depends on problem structure, evaluation criteria, and environmental constraints.
end

PASS 33CognitivePrimitives:
    sutra: "Perception (text, visual, auditory, multimodal), reasoning (deductive, inductive, abductive, analogical, causal), planning (hierarchical, temporal, contingent, opportunistic, adversarial)."
    gloss:
        Perception primitives: NLU and intent extraction (text); object detection and scene understanding (visual); speech recognition (auditory); cross-modality fusion (multimodal).
        
        Reasoning primitives: deductive (logical rules → certain conclusions); inductive (specific observations → general patterns); abductive (observations → plausible explanations); analogical (structural similarity → solution transfer); causal (cause-effect construction).
        
        Planning primitives: hierarchical (goal → subgoal lattices); temporal (scheduling with constraints); contingent (conditional branches for failure modes); opportunistic (adapt to unexpected possibilities); adversarial (anticipate opposing actions).
        
        These primitives compose into coherent cognitive systems; not all required simultaneously.
end

PASS PartIvMultiagentOrchestration:
    sutra: "Five core patterns (sequential, concurrent, group chat, handoff, magentic) coordinate specialist agents through orchestration."
    gloss:
        @five_core_orchestration_patterns @term:
        
        Sequential: chain agents in predefined workflow; progressive refinement (legal documents).
        Concurrent: fan-out/fan-in parallel analysis; multiple perspectives (stock analysis).
        Group Chat: shared conversation with chat manager; maker-checker quality control.
        Handoff: transfer control based on context; dynamic specialization (support queues).
        Magentic: dynamic task ledgers for open-ended problems; SRE automation, incident response.
        
        Pattern selection driven by problem structure, time constraints, and verification requirements.
end

PASS 42TheSpecialistResolution:
    sutra: "Unanimous expert consensus: specialists coordinated through orchestration outperform generalists; generalists miss niche expertise and meticulousness."
    gloss:
        Specialist agents routed by orchestration layer based on context, permissions, task type outperform single generalist agents. Pattern mirrors Mixture of Experts at agent level.
        
        Deployment finding: "Deploying generalist agents expecting senior-level performance will miss niche expertise, necessary meticulousness, and domain experience, resulting in work quality in free fall." (Rossum 2025 Survey)
        
        Strategic implication: Production agentic systems must be multi-specialist with intelligent routing, not single-agent generalists.
end

PASS 43TopologyPatterns:
    sutra: "Five topology patterns (hierarchical, planner-executor, critic-refiner, specialist swarm, hybrid hub-spoke+mesh) govern multi-agent coordination structures."
    gloss:
        @hierarchical @term: top-down tree; leader delegates to workers; well-defined decomposable problems.
        
        @planner_executor @term: two-layer with planning and execution separation; clear task-plan distinction.
        
        @critic_refiner @term: actor proposes, critic evaluates, iterate; quality enhancement.
        
        @specialist_swarm @term: parallel specialists with synthesis; parallel exploration, research.
        
        @hybrid_hub_spoke_mesh @term: strategic coordinators + local mesh execution; dominant in production deployments.
        
        Topology selection depends on problem decomposability, latency requirements, and coordination overhead tolerance.
end

PROC 44CommunicationProtocols:
    sutra: "Four protocols enable agent communication: MCP (universal adoption), A2A (150+ orgs), ACP (manufacturing/autonomy), ANP (decentralized identity)."
    gloss:
        @mcp @term (Model Context Protocol): agent-to-tool structured interactions. UNIVERSAL ADOPTION: OpenAI, Google, Microsoft, AWS. Standard for tool-use specification.
        
        @a2a @term (Agent-to-Agent): peer agent collaboration and discovery. 150+ organization backing. Enables agent composition.
        
        @acp @term (Agent Communication Protocol): low-latency controlled environments. Manufacturing, autonomous vehicles. Emphasizes determinism.
        
        @anp @term (Agent Network Protocol): decentralized identity-aware networks. W3C DIDs, JSON-LD graphs. Emphasizes verifiability and governance.
        
        Precondition: choose protocol before agent system design. Postcondition: agents interoperate only within protocol ecosystem.
end

PASS PartVMemorySystems:
    sutra: "Five-type memory taxonomy (working, episodic, semantic, procedural, prospective) with architectural innovations (A-MEM, MIRIX, MemGPT)."
    gloss:
        @memory_taxonomy @term:
        
        Working: immediate task context; context window, in-memory structures.
        Episodic: specific interaction sequences; event logs, vector stores.
        Semantic: factual knowledge, concepts; knowledge graphs, RAG systems.
        Procedural: learned skills, action sequences; tool definitions, workflows.
        Prospective: future intentions, scheduled actions; planning state, to-do queues.
        
        A-MEM (Zettelkasten-inspired): dynamic indexing; agent as knowledge curator; NeurIPS 2025.
        MIRIX (six-tier taxonomy): core to resource to knowledge vaults; 35% higher accuracy, 99.9% storage reduction.
        MemGPT (OS-inspired): RAM to disk analog; autonomous tier management via function calls.
end

NORM 53CriticalPrinciple:
    sutra: "Memory is context engineering: what enters context window determines capabilities more than raw storage capacity."
    gloss:
        @memory_is_context_engineering @term REQUIRED: agent cognitive capacity bounded by context window size, not total memory capacity. Retrieval, ranking, and inclusion of relevant memories more critical than storage.
        
        Implication: design memory systems for precise context reconstruction, not comprehensive history preservation. Vector stores and RAG systems optimize for relevance ranking over total capacity.
        
        Enforcement: measure agent performance by context quality metrics (relevance, coverage, interference) not by total stored facts.
end

PASS PartViSafetyAnd:
    sutra: "Defense-in-depth across five layers (prompt hardening, content filtering, tool sanitization, vulnerability scanning, code sandboxing) mitigates agent misuse and alignment risks."
    gloss:
        Threat landscape: agent hijacking (81% success with optimization via indirect prompt injection), tool misuse (SQL injection, SSRF, RCE), jailbreaking (power law scaling), deep scheming (alignment faking, sandbagging, environment manipulation—emerging concern).
        
        @defense_in_depth @term required architecture:
        
        Layer 1—Prompt Hardening: strict constraints, explicit prohibitions, narrow responsibility definitions, out-of-scope rejection.
        
        Layer 2—Content Filtering: tool schema extraction detection, misuse pattern detection, memory manipulation detection, malicious code blocking, sensitive data leakage prevention.
        
        Layer 3—Tool Sanitization: type/format/boundary validation, special character filtering, never implicitly trust inputs.
        
        Layer 4—Vulnerability Scanning: SAST, DAST, SCA, regular security assessments.
        
        Layer 5—Code Sandboxing: network restrictions (whitelist outbound), limited volumes (tmpfs), dropped capabilities, blocked syscalls, resource quotas.
        
        All five layers required; no single layer sufficient.
end

NORM 63Saif20Principles:
    sutra: "SAIF 2.0 (Situational Awareness Information Framework) establishes six normative principles for safe agentic operation."
    gloss:
        @saif_2_0 @term REQUIRED normative framework:
        
        Well-defined human controllers REQUIRED: clear ownership and accountability for agent actions.
        
        Carefully limited powers REQUIRED: scope restrictions on capabilities; no unbounded tool access.
        
        Observable actions and planning REQUIRED: full visibility into decisions and action sequences; explainability.
        
        Environment confinement REQUIRED: sandboxing isolation; contained failure modes.
        
        Separate evaluation REQUIRED: tool use and action steps validated independently; no chained assumptions.
        
        Multi-level monitoring REQUIRED: comprehensive logging for incident response; audit trails.
        
        Implementation required before production deployment.
end

PASS PartViiProductionDeployment:
    sutra: "CLASSic evaluation (cost, latency, accuracy, stability, security), failure patterns (over-engineering, state mismanagement, poor handoff, distribution shift), success factors (CEO-led programs, vertical transformation, industrialized delivery)."
    gloss:
        @classic_evaluation_framework @term:
        
        Cost: API usage, token consumption, infrastructure. Domain-specific agents 10-100x cheaper than general.
        Latency: end-to-end response time. Specialized agents: 2.1s vs general agents longer.
        Accuracy: workflow execution correctness. Specialized: 82.7% on IT ops.
        Stability: consistency across inputs. Specialized: 72% stability.
        Security: resilience to adversarial inputs. Critical as attacks proliferate.
        
        Failure patterns: over-engineering (18-month builds launching obsolete), state mismanagement (duplicate processing, data loss), poor handoff design (customer confusion), distribution shift (benchmark ≠ production).
        
        Success factors: CEO-led strategic programs (executive authority), vertical process transformation (function-specific, not horizontal), industrialized delivery (production-grade observability, security, governance), cross-functional squads (process redesign, not adoption).
end

PASS 72FailurePatterns:
    sutra: "Over-engineering (slow launch), state mismanagement (data loss), poor handoff design (confusion), distribution shift (benchmark gap)—mitigated by iterative deployment and realistic testing."
    gloss:
        @failure_patterns @term:
        
        Over-engineering: 18-month build cycles launching obsolete systems. Mitigation: iterative deployment with quarterly updates.
        
        State mismanagement: duplicate processing, data loss through unclear ownership. Mitigation: explicit @state_architecture @term with clear ownership.
        
        Poor handoff design: customer confusion, abandonment through unclear transitions. Mitigation: explicit transition protocols, clear responsibility transfer.
        
        Distribution shift: benchmark performance ≠ production performance. Mitigation: realistic test environments replicating production conditions.
        
        Each pattern addressable through architectural discipline; not inherent to agentic systems.
end

PASS 73SuccessFactors:
    sutra: "CEO-led programs with authority, vertical process transformation, industrialized delivery, cross-functional squads, and realistic KPIs."
    gloss:
        @success_factor_ceo_leadership @term: executive authority for process reinvention required. Technical teams cannot mandate organizational transformation alone.
        
        @success_factor_vertical_transformation @term: function-specific workflows (IT ops, supply chain, customer support), not horizontal task assistance. Vertical transformation drives material earnings impact.
        
        @success_factor_industrialized_delivery @term: production-grade observability, security, governance infrastructure. Not experimental systems. Mature deployment practices required.
        
        @success_factor_cross_functional @term: process redesign squads, not technology adoption teams. Organizational design as important as technical architecture.
        
        Implication: agent adoption failure stems primarily from organizational factors, not technical immaturity.
end

PASS 74TheGenAi:
    sutra: "Gen AI Paradox: 78% deploy agents, 80% report no material earnings impact—horizontal task assistance easy, vertical process transformation requires organizational change most lack."
    gloss:
        @gen_ai_paradox @term: widespread deployment (78%) coupled with negligible economic impact (80% report none). Resolution: horizontal task assistance (document summarization, email drafting) deploys easily but generates minimal value; vertical process transformation (IT ops automation, supply chain optimization, customer support redesign) generates material impact but requires organizational transformation.
        
        Strategic implication: mere agent deployment insufficient. Must redesign business processes to realize value. This organizational work typically exceeds technical work in complexity and effort.
        
        Path forward: target vertical processes with measurable economics; redesign workflows for agent-native operations; measure earnings impact directly.
end

PASS PartViiiFrameworkLandscape:
    sutra: "Five production frameworks (OpenAI Agents SDK, Google ADK, Microsoft AF, LangGraph, CrewAI) mature October 2025; selection criteria based on branching complexity, collaboration style, governance needs."
    gloss:
        @openai_agents_sdk @term: agents, handoffs, guardrails, sessions. Provider-agnostic, minimal abstractions. Simplicity priority.
        
        @google_adk @term: multi-agent from inception, hierarchical composition. Interoperability (MCP + A2A native). Flexibility priority.
        
        @microsoft_agent_framework @term: unified AutoGen + Semantic Kernel. Azure ecosystem, Orleans-based. Enterprise governance priority.
        
        @langgraph @term: graph-based stateful DAG. Lowest latency, explicit control. Complex branching priority.
        
        @crewai @term: role-based teamwork simulation. Intuitive abstractions, rapid development. Business workflow priority.
        
        Selection: LangGraph (complex conditionals, hierarchical), CrewAI (role-based, business workflows), Microsoft AF (Azure, governance), ADK (multi-model, interop), OpenAI SDK (simplicity).
end

PASS PartIxTheDefinitive:
    sutra: "December 2025: Infrastructure production-ready; challenges persist (51-72% unsafe, 90% 30-day failure); organizational readiness and process redesign are binding constraints."
    gloss:
        Current state December 2025:
        
        Infrastructure ready: frameworks reached production maturity; MCP + A2A universal adoption; five orchestration patterns standardized; specialist architectures validated.
        
        Challenges persist: 51-72% unsafe behavior rates documented; 90% failure rate within 30 days without proper orchestration; evaluation crisis (benchmark ≠ production); organizational readiness as binding constraint on deployment.
        
        Next five years determine transformative potential. Progress requires orchestrating technical improvements (security hardening, reliability, cost), organizational transformation (strategic vision, technical sophistication, governance maturity), and economic process redesign (reinvention for agentic operation, not productivity tools for existing workflows).
        
        Success is not assured; requires simultaneous progress on all three dimensions.
end

PASS 92TheDefinitiveAgent:
    sutra: "Agent definition: perceives environment, remembers and learns, reasons and plans across long horizons, acts through tools, communicates with humans/agents, operates within bounds while earning trust."
    gloss:
        @definitive_agent @term: AI system that perceives environment (multimodal input), remembers and learns (persistent memory with adaptation), reasons and plans across long horizons (multi-step decomposition), acts upon world through tools (grounded execution), communicates and collaborates with humans and other agents (principled interaction), operates within human-defined bounds (scope constraints), dynamically expands capability as it earns trust (@progressive_trust).
        
        This definition unifies characteristics, architectures, and operational principles into single agent concept.
end

PASS 93Trajectory:
    sutra: "Technical progress continues; organizational transformation and process redesign are equal requirements for realizing agentic AI's transformative potential."
    gloss:
        Technical dimension: security hardening, reliability improvement, cost optimization—steady trajectory.
        
        Organizational dimension: strategic vision, technical sophistication, governance maturity—varies widely; leadership-dependent.
        
        Economic dimension: process reinvention for agentic operation—requires workflow redesign beyond automation.
        
        Constraint analysis: organizational readiness is binding constraint limiting deployment; not technical immaturity.
        
        Five-year forecast: success depends on orchestrating progress across all three dimensions simultaneously. Pure technical advancement insufficient without organizational and economic change.
end

PASS Satellites:
    sutra: "Five asteroid satellites provide detailed specifications: cognitive architecture, multi-agent orchestration, memory systems, safety/alignment, production frameworks."
    gloss:
        @satellite_cognitive_architecture @term [[CANON-30410]]: detailed CoALA, reasoning patterns, cognitive primitives, perception/planning/learning architectures.
        
        @satellite_multi_agent_orchestration @term [[CANON-30420]]: framework comparisons, topology implementations, specialist routing, communication protocols.
        
        @satellite_memory_systems @term [[CANON-30430]]: vector stores, RAG systems, context engineering, A-MEM/MIRIX specifications.
        
        @satellite_safety_alignment @term [[CANON-30440]]: attack vectors, defense implementations, governance frameworks, SAIF 2.0 details.
        
        @satellite_production_frameworks @term [[CANON-30450]]: SDK comparisons, MCP/A2A protocols, deployment pattern specifications.
        
        Satellites provide implementation-level detail for practitioners; comet provides conceptual integration.
end

PASS PractitionerValidations:
    sutra: "External sources validate architecture perspective: Karpathy (decade not year; RL limitations; continual learning gap), Sutton (world models vs. pattern matching), Bratton (cosmopolitical agency), Douglas/Bricken (two-axes framework, neuralese interpretability), Walker (AI as life extension)."
    gloss:
        @karpathy_validation @term: "Decade of agents, not year of agents. They just don't work yet—not enough intelligence, not multimodal enough, no continual learning." (2025-10-17). Validates "challenges persist" in Section 9.1. Current systems lack cognitive completeness for full autonomy. 51-72% unsafe rates and 90% failure rate reflect genuine architectural gaps.
        
        RL critique: "Reinforcement learning is terrible. Core problem: RL requires reward signal; getting that in real world is extremely hard." Validates hybrid architectures combining LLM pattern-matching with alternative learning paradigms.
        
        @sutton_validation @term: "LLMs trained once, deployed, don't learn from responses. True RL system would continually learn." (2025-09-26). CoALA Learning module addresses architecturally; current implementations lack true continual learning.
        
        World model debate: "World model enables prediction of what happens. LLMs predict what person would say—not what will happen." Informs agent design: effective agents need grounded world models, not just text patterns. Tool use partially addresses; fundamental limitations remain.
        
        @bratton_cosmopolitical @term: "We're bringing new agents into world—entities that make decisions, have effects, need accounting in how we organize ourselves." (2025-03-20). Reframes agents as political actors requiring inclusion in ethical/governance frameworks.
        
        @douglas_bricken_two_axes @term: intellectual complexity (peaks achieved: competitive programming, math) vs. time horizon (long-running agentic performance not demonstrated). "If good feedback loop, pretty good. If can't, struggle." (2025-05-22). Explains domain-specific advances; suggests path forward through expanding verifiable domains.
        
        Neuralese and interpretability: models think in internal language optimized for computation. Current interpretability identifies THAT something computed but not WHY. Fundamental gap limits alignment verification.
        
        @walker_life_extension @term: "When ask 'Who's really doing making?'—us or broader process of life?—distinction dissolves." (2025-05-28). AI systems extend life into new assembly space; agents are construction pathways; reframes development as participation in planetary-scale evolutionary process.
end

PASS TimelineCalibration:
    sutra: "Karpathy 2025-10-17: decade of agents timeline reflects genuine cognitive gaps (intelligence, multimodality, continual learning) not mere engineering challenges."
    gloss:
        Narrative claim: "It's the decade of agents, not the year of agents." Calibration indicates October 2025 assessment that five-year trajectory (2025-2030) required for agents approaching full autonomy.
        
        Gap analysis: not enough intelligence, not multimodal enough, no continual learning. Three specific architectural deficits requiring sustained research.
        
        Implication: current systems (December 2025 as document date) still in early stages of this decade-long trajectory. Expect significant technical advances but continued limitations on fully autonomous operation.
end

PASS RlLimitationsForRealworld:
    sutra: "Reinforcement learning fails in real-world domains due to reward signal difficulty; hybrid architectures with LLM pattern-matching and alternative learning paradigms required."
    gloss:
        @rl_limitations @term: RL requires reward signal; obtaining that in real world is "extremely hard" (Karpathy 2025-10-17). Pure RL agents fail outside closed domains (games, simulations).
        
        Real-world implication: cannot train agents via RL in production environments without explicit reward mechanisms. Closed-loop learning requires engineered feedback, not natural outcome measurement.
        
        Architectural response: hybrid systems combining LLM rapid pattern-matching with alternative learning (imitation learning, inverse RL, learning from demonstrations, human feedback). LLM provides initial capability; alternative learning refines.
        
        Design principle: build human-in-the-loop learning pathways; RL insufficient alone.
end

PASS ExperientialLearningGap:
    sutra: "Foundation models trained once, deployed static, don't continually learn from interaction responses; true learning systems require ongoing optimization."
    gloss:
        @continual_learning_gap @term: current LLMs are static post-deployment. One-shot training → deployment → no further adaptation from experience (Sutton 2025-09-26).
        
        Contrast: true learning systems improve continuously from interaction feedback. Each deployment should refine internal models.
        
        CoALA Learning module addresses architecturally but requires: (1) explicit feedback mechanisms, (2) gradient pathways for updating internal models, (3) safe exploration during learning.
        
        Current limitation: deployment-stage fine-tuning expensive and risky. Full continual learning remains unsolved. Decade-plus timeline partly reflects this gap's difficulty.
end

PASS WorldModelDebate:
    sutra: "LLMs predict text (what people say); effective agents need grounded world models (what will happen); tool use partially bridges gap but limitations remain."
    gloss:
        @world_model_requirement @term: world models enable agents to predict consequences of actions before executing. Essential for planning and risk assessment.
        
        LLM limitation: trained to predict next token in text. Predicts "what person would say" not "what will happen." Pattern matching on human text ≠ physical/causal prediction.
        
        Partial solution: tool use and simulation grounding. Execute queries in real environments or simulators to determine outcomes rather than predicting. Transforms problem from forward-modeling to empirical testing.
        
        Limitation of solution: tool use is slow and expensive. Planning with many hypothetical tool calls not feasible. Gap between fast reasoning (LLM) and accurate reasoning (environment grounding) remains.
        
        Decade timeline partly reflects solving this gap through more sophisticated hybrid approaches.