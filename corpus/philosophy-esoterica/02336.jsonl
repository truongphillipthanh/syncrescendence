{"atom_id": "ATOM-SOURCE-20260104-634-0001", "source_id": "SOURCE-20260104-634", "category": "claim", "content": "New AI research proves that 'Context Rot' destroys reasoning capabilities as inputs scale, despite promises of 'infinite' context windows.", "line_start": 12, "line_end": 13, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.2, 0.1, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260104-634-0002", "source_id": "SOURCE-20260104-634", "category": "concept", "content": "Recursive Language Models (RLMs) are a radical solution introduced by MIT research that act as a Neurosymbolic Operating System.", "line_start": 15, "line_end": 16, "chaperone": {"context_type": "hypothesis", "argument_role": "claim", "tension_vector": [0.8, 0.2, 0.1, 0.4, 0.2, 0.5], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260104-634-0003", "source_id": "SOURCE-20260104-634", "category": "praxis_hook", "content": "Recursive Language Models (RLMs) address 'Context Rot' by writing Python code to mechanically split massive datasets and recursively 'spawn' fresh model instances to process them, rather than force-feeding data into a single Transformer.", "line_start": 16, "line_end": 18, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.3, 0.7, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260104-634-0004", "source_id": "SOURCE-20260104-634", "category": "claim", "content": "Recursive Language Models (RLMs) achieve a staggering leap in performance, with RLM(GPT-5) scoring 58% on quadratic complexity tasks where base GPT-5 scores below 0.1%.", "line_start": 20, "line_end": 21, "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.1, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260104-634-0005", "source_id": "SOURCE-20260104-634", "category": "prediction", "content": "The 'Inference-Time Scaling' mechanism of Recursive Language Models (RLMs) signals the end of static Large Language Models (LLMs) as we know them.", "line_start": 23, "line_end": 23, "chaperone": {"context_type": "speculation", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.2, 0.8, 0.2, 0.4], "opposes_atom_ids": []}, "extensions": {}}
