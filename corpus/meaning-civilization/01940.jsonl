{"atom_id": "ATOM-SOURCE-20251216-818-0001", "source_id": "SOURCE-20251216-818", "category": "claim", "content": "The primary reason AI projects fail to deliver value is not due to the model's intelligence, but because 'correctness' is undefined.", "line_start": 16, "line_end": 17, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.2, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251216-818-0002", "source_id": "SOURCE-20251216-818", "category": "praxis_hook", "content": "Before making any AI architecture decisions, define what 'correct' means for the project.", "line_start": 19, "line_end": 19, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.9, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251216-818-0003", "source_id": "SOURCE-20251216-818", "category": "claim", "content": "Undefined quality in AI projects renders all subsequent architectural choices meaningless.", "line_start": 21, "line_end": 21, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.7, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251216-818-0004", "source_id": "SOURCE-20251216-818", "category": "claim", "content": "Humans often shift goalposts and attribute unreliability to the AI system rather than their own undefined expectations.", "line_start": 22, "line_end": 22, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.5, 0.5, 0.2, 0.3, 0.5, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251216-818-0005", "source_id": "SOURCE-20251216-818", "category": "claim", "content": "Hallucinations in AI are fundamentally a correctness problem, not solely a model problem.", "line_start": 33, "line_end": 33, "chaperone": {"context_type": "hypothesis", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.2, 0.4, 0.6, 0.5], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251216-818-0006", "source_id": "SOURCE-20251216-818", "category": "praxis_hook", "content": "To build effective AI, define correctness in terms of claims, evidence, and failure penalties.", "line_start": 42, "line_end": 43, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.8, 0.3, 0.1, 0.2, 0.9, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251216-818-0007", "source_id": "SOURCE-20251216-818", "category": "claim", "content": "AI builders who remain vague about quality will experience stalled adoption of their AI solutions.", "line_start": 43, "line_end": 43, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.6, 0.7, 0.7], "opposes_atom_ids": []}, "extensions": {}}
