# Graphic Cards for AI

**Channel**: Caleb Writes Code
**Published**: 2025-11-24
**Duration**: 11m 48s
**URL**: https://www.youtube.com/watch?v=z83-C4iwwEk

## Description (no transcript available)

Nvidia and AMD graphic cards are becoming a commodity where pricing has been a huge barrier for even consumers to look into running AI locally at home.
What are some metrics I should consider in purchasing graphic cards and what graphic cards is good? Do I only look at VRAM? or do the software stack matter as well like ROCm and CUDA?

Open models like Qwen, QwQ, GLM, Llama, Phi and more are all becoming a strong candidate to run these models at home.

#ai #graphiccard #technology 

Chapters
00:00 Intro
00:29 AI on CPU
02:23 AI on GPU
03:08 RTX 3060
04:10 RTX 3090
06:28 Rent GPU
07:20 RTX 4090
09:39 RTX 5090
10:13 AMD
11:18 Conclusion
