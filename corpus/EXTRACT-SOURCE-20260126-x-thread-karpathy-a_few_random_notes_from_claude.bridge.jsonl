{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "3f71b71f-10ee-5e6a-a47f-c26063753337", "timestamp": "2026-02-24T00:57:17.667320+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0001", "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "category": "claim", "content": "The author's coding workflow shifted from 80% manual+autocomplete and 20% agents in November to 80% agent coding and 20% edits+touchups in December, primarily programming in English.", "line_start": 7, "line_end": 10, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.1, 0.6, 0.1, 0.1, 0.5, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "entity_type": "Claim", "name": "The author's coding workflow shifted from 80% manual+autocomplete and 20% agents", "content": "The author's coding workflow shifted from 80% manual+autocomplete and 20% agents in November to 80% agent coding and 20% edits+touchups in December, primarily programming in English.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "line_start": 7, "line_end": 10, "atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0001"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.1, 0.6, 0.1, 0.1, 0.5, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "0d0ee69d-603b-5b8d-97c6-6d9de9960163", "timestamp": "2026-02-24T00:57:17.667320+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0002", "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "category": "claim", "content": "The shift to agent-based coding represents the biggest change to the author's basic coding workflow in approximately two decades, occurring within a few weeks.", "line_start": 13, "line_end": 15, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.4, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "entity_type": "Claim", "name": "The shift to agent-based coding represents the biggest change to the author's ba", "content": "The shift to agent-based coding represents the biggest change to the author's basic coding workflow in approximately two decades, occurring within a few weeks.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "line_start": 13, "line_end": 15, "atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0002"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.4, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "6b4a3739-b676-5015-b724-d67e6075e688", "timestamp": "2026-02-24T00:57:17.667320+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0003", "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "category": "prediction", "content": "A similar shift in coding workflow is likely happening to a double-digit percentage of engineers, while general awareness remains in the low single digits.", "line_start": 15, "line_end": 18, "chaperone": {"context_type": "speculation", "argument_role": "claim", "tension_vector": [0.3, 0.5, 0.1, 0.7, 0.3, 0.4], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "entity_type": "Prediction", "name": "A similar shift in coding workflow is likely happening to a double-digit percent", "content": "A similar shift in coding workflow is likely happening to a double-digit percentage of engineers, while general awareness remains in the low single digits.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "line_start": 15, "line_end": 18, "atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0003"}, "metadata": {"category": "prediction", "chaperone": {"context_type": "speculation", "argument_role": "claim", "tension_vector": [0.3, 0.5, 0.1, 0.7, 0.3, 0.4], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "5d92c3fd-1003-5ea8-bd14-864eaa72a524", "timestamp": "2026-02-24T00:57:17.667320+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0004", "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "category": "claim", "content": "Current hype around \"no need for IDE anymore\" and \"agent swarm\" is premature because models still make subtle conceptual mistakes, often making wrong assumptions without checking or seeking clarification.", "line_start": 20, "line_end": 26, "chaperone": {"context_type": "rebuttal", "argument_role": "counterevidence", "tension_vector": [0.2, 0.3, 0.6, 0.2, 0.4, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "entity_type": "Claim", "name": "Current hype around \"no need for IDE anymore\" and \"agent swarm\" is premature bec", "content": "Current hype around \"no need for IDE anymore\" and \"agent swarm\" is premature because models still make subtle conceptual mistakes, often making wrong assumptions without checking or seeking clarification.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "line_start": 20, "line_end": 26, "atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0004"}, "metadata": {"category": "claim", "chaperone": {"context_type": "rebuttal", "argument_role": "counterevidence", "tension_vector": [0.2, 0.3, 0.6, 0.2, 0.4, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "34ab1c61-38d0-5082-b930-9c62924c9399", "timestamp": "2026-02-24T00:57:17.667320+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0005", "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "category": "claim", "content": "LLMs tend to overcomplicate code, bloat abstractions, fail to clean up dead code, and sometimes alter or remove comments/code they don't understand, despite explicit instructions.", "line_start": 28, "line_end": 35, "chaperone": {"context_type": "anecdote", "argument_role": "counterevidence", "tension_vector": [0.2, 0.4, 0.5, 0.2, 0.4, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "entity_type": "Claim", "name": "LLMs tend to overcomplicate code, bloat abstractions, fail to clean up dead code", "content": "LLMs tend to overcomplicate code, bloat abstractions, fail to clean up dead code, and sometimes alter or remove comments/code they don't understand, despite explicit instructions.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "line_start": 28, "line_end": 35, "atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0005"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "counterevidence", "tension_vector": [0.2, 0.4, 0.5, 0.2, 0.4, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "aeea738e-5830-5997-8b13-6d768773ad38", "timestamp": "2026-02-24T00:57:17.667320+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0006", "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "category": "claim", "content": "Despite their flaws, LLM assistance is a net huge improvement in coding, making it difficult to return to manual coding.", "line_start": 37, "line_end": 38, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.1, 0.7, 0.1, 0.1, 0.6, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "entity_type": "Claim", "name": "Despite their flaws, LLM assistance is a net huge improvement in coding, making", "content": "Despite their flaws, LLM assistance is a net huge improvement in coding, making it difficult to return to manual coding.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "line_start": 37, "line_end": 38, "atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0006"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.1, 0.7, 0.1, 0.1, 0.6, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "5258c034-581a-5e9d-b9fc-a991d487d6fd", "timestamp": "2026-02-24T00:57:17.667320+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0007", "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "category": "praxis_hook", "content": "The author's current coding workflow involves using a few Claude coding sessions in ghostty windows/tabs on the left, with an IDE on the right for viewing code and manual edits.", "line_start": 40, "line_end": 41, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.1, 0.5, 0.1, 0.1, 0.8, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "entity_type": "PraxisHook", "name": "The author's current coding workflow involves using a few Claude coding sessions", "content": "The author's current coding workflow involves using a few Claude coding sessions in ghostty windows/tabs on the left, with an IDE on the right for viewing code and manual edits.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "line_start": 40, "line_end": 41, "atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0007"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.1, 0.5, 0.1, 0.1, 0.8, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "66026329-12c8-54c6-8cb0-529c141ae05e", "timestamp": "2026-02-24T00:57:17.667320+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0008", "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "category": "claim", "content": "LLM agents exhibit relentless tenacity, never tiring or demoralized, continuing to try solutions where a human would give up, which highlights stamina as a core bottleneck in work.", "line_start": 44, "line_end": 48, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.6, 0.1, 0.2, 0.4, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "entity_type": "Claim", "name": "LLM agents exhibit relentless tenacity, never tiring or demoralized, continuing", "content": "LLM agents exhibit relentless tenacity, never tiring or demoralized, continuing to try solutions where a human would give up, which highlights stamina as a core bottleneck in work.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "line_start": 44, "line_end": 48, "atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0008"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.6, 0.1, 0.2, 0.4, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "31f7a1a1-e6fd-5e17-be0c-fc1b9c0bab95", "timestamp": "2026-02-24T00:57:17.667320+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0009", "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "category": "claim", "content": "LLM assistance leads to an expansion of work rather than just a speedup, enabling users to code things previously deemed not worth it or to approach code beyond their current knowledge/skill.", "line_start": 52, "line_end": 56, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.4, 0.5, 0.1, 0.2, 0.5, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "entity_type": "Claim", "name": "LLM assistance leads to an expansion of work rather than just a speedup, enablin", "content": "LLM assistance leads to an expansion of work rather than just a speedup, enabling users to code things previously deemed not worth it or to approach code beyond their current knowledge/skill.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude", "line_start": 52, "line_end": 56, "atom_id": "ATOM-SOURCE-20260126-x-thread-karpathy-a_few_random_notes_from_claude-0009"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.4, 0.5, 0.1, 0.2, 0.5, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
