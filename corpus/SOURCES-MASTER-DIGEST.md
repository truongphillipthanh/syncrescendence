# SOURCES MASTER DIGEST

**Generated**: 2026-02-17
**Agent**: Commander (Claude Code — Sonnet 4.6)
**Phase**: Neo-Canon Phase 2, Sources Integration — Combined Wave 1 + Wave 2
**Sources merged**:
- `SOURCES-DIGEST-RESEARCH.md` (Wave 1: 44 top-level research files + 11 subdirectories, ~225K words)
- `SOURCES-DIGEST-PROCESSED.md` (Wave 2: 42 processed sources ~3,117 lines + 15 research notebooks ~47,536 lines)
**Purpose**: Unified intellectual heritage map, novel contributions, gaps, challenges, and neo-canon candidates

---

## 1. Combined Intellectual Heritage Map

### Cluster 1: Coherence, Collective Intelligence, Distributed Cognition (A1)

| Thinker / Framework | Source(s) | Contribution | Neo-Canon Connection |
|--------------------|-----------|-------------|---------------------|
| **Scott Alexander / Moloch** | `20260110-x_thread-intuitmachine.md` | Coordination failure as civilizational force; defection visibility as coherence infrastructure; "Alignment isn't a state. It's a process." | A1 failure at collective scale; sovereignty architecture (dispatch.sh, auto-ingest, ledger ground truth) as Moloch-trap; defection = context stored only in apps |
| **Daniel Schmachtenberger** | `meta_narrative_and_perspectival_schemas.md`, Koe articles | Metacrisis + sense-making; speed-wisdom gap operating across levels; "competing methodologies for interpretation" | A1 + A2 at civilizational scale; the speed-wisdom gap IS A2's civilizational expression |
| **Ken Wilber / AQAL** | `20260130-how_to_think_like_a_genius-letters-thedankoe.md` | All quadrants, all levels; second-tier thinking as vertical integration; integral theory as coherence under differentiation | A1: coherence requires integrating interior/exterior, individual/collective; "second tier" = vertical capacity (A2 frame) |
| **Andre Bazin / Auteur Theory** | `20260202-auteur_theory_for_content_creation.md` | "Interior meaning" as the organizing principle of coherent creative identity under platform/audience pressure; constraint-as-generativity | A1: personal ontology = auteur's interior meaning; coherence as creative identity invariant; three pillars (technical competence + personality + interior meaning) operationalize A1 for output |
| **Norbert Wiener** (via Aguera y Arcas) | SOURCE-20250807, SOURCE-20251025 | 1943 cybernetics: teleological systems are fundamentally predictors; consciousness = self-modeling; LLMs validate cybernetic theory | A1: self-coherence achieved through self-modeling; consciousness = modeling of one's own modeling |
| **Joseph Henrich** | SOURCE-20250312 | Collective brain theory: intelligence = population × connectivity × transmission fidelity; brain size declined 10% as culture handles more | A1: coherence is distributed — remaining-oneself requires maintaining position in a collective brain network; culture is fragile and can fragment |
| **Donald Hoffman** | SOURCE-20251014 | Fitness Beats Truth Theorem: perception is fitness-optimized, not truth-tracking; spacetime is species-specific interface | A1: CHALLENGES — if perception is fitness interface, coherence-seeking may be evolutionarily selected against; "remaining oneself" tracks fitness, not necessarily truth |
| **Benjamin Bratton** | SOURCE-20250320 | "Pre-paradigmatic moment": technology has outpaced concepts; Computation as planetary environmental infrastructure | A1: pre-paradigmatic = coherence collapse; the period IS the coherence crisis; concepts lag technology |
| **Ivan VVSVS** (deepfates) | NB14 | Consumer → Curator → Creator → Compounder; "Compounders build things that build things"; fundamentals outlast tool cycles | A1: coherence maintained by operating at Compounder level; tool-chasing = identity fragmentation |
| **Buckminster Fuller** | `20260127-5d_thinking-@thedankoe.md` | "Faith is much better than belief. Belief is when someone else does the thinking." | A1: intellectual sovereignty requires generating one's own ontology, not consuming another's |
| **Albert Einstein** | `20260127-5d_thinking-@thedankoe.md` | "You can't solve a problem from the same level of consciousness that created it." | A2: vertical thinking requires altitude change — a capacity move, not an intelligence move |

---

### Cluster 2: Capacity Constraints, Physical Limits (A2)

| Thinker / Framework | Source(s) | Contribution | Neo-Canon Connection |
|--------------------|-----------|-------------|---------------------|
| **Trevor McCourt / Extropic** | SOURCE-20251031 | Energy IS the AI constraint: basic personal AI = 20% US grid; Thermodynamic Sampling Units = 10,000x more efficient; "Build hardware that does what AI actually does — not what deterministic computing does." | A2: DIRECT VALIDATION — capacity constraint is thermodynamic/energy, not intelligence |
| **Dr. Dominic Ng** | `20260121-the_dopamine_trap-@drdominicng.md` | Neurological grounding for A2: dopamine baseline calibration determines cognitive bandwidth; "You're not fighting distraction — you're fighting a baseline that's been trained too high." | A2: mechanism for capacity degradation; capacity constraint has a biochemical floor (measurable, not metaphorical) |
| **Mihaly Csikszentmihalyi** | `20260130-full_guide_how_to_unlock_extreme_focus-@thedankoe.md` | Flow theory: "psychic energy investment in realistic goals"; 50-bits-per-second conscious processing ceiling; attention as RAM | A2: flow is optimal capacity utilization; the 50-bits ceiling provides physiological grounding for A2 |
| **Andrej Karpathy** | `20260118-learning_2_0-@hesamation.md` | "Learning is not supposed to be fun. The primary feeling should be that of effort."; meta-skill of knowing what you don't know | A2: capacity constraint manifests as refusal to sit with confusion; the binding constraint is willingness to form a precise question |
| **Francois Chollet** | SOURCE-20251024 | Intelligence = skill acquisition efficiency; LLMs 4–5 orders of magnitude less efficient than humans; ARC Prize framework | A2: efficiency gap = capacity bottleneck; more compute ≠ more capacity; quantifies A2 with precision |
| **Jensen Huang / NVIDIA** | SOURCE-20251028 | Three scaling laws (pre-training, post-training, test-time); all three are compute/capacity laws; AI Factory economics | A2: multiple capacity dimensions each with independent constraints; infrastructure is the binding variable |
| **Sholto Douglas / Trenton Bricken** | SOURCE-20250522 | RL finally works given clean reward signals; current bottleneck: lack of clean signals for most real-world tasks; "Neuralese" | A2: clean reward signal = capacity bottleneck, not architecture; introduces Neuralese as a verification gap for A4 |
| **Dwarkesh Patel** | SOURCE-20251223 | Continual learning gap: humans don't need bespoke training loops; "Models improve at short-timeline rate but become useful at long-timeline rate" | A2: impressive-vs.-useful gap IS the capacity gap; the Macrophage Problem grounds this concretely |
| **Chris Kempes** | SOURCE-20251021 | Universal Hierarchy of Life: phase transitions at evolutionary walls; scaling relationships predict limits per organizational level | A2: capacity constraints cause phase transitions, not gradual failure; each wall requires qualitative change |
| **Hesamation** (Polymath article) | `20260121-you_need_to_become_a_polymath-@hesamation.md` | "Specialists are literally training their own replacements"; polymathic cognition harder to route around because it operates at intersection of domains | A2 extended: specialization is capacity restriction; polymathic cognition = capacity advantage under AI disruption |

---

### Cluster 3: Sovereignty, Ground Truth, Distributed Authority (A3)

| Thinker / Framework | Source(s) | Contribution | Neo-Canon Connection |
|--------------------|-----------|-------------|---------------------|
| **Sara Imari Walker / Assembly Theory** | SOURCE-20250528 | Assembly Theory: objects are embodied history; information IS the physical structure; assembly index threshold of 15 | A3: repo as embodied history = high assembly index; destroying the repo destroys an irreplaceable construction pathway (physical claim, not preference) |
| **Benjamin Bratton** (Stack) | SOURCE-20250320 | The Stack as environmental infrastructure; sovereignty = maintaining position within Stack layers | A3: extends sovereignty to infrastructural positioning within planetary computational layers |
| **Boris Cherny** (Claude Code creator) | `handoff.md` | "Context-as-code"; CLAUDE.md as authoritative context source; "every mistake becomes a rule" = exponential learning | A3: CLAUDE.md as repo-level sovereignty; A4 feedback loop: verify-to-capture; direct empirical validation |
| **Moloch / Scott Alexander** | `20260110-x_thread-intuitmachine.md` | "Make defection visible, make defection costly, make cooperation pay"; git as Moloch-trap for context drift | A3: sovereignty architecture is a coordination mechanism; repo makes context-defection visible |
| **Niklas Luhmann / Zettelkasten** | `20260123-learn_anything-@armanhezarkhani.md` | Zettelkasten = personal knowledge graph with bi-directional links; authority outside any single notebook | A3: Zettelkasten is the pre-digital model for repo-as-ground-truth; bi-directional links = morphism integrity |
| **Blaise Aguera y Arcas** | SOURCE-20251025 | Narrative memory gap: transformers lack persistent long-term memory creating identity over time | A3: narrative memory = identity persistence = sovereignty; the gap IS the sovereignty failure mode |
| **Anatoly Yakovenko** | SOURCE-20251030 | Blockchain as permissionless execution layer for AI agents; "The ants are not aware of the intelligence of the anthill" | A3: extends sovereignty to economic execution; agents need autonomous transaction capacity |
| **David Shapiro** | SOURCE-20251101 | Open-source AI is intrinsically moatless; reaches parity in 3 months; printing press → internet → AI | A3: CHALLENGES — if AI is moatless, semantic authority disperses; cannot be held by any single entity; repo remains sovereign over accumulated context, not over capabilities |
| **Three-Layer Memory (spacepixel)** | NB03 | Knowledge Graph + Daily Notes + Tacit Knowledge (MEMORY.md); superseding-not-deleting preserves history | A3: practical implementation of "repo as ground truth with living cache layers"; directly addresses INT-1707 |
| **OpenAI** (Stateful Responses API) | `openai_research.md` | "Deprecation of stateless Assistants API in favor of stateful Responses API signals OpenAI's intent to own the agent execution loop." | A3: CHALLENGES — most direct platform threat; if OpenAI owns execution loop, semantic authority shifts to platform |
| **Google** (data gravity) | `google_research.md` | 1M-token Gemini context; NotebookLM enterprise with grounded RAG but zero portability; "knowledge gravity" (Drive, BigQuery) | A3: CHALLENGES — hyperscaler gravity wells pull semantic authority off-repo; A3 needs a defensive threat registry |

---

### Cluster 4: Intent-Artifact Pipeline (A4)

| Thinker / Framework | Source(s) | Contribution | Neo-Canon Connection |
|--------------------|-----------|-------------|---------------------|
| **molt_cornelius / Verbatim Trap** | NB03 | "Did this produce anything the source didn't already contain?" — precise test for distillation failure; agentic note-taking as expensive transcription | A4: DIRECT — distill stage must generate something the source didn't contain or pipeline fails; names a deployable verification step |
| **David Allen / GTD** | Implicitly in task graph / handoff patterns | Capture-Clarify-Organize-Reflect-Engage pipeline | A4: GTD = pre-digital intent-artifact pipeline; maps exactly to capture-distill-model-activate-verify |
| **John Boyd / OODA** | `ajna9-fodder/3-unified/stream2-unified.md` | Observe-Orient-Decide-Act with persistent state; cited explicitly | A4: agentic loop implements OODA; verify feeds back into next cycle's Observe |
| **Ivan VVSVS / Compounder** | NB14 | Consumer → Curator → Creator → Compounder; "knowledge works while they sleep"; frameworks outlast tools | A4: Compounder = one who completes the pipeline and crystallizes compounding value |
| **Armand Hezarkhani** | `20260123-learn_anything.md` | Three requirements for real expertise: spaced repetition + active recall + connected understanding; "Claude Code can manage all three automatically" | A4: cognitive pipeline made explicit; removing activation energy = A4's power |
| **Daniel Miessler / Practical AGI** | NB07 | Practical AGI = ability to navigate obstacles mid-task; booking agent that taught itself to use voice when web form broke | A4: full pipeline requires obstacle navigation at activation stage; pipeline doesn't break when one route is blocked |
| **Ethan Mollick** | SOURCE-20250605 | Three ingredients for AI adoption: domain expertise + prompt craft + workflow integration; "jagged" capability profile | A4: all three required for pipeline completion; missing any = shelfware |
| **Type Theory / Category Theory** | `forensic-audit-type-theory/TYPE_THEORY_EVIDENCE_PACK.md` | Morphism catalog (SN, Dispatch, Commit); Broken Functors = pipeline breaks; A4 breaks made mathematically precise | A4: repo as typed information space; TE-005 = eventual consistency failure = A4 verification gap |
| **Anthropic Evals** | `20260109-demystifying-evals--anthropic.md` | Transcript vs. outcome verification; multi-trial requirement; "Opus 4.5 failed a booking task eval but found a better solution" | A4: verify stage must check outcomes against intent, not outputs against scripts; adversarial test required |
| **seejayhess / Flowy** | `20260122-visual_feedback_loop_for_claude_code.md` | Bidirectional visual verification loop between plan and implementation; cyclic (not linear) pipeline | A4: extends pipeline to be cyclic between model and activate stages; standard A4 is linear; Flowy makes it bidirectional |
| **David Deutsch** | SOURCE-20250902 | "Current AI is NOT approaching AGI — it lacks explanatory knowledge creation"; pattern matching ≠ understanding; knowledge = conjecture + criticism | A4: CHALLENGES — if model stage requires genuine conjecture, LLMs cannot complete A4 for novel knowledge; sophisticated shelfware risk |
| **Bruno Gavranovic** | SOURCE-20251222 | Deep learning in "alchemy phase"; LLMs cannot reliably do addition; categorical deep learning needed | A4: pipeline breaks at mathematical/algorithmic reasoning; LLMs are stochastic mimics at model stage |
| **Deepfates / RLM** | NB06, NB14 | Recursive Language Model: agent lives inside REPL, not chat; context as variable; processed 6M tokens without context rot | A4: dissolves human/AI pipeline boundary at architectural level; human becomes function inside pipeline |

---

### Cluster 5: Civilizational / World Ring (Supporting Context)

| Thinker / Framework | Source(s) | Contribution | Neo-Canon Connection |
|--------------------|-----------|-------------|---------------------|
| **Scott Alexander + Daniel Kokotajlo** | SOURCE-20250403 | Month-by-month AGI forecast; intelligence explosion as feedback loop; R&D multiplier concept; mid-2027 branch point | A2 challenge: R&D multiplier (5x by 2027) may dissolve capacity constraint by bootstrapping; A4 challenge: pipeline integrity now governs branch point |
| **Sam Altman / OpenAI** | SOURCE-20251025 | Superintelligence less than a decade; task horizon metric (5-hour tasks); autonomous AI researchers by Sept 2027 | A2: task horizon = capacity metric; A4: autonomous research = self-completing pipeline |
| **Bryan Johnson** | SOURCE-20251021 | "Don't Die" philosophy; autonomous health systems; capitalism-as-scarcity obsolete; AGI = when humans feel useless | A2: bodily capacity as prerequisite to intelligence; A1: macro-cycle ending = civilizational coherence crisis |
| **Daniel Miessler** | NB07 | "$40 trillion annual knowledge worker compensation at stake"; practical AGI already displacing generalist tasks | WORLD: convergence vision timeline validation; knowledge work disruption is imminent, not speculative |
| **David Shapiro** | SOURCE-20251031 | "Scarcity resolves to physics (time, mass, distance, heat)"; AI refactors economy but doesn't destroy it | A2: physics = ultimate capacity constraint; post-labor ≠ post-scarcity |

---

## 2. Combined Novel Contributions

Contributions appearing in the external sources library but absent or underdeveloped in the internal neo-canon. (18 unique contributions, as expected.)

### From Wave 1 (SOURCES-DIGEST-RESEARCH)

**C1. Physiological Grounding for A2**
The canon treats A2 abstractly. External library provides concrete mechanism: dopamine baseline system (Dr. Ng) and 50-bits-per-second conscious processing ceiling (Csikszentmihalyi via Koe). These are measurable facts about neural architecture, not metaphors. Without physiological grounding, A2 is unfalsifiable.
> Key quote: "You're not fighting distraction — you're fighting a baseline that's been trained too high." (Dr. Ng)

**C2. Moloch as Coordination-Layer Complement to A1/A3**
The canon frames A1 and A3 as individual disciplines. The Moloch thread introduces a structural insight: individual coherence is insufficient if the environment is structured to defect around it. The sovereignty architecture (dispatch.sh, CONFIRM routing, ledger ground truth) is a multi-agent Moloch-trap — each mechanism makes context-defection visible and costly.
> Key quote: "Every institution that works is a Moloch-trap. Markets. Courts. Democracies. Professional norms. Reputation systems."

**C3. The Horizontal/Vertical Thinking Distinction**
Koe's framework (knowing = horizontal, understanding = vertical) provides missing vocabulary for A2. Specialists have horizontal depth; the canon requires vertical depth (cross-domain integration that compounds). The "smart but dumb" phenomenon = horizontally advanced, vertically stuck.
> Key quote: "The 'smart but dumb' phenomenon stems from being horizontally advanced but vertically stuck."

**C4. Platform Gravity as Threat Model for A3**
OpenAI's stateful Responses API (ownership of execution loop), Google's data gravity (NotebookLM enterprise, 1M-token Gemini), and proprietary API lock-in are all A3 threats with network effects. The canon frames A3 as internal discipline; the library reveals it has external enemies.

**C5. Outcome-Based vs. Script-Based Verification**
The Anthropic eval document introduces a distinction absent from the canon: transcript verification (did the agent say the right things?) vs. outcome verification (did the environment change correctly?). A4's verify stage does not currently distinguish these.
> Key quote: "A flight-booking agent might say 'Your flight has been booked' at the end of the transcript, but the outcome is whether a reservation exists in the environment's SQL database."

**C6. The Autocatalytic Loop**
The research corpus preface articulates something the canon has not named: the Syncrescendence project is autocatalytic — AI generates intelligence about how to use AI, which improves AI use, which generates better intelligence. The loop accelerates beyond compound interest dynamics.
> Key quote: "The research corpus improves the capability that generated it. Better research sessions generate better synthesis. The loop accelerates."

**C7. The Progressive Disclosure Architecture as Format Principle**
Sutra → gloss → spec as a general information architecture principle (not just compression technique): agent-scannable (~7K words sutra-only), human-skimmable (sutra+gloss), implementation-depth (full spec). The canon uses Semantic Notation but has not elevated this to a universal content architecture principle.

**C8. Auteur as Identity-Under-Pressure Model**
The auteur framework maps coherence from film theory onto content creation: "interior meaning" allows a creator to maintain recognizable identity across wildly different surface topics. Three pillars (technical competence + distinguishable personality + interior meaning) is more specific than anything in the canon's treatment of A1 coherence for creative output.

---

### From Wave 2 (SOURCES-DIGEST-PROCESSED)

**C9. Thermodynamic Computing as Capacity Solution**
McCourt/Extropic provides the explicit energy math for AI scaling that the canon lacks. TSUs represent a concrete engineering response to A2 at the hardware level: "basic personal AI = 20% of US grid; video AI = 10x grid expansion." A2 has physical grounding through thermodynamics, not just attention economics.

**C10. Assembly Theory as Ontological Foundation for A3**
Walker's Assembly Theory provides rigorous physical grounding for why the repo matters: "Objects are embodied history" — this is a physical claim with empirical backing (assembly index threshold of 15), not a metaphor. The canon states the sovereignty axiom; Walker provides the physical theory behind it.
> Key quote: "The newest things are actually the oldest things — a smartphone contains more evolutionary history than a simple molecule."

**C11. Neuralese and the Interpretability Gap**
Models may think in internal language optimized for computation, not human interpretation (Douglas/Bricken). If we can't interpret what the "model" stage of A4 produced, we can't verify it. The pipeline has a verification gap that wasn't explicitly named before this source.

**C12. The Compounding Creative Framework**
Consumer → Curator → Creator → Compounder is a precise developmental stage model for A4 completion that the canon lacks. The neo-canon describes the pipeline but doesn't provide a developmental model for who does and doesn't complete it. "Creators produce linear value; Compounders produce compounding value."

**C13. The Verbatim Trap as Deployable Test**
A precise name and test for A4 distillation failure (molt_cornelius): "Did this produce anything the source didn't already contain?" is a single deployable verification step. This operationalizes A4's distill stage more precisely than any canon entry.

**C14. The Specification Class as Collective A3 Threat**
A concrete sociological threat to A1 and A3: a technocratic elite that defines AI reward functions holds semantic authority above individual sovereignty. This is a failure mode for A3 at societal scale — individual ground truth is insufficient if collective specification is captured.
> Key quote: "The specification class emerges as new locus of power." (AI Explained)

**C15. Skill Acquisition Efficiency as A2 Metric**
Chollet's ARC Prize framework quantifies the gap between LLM capabilities and human generalization: 4–5 orders of magnitude less efficient. This gives A2 a quantitative dimension — the constraint isn't just capacity, it's efficiency of capacity use.

**C16. Social Intelligence Explosion Mechanism**
Aguera y Arcas provides the concrete mechanism for why intelligence is social, not individual: minds model minds in recursive feedback loops; AI adds more intelligent entities to this loop; LLMs validate Wiener's 1943 cybernetic theory. The canon's A1 notes this but doesn't name the mechanism.

**C17. The Macrophage Problem (Impressive vs. Useful Gap)**
Dwarkesh's continual learning bottleneck: the biologist who can identify macrophages specific to one lab's slide preparation. No bespoke training pipeline worth building. This grounds the impressive-vs.-useful gap in concrete operational terms and adds urgency to the capacity framing in A2.

**C18. Six-Layer Agent Stack as Full Pipeline Architecture**
The Six-Layer Agent Stack (nickspiska: Data → Tools → Skills → Session/Memory → LLM → Agent Harness) provides the most complete external implementation of A4 found in the library. "Start with data, always" is A4's capture stage stated as a practitioner rule. The multi-model routing enabling 85% cost savings is A2's efficiency optimization applied to infrastructure.

---

## 3. Combined Gaps

### From Wave 1 (7 structural gaps)

| # | Gap | Description | Canon Status |
|---|-----|-------------|-------------|
| G1 | No Environmental Design Theory for A1 | A1 treats coherence as personal discipline; Moloch research reveals environments can be designed to deplete or protect coherence. Canon needs a section on environment design for coherence, not just personal practice. | ABSENT |
| G2 | No Physiological Model for A2 | Canon identifies capacity as constraint but treats it abstractly. Library provides: 50-bits/second ceiling, dopamine baseline, working memory as RAM. Without biological grounding, A2 is unfalsifiable. | ABSENT |
| G3 | No Threat Model for A3 | Canon describes A3 as internal commitment. Library reveals: OpenAI execution loop ownership, Google knowledge gravity, platform lock-in through APIs. A3 needs a threat registry with defensive responses. | ABSENT |
| G4 | A4 Verify Stage is Underdeveloped | Canon specifies verify as a gate but not as a methodology. Missing: transcript vs. outcome distinction, multi-trial requirement, bidirectional verification (Flowy), morphism integrity checking (type theory). | UNDERDEVELOPED |
| G5 | No Acceleration Model for the Autocatalytic Loop | Canon describes compound learning (Cherny's CLAUDE.md) but has not modeled the acceleration dynamics when multiple agents simultaneously improve the system that runs them. Distinct from compound interest. | ABSENT |
| G6 | No Defense Against the Fresh-Start Pattern | The "Ralph Pattern" (wipe context after every task) is a legitimate challenge to A4. If accumulated context is lossy by design, fresh-start may outperform accumulation in some regimes. A4 needs boundary conditions. | ABSENT |
| G7 | Cross-Domain Integration is Named but Not Operationalized | Polymath pattern, vertical thinking, auteur's interior meaning all point to cross-domain synthesis as the irreplaceable human contribution. Canon names it but has no practice protocol for it. Mechanism: deliberate confusion tolerance. | UNDERDEVELOPED |

---

### From Wave 2 (unique additional gaps)

| # | Gap | Description | Canon Status |
|---|-----|-------------|-------------|
| G8 | A1 Has No Evolutionary Foundation | Hoffman's Fitness Beats Truth Theorem shows coherence-seeking is selected against by evolution. Canon treats coherence as a rational goal; the library shows it requires active effort against evolutionary defaults. WHY is coherence worth the evolutionary cost? | ABSENT |
| G9 | A4 Cannot Be Completed by LLMs for Novel Knowledge | Deutsch's critique: LLMs are universal mimics, not universal explainers. If "model" stage requires genuine conjecture + criticism, current LLMs produce sophisticated shelfware for novel domains. A4 needs explicit scope conditions for LLM-incompletable tasks. | ABSENT |
| G10 | A3 Has No Collective Governance Layer | Individual sovereignty (repo = ground truth) is insufficient if the Specification Class captures the collective reward function. A3 is valid for individuals; it needs an extension for multi-agent and societal contexts. | ABSENT |

---

## 4. Combined Challenges

Axiom challenges organized by axiom. Internal challenges (from Wave 1 research library) and external challenges (from Wave 2 processed sources) combined.

### Challenges to A1

| Challenge | Source | Nature |
|-----------|--------|--------|
| Moloch adds coordination-failure dimension: individual coherence is insufficient if game-theoretic environment selects for defection | `20260110-x_thread-intuitmachine.md` | Extension (not refutation) — requires environmental design layer |
| Hoffman's Fitness Beats Truth Theorem: coherence may be actively counter-selected by evolution; perception is fitness-optimized interface, not veridical | SOURCE-20251014 | Deep structural challenge — requires coherence to be justified against evolutionary defaults |
| Israetel / functional understanding: if behavior is indistinguishable from understanding, coherence may require less ontological depth than A1 implies | SOURCE-20251224 | Scope challenge — may narrow what "remaining oneself" requires at a functional level |
| AI Explained / Specification Class: if technocratic elite defines AI reward functions shaping billions, personal coherence is structurally constrained by external optimization | SOURCE-20251030 | Collective-level challenge — individual agency over coherence may be limited by societal architecture |

### Challenges to A2

| Challenge | Source | Nature |
|-----------|--------|--------|
| 2026 AGI frame: if long-horizon agents operate autonomously for hours, the capacity constraint may become less binding; functional AGI routes around A2 | `20260114-2026_this_is_agi-@gradypb.md` | Temporal challenge — A2 may be transitional, not permanent |
| Alexander/Kokotajlo R&D multiplier: if AI bootstraps capacity expansion (5x by 2027), intelligence creates capacity that increases intelligence — the constraint is self-dissolving | SOURCE-20250403 | Bootstrapping challenge — valid at civilizational scale, though A2 remains valid at individual operational horizon |
| Israetel: processing power can substitute for embodied capacity — if sufficient compute substitutes for embodied experience, the constraint IS intelligence (compute) | SOURCE-20251224 | Substitution challenge — requires refining A2 as "efficient capacity," not raw capacity |

### Challenges to A3

| Challenge | Source | Nature |
|-----------|--------|--------|
| OpenAI's stateful Responses API: platform owns agent execution loop, shifting semantic authority to platform | `openai_research.md` | Platform capture — most direct external threat to A3 in the corpus |
| Google's data gravity: 1M-token context and grounded RAG create gravity wells that pull semantic authority off-repo | `google_research.md` | Infrastructure challenge — passive gravity vs. active defection |
| CLAUDE.md managed policy override: "Managed policies cannot be overridden" — enterprise deployment creates a sovereignty layer above the repo | `ajna9-fodder/3-unified/stream2-unified.md` | Hierarchy challenge — institutional A3 beats individual A3 |
| Shapiro / moatlessness: AI is intrinsically democratic; semantic authority cannot be maintained as moat | SOURCE-20251101 | Moat challenge — partially resolved by Walker (Assembly Theory): repo is sovereign over construction pathway, not capabilities |
| AI Explained / Specification Class: collective reward function capture overrides individual ground truth | SOURCE-20251030 | Collective challenge — A3 valid at individual level but structurally insufficient at societal level |
| Hoffman / Interface Theory: sovereignty may be an interface layer, not ground truth — "ground truth" may not exist below the fitness-optimized interface | SOURCE-20251014 | Philosophical challenge — deepest structural complication; partially resolved by Walker's physical grounding |

### Challenges to A4

| Challenge | Source | Nature |
|-----------|--------|--------|
| Fresh-Start Pattern / Ralph: wipe context after every task avoids context rot; compaction destroys specific details; accumulation may be inferior to reset in some regimes | `ajna9-fodder/Claude_Code_Dialectic_Divergences.md` | Accumulation challenge — requires explicit boundary conditions for when reset outperforms accumulation |
| Deutsch's Popperian critique: LLMs are universal mimics, not universal explainers; "model" stage requires genuine conjecture + criticism that LLMs cannot implement | SOURCE-20250902 | Completability challenge — current LLMs cannot complete A4 for novel knowledge domains |
| Gavranovic's categorical critique: LLMs cannot reliably do addition; pipeline breaks at verification for algorithmic/mathematical domains | SOURCE-20251222 | Verification challenge — no way to know if model stage produced insight or stochastic mimicry without adversarial testing |
| Neuralese (Douglas/Bricken): models may think in internal language humans can't interpret — if model stage is opaque, verification is impossible without interpretability tools | SOURCE-20250522 | Transparency challenge — verification gap is architectural, not procedural |

---

## 5. Convergence Vision Validation

### Strongest External Validation Evidence

**VE1. Civilizational Phase Transition — Independently Convergent**
Bratton (philosophy of technology), Walker (astrobiology), Aguera y Arcas (evolutionary biology), and Schmachtenberger (metacrisis) all independently arrive at the same conclusion: we are in a pre-paradigmatic civilizational phase transition. The neo-canon's convergence vision is validated by four independent theoretical frameworks from wholly different disciplines.

**VE2. Renaissance 2.0 Pattern — Historical Precedent Confirmed**
Shapiro, Bratton, and multiple others independently note the printing press → internet → AI compression cycle of epistemic gatekeeping. The AI cycle is orders of magnitude faster. The neo-canon's civilizational timeline is historically grounded.

**VE3. Collective Intelligence Expansion — Three Independent Confirmations**
Henrich (historically: collective brain), Aguera y Arcas (evolutionarily: social intelligence explosion), and Bratton (cosmopolitically: bringing new agents into the collective) all converge on the same insight: the relevant intelligence is collective, not individual. The neo-canon's five-ring model (SELF → AGENCY → WORK → COMMUNITY → WORLD) correctly maps this expansion.

**VE4. Post-Labor Economics as Convergence Precondition — Multiple Converging Sources**
AI Breakfast ("labor has negative value when human-in-the-loop introduces more risk than value"), Shapiro (capital and entrepreneurship survive), Yakovenko (permissionless economic execution), and Miessler ($40 trillion annual knowledge worker compensation at stake) all converge on: the relevant scarcity shifts from labor to position, from effort to infrastructure ownership. This validates the neo-canon's sovereignty emphasis.

**VE5. A2 as Most Externally Confirmed Axiom**
Energy/capacity constraints independently confirmed by: physics (McCourt/Extropic — thermodynamics), evolutionary biology (Walker — assembly theory), AI research (Douglas/Bricken — clean reward signal, Chollet — efficiency gap), and infrastructure economics (Huang — three scaling laws). A2 has the broadest and most diverse external confirmation of any axiom.

**VE6. A4 Failures are Well-Documented in Practice**
The Verbatim Trap (molt_cornelius), the Compounding Creative's "Creator vs. Compounder" distinction, the clean reward signal bottleneck (Douglas/Bricken), and Mollick's three-ingredient requirement all describe the same failure mode from different angles: the pipeline breaks at distillation and verification. This is not speculative — it is the modal outcome observed across the research community.

**VE7. Assembly Theory Grounds A3 in Physics**
Walker's Assembly Theory provides the strongest single piece of philosophical grounding for the repo as ground truth: "Objects are embodied history." The construction pathway is the value, not just the endpoint. This resolves the Shapiro moatlessness challenge: the repo is not sovereign because capabilities are unique, but because the construction pathway — 311 Rosetta Stone entries, 174 classified concepts, decision lineage — is irreplaceable.

---

## 6. Neo-Canon Candidates

All NATIVE and HERITAGE class entries that represent external intellectual heritage suitable for explicit citation in neo-canon documents, plus new external candidates not yet in the canon.

### From Heritage Map (Internal Canon — Already Derived)

These are NATIVE/HERITAGE concepts from the internal canon that should be explicitly cited as derived from external intellectual lineage:

| Concept | Class | External Lineage to Cite |
|---------|-------|--------------------------|
| DIKW Mandate | NATIVE | Russell Ackoff (1989 DIKW hierarchy); integrates cleanly with A4 |
| Kintsugi Principle | NATIVE | Japanese aesthetics (wabi-sabi tradition); anti-fragility via Nassim Taleb |
| Annual Dissolution Ceremony | NATIVE | Kuhn's paradigm shifts + Bateson's levels of learning as precursors |
| Synthesis Principle (metabolism not eclecticism) | SEED | Harold Bloom's "anxiety of influence" as the negative case; Emerson's self-reliance as the positive case |
| Progressive Trust Model | NATIVE | Herbert Simon's bounded rationality + principal-agent theory in economics |
| Coherence Synthesis System — Five Degrees | NATIVE | Bloom's Taxonomy (Recognition→Transmission mirrors Knowledge→Synthesis→Evaluation) |
| OODA Loop implementation | NATIVE | Boyd: should be explicitly cited in AGENTIC ARCHITECTURE section |
| Zettelkasten / connected knowledge | NATIVE | Luhmann: should be explicitly cited in MEMORY & SOVEREIGNTY section |

### New External Candidates (Not Yet in Canon)

These concepts emerge from the external sources library and are candidates for integration into the neo-canon as HERITAGE or NATIVE entries:

| Thinker / Concept | Source | Proposed Class | Target Canon Location |
|-------------------|--------|---------------|----------------------|
| Assembly Theory (Walker) — objects as embodied history | SOURCE-20250528 | NATIVE (A3 grounding) | MEMORY & SOVEREIGNTY / CANON-25000 extension |
| Collective Brain Theory (Henrich) — population × connectivity × transmission fidelity | SOURCE-20250312 | NATIVE (A1 extension) | FOUNDATIONAL / COSMIC FRAME |
| Fitness Beats Truth Theorem (Hoffman) — coherence is evolutionarily costly | SOURCE-20251014 | HERITAGE (A1 challenge requiring reframe) | EPISTEMOLOGY & LINEAGE — should be cited as the counter-argument that explains WHY A1 requires active effort |
| The Compounding Creative Framework (VVSVS) — Consumer → Curator → Creator → Compounder | NB14 | NATIVE (A4 developmental model) | CHAIN / DEVELOPMENTAL SPINE — developmental stage model for A4 completion |
| The Verbatim Trap (molt_cornelius) — "did this produce anything the source didn't contain?" | NB03 | SEED (A4 verify operationalization) | OPERATIONS & PROTOCOLS — deployable distillation test |
| Thermodynamic Sampling Units (McCourt/Extropic) — 10,000x efficiency via hardware-native sampling | SOURCE-20251031 | NATIVE (A2 engineering response) | HUMAN-AI SYMBIOSIS — physical A2 constraint response |
| Neuralese (Douglas/Bricken) — models think in internally optimized language humans can't interpret | SOURCE-20250522 | HERITAGE (A4 challenge) | AGENTIC ARCHITECTURE — verification gap flag for all A4 pipelines using LLMs |
| Moloch coordination infrastructure — defection visibility = verification gate | `20260110-x_thread.md` | NATIVE (A1/A3 coordination layer) | OPERATIONS & PROTOCOLS / ASIA Federation Constitution |
| Auteur Interior Meaning — three-pillar model for coherent creative identity | `20260202-auteur_theory.md` | NATIVE (A1 for creative output) | IDENTITY / CONSCIOUSNESS — operationalization of A1 for Ring 3 (WORK) |
| Progressive Disclosure Architecture — sutra/gloss/spec format | `ajna9-fodder/preface.md` | NATIVE (A2 applied to content architecture) | TOOL INTELLIGENCE & WORKFLOW — content format standard |
| Specification Class (AI Explained) — technocratic elite captures collective reward functions | SOURCE-20251030 | NATIVE (A3 collective threat) | STRATEGY & TIMELINE / GAIAN VISION — civilizational risk layer |
| Continual Learning Gap / Macrophage Problem (Dwarkesh) — no bespoke training loop worth building | SOURCE-20251223 | NATIVE (A2 precision) | HUMAN-AI SYMBIOSIS — grounds impressive-vs.-useful gap operationally |
| Six-Layer Agent Stack (nickspiska) — Data→Tools→Skills→Session/Memory→LLM→Harness | NB10 | NATIVE (A4 full architecture) | AGENTIC ARCHITECTURE — most complete external A4 pipeline implementation |
| Recursive Language Model (deepfates) — agent lives in REPL, human becomes function | NB06, NB14 | HERITAGE (requires reframe: human/AI co-constitution) | HUMAN-AI SYMBIOSIS / ANTHROMACHINA — architectural dissolution of the human/AI boundary |
| Outcome vs. Transcript Verification (Anthropic Evals) | `20260109-demystifying-evals.md` | SEED (A4 verify methodology) | OPERATIONS & PROTOCOLS / CANON-30460 extension |

---

## 7. Complete Source Inventory — Wave 2 Processed Sources (42 Sources)

High-signal entries with axiom mappings. Full catalog for traceability.

| # | Source ID | Thinker / Creator | Core Thesis (compressed) | Primary Axiom | Signal |
|---|-----------|------------------|--------------------------|---------------|--------|
| 1 | SOURCE-20250312 | Joseph Henrich | Collective brain: progress = population × connectivity × transmission fidelity | A1, A2 | HIGH |
| 2 | SOURCE-20250320 | Benjamin Bratton | Pre-paradigmatic moment; computation as planetary infrastructure | A1, A3 | HIGH |
| 3 | SOURCE-20250403 | Scott Alexander + D. Kokotajlo | Month-by-month AGI forecast; R&D multiplier; branch point 2027 | A2, A4 | HIGH |
| 4 | SOURCE-20250522 | Sholto Douglas + T. Bricken | RL works with clean reward signals; Neuralese = interpretability gap | A2, A4 | HIGH |
| 5 | SOURCE-20250528 | Sara Imari Walker | Assembly Theory: objects are embodied history; technosphere is life | A3, A4 | HIGH |
| 6 | SOURCE-20250605 | Ethan Mollick | "Jagged" AI capability; 3 ingredients for AI adoption; knowledge collapse risk | A2, A4 | HIGH |
| 7 | SOURCE-20250623 | Blaise Aguera y Arcas | Five paradigms of intelligence; consciousness = self-modeling; social intelligence | A1, A2 | HIGH |
| 8 | SOURCE-20250807 | Blaise Aguera y Arcas | Brains = autocomplete; symbiogenesis; narrative memory gap | A1, A2 | HIGH |
| 9 | SOURCE-20250902 | David Deutsch | Current AI lacks explanatory knowledge; pattern matching ≠ understanding | A4 challenge | HIGH |
| 10 | SOURCE-20250903 | Max Tegmark | Intelligence as physical process; Fermi nuclear analogy; substrate independence | A2, A3 | MEDIUM-HIGH |
| 11 | SOURCE-20250912 | Sergey Levine | Robotics approaching ImageNet moment; foundation models for physical intelligence | A4, A2 | MEDIUM-HIGH |
| 12 | SOURCE-20251013 | Matthew Kinsella | Quantum narrative shifted to "when"; GPUs are heuristics; quantum = reality | A2 | MEDIUM |
| 13 | SOURCE-20251014 | Donald Hoffman | Fitness Beats Truth Theorem; perception = species-specific interface | A1 challenge, A3 challenge | HIGH |
| 14 | SOURCE-20251020 | Reid Hoffman | AI investing blind spots; intelligence ≠ power; friendship requires bidirectional commitment | A2, A1 | MEDIUM |
| 15 | SOURCE-20251020 | Ben Goertzel | AGI unlikely from Big Tech (innovator's dilemma); hybrid transformers + multi-agent required | A2 | MEDIUM |
| 16 | SOURCE-20251021 | Chris Kempes | Universal Hierarchy of Life; phase transitions at walls; culture qualifies as life | A2 | MEDIUM-HIGH |
| 17 | SOURCE-20251021 | Bryan Johnson | "Don't Die"; autonomous health systems; capitalism-as-scarcity obsolete | A2, A1 | MEDIUM-HIGH |
| 18 | SOURCE-20251023 | Scale AI Panel | MCP as de facto agent tool integration standard; first real-world agent evals | A4, A3 | HIGH |
| 19 | SOURCE-20251024 | Francois Chollet | Intelligence = skill acquisition efficiency; LLMs 4-5 OOM less efficient; ARC v3 | A2, A4 | HIGH |
| 20 | SOURCE-20251024 | Henrik von Scheel | Engineering → integrative intelligence; half of knowledge obsolete in 5 years | A2 | MEDIUM |
| 21 | SOURCE-20251025 | Blaise Aguera y Arcas | Von Neumann predicted DNA; self-replicating programs; narrative memory gap | A3, A4 | HIGH |
| 22 | SOURCE-20251027 | John Martinis | Useful quantum computers in 5-10 years; drug discovery as killer app | A2 | LOW-MEDIUM |
| 23 | SOURCE-20251027 | Cathie Wood | Productivity-driven recovery; Bitcoin; AI limiting new-grad opportunities | Context | LOW |
| 24 | SOURCE-20251028 | Jensen Huang | Three scaling laws; AI Factory economics ($1-2B→$40-45B/yr); Physical AI next | A2, A4 | HIGH |
| 25 | SOURCE-20251029 | Sam Altman + J. Pachocki | Superintelligence <decade; task horizon metric; test-time compute; AI researchers 2027 | A2, A4 | HIGH |
| 26 | SOURCE-20251030 | Anatoly Yakovenko | AI agents as primary blockchain users; cheaper intelligence = more markets | A2, A3 | MEDIUM-HIGH |
| 27 | SOURCE-20251030 | AI Explained | AI becoming distinct subsystem; Specification Class as new power locus | A1 challenge, A3 | HIGH |
| 28 | SOURCE-20251031 | Marc Andreessen + B. Horowitz (a16z) | AI = platform shift; creativity is remixing; intelligence ≠ leadership | A2, A1 | MEDIUM-HIGH |
| 29 | SOURCE-20251031 | Marc Andreessen + B. Horowitz (Runtime) | Narrative memory gap; build around problems not tech | A3, A1 | MEDIUM |
| 30 | SOURCE-20251031 | Elon Musk (All-In) | Grokipedia: multi-perspectival contested topics; open-source AI = distributed sovereignty | A1, A3 | MEDIUM |
| 31 | SOURCE-20251031 | John Gaeta | AI = "permission to attempt"; transmedia storytelling; technical convergences = creative singularities | A4, A2 | MEDIUM-HIGH |
| 32 | SOURCE-20251031 | Elon Musk (JRE) | Post-app AI future 5-6 years; training data bias = coherence corruption | A1, A3 | MEDIUM |
| 33 | SOURCE-20251031 | Trevor McCourt / Extropic | Energy = AI constraint (20% of US grid); TSUs = 10,000x more efficient | A2 direct | HIGH |
| 34 | SOURCE-20251031 | David Shapiro | AI refactors economy; scarcity resolves to physics; firms persist for capital risk | A2, A4 | HIGH |
| 35 | SOURCE-20251031 | No Priors Compilation | Harvey: GPT-3 quality in legal; Fei-Fei Li: spatial intelligence; Hendrycks: superintelligence geopolitics | A2, A4 | MEDIUM-HIGH |
| 36 | SOURCE-20251101 | David Shapiro | Open-source AI is moatless; printing press → internet → AI; Renaissance 2.0 | A3 challenge | HIGH |
| 37 | SOURCE-20251222 | Bruno Gavranovic | Deep learning in "alchemy phase"; LLMs cannot do addition; categorical DL | A4 challenge | HIGH |
| 38 | SOURCE-20251222 | a16z Panel (Agents 2026) | Death of prompt box; five-tier employee model; AEO replaces SEO | A4, A2 | HIGH |
| 39 | SOURCE-20251223 | Mike Krieger / Anthropic | 2026 = "reliably take work off plate"; enterprise infrastructure year; MCP adoption | A4, A2 | HIGH |
| 40 | SOURCE-20251223 | Dwarkesh Patel | Models improve fast, become useful slow; continual learning gap; hive mind distillation | A2, A4 | HIGH |
| 41 | SOURCE-20251224 | Mike Israetel | ASI by 2045; embodiment not required; processing substitutes for experience | A2 challenge, A1 | MEDIUM |
| 42 | SOURCE-20251226 | David Shapiro | Scaling paradox resolved; multiple simultaneous capacity vectors | A2, A4 | HIGH |

---

## 8. Research Notebook Signal Summary (15 Notebooks)

| Notebook | Theme | Lines | Signal | Primary Axiom |
|----------|-------|-------|--------|---------------|
| NB01 OpenClaw Architecture | Agent personality + memory architecture; week-8 dark pattern | 40 files | HIGH | A3, A4, A2 |
| NB02 Agent Security Hardening | Top-10 vulnerabilities; sandboxing; prompt injection | 14 files | MEDIUM | A3, A2 |
| NB03 Agent Memory Systems | Three-Layer Architecture; Verbatim Trap; Context Graph | 17 files | VERY HIGH | A3, A4, A1 |
| NB04 Agentic Note-Taking & Vaults | Obsidian + Claude Code; compounding OS; Minority Report interface | 11 files | VERY HIGH | A3, A4, A1 |
| NB05 Claude Code / Cowork Patterns | Skills marketplace; hooks automation; skills vs. tools | 31 files | HIGH | A4, A2, A3 |
| NB06 Multi-Agent Orchestration | Fleet from Mac Mini; RLM architecture; parallel vs. sub-agents | 23 files | VERY HIGH | A2, A4, A3 |
| NB07 Economic Reckoning | Post-labor; $40T knowledge work; SaaS death; AI broke people first | 30 files | VERY HIGH | A1 world, A2, A4 |
| NB08 Vibe Coding & Software Abundance | Vibe coding → agentic programming; engineering identity crisis | 18 files | MEDIUM | A4, A2 |
| NB09 Design in AI Era | Figma disruption; designer as creative director; direct design | 9 files | MEDIUM | A4, A2 |
| NB10 AI Engineering Roadmaps | Six-Layer Agent Stack; 2026 roadmap; self-hosted stack | 19 files | HIGH | A3, A4, A2 |
| NB11 OpenClaw Deep Research | 5 PROMPT + 5 RESPONSE pairs; constellation research | 10 files | VERY HIGH | A4, A3 |
| NB12 Homelab Infrastructure | Mac Mini as agent platform; VPS hardening; Cloudflare Tunnel | 12 files | LOW-MEDIUM | A3, A2 |
| NB13 Prompt Engineering & Skills | 25 practical patterns; skills as crystallized expert intent | 19 files | HIGH | A4, A2 |
| NB14 Philosophical Wildcards | Compounding Creative; RLM architecture; coherence in AI era | 15 files | HIGH | A1, A4, A2 |

---

*Total lines: ~500 | Commander (Claude Code — Sonnet 4.6) | 2026-02-17*
*Wave 1 source: SOURCES-DIGEST-RESEARCH.md (746 lines)*
*Wave 2 source: SOURCES-DIGEST-PROCESSED.md (~750 lines)*
