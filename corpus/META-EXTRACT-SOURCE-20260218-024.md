# Extraction: SOURCE-20260218-024

**Source**: `SOURCE-20260218-x-thread-minchoi-this_is_big_anthropic_just_published_a.md`
**Atoms extracted**: 6
**Categories**: claim, concept, framework

---

## Claim (4)

### ATOM-SOURCE-20260218-024-0002
**Lines**: 7-10
**Context**: consensus / evidence
**Tension**: novelty=0.20, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.90

> Software engineering accounts for nearly 50% of all tool calls made by AI agents, based on data from Anthropic's public API (n = 998,481).

### ATOM-SOURCE-20260218-024-0004
**Lines**: 29-31
**Context**: consensus / evidence
**Tension**: novelty=0.30, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.80

> The 99.9th percentile 'work time' for Claude Code, representing how long it works before stopping, nearly doubled from under 25 minutes to over 45 minutes in approximately three months (late September to early January), indicating increased autonomous operation.

### ATOM-SOURCE-20260218-024-0005
**Lines**: 40-42
**Context**: consensus / evidence
**Tension**: novelty=0.30, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.80

> Experienced users of Claude Code have a higher auto-approval rate (over 40%) compared to new users (~20%), but they also interrupt the agent more frequently, shifting oversight from approving every step to monitoring and intervening.

### ATOM-SOURCE-20260218-024-0006
**Lines**: 50-51
**Context**: consensus / evidence
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.70

> On complex tasks, Claude Code stops to ask questions more than twice as often as humans interrupt it, indicating agent-initiated oversight.

## Concept (1)

### ATOM-SOURCE-20260218-024-0003
**Lines**: 19-20
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.10, actionability=0.50, epistemic_stability=0.80

> Anthropic defines an AI agent as a model combined with tools that enable it to take actions.

## Framework (1)

### ATOM-SOURCE-20260218-024-0001
**Lines**: 3-5
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.70

> Anthropic has published a framework for measuring AI agent autonomy, which assesses how independently an AI can plan, use tools, recover from mistakes, and complete tasks end-to-end.
