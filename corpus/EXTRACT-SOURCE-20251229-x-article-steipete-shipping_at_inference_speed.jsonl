{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0001", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "The author can now ship code at an unreal speed due to advancements in \"vibe coding\" with AI agents.", "line_start": 6, "line_end": 7, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.2, 0.7, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0002", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "The argument that writing code is necessary to understand bad architecture and that agents create disconnection is disagreed with; spending enough time with agents allows one to know how long tasks should take, making one suspicious if an agent like Codex doesn't solve a problem quickly.", "line_start": 10, "line_end": 13, "chaperone": {"context_type": "rebuttal", "argument_role": "claim", "tension_vector": [0.4, 0.6, 0.3, 0.2, 0.5, 0.5], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0003", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "The amount of software the author can create is primarily limited by AI inference time and the need for hard thinking, with most software not requiring hard thinking as it mainly involves data manipulation and display.", "line_start": 15, "line_end": 18, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.4, 0.5, 0.1, 0.3, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0004", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "praxis_hook", "content": "For building software with AI agents, start with a CLI as the simplest form, allowing agents to directly call it and verify output, thus closing the loop.", "line_start": 18, "line_end": 20, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.2, 0.8, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0005", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "GPT 5 was a significant unlock for building software like a factory, leading the author to trust the model more and reduce the need to read much code, instead focusing on system design and component structure.", "line_start": 22, "line_end": 28, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.3, 0.6, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0006", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "Key decisions in software development now revolve around language/ecosystem and dependencies, with TypeScript for web, Go for CLIs, and Swift for macOS/UI being the author's preferred choices.", "line_start": 30, "line_end": 32, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.5, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0007", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "Go has become a preferred language because AI agents are effective at writing it, and its simple type system facilitates fast linting.", "line_start": 32, "line_end": 34, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.4, 0.5, 0.1, 0.2, 0.6, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0008", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "For Mac or iOS development, Xcode and xcodeproj files are often no longer necessary, as Swift's build infrastructure and AI agents like Codex can handle most tasks, including running iOS apps and dealing with the Simulator.", "line_start": 36, "line_end": 39, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.3, 0.7, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0009", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "Benchmarks for AI models like Opus and Codex are becoming less trustworthy, and direct experience is needed to understand their differences.", "line_start": 42, "line_end": 44, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.3, 0.2, 0.3, 0.4, 0.5], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0010", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "Codex is trained to read a significant amount of code before starting, sometimes silently for 10-15 minutes, which increases the chance of fixing the correct issue, unlike Opus which is more eager but can miss parts in larger tasks.", "line_start": 44, "line_end": 46, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.5, 0.4, 0.2, 0.3, 0.6, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0011", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "Opus has a special quality that makes it enjoyable to work with, distinguishing it from models like GPT-5 for general-purpose tasks and powering the author's AI agent, Clawd.", "line_start": 46, "line_end": 48, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.2, 0.1, 0.2, 0.1, 0.4], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0012", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "praxis_hook", "content": "When working with agentic engineering, develop a feeling for what tasks will be easy and where the model will struggle, allowing for efficient prompting where the model can work independently for extended periods.", "line_start": 57, "line_end": 60, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.1, 0.6, 0.7, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0013", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "praxis_hook", "content": "Utilize a queueing feature for new ideas in an agentic pipeline, as multi-agent orchestration or automatic task management systems are often unnecessary, with the human being the primary bottleneck.", "line_start": 62, "line_end": 65, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.5, 0.3, 0.1, 0.2, 0.8, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0014", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "An iterative approach to software building, involving building, playing, and refining based on 'feel,' is more effective than systems requiring a complete initial idea, as the problem domain often evolves through exploration.", "line_start": 65, "line_end": 71, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.7, 0.5], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0015", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "praxis_hook", "content": "To manage multiple projects, use an agent to run in the project folder and, upon discovering a new pattern, instruct it to apply the change across all recent Go projects and update their changelogs.", "line_start": 67, "line_end": 70, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.1, 0.2, 0.8, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0016", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "praxis_hook", "content": "Automate tasks by creating 'skills' for agents, such as registering domains, changing DNS, writing frontends, or controlling specific devices on a network (e.g., 'go to my mac studio and update xxx').", "line_start": 72, "line_end": 75, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0017", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "Working on two Macs simultaneously, with one as a primary workstation and the other accessed via Jump Desktop for specific tasks, simplifies managing projects and avoids UI/browser automation popups on the main machine.", "line_start": 77, "line_end": 82, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.2, 0.1, 0.1, 0.7, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0018", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "Using a remote Mac Studio for tasks allows them to continue running even when the MacBook is closed, making it a reliable main workstation when traveling.", "line_start": 85, "line_end": 86, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.2, 0.1, 0.1, 0.7, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0019", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "Asynchronous agents like Codex or Cursor web lack steerability and add complexity due to pull request workflows, making the simplicity of the terminal preferable for certain tasks.", "line_start": 86, "line_end": 89, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.2, 0.2, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0020", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "Slash commands are often not useful, with 'skills' replacing some functionality and direct typing (e.g., 'commit/push') being equally efficient and more reliable.", "line_start": 91, "line_end": 93, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.1, 0.2, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0021", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "praxis_hook", "content": "Instead of dedicated refactoring days, address code cleanup and optimization ad-hoc, immediately dealing with issues when prompts take too long or 'ugly' code appears in the stream.", "line_start": 95, "line_end": 97, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.2, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0022", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "claim", "content": "Issue trackers like Linear often don't stick for personal use; important ideas are tried immediately, and less important ones are either remembered or deemed not critical.", "line_start": 99, "line_end": 101, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.1, 0.2, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0023", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "praxis_hook", "content": "When finding a bug, immediately prompt an AI to address it, as this is faster than writing it down and later switching context.", "line_start": 101, "line_end": 103, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.3, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20251229-x-article-steipete-shipping_at_inference_speed-0024", "source_id": "SOURCE-20251229-x-article-steipete-shipping_at_inference_speed", "category": "praxis_hook", "content": "When building anything, start with the core model and a Command Line Interface (CLI) first to ensure the core functionality is robust before developing additional interfaces like Chrome extensions.", "line_start": 105, "line_end": 108, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.2, 0.9, 0.8], "opposes_atom_ids": []}, "extensions": {}}
