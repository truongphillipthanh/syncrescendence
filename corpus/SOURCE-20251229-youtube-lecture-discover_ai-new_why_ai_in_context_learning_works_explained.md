# NEW: Why AI In-Context Learning Works (Explained)

**Channel**: Discover AI
**Published**: 2025-12-29
**Duration**: 31m 22s
**URL**: https://www.youtube.com/watch?v=mOjWG7hxPUI

## Description (no transcript available)

How exactly does In-context Learning happen? What are the exact learning algorithms inside the transformer layers that activate what we call activations? What is their relation to the fine-tuning with optimized weight tensor structures? Why are they correlated? 

Is ICL just another form of Fine-tuning as a Rank-1 update function in the weight tensor space? Could it be that simple? Did we design the transformer architecture with open degrees of freedom, we are just now discovering? 

All rights w/ authors:

Pre-print ONE
Learning without training:
The implicit dynamics of in-context learning
Benoit Dherin∗
Google Research
dherin@google.com
Michael Munn∗
Google Research
munn@google.com
Hanna Mazzawi∗
Google Research
mazzawi@google.com
Michael Wunder
Google Research
mwunder@google.com
Javier Gonzalvo
Google Research
xavigonzalvo@google.com

Pre-Print TWO
A Simple Generalisation of the Implicit Dynamics of
In-Context Learning
Francesco Innocenti1, 2, 3 El Mehdi Achour4
1MRC Brain Network Dynamics Unit, University of Oxford, UK
2MRC CoRE in Restorative Neural Dynamics, UK
3University of Sussex, Brighton, UK
4University Mohammed VI Polytechnic, College of Computing, Rabat, Morocco
Correspondence to: francesco.innocenti@ndcn.ox.ac.uk

#airesearch 
#aiexplained 
#artificialintelligence 
#ailearning
