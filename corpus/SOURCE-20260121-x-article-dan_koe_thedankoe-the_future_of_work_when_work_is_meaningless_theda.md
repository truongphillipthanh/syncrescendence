---
id: SOURCE-20260121-002
title: "The Future Of Work When Work Is Meaningless @Thedankoe"
platform: x
format: article
creator: DAN KOE (thedankoe)
date_published: 20260121
status: triaged
original_filename: "research/20260121-x_article-the_future_of_work_when_work_is_meaningless-@thedankoe.md"
aliases:
  - "Dan Koe Future of Work"
  - "Meaning Crisis Work"
teleology: strategize
notebooklm_category: philosophy-paradigm
synopsis: "Dan Koe explores what happens to creative work and meaning when AI automates most production. Traces the meaning crisis through societal evolution (premodern to metamodern), argues that meaning itself becomes the scarce good in a post-AGI economy, and proposes that human experience, struggle, and curiosity are the irreplaceable elements."
key_insights:
  - "In a world without scarcity, becoming the scarce good requires cultivating irreplaceable human qualities — lived experience, taste, and meaning-making capacity"
  - "The meaning crisis predates AI — automation merely accelerates the collapse of meaning structures that industrialization already hollowed out"
  - "Creative work survives AGI precisely because it emerges from subjective human experience that cannot be replicated by pattern-matching"
topics:
  - philosophy
  - career
  - content-creation
  - ai-engineering
  - opinion
  - framework
signal_tier: paradigm
url: "https://x.com/thedankoe/status/2014022520513634718"
author: "DAN KOE (@thedankoe)"
captured_date: 2026-01-21
---

# The Future of Work When Work Is Meaningless

Everyone is worried about whether or not AI will replace them.

But I can't help but think that there is something about the human experience that can't be replaced.

I can't help but think that humans will still want to work. That is, they will still want to create something, share it with another, and be recognized for their contribution by receiving some form of currency in return. This is a fundamental aspect of human nature, but it's unfortunate that "work" has become a dirty word stripped of meaning as productivity has become our God.

I am less concerned with industrial factory-style work being automated. We all know what that soulless pit does to a person.

I am much more concerned with creative work.

What will that future look like?

Will money become obsolete?

Will AGI write all prose and create all art?

If struggle, status, and curiosity are the generators of meaning, and AGI promises to rid us of such, what do we do?

What is the one thing that AGI can't replace, if anything?

In a world without scarcity, how do you become the scarce good?

I want to share 6 ideas on the future of work, the skills and traits you must optimize for as a creative, and ultimately how to live a meaningful life in a future that feels daunting. I'll share both my own thoughts and theories that I believe hold relevant weight.

And if you are a creative who wants to know if AI will ever replace your work, this is for you.

(By the way, my articles are long. If you don't have time right now, bookmark it, but I don't expect this to please those with goldfish attention spans. My goal with these is for you to understand rather than collect a bunch of bullet points that sound nice but do nothing for you.)

## I – The Meaning Crisis Makes Meaning Worth Paying For

(Description: A monochromatic, sketch-like illustration showing a crowd of mechanical humanoid figures with circular optical lenses for eyes, arranged in formation across a landscape. The figures have a dystopian, mass-produced appearance with intricate mechanical detailing visible on their bodies and armor-like coverings. The scene evokes themes of automation, conformity, and loss of individuality.)

Meaning has become a scarce good.

It's not hard to see that.

But to understand how we got into this mess, a little history lesson helps.

You see, reality develops toward greater complexity over time. When things become too complex or chaotic, a new ordered structure (or a new whole to envelop the parts) must emerge.

A few simple examples:

- Letter → Word → Sentence → Paragraph
- Atom → Cell → Molecule → Organism
- Matter → Life → Mind → Spirit

This is how reality is structured.

When it comes to meaning, I want to focus on how societies have evolved, which can be seen in two ways:

1) The techno-economic base (or dominant mode of production) of past societies and specific technology used.

Foraging → Horticultural → Agrarian → Industrial → Informational → Whatever comes next (Intelligence?)

2) The dominant worldview and value structure of people within those societies (their meaning-making system).

Premodern → Modern → Postmodern → Whatever comes next (Metamodern?)

For brevity, we can speedrun the first few.

Foraging societies were hunter-gatherers. Easy. In horticultural societies, men were the hunters and women tended small plots. In agrarian societies, food came from large scale farming, enabling massive surpluses, allowing men to work less so they could use their new time to explore, discover, and conquer.

The technologies of these societies developed from:

Axes, spears, and fire → Hoe and digging sticks → Animal drawn plow (from human labor to animal labor).

All of these societies fell largely within the premodern worldview.

In other words, meaning is given by a higher power (elders, scriptures, kings, priests). You were told what to believe. You conformed. Agency was a trait that could get you killed or cast out.

Then came the Industrial Age, where food production came from mechanized agriculture. Fewer farmers fed more people, food became a commodity. The primary technologies were steam, coal, and oil. Human and animal labor were needed far less.

One key insight here is that the techno-economic base of a society creates the conditions for a new level of worldview and value system to be possible at scale.

An industrial society allowed for the modern worldview to take hold that valued rationality. Meaning was discovered through reason, science, and evidence rather than inherited by tradition. Nature became disenchanted, progress replaced the divine, and merit replaced birthright.

That's where things started to go wrong.

First, productivity became overemphasized at a young age. The second you were born, you were already expected to go to school, get a job, and become a cog in the machine. You were programmed like a robot since the start.

Second, we disconnected from the tribe, village, and community. We are alone in a big digital world of artificial connection.

Third, religious and spiritual frameworks were replaced with the mechanical model of the universe. Meaning was no longer given by the divine.

Fourth, we began outsourcing our agency to institutions and forgot the value of self-directed work. 9-5 jobs replaced the work of artisans and farmers.

These have all led to a corruption in what we do and how we work. Work was broken into simple, repetitive tasks that kept workers dumb to the entire process so they couldn't replicate it on their own (why generalists always beat specialists, as we've discussed in previous articles).

In other words, meaningless work became our sole focus and means of survival. So much so that we can't see it any other way, and many people are in for a rude awakening when AI does remove this cancer from us.

That leads to the Information Age, where the invention of the computer led to a further abstraction from labor. We now sit at desks to work rather than tending fields - for the most part - and allow machines to do the heavy lifting.

The dominant worldview now is Postmodern, where we have begun to deconstruct everything prior.

(By the way, I promise this is relevant to the future of work).

The key insight of postmodernism is aperspectivalism, or that no perspective is privileged. All views are situated, partial, and contextual. This is a great achievement, because we now know that one view is not the one true and absolute view (religiously, politically, etc) that everyone must conform to.

This achievement, however, has only accelerated the meaning crisis even further. So much so that we are waking up to the fact that something has to change.

It also leads to a contradiction that must be solved in the next stage of development (the age of intelligence) we are entering:

If no perspective is better, truer, or more developed than another, then the claim that all perspectives are equally valid is a perspective you are claiming is better. It is a value ranking. You deconstruct all hierarchies by creating your own.

Postmodernism correctly saw that no perspective is absolute, but then incorrectly concluded that no perspective is better.

Some perspectives are, in fact, better.

Why does this matter?

First, meaning effectively evolved as so:

Meaning from "Up There" (the Gods) → Meaning from "Out There" (productivity and progress) → Meaning From "Nowhere" (supposed equality) → What comes next (Meaning From "In Here?")

Second, taste is a core skill that will matter going into the future, demanding that you say one thing is better than another. It demands exclusion.

Third, agency is also becoming a core survival skill. Very few people of the past consciously embodied it.

Fourth, your individual perspective may just be the one thing that AGI can't replace. It may just be your competitive edge in your creative work.

Fifth, creatives are the meaning-architects of a society, and if the baby is thrown out with the bathwater (jobs), the result could be catastrophic.

And last, we're smack in the middle of chaos, demanding a new structure to emerge. We get to play a role in how the future is formed. This is one massive reason why I write so much.

Further, productivity is no longer a reliable identity.

Nobody knows what path to take or what skill to learn.

Meaning is at an all time low, but so is certainty and security.

So what's the next stage?

What can we learn to ensure that we don't enter this new world at a massive disadvantage?

To understand that, we must understand the emerging techno-economic base (artificial intelligence), because that creates the conditions for the next worldview, and thus what we value, and even further what we do.

Important stuff.

## II – The Acceleration of AI (and Meaninglessness)

(Description: A complex spiral/concentric circle diagram showing ego development theory with two primary axes: "WE culture and worldview" (left side) and "ITS social system and environment" (right side). The diagram displays multiple numbered stages (1-8) moving outward from a central point labeled "archaic," showing progression through psychological development stages including: survival clans, ethnic tribes, feudal empires, early nations, corporate states, value communities, integral commons, and holistic meshworks on the right; and corresponding stages on the left including: instinctual, beige, purple (magic), red (mythic), blue (ecocentric), orange (achiever), green (sensitive self), and teal (integral) levels. The diagram uses dotted radial lines and text labels to organize the developmental continuum.)

AI promises to remove us of all labor.

At least that's what the hype is all about and what everyone is focused on.

It promises to provide the necessities so that we no longer live in scarcity.

But by all measures, the way in which it does so only increases the scarcity of meaning. Many people, including myself, derive meaning from a certain type of labor. I am not anti-AI in slightest, but I do not see a world where AI removes the craft from the creative.

But why?

Why will work disappear?

And what replaces the economic function of jobs?

To get a full picture, David Shapiro's Post Labor Economics is a useful theory for what the future could look like.

The problem that's on everyone's mind is this:

Since jobs have been a thing (working for a wage), companies pay the workers, workers spend the money, companies make the money, and the cycle continues.

But then AI comes along and threatens it all.

As a company, the thought of having a machine do all your work is enticing. Humans are expensive, complicated, emotional, and legally risky. Up until now, the only option was to hire humans.

Once AI and robots cross the "better, faster, cheaper, safer" threshold for given job (let's assume they actually do reach that point, we can only guess for now), it becomes economically irrational to keep humans doing the work. Irrational does not mean immoral or optional. I'm not here to take a stab at the morality of doing this.

It's irrational because the hoe replaced the digging stick. The animal drawn plow replaced the hoe (and allowed a new class of explorers and conquerers to emerge). Industrial machines replaced the plow. With each evolution, the power and potential of an individual who utilized the tools increased. In today's world, an individual can run a more lean and profitable business than many corporations could in the past. You can learn anything and build anything, but even with that power, most people will do nothing, and those who do will be in endless competition with each other, making us all ask where one's competitive advantage lies.

But of course, there's a huge problem with AI replacing all jobs.

If everyone gets fired, no one has money. If no one has money, no one buys anything. If no one buys anything, the economy collapses.

As we'll find, the above sentence applies to people with jobs, not people with companies, and I can't help but think about this quote from Naval:

There are almost 7B people on this planet. Someday, I hope, there will be almost 7B companies.

Right now, most people are worried about how they'll get paid if they don't have a job. The only three ways households get money is as so:

- **Wages** – Someone pays you for your labor (employer, customer, self-employment)
- **Transfers** – Government pays you (UBI, Social Security, SNAP, Medicare)
- **Capital Income** – Your assets pay you (dividends, rent, interest, appreciation)

If the first collapses, the second and third have to carry the weight. But transfers alone create political instability and lose price signals. It just won't work as an overall solution.

Meaning, one potential solution would be broadening capital participation. Regular people would own income-generating assets.

To keep this brief, I will not list all of the proposed mechanisms for this. Because the truth is that some people, especially creatives, will still want to work and be acknowledged for their work. That's what we're here to talk about.

Personally, I do not want to sit around and collect a baseline level of cash. Much of the meaning in my life comes from growing personally and professionally across various domains of life, and growth requires agency, and if money shifts from a productivity metric to a way to express agency, that is the path I would want to pursue.

I would recommend digging further into Shapiro's ideas and following him for when his comprehensive book on this topic, Labor Zero, comes out.

Fortunately, there are jobs that may persist even when automation is superior. These jobs are based on humans specifically demanding other humans:

- High-liability roles (where there's someone to blame)
- Statutory positions (legally required humans)
- Experience economy (bartenders, boutiques, art)
- Meaning makers (helping people navigate the human experience)
- Relationship/trust jobs (sales, diplomacy, negotiation)

As an everyday creative, I want to focus on the third and fourth option.

That is what humans will pay a premium for.

But before we talk about how to join the new meaning economy or what high-level skills are required, we've missed something critical, which is how meaning is generated in the first place.

## III – The Evolution and Anatomy of Meaning (Robots vs Humans)

The elegance of the future is not in man versus machine but in their division of labor: silicon sanding the rough edges of necessity so carbon can ascend to meaning. We will abolish baristas and canonize chefs, silence agents and encore actors. It is the same selfish instinct in both arenas—purge friction, preserve narrative—driving a world where the driest chores are done by circuits and the juiciest stories are told by people who bleed. – Chris Paik

For most of history, humans found meaning - or a reason to live - by looking up to the sky.

"Up there."

Meaning was given.

Then, we got smarter, supposedly. We made productivity our God. We looked to science and reason for meaning.

"Out there."

Meaning was earned.

Now, we've become too smart for our own good. We looked for meaning in relativity and couldn't find it.

"Nowhere."

Meaning was deconstructed.

Going into the future, it is your job to pick up the pieces. You must accept your role as the creator you are. The tool builder. The explorer. The problem solver. If you outsource too much of your agency to the machines, they will be just fine having you hooked up to a collective dopamine IV.

(Description: An animated scene showing three stylized human figures in a vibrant, neon-lit futuristic cityscape. The figures are wearing red and white outfits, captured mid-expression with exaggerated facial features characteristic of 3D animation. The background features colorful urban architecture with bright pink, blue, and orange neon signage typical of cyberpunk aesthetic. The overall tone suggests themes of human experience, interaction, and presence in a technology-dominated world.)

Now, meaning must be generated.

How do you generate meaning?

Well, it helps to look at what creates meaninglessness.

First, meaninglessness stems from stagnation. If you do nothing with your life - like many will once jobs are gone and they have just enough to stay afloat - you do not stay the same. You slowly fall into chaos. Entropy can be observed in the mind, too.

Second, meaninglessness is amplified by isolation. Without tribes and villages, we are the loneliest we've ever been. Screen in face waiting for the next paycheck so you can buy buy buy.

We could then say that the two pillars of meaning are the feeling of forward movement and a connection to something greater than yourself.

Progress and contribution.

For the longest time, we outsourced both. Progress was given by an employer and connection was given by a divine authority. Now, both are in your hands, and that will not sit well with a lot of people.

Progress and contribution are activated through creative problem-solving. You have an aim for the future, you identify a problem preventing you from moving forward, you create a solution through experimentation, and you pass that on to someone else in a similar position, and if that person deems it valuable enough, they will exchange another form of value back with you.

Of course, that doesn't help with understanding how creatives will survive if all jobs are gone. We're getting to that.

What I am arguing is that you must become a creator. You must build your own thing. You must take your own path. You must express your agency. Do not, by any means, sit around waiting for the day when the world promises to solve all your problems, because I promise that it won't.

Beyond the two pillars of meaning, there are three generators:

- **Struggle** – The engine of progress. What you choose to struggle for (or care about) is your purpose.
- **Curiosity** – The direction of progress. The non-linear choice of attention to solve problems.
- **Status** – The proof of contribution. The recognition that completes the loop.

When you put all those together, you get a story.

Stories, authentic stories, are what will demand a premium price tag.

Because the human brain is a story engine.

That's how we make sense of the world.

We hate when something is slow when it should be fast.

We hate long lines at the DMV. We hate the small-talking Uber Driver that's late. We hate sitting for 30 minutes on hold to ask what should be a simple support question. We hate when our fast food order is wrong.

But we will pay top dollar to fly across the world to dine at a five-star restaurant.

We sit on the edge of our seats while watching a tear-jerking play at the theatre.

When the task is about speed, accuracy, or utility, leave it to the machines. But when our mind leave the state of needing to do something just to get it done (when we engage in leisure, which there will be plenty of in the future) we crave something entirely different.

We crave the potential for failure.

We crave the lesson of the man who bleeds.

We crave the story, drama, novelty, myth and meaning, and we pay good money for it.

An entire economy will be built around this, and the construction has already started.

The question then is, what is so unique about you? And how can we be sure this won't be replaced by machines?

## IV – The Creator Economy = The Meaning Economy

If you are not paid from a job, and you do not find meaning in collecting just enough passive income to cover your necessities, what's left?

To get paid from people who believe in what you are doing and want to see more of it in the world.

You pursue what you care about and inspire people to care about it too.

Attention, then, is the scarce resource that creatives will be competing for.

We've already been seeing this play out in the creator economy.

Elon Musk, as an obvious example, understands the raw power of attention. He can quite literally shape the future with it. He can marshal capital, talent, and networks. He is a resource of all resources to ensure that his life's work of becoming interplanetary is carried out.

Mr. Beast is another. He is a master of attention capture, reinvests that back into production, which leads to more attention.

Think about how you get your education, news, and knowledge today. Most of it is on social media from creators who have taken it on as their job to provide their point of view. Centralized education and information is still at large, but not for long.

However, I don't want to be the next Mr. Beast. You probably don't want the risk and criticism of Musk. You simply want to pursue your interests and share it with a tribe of people who care about your vision just as much as you do, just like your brain is wired for. You want to generate and share meaning.

The biggest misconception of the creator economy is that it's a winner takes all battleground. That couldn't be any further from the truth.

Justin Welsh, a friend in the space, is known for wanting a quiet life. He wants meaningful work, ample family time, and the ability to do what he wants without financial stress. He does quite well for himself and has full control over how long he "works."

But you don't even have to go that big. There are plenty of people with small followings that make more than enough to live well. They don't grind 16 hours a day. They don't care about becoming billionaires. They just have something they deem meaningful and share it (while pairing it with the specific skills that allow them to garner attention, as we will discuss). You see these people every day. And by the way, if you want to become a billionaire or work extreme hours, be my guest, some people love that way of life and I'm not here to tell you how to live.

"But Dan, what about the dead internet? Isn't AI just going to flood the space with brain rot and slop?"

Yes, actually.

How is that not a good thing?

You're telling me that everyone is flooding the space with mediocre content so it's never been easier to stand out? I think most of the worry about AI slop stems from a lack of understanding how attention works.

Once everyone can do it instantly, it becomes instantly worthless.

Sure, anyone can have AI write 1000 posts or 10 articles to play the algorithm lottery, but how often do you see "slop" actually go viral? And if it did, doesn't that mean it's not slop?

Slop lives on a spectrum. When I went mega viral last week, I had people reducing my article to "just a bunch of self-help cliches" when, if you actually read the article, you know that is a bit of a stretch - considering the sections on psychology, epistemology, and human behavior. There is no AI prompt that could produce that exact same article, or even this same article. Not to say that it was the deepest writing on Earth, but it makes me question why a bit of self-help sends certain people into a blind rage - could self-help not help you there? Smart people are often biased to the domains they are smart in, which is quite an unproductive way of thinking. And frankly, once a piece of content becomes "popular," people who identify as anti-mainstream immediately find a reason to hate it. One mans slop is another mans treasure and vice versa.

Slop aside, you have access to ChatGPT, right? Then why are you reading this? Is it because you didn't know what to type into the chatbot? Is it because there's more to life than answering the questions you know to ask? Do you think ChatGPT is just going to deliver this exact article to you on a silver platter one day? Seriously, think about those questions before you start going on about how everything is doomed.

The truth is that skills are being abstracted up a layer.

The manual task of typing words on a page or adding brush strokes to a painting still matter, because compiling everything into a chat input removes agency for work that demands a personal touch, but they don't matter as much as the mind of the artist doing that thing.

Skills like marketing, persuasion, writing, digital art, programming, and more still matter, but the people who are able to get the most results are operating from a higher level.

They're operating at the human level.

## V – The Last Defensible Moat Is You

As a writer, I've been thinking about this a lot over the past few years.

Will AI ever be able to fully replace creatives and artists? That seems kind of bleak no matter which way you spin it.

Can AI ever write what I write?

Can AI ever create the music of a famous musician?

Can AI ever produce a Spielberg level film?

Can AI ever build a company like Steve Jobs could with Apple?

The answer I came to was... yes, but no.

Many will argue that AI can generate a beautiful essay or film, especially as the models get better, but they're missing something crucial.

Let's call this The Swap Test:

If you could swap the creator and the creation would be just as valuable, then AI can replace it.

If the creation only works because you made it, then that's your edge. It carries your perspective, your situation, and your taste.

You see, certain types of work have an objective floor.

When it comes to writing, it's perfectly fine if AI writes documentation, summarizes multiple sources of information, or makes instructions clearer. Hell, I would even argue that AI can take a brain dump of your original thoughts and structure them into something publishable, but some people may have a style they want to get across as well.

In other words, if speed and efficiency matter over voice, you can hand off control to AI.

But when it comes to writing a personal essay about grief after losing a parent, or writing an article arguing why minimalism is a trap for creatives, there's something different at play.

Your point of view is at play.

You know, the most unique thing on this planet that nobody else has access to.

The culmination of beliefs, ideas, and experiences that can't be reversed or resimulated that has been forming since the day you were born.

So that begs the question, if anyone can copy your writing, product, music, or art with a single prompt, when should you not hand over control to AI?

It lies in what AI cannot access.

- AI cannot think **from** your perspective. It can only think about your perspective or in the style of your perspective.
- AI cannot replicate your energy signature. It cannot select what to focus on and why it matters to **you** right now.
- AI cannot perform genuine sensemaking. It cannot decide what information means, what's important, or how to frame it.
- AI does not have a **trajectory.** It does not have the stakes of death. And even if mortality becomes a solved problem, once a moment passes for humans, it's over. AI can simulate stories, but time does not serve as a natural compression algorithm like it does for us.
- AI does not have evolving taste. It does not look back on its writing from a year ago and disagree with it. It does not grow.

In other words, AI can copy anything, but it cannot copy what happens next until it has already happened.

You, as a creative, have a perspective that is always evolving. AI is always chasing where you were but not where you are now.

By the time AI copies you, which could be instantly, you have already moved on.

What is considered "great work" is a moving target that evolves with society and culture. For creatives, the act of discovering what they think is the process.

If AI could perfectly write like me, right now, then I, being a stubborn human being, would not want to write about that anymore. What I care about would instantly change.

When I try to get AI to write like me, I immediately dislike it. Therefore, I would not write that thing.

So what's changed going into the future of work?

Nothing, really. We're finally just uncovering what mattered in the first place. People are so worried about the onslaught of AI slop without realizing that goods in high supply become commodities. The human perspective cannot be commoditized, therefore it will always demand a premium.

All of that makes sense and sounds nice, but it's not very practical.

So what can you start doing, right now, to ensure that you create a perspective worth paying for?

## VI – The Post-Labor Skill Stack

The skill stack of the future cannot be pinned down to career specific skills.

We all know that AI can write content, code, and music.

What's much more important is developing the skills that make those things human.

Since this letter is getting long, I'm going to keep this brief. I already have and will continue to expand on these skills in my future writing. For now, this list is just for awareness so you can begin noticing opportunities to refine acquire and refine them.

The skill stack, which is more of a skill hierarchy, looks like so:

### 1) Agency – The Meta Skill That Creates a Story Worth Telling

Agency is the ability to act without permission or outside prompting.

In other words, it's your ability to create a unique story. It's your ability to set a trajectory for your life and make the billions of small and large decisions that move you forward, backward, and side to side. Within each of those decisions lies an opportunity to acquire pieces of knowledge that are then deposited in what you choose to create.

Agency is practiced through the 3 generators of meaning we discussed prior: struggle, status, and curiosity.

Struggle requires you to make deliberate choices, reject conformity, step into the arena, create the potential for failure, and develop a character arc. Staying on the default path society wants you on is a surefire way to get replaced.

Status, in the future, will still revolve around money, but money will shift from a productivity metric to a tool to express agency. The more money you acquire (not that you need to get uber rich) the more options you have, and the more unique your decision making can be. The complexity of your story increases with money.

Curiosity is how you, specifically, filter signal from noise. The more distracted and numb you become, the less you can notice your core pulling you toward a novel path in life.

### 2) Taste – The Skill of Discernment

AI right now is creating the infinite library problem.

If a library contained every possible book with every permutation of characters, it would contain all truths, all falsehoods, and all gibberish.

The library is effectively useless because finding meaningful text is statistically impossible.

Information without curation or structure is noise.

The curation and structure come from your taste.

Further, AI also creates the infinite monkey problem.

Given infinite time, a bunch of monkeys typing randomly could produce Shakespeare, but the output is meaningless because there's no intention or selection behind it.

To develop taste you must build something of your own.

Because if taste is the ability to discern what's worth keeping vs what's not, and you do not have full control over that process, you are being molded by the taste of another.

As a creative, curation is a far more important skill than creation.

### 3) Perspective – Increasing Your Human Capacity

Developmental psychology illustrates that human values and worldviews evolve through predictable stages over time.

We learned this back up at the top of this letter.

Typically, these stages follow a simple pattern: your mind becomes less conformist, ideological, and dogmatic - as long as you do not get stuck.

In other words, your mind expands. You're able to make sense of higher level systems and constructs. You're able to house greater complexity of thought without labeling it as "wrong" as a defense mechanism for a lack of understanding.

In other other words, you collect more perspective. You do not see the world from a narrow lens, which hinders your ability to curate, which limits the value of your taste.

The problem, as we see very clearly on social media, is that most of the population (documented at around 50%) lives in a highly conformist stage of development.

Meaning, most people don't have the cognitive capacity for genuine agency. They simply hear that they should become high agency and conform to that idea, which is a low agency behavior.

We've talked about ego development theory plenty of times before, and I will continue talking about it, but here's the 80/20 of what actually increases your capacity for greater perspective:

- You do not try to "level up." You simply allow yourself to become disoriented or knocked out of equilibrium and let that become your new normal with time (and without rejecting it).
- Example: When you get a new job and feel like you can't do it, because your current mind can't metabolize it, you learn. Same goes for new relationships or exposing yourself to new cultures.
- The worst thing you can do is double down on your current perspective, because that's how you close yourself off to growth.

People try to resolve pain or dissonance too quickly because in today's world, everything is quick.

They take the political opinion as law and now everyone else is wrong.

Or, they experience a false transformation and act like the higher stage without actually embodying it. We see this all the time in hippies. They use spirituality as a status symbol to mask their massive ego.

### 4) Persuasion – The Ability to Get People to Care

You have something you've created.

Something you care about.

But most creatives stop there. They simply think they can post, write, produce and somehow people will magically find it. Or, they think that sounding intelligent or clever in their writing is enough to signal that their ideas are worth following. In reality, nobody cares unless you can persuade them as to how it's beneficial to their lives.

When we lived in villages in tribes, you were assigned a role. You produced what was necessary and others benefited from it.

In today's world, you're seemingly all alone. You must put in effort to get your work spread.

Because you can have the best book, product, painting, or music in the world, but if you don't understand the attention mechanisms (marketing, sales, social media, advertising) nobody is going to see it, and nobody is going to care enough to pay you. Art must merge with business.

We don't need to go into "how" to learn these skills, because they are lower in this skill hierarchy for a reason.

You learn them automatically by building your own thing, making mistakes, and correcting those mistakes, and only a person of higher development can do that effectively.

In a nutshell: if you aren't getting the results you want, you need to experiment, learn, and iterate until you do. That's how you become effective at anything.

### 5) Technical Know-How – Utilizing AI and Tools

This letter may seem like it's against AI, but I can assure you that is not the case.

You don't need to pick a team.

And c'mon, we just talked about that with developing perspective.

The truth is, everyone is going to be working with AI in some capacity, even the creatives who swear against it (while posting on X about how much they hate AI, feeding straight into Grok's algorithm, well done.)

The best advice I can give, as always, is to experiment.

Try to use AI for the next project you build.

Ask the AI how you can pass off tasks that don't demand a personal touch.

Feed it this letter if you want, give a description about what you are trying to create, and start playing around. See if it can provide some cognitive offload so your mind is more free to focus on what matters.

---

I will leave it there, because I'm as tired of writing as I'm sure you are reading this.

Thank you for your attention.

– Dan