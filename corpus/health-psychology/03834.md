# Extraction: SOURCE-20260210-115

**Source**: `SOURCE-20260210-youtube-lecture-the_neuron-this_new_ai_model_thinks_without_language_w_eve_bodnia_of_lo.md`
**Atoms extracted**: 7
**Categories**: claim, concept, praxis_hook

---

## Claim (5)

### ATOM-SOURCE-20260210-115-0001
**Lines**: 10-10
**Context**: consensus / claim
**Tension**: novelty=0.00, consensus_pressure=1.00, contradiction_load=0.00, speculation_risk=0.60, actionability=0.00, epistemic_stability=1.00

> Most AI today is built to predict the next word.

### ATOM-SOURCE-20260210-115-0002
**Lines**: 11-11
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.80, contradiction_load=0.00, speculation_risk=0.60, actionability=0.00, epistemic_stability=0.90

> Intelligence does not work by predicting the next word.

### ATOM-SOURCE-20260210-115-0004
**Lines**: 18-18
**Context**: consensus / claim
**Tension**: novelty=0.50, consensus_pressure=0.50, contradiction_load=0.00, speculation_risk=0.60, actionability=0.00, epistemic_stability=0.70

> Unlike large language models, energy-based models do not rely on tokens or next-word prediction.

### ATOM-SOURCE-20260210-115-0006
**Lines**: 20-22
**Context**: hypothesis / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.00, speculation_risk=0.30, actionability=0.50, epistemic_stability=0.60

> Energy-based models are relevant for spatial reasoning, planning, robotics, and safety-critical systems.

### ATOM-SOURCE-20260210-115-0007
**Lines**: 22-23
**Context**: hypothesis / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.00, speculation_risk=0.40, actionability=0.10, epistemic_stability=0.50

> Language may be better treated as an interface rather than the core of intelligence.

## Concept (1)

### ATOM-SOURCE-20260210-115-0003
**Lines**: 15-16
**Context**: hypothesis / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.00, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.60

> Energy-based models (EBMs) are a fundamentally different way to build AI systems compared to large language models (LLMs).

## Praxis Hook (1)

### ATOM-SOURCE-20260210-115-0005
**Lines**: 19-20
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.00, speculation_risk=0.10, actionability=0.70, epistemic_stability=0.70

> Energy-based models reason over an energy landscape, allowing them to evaluate many possible solutions at once.
