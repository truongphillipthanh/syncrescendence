# Extraction: SOURCE-20250104-643

**Source**: `SOURCE-20250104-youtube-interview-machine_learning_street_talk-don_t_invent_faster_horses_prof_jeff_clune.md`
**Atoms extracted**: 6
**Categories**: claim, concept, praxis_hook

---

## Claim (1)

### ATOM-SOURCE-20250104-643-0005
**Lines**: 35-39
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.60, actionability=0.50, epistemic_stability=0.70

> AI safety measures are necessary, especially as AI technology matures into powerful, open-ended forms, due to potential risks like agents inadvertently causing harm or malicious actors subverting AI capabilities.

## Concept (2)

### ATOM-SOURCE-20250104-643-0001
**Lines**: 10-12
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> Open-ended evolutionary algorithms are systems designed to continuously generate novel and interesting outcomes, drawing inspiration from nature's creativity.

### ATOM-SOURCE-20250104-643-0003
**Lines**: 27-29
**Context**: hypothesis / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.40, epistemic_stability=0.60

> 'Interestingness' is an elusive quality that guides AI agents toward genuinely original discoveries, serving as a central theme in Clune's work.

## Praxis Hook (3)

### ATOM-SOURCE-20250104-643-0002
**Lines**: 12-16
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.60, epistemic_stability=0.50

> Clune and collaborators aim to build 'Darwin Complete' search spaces where any computable environment can be simulated, using large language models and reinforcement learning to enable AI agents to continuously develop new skills, explore uncharted domains, and cooperate.

### ATOM-SOURCE-20250104-643-0004
**Lines**: 29-32
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.70, epistemic_stability=0.50

> To ensure 'interestingness' reflects authentic novelty and avoids issues like Goodhart's Law, Clune employs language models as proxies for human judgment.

### ATOM-SOURCE-20250104-643-0006
**Lines**: 39-41
**Context**: method / claim
**Tension**: novelty=0.50, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.60, actionability=0.80, epistemic_stability=0.60

> Mitigating AI risks requires prudent governance, including democratic coalitions, regulation of cutting-edge models, and global alignment protocols.
