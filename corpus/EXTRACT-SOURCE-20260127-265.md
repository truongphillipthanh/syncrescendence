# Extraction: SOURCE-20260127-265

**Source**: `SOURCE-20260127-youtube-interview-win_win_with_liv_boeree-what_happens_after_superintelligent_ai_will_macaskill_liv_bo.md`
**Atoms extracted**: 4
**Categories**: claim, praxis_hook

---

## Claim (3)

### ATOM-SOURCE-20260127-265-0001
**Lines**: 10-10
**Context**: consensus / claim
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.40

> Many believe superintelligence is just a few years away.

### ATOM-SOURCE-20260127-265-0003
**Lines**: 15-17
**Context**: consensus / evidence
**Tension**: novelty=0.10, consensus_pressure=0.90, contradiction_load=0.10, speculation_risk=0.60, actionability=0.20, epistemic_stability=0.80

> Will MacAskill is a lead researcher at Forethought, a nonprofit focused on navigating the transition to a post-AGI world safely.

### ATOM-SOURCE-20260127-265-0004
**Lines**: 20-25
**Context**: speculation / claim
**Tension**: novelty=0.40, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.70, actionability=0.30, epistemic_stability=0.40

> The conversation with Will MacAskill explores why "utopias" often fail, the plausibility of authoritarian lock-in, and the potential for decentralized governance of resources like the sun, space, and high seas to prevent corporate dictatorships.

## Praxis Hook (1)

### ATOM-SOURCE-20260127-265-0002
**Lines**: 10-15
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.40, actionability=0.70, epistemic_stability=0.50

> We need to actively research what comes after superintelligent AI, assuming humanity survives it, and how to prepare for a post-AGI world safely.
