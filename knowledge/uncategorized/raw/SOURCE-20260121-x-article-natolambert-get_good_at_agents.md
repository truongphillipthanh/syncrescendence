---
id: SOURCE-20260121-x-article-natolambert-get_good_at_agents
platform: x
format: article
creator: natolambert
title: get good at agents
status: triaged
original_filename: "20260121-x_article-get_good_at_agents-@natolambert.md"
url: https://x.com/natolambert/article/2014023020302704698
author: "Nathan Lambert (@natolambert)"
captured_date: 2026-01-21
signal_tier: strategic
topics: ""
teleology: strategize
notebooklm_category: ai-agents
aliases: ""
synopsis: ""
key_insights: ""
---
# Get Good at Agents

(Description: A conductor standing at a podium with arms raised in front of a full orchestra. The conductor is wearing a black tuxedo, viewed from behind. Violinists, cellists, and other orchestra members are seated throughout the frame with sheet music visible on stands. Warm stage lighting illuminates the scene with golden-amber tones.)

Two weeks ago, I wrote a review of how Claude Code is taking the AI world by storm, saying that "software engineering is going to look very different by the end of 2026." That article captured the power of Claude as a tool and a product, and I still stand by it, but it undersold the changes that are coming in how we use these products in careers that interface with software.

The more personal angle was how "I'd rather do my work if it fits the Claude form factor, and soon I'll modify my approaches so that Claude will be able to help." Since writing that, I'm stuck with a growing sense that taking my approach to work from the last few years and applying it to working with agents is fundamentally wrong. Today's habits in the era of agents would limit the uplift I get by micromanaging them too much, tiring myself out, and setting the agents on too small of tasks. What would be better is more open ended, more ambitious, more asynchronous.

I don't yet know what to prescribe myself, but I know the direction to go, and I know that searching is my job. It seems like the direction will involve working less, spending more time cultivating peace, so the brain can do its best directing — let the agents do most of the hard work.

Since trying Claude Code with Opus 4.5, my work life has shifted closer to trying to adapt to a new way of working with agents. This new style of work feels like a larger shift than the era of learning to work with chat-based AI assistants. ChatGPT let me instantly get relevant information or a potential solution to the problems I was already working on. Claude Code has me considering what should I work on now that I know I can have AI independently solve or implement many sub-components.

Every engineer needs to learn how to design systems. Every researcher needs to learn how to run a lab. Agents push the humans up the org chart.

I feel like I have an advantage by being early to this wave, but no longer feel like just working hard will be an lasting edge. When I can have multiple agents working productively in parallel on my projects, my role is shifting more to pointing the army rather than using the power-tool. Pointing the agents more effectively is far more useful than me spending a few more hours grinding on a problem.

My default workflow now is GPT 5 Pro for planning, Claude Code with Opus 4.5 for implementation. I often have Claude Code pass information back to GPT 5 Pro for a deep search when stuck with a very detailed prompt. Codex with GPT 5.2 on xhigh thinking effort alone feels very capable, more meticulous than Claude even, but I haven't yet figured out how to get the best out of it. GPT Pro feels itself to be a strong agent trapped in the wrong UX — it needs to be able to think longer and have a place to work on research tasks.¹

It seems like all of my friends (including the nominally "non-technical" ones) have accepted that Claude can rapidly build incredible, bespoke software for you. Claude updated one of my old research projects to uv so it's easier to maintain, made a verification bot for my Discord, crafted numerous figures for my RLHF book, feels close to landing a substantial feature in our RL research codebase, and did countless other tasks that would've taken me days. It's the thing de jour — tell your friends and family what trinket you built with Claude. It undersells what's coming.

I've taken to leaving Claude Code instances running on my DGX Spark trying to implement new features in our RL codebase when I'm at dinner or work. They make mistakes, they catch most of their own mistakes, and they're fairly slow too, but they're capable. I can't wait to go home and check on what my Claudes were up to.

The feeling that I can't shake is a deep urgency to move my agents from working on toy software to doing meaningful long-term tasks. We know Claude can do hours, days, or weeks, of fun work for us, but how do we stack these bricks into coherent long-term projects? This is the crucial skill for the next era of work.

There are no hints or guides on working with agents at the frontier — the only way is to play with them. Instead of using them for cleanup, give them one of your hardest tasks and see what it gets stuck on, see what you can use it for.

Software is becoming free, good decision making in research, design, and product has never been so valuable.

Being good at using AI today is a better moat than working hard.

Full post + reading list available directly on [@interconnectsai](https://www.interconnects.ai/p/get-good-at-agents): https://www.interconnects.ai/p/get-good-at-agents