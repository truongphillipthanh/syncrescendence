---
url: https://x.com/Altimor/status/2024166553357336660
author: "Flo Crivello (@Altimor)"
captured_date: 2026-02-21
id: SOURCE-20260218-019
original_filename: "20260218-x_thread-some_notes_about_the_slew_of_chinese_models_coming_out_kimi_k2_5_minimax_glm_5_etc-@altimor.md"
status: triaged
platform: x
format: thread
creator: altimor
signal_tier: tactical
topics:
  - agentic-development
  - extended-thinking
  - cost-optimization
teleology: extract
notebooklm_category: ai-engineering
aliases:
  - "X Thread Chinese AI Models Evaluation"
synopsis: "X Thread: Chinese AI Models Evaluation **Post 1** — 8:58 AM · Feb 18, 2026 Some notes about the slew of Chinese models coming out (Kimi K2.5, MiniMax, GLM-5 etc) claiming to "match Sonnet / Opus / God in evals at 1/10th of the price" --- **Post 2** — Feb 18 By far our biggest cost at Lindy is inference, so believe me when I say we've looked at these models very closely (and continue doing so)."
key_insights:
  - "Their actually delivering on their claims would make a material difference to the business."
  - "But it's delusional to think they're actually at Sonnet / Opus level — they're still at least one generation behind."
  - "Take the evals with a huge grain of salt."
---
# X Thread: Chinese AI Models Evaluation
**Post 1** — 8:58 AM · Feb 18, 2026
Some notes about the slew of Chinese models coming out (Kimi K2.5, MiniMax, GLM-5 etc) claiming to "match Sonnet / Opus / God in evals at 1/10th of the price"
---
**Post 2** — Feb 18
By far our biggest cost at Lindy is inference, so believe me when I say we've looked at these models very closely (and continue doing so). Their actually delivering on their claims would make a material difference to the business.
---
**Post 3** — Feb 18
But every time we've evaluated them, we've found the same thing: that their real life performance, for agentic behavior, and outside of coding use cases, falls extremely short of what they show on evals.
---
**Post 4** — Feb 18
I think the industry consensus is right: these Chinese labs are:
1/ distilling frontier models (duh), which leads to much more "shallow" intelligence
2/ training for evals
3/ potentially stealing weights (I do believe at least 4o's weights got exfiltrated)
---
**Post 5** — Feb 18
Not saying these models will always be bad, or that these labs are completely incompetent. They're doing a fine job. But it's delusional to think they're actually at Sonnet / Opus level — they're still at least one generation behind. Take the evals with a huge grain of salt.