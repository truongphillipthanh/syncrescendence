{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "68b2e6b7-d6a4-5bc3-aaf8-7bed6e90e5b8", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0001", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "The quality of search context feeding LLMs is a more fundamental bottleneck for AI agents than the choice of LLM itself.", "line_start": 15, "line_end": 16, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.5, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "The quality of search context feeding LLMs is a more fundamental bottleneck for", "content": "The quality of search context feeding LLMs is a more fundamental bottleneck for AI agents than the choice of LLM itself.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 15, "line_end": 16, "atom_id": "ATOM-SOURCE-20260213-011-0001"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.5, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "6e5023b8-9725-5aeb-8ce5-ad76f4e39f1e", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0002", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "An agent with poor search capabilities cannot reason effectively, regardless of the underlying LLM's power, leading to hallucinations, looping, and poor user outcomes.", "line_start": 18, "line_end": 21, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.5, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "An agent with poor search capabilities cannot reason effectively, regardless of", "content": "An agent with poor search capabilities cannot reason effectively, regardless of the underlying LLM's power, leading to hallucinations, looping, and poor user outcomes.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 18, "line_end": 21, "atom_id": "ATOM-SOURCE-20260213-011-0002"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.5, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "f0e75482-18e2-51e0-9339-1e1de180d0de", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0003", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Brave's research indicates that a weaker open-weight model (Qwen3) combined with high-quality search context can outperform stronger models like ChatGPT, Perplexity, and Google AI Mode.", "line_start": 30, "line_end": 33, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.4, 0.5, 0.1, 0.2, 0.3, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Brave's research indicates that a weaker open-weight model (Qwen3) combined with", "content": "Brave's research indicates that a weaker open-weight model (Qwen3) combined with high-quality search context can outperform stronger models like ChatGPT, Perplexity, and Google AI Mode.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 30, "line_end": 33, "atom_id": "ATOM-SOURCE-20260213-011-0003"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.4, 0.5, 0.1, 0.2, 0.3, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "f2a1a23e-875e-5aa8-be1c-7387d2f80fcc", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0004", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "In a 1,500-query evaluation, Ask Brave (Qwen3 + LLM Context API) scored 4.66/5, surpassing ChatGPT (4.32), Google AI Mode (4.39), and Perplexity (4.01), with only Grok (4.71) scoring higher.", "line_start": 35, "line_end": 36, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.4, 0.5, 0.1, 0.2, 0.3, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "In a 1,500-query evaluation, Ask Brave (Qwen3 + LLM Context API) scored 4.66/5,", "content": "In a 1,500-query evaluation, Ask Brave (Qwen3 + LLM Context API) scored 4.66/5, surpassing ChatGPT (4.32), Google AI Mode (4.39), and Perplexity (4.01), with only Grok (4.71) scoring higher.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 35, "line_end": 36, "atom_id": "ATOM-SOURCE-20260213-011-0004"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.4, 0.5, 0.1, 0.2, 0.3, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "4b605eaf-0136-59e9-897e-8b2ff118f9d5", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0005", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Context quality is a more significant differentiator than model capability for AI agents.", "line_start": 37, "line_end": 37, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.5, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Context quality is a more significant differentiator than model capability for A", "content": "Context quality is a more significant differentiator than model capability for AI agents.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 37, "line_end": 37, "atom_id": "ATOM-SOURCE-20260213-011-0005"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.5, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "31536206-300f-5170-8b28-24406f80df4b", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0006", "source_id": "SOURCE-20260213-011", "category": "framework", "content": "Five search APIs (Brave, Tavily, Exa, Perplexity, Firecrawl) offer different philosophies for integrating web content into LLMs: Brave (own index, LLM-optimized chunks, privacy-first), Tavily (agent-native, search + extract + crawl), Exa (neural semantic search), Perplexity (Sonar API, answers with citations), Firecrawl (extract-first, scrape anything, structured).", "line_start": 41, "line_end": 43, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.2, 0.2, 0.6, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Framework", "name": "Five search APIs (Brave, Tavily, Exa, Perplexity, Firecrawl) offer different phi", "content": "Five search APIs (Brave, Tavily, Exa, Perplexity, Firecrawl) offer different philosophies for integrating web content into LLMs: Brave (own index, LLM-optimized chunks, privacy-first), Tavily (agent-native, search + extract + crawl), Exa (neural semantic search), Perplexity (Sonar API, answers with citations), Firecrawl (extract-first, scrape anything, structured).", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 41, "line_end": 43, "atom_id": "ATOM-SOURCE-20260213-011-0006"}, "metadata": {"category": "framework", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.2, 0.2, 0.6, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "50986284-d7ef-5e17-9a52-5ba9f939b6d3", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0007", "source_id": "SOURCE-20260213-011", "category": "concept", "content": "Brave's LLM Context API performs a full search on its independent index of 35+ billion pages, then extracts 'smart chunks' (clean text, structured data, JSON-LD, tables, code, forum discussions, YouTube captions) from pages in real-time, ranking them by relevance and compiling them into a token-efficient format for LLM consumption.", "line_start": 47, "line_end": 51, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.4, 0.3, 0.4, 0.5], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Concept", "name": "Brave's LLM Context API performs a full search on its independent index of 35+ b", "content": "Brave's LLM Context API performs a full search on its independent index of 35+ billion pages, then extracts 'smart chunks' (clean text, structured data, JSON-LD, tables, code, forum discussions, YouTube captions) from pages in real-time, ranking them by relevance and compiling them into a token-efficient format for LLM consumption.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 47, "line_end": 51, "atom_id": "ATOM-SOURCE-20260213-011-0007"}, "metadata": {"category": "concept", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.4, 0.3, 0.4, 0.5], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "599be083-e587-5085-beee-7ce6c387b649", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0008", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Brave's LLM Context API has a p90 latency under 600ms for the full pipeline (search + extraction + ranking) with less than 130ms overhead on top of normal search.", "line_start": 53, "line_end": 53, "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.5, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Brave's LLM Context API has a p90 latency under 600ms for the full pipeline (sea", "content": "Brave's LLM Context API has a p90 latency under 600ms for the full pipeline (search + extraction + ranking) with less than 130ms overhead on top of normal search.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 53, "line_end": 53, "atom_id": "ATOM-SOURCE-20260213-011-0008"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.5, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "84ba0f95-0a33-5c4a-a45b-04c45c7a28ef", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0009", "source_id": "SOURCE-20260213-011", "category": "concept", "content": "Tavily is a search API purpose-built for AI agents, offering four endpoints: Search (web discovery), Extract (content from URLs), Map (site structure), and Crawl (navigate and extract from entire sites).", "line_start": 65, "line_end": 67, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.4, 0.3, 0.4, 0.5], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Concept", "name": "Tavily is a search API purpose-built for AI agents, offering four endpoints: Sea", "content": "Tavily is a search API purpose-built for AI agents, offering four endpoints: Search (web discovery), Extract (content from URLs), Map (site structure), and Crawl (navigate and extract from entire sites).", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 65, "line_end": 67, "atom_id": "ATOM-SOURCE-20260213-011-0009"}, "metadata": {"category": "concept", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.4, 0.3, 0.4, 0.5], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "4fd059c5-c768-5eaf-8701-0b4bc1328d3f", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0010", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Perplexity's citation tokens are now free on standard Sonar and Sonar Pro, which reduces per-query costs.", "line_start": 70, "line_end": 72, "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.1, 0.8, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Perplexity's citation tokens are now free on standard Sonar and Sonar Pro, which", "content": "Perplexity's citation tokens are now free on standard Sonar and Sonar Pro, which reduces per-query costs.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 70, "line_end": 72, "atom_id": "ATOM-SOURCE-20260213-011-0010"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.1, 0.8, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "cbc18b2b-0b22-5052-9dbf-3eb574bea031", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0011", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Perplexity's total cost per query is difficult to predict due to its dependence on model choice, context size, and token volume, unlike flat-rate APIs.", "line_start": 72, "line_end": 74, "chaperone": {"context_type": "consensus", "argument_role": "limitation", "tension_vector": [0.1, 0.7, 0.1, 0.6, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Perplexity's total cost per query is difficult to predict due to its dependence", "content": "Perplexity's total cost per query is difficult to predict due to its dependence on model choice, context size, and token volume, unlike flat-rate APIs.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 72, "line_end": 74, "atom_id": "ATOM-SOURCE-20260213-011-0011"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "limitation", "tension_vector": [0.1, 0.7, 0.1, 0.6, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "749284e2-e2c5-5140-b80f-493f105eb0a0", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0012", "source_id": "SOURCE-20260213-011", "category": "concept", "content": "Exa (formerly Metaphor) uses neural embeddings trained on its own index of tens of billions of pages to enable semantic search by meaning rather than keywords.", "line_start": 77, "line_end": 78, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.4, 0.3, 0.4, 0.5], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Concept", "name": "Exa (formerly Metaphor) uses neural embeddings trained on its own index of tens", "content": "Exa (formerly Metaphor) uses neural embeddings trained on its own index of tens of billions of pages to enable semantic search by meaning rather than keywords.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 77, "line_end": 78, "atom_id": "ATOM-SOURCE-20260213-011-0012"}, "metadata": {"category": "concept", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.4, 0.3, 0.4, 0.5], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "75c26fc9-586e-5609-bd69-a423eac2744b", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0013", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Exa 2.0 offers three tiers: Exa Fast (sub-350ms p50), Exa Auto (balances latency and quality), and Exa Deep (agentic multi-search, ~3.5s p50, highest quality), with Exa Instant pushing latency below 200ms for real-time applications.", "line_start": 79, "line_end": 80, "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.5, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Exa 2.0 offers three tiers: Exa Fast (sub-350ms p50), Exa Auto (balances latency", "content": "Exa 2.0 offers three tiers: Exa Fast (sub-350ms p50), Exa Auto (balances latency and quality), and Exa Deep (agentic multi-search, ~3.5s p50, highest quality), with Exa Instant pushing latency below 200ms for real-time applications.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 79, "line_end": 80, "atom_id": "ATOM-SOURCE-20260213-011-0013"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.5, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "260dcc7c-f416-596d-8810-75e28eadd2a7", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0014", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Firecrawl specializes in extraction, starting with a URL to retrieve all content from a page, including handling JavaScript rendering, pagination, authentication, CAPTCHAs, and multi-page workflows automatically.", "line_start": 84, "line_end": 88, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.8, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Firecrawl specializes in extraction, starting with a URL to retrieve all content", "content": "Firecrawl specializes in extraction, starting with a URL to retrieve all content from a page, including handling JavaScript rendering, pagination, authentication, CAPTCHAs, and multi-page workflows automatically.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 84, "line_end": 88, "atom_id": "ATOM-SOURCE-20260213-011-0014"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.8, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "3830d198-cc4a-542e-a36a-89dc91bc203b", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0015", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Firecrawl is open source and self-hostable.", "line_start": 88, "line_end": 88, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.1, 0.1, 0.7, 0.9], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Firecrawl is open source and self-hostable.", "content": "Firecrawl is open source and self-hostable.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 88, "line_end": 88, "atom_id": "ATOM-SOURCE-20260213-011-0015"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.1, 0.1, 0.7, 0.9], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "7b8ba7b1-15c3-56d0-836a-d3ce87900da4", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0016", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Firecrawl reported 77.2% coverage and 0.638 F1 quality in its own comparison testing, compared to Exa's 69.2% coverage and 0.508 F1.", "line_start": 88, "line_end": 91, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.2, 0.5, 0.1, 0.3, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Firecrawl reported 77.2% coverage and 0.638 F1 quality in its own comparison tes", "content": "Firecrawl reported 77.2% coverage and 0.638 F1 quality in its own comparison testing, compared to Exa's 69.2% coverage and 0.508 F1.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 88, "line_end": 91, "atom_id": "ATOM-SOURCE-20260213-011-0016"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.2, 0.5, 0.1, 0.3, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "7cba4b7b-f587-5874-b8d9-5fbb7818df1f", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0017", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Firecrawl's reported benchmarks are vendor-published and not independently audited.", "line_start": 91, "line_end": 92, "chaperone": {"context_type": "consensus", "argument_role": "limitation", "tension_vector": [0.1, 0.8, 0.1, 0.1, 0.1, 0.9], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Firecrawl's reported benchmarks are vendor-published and not independently audit", "content": "Firecrawl's reported benchmarks are vendor-published and not independently audited.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 91, "line_end": 92, "atom_id": "ATOM-SOURCE-20260213-011-0017"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "limitation", "tension_vector": [0.1, 0.8, 0.1, 0.1, 0.1, 0.9], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "6f31065e-3eac-51ec-955b-9dfac9a6a95d", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0018", "source_id": "SOURCE-20260213-011", "category": "concept", "content": "Firecrawl is an extraction tool used after a search engine finds relevant URLs, rather than a search engine itself.", "line_start": 94, "line_end": 95, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.6, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Concept", "name": "Firecrawl is an extraction tool used after a search engine finds relevant URLs,", "content": "Firecrawl is an extraction tool used after a search engine finds relevant URLs, rather than a search engine itself.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 94, "line_end": 95, "atom_id": "ATOM-SOURCE-20260213-011-0018"}, "metadata": {"category": "concept", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.6, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "c672bc7d-8348-5c6f-88e8-4c92bdd0603e", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0019", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Firecrawl's pricing is flat and predictable at one credit per page, without depth multipliers or variable consumption.", "line_start": 95, "line_end": 97, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.1, 0.6, 0.3, 0.9], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Firecrawl's pricing is flat and predictable at one credit per page, without dept", "content": "Firecrawl's pricing is flat and predictable at one credit per page, without depth multipliers or variable consumption.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 95, "line_end": 97, "atom_id": "ATOM-SOURCE-20260213-011-0019"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.1, 0.6, 0.3, 0.9], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "c46a4f2d-4888-5207-960d-c243229020fa", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0020", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "At 100K pages monthly, Firecrawl costs $83, which is significantly less than Tavily's $500-800 for equivalent extraction.", "line_start": 97, "line_end": 98, "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.1, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "At 100K pages monthly, Firecrawl costs $83, which is significantly less than Tav", "content": "At 100K pages monthly, Firecrawl costs $83, which is significantly less than Tavily's $500-800 for equivalent extraction.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 97, "line_end": 98, "atom_id": "ATOM-SOURCE-20260213-011-0020"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.1, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "2fd4d28c-08ff-5675-ab8a-d1f6c601175d", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0021", "source_id": "SOURCE-20260213-011", "category": "praxis_hook", "content": "The optimal strategy for agent builders is to route different query types to different APIs based on their strengths, rather than picking a single API.", "line_start": 119, "line_end": 121, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "PraxisHook", "name": "The optimal strategy for agent builders is to route different query types to dif", "content": "The optimal strategy for agent builders is to route different query types to different APIs based on their strengths, rather than picking a single API.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 119, "line_end": 121, "atom_id": "ATOM-SOURCE-20260213-011-0021"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "3e40ccad-10c1-5e26-bd43-6456448003da", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0022", "source_id": "SOURCE-20260213-011", "category": "concept", "content": "Brave's LLM Context API is not a wrapper around other search engines, not bundled with a forced LLM, and not just a search endpoint.", "line_start": 139, "line_end": 142, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.1, 0.4, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Concept", "name": "Brave's LLM Context API is not a wrapper around other search engines, not bundle", "content": "Brave's LLM Context API is not a wrapper around other search engines, not bundled with a forced LLM, and not just a search endpoint.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 139, "line_end": 142, "atom_id": "ATOM-SOURCE-20260213-011-0022"}, "metadata": {"category": "concept", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.1, 0.4, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "c67ec009-cb71-5b65-b1bb-ddf913d5eb5e", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0023", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Brave's blog argues that scrapers are legally risky (citing Google v. SerpAPI), can be arbitrarily shut off, and cannot offer true Zero Data Retention because queries pass through a third party.", "line_start": 139, "line_end": 141, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.3, 0.1, 0.1, 0.1, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Brave's blog argues that scrapers are legally risky (citing Google v. SerpAPI),", "content": "Brave's blog argues that scrapers are legally risky (citing Google v. SerpAPI), can be arbitrarily shut off, and cannot offer true Zero Data Retention because queries pass through a third party.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 139, "line_end": 141, "atom_id": "ATOM-SOURCE-20260213-011-0023"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.3, 0.1, 0.1, 0.1, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "82551ee7-6b14-5880-a460-f3e60abbb985", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0024", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Brave is positioning itself as the safe infrastructure choice for enterprise AI due to being the only western independent search index at scale outside Big Tech.", "line_start": 141, "line_end": 142, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.3, 0.1, 0.1, 0.1, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Brave is positioning itself as the safe infrastructure choice for enterprise AI", "content": "Brave is positioning itself as the safe infrastructure choice for enterprise AI due to being the only western independent search index at scale outside Big Tech.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 141, "line_end": 142, "atom_id": "ATOM-SOURCE-20260213-011-0024"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.3, 0.1, 0.1, 0.1, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "d0d4a5f5-c662-5d77-bae9-6a11680ef5a4", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0025", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Brave's LLM Context API is a purpose-built pipeline that searches an independent 35B-page index, extracts smart chunks from results, ranks them for relevance, and delivers them in a token-budget-controlled format for any LLM, all under 600ms.", "line_start": 144, "line_end": 148, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.1, 0.7, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Brave's LLM Context API is a purpose-built pipeline that searches an independent", "content": "Brave's LLM Context API is a purpose-built pipeline that searches an independent 35B-page index, extracts smart chunks from results, ranks them for relevance, and delivers them in a token-budget-controlled format for any LLM, all under 600ms.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 144, "line_end": 148, "atom_id": "ATOM-SOURCE-20260213-011-0025"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.1, 0.7, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "7da3cf2a-c8ae-5728-8ab7-ce4380a601b8", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0026", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "The search layer is becoming the primary differentiator for agent builders because LLMs are commoditizing and their performance is converging.", "line_start": 147, "line_end": 150, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.3, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "The search layer is becoming the primary differentiator for agent builders becau", "content": "The search layer is becoming the primary differentiator for agent builders because LLMs are commoditizing and their performance is converging.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 147, "line_end": 150, "atom_id": "ATOM-SOURCE-20260213-011-0026"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.3, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "023c2295-21c0-5e40-9226-e7029656bab1", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0027", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "An open-weight model with good search context outperformed frontier models with worse context in Brave's evaluation.", "line_start": 148, "line_end": 149, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.4, 0.3, 0.1, 0.2, 0.1, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "An open-weight model with good search context outperformed frontier models with", "content": "An open-weight model with good search context outperformed frontier models with worse context in Brave's evaluation.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 148, "line_end": 149, "atom_id": "ATOM-SOURCE-20260213-011-0027"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.4, 0.3, 0.1, 0.2, 0.1, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "f8a8b634-c09b-58a8-822d-ef137548dc68", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0028", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "The search API choice is now a product decision, not just an infrastructure one, due to its impact on LLM performance differentiation.", "line_start": 150, "line_end": 151, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.3, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "The search API choice is now a product decision, not just an infrastructure one,", "content": "The search API choice is now a product decision, not just an infrastructure one, due to its impact on LLM performance differentiation.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 150, "line_end": 151, "atom_id": "ATOM-SOURCE-20260213-011-0028"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.3, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "36632b29-bce3-5bc4-a2ec-14a0ab56d59c", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0029", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "The most effective agent stacks utilize a hybrid approach, routing different query types to different APIs.", "line_start": 154, "line_end": 155, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.5, 0.1, 0.3, 0.7, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "The most effective agent stacks utilize a hybrid approach, routing different que", "content": "The most effective agent stacks utilize a hybrid approach, routing different query types to different APIs.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 154, "line_end": 155, "atom_id": "ATOM-SOURCE-20260213-011-0029"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.5, 0.1, 0.3, 0.7, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "a4086fa8-5a52-5779-b801-e7bb5a6c3a2f", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0030", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Using a multi-API approach can reduce costs by 40-60% compared to using a single provider for all agent search needs.", "line_start": 158, "line_end": 159, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.3, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Using a multi-API approach can reduce costs by 40-60% compared to using a single", "content": "Using a multi-API approach can reduce costs by 40-60% compared to using a single provider for all agent search needs.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 158, "line_end": 159, "atom_id": "ATOM-SOURCE-20260213-011-0030"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.3, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "76b40f9d-d445-595e-9bfa-ab1ab8059e61", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0031", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Privacy and independence are now critical factors for enterprise AI teams, especially in regulated industries with sensitive query content.", "line_start": 162, "line_end": 164, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.5, 0.1, 0.3, 0.4, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Privacy and independence are now critical factors for enterprise AI teams, espec", "content": "Privacy and independence are now critical factors for enterprise AI teams, especially in regulated industries with sensitive query content.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 162, "line_end": 164, "atom_id": "ATOM-SOURCE-20260213-011-0031"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.5, 0.1, 0.3, 0.4, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "a56b571b-51b9-5bf7-b730-037b65a88778", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0032", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Brave's ZDR policy and SOC 2 attestation are competitive advantages for enterprise AI in regulated industries.", "line_start": 164, "line_end": 165, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.2, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Brave's ZDR policy and SOC 2 attestation are competitive advantages for enterpri", "content": "Brave's ZDR policy and SOC 2 attestation are competitive advantages for enterprise AI in regulated industries.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 164, "line_end": 165, "atom_id": "ATOM-SOURCE-20260213-011-0032"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.2, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "ebc62d85-857d-55f9-9d24-53fcd32bd6ff", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0033", "source_id": "SOURCE-20260213-011", "category": "claim", "content": "Firecrawl's open-source self-hosting option provides full data sovereignty for teams requiring it.", "line_start": 165, "line_end": 166, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.1, 0.2, 0.5, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "Claim", "name": "Firecrawl's open-source self-hosting option provides full data sovereignty for t", "content": "Firecrawl's open-source self-hosting option provides full data sovereignty for teams requiring it.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 165, "line_end": 166, "atom_id": "ATOM-SOURCE-20260213-011-0033"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.1, 0.2, 0.5, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "27e4a1a8-bf45-591e-8404-5ce51d675b85", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0034", "source_id": "SOURCE-20260213-011", "category": "praxis_hook", "content": "For agents running on OpenClaw, the Brave LLM Context API is the easiest path to high-quality web grounding, especially since Brave Search MCP server is already integrated.", "line_start": 169, "line_end": 171, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.4, 0.5, 0.1, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "PraxisHook", "name": "For agents running on OpenClaw, the Brave LLM Context API is the easiest path to", "content": "For agents running on OpenClaw, the Brave LLM Context API is the easiest path to high-quality web grounding, especially since Brave Search MCP server is already integrated.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 169, "line_end": 171, "atom_id": "ATOM-SOURCE-20260213-011-0034"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.4, 0.5, 0.1, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "565fb9da-2ff8-5991-9493-ead465a8ae70", "timestamp": "2026-02-24T00:39:37.364214+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260213-011-0035", "source_id": "SOURCE-20260213-011", "category": "praxis_hook", "content": "Combine Brave LLM Context API with Exa for research tasks and Firecrawl for deep extraction to create a more powerful agent stack.", "line_start": 171, "line_end": 171, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.5, 0.1, 0.3, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260213-011", "entity_type": "PraxisHook", "name": "Combine Brave LLM Context API with Exa for research tasks and Firecrawl for deep", "content": "Combine Brave LLM Context API with Exa for research tasks and Firecrawl for deep extraction to create a more powerful agent stack.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260213-011", "line_start": 171, "line_end": 171, "atom_id": "ATOM-SOURCE-20260213-011-0035"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.5, 0.1, 0.3, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
