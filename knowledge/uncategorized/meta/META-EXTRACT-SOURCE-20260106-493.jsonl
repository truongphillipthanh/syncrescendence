{"atom_id": "ATOM-SOURCE-20260106-493-0001", "source_id": "SOURCE-20260106-493", "category": "claim", "content": "Pathway is building the world’s first post-Transformer frontier model, called BDH (Dragon Hatchling architecture).", "line_start": 16, "line_end": 18, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.8, 0.2, 0.1, 0.3, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260106-493-0002", "source_id": "SOURCE-20260106-493", "category": "concept", "content": "Current language models are stuck in a “Groundhog Day” loop because they lack memory and true temporal reasoning, waking up without retaining information from previous interactions.", "line_start": 20, "line_end": 23, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.7, 0.1, 0.2, 0.1, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260106-493-0003", "source_id": "SOURCE-20260106-493", "category": "claim", "content": "Pathway’s BDH architecture introduces true temporal reasoning and continual learning to AI models.", "line_start": 23, "line_end": 24, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.8, 0.2, 0.1, 0.3, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260106-493-0004", "source_id": "SOURCE-20260106-493", "category": "claim", "content": "Transformers lack real memory and time awareness.", "line_start": 27, "line_end": 27, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.7, 0.1, 0.2, 0.1, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260106-493-0005", "source_id": "SOURCE-20260106-493", "category": "framework", "content": "The BDH architecture uses brain-like neurons, synapses, and emergent structure.", "line_start": 28, "line_end": 28, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.8, 0.2, 0.1, 0.3, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260106-493-0006", "source_id": "SOURCE-20260106-493", "category": "claim", "content": "AI models can \"get bored,\" adapt, and strengthen connections.", "line_start": 29, "line_end": 29, "chaperone": {"context_type": "hypothesis", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.2, 0.5, 0.3, 0.5], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260106-493-0007", "source_id": "SOURCE-20260106-493", "category": "claim", "content": "Pathway sees reasoning, not language, as the core of intelligence.", "line_start": 30, "line_end": 30, "chaperone": {"context_type": "hypothesis", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.2, 0.4, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260106-493-0008", "source_id": "SOURCE-20260106-493", "category": "claim", "content": "BDH enables infinite context, live learning, and interpretability.", "line_start": 31, "line_end": 31, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.8, 0.2, 0.1, 0.3, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260106-493-0009", "source_id": "SOURCE-20260106-493", "category": "claim", "content": "Gluing two trained models together actually works in BDH.", "line_start": 32, "line_end": 32, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.4, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260106-493-0010", "source_id": "SOURCE-20260106-493", "category": "claim", "content": "The path to AGI is through generalization, not scaling.", "line_start": 33, "line_end": 33, "chaperone": {"context_type": "hypothesis", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.2, 0.5, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260106-493-0011", "source_id": "SOURCE-20260106-493", "category": "claim", "content": "The BDH architecture could power the next era of scientific innovation.", "line_start": 36, "line_end": 36, "chaperone": {"context_type": "speculation", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.8, 0.2, 0.5], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260106-493-0012", "source_id": "SOURCE-20260106-493", "category": "claim", "content": "BDH represents one of the most ambitious rethinks of AI architecture since Transformers, drawing inspiration from brain-like message passing and emergent neural structures.", "line_start": 38, "line_end": 40, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.8, 0.2, 0.1, 0.3, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}
