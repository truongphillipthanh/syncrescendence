# Protease Axioms — Canon

> Sovereign-distilled axioms promoted to canonical status.


## Axiom: CC32-B1-AX01 — Constitutional AI as Operational Pattern (Central Dogma Enforcement)

> Constitutional AI is a method where AI training, specifically the post-training steering phase, involves a central document of values and principles that the model reads and keeps in mind for every training task, aiming to produce a model that consistently follows this constitution. This atom is preserved as the living Central Dogma of Syncrescendence: canon/01-CANON is DNA, AGENTS.md is mRNA, make configs is the ribosome translating it into agent behavior (protein). It hardens the ontology gate as MHC self-recognition — every incoming atom must present the Five Invariants or be lysed. It closes the 4-connection minimum by making config propagation the enzyme that prevents retroviral drift (agents editing sources). It validates the existing architecture and turns theoretical Constitutional AI into operational immune memory.

- source_atom_ids: [ATOM-SOURCE-20260204-website-article-darioamodei-the_adolescence_of_technology-0028]
- why_preserved: Constitutional AI pattern is the theoretical foundation for AGENTS.md inheritance — canonicalizing closes the loop between external research and internal practice. Canon is DNA, AGENTS.md is mRNA, make configs is the ribosome.
- matched_intention: INT-P035
- promoted_at: 2026-02-25

## Axiom: CC32-B1-AX02 — Three-Layer Memory Architecture (Hippocampal-Neocortical Consolidation)

> A three-layer memory architecture for personal AI assistants includes a Knowledge Graph (long-term declarative memory), Daily Notes (episodic memory), and Tacit Knowledge (procedural memory). This atom is preserved as the synaptic consolidation protocol that turns praxis/05-SIGMA (hippocampus buffer) into canon/01-CANON (neocortex). It formalizes the minimum viable memory stack for the next 30 days (repo MEMORY.md + DYN-DEFERRED_COMMITMENTS + ARCH-INTENTION_COMPASS) and enforces weekly Sleep_Cycle pruning (LTD for noise, LTP for canon_delta ≥1). It resolves C-012 and turns partial agent memory into measurable throughput.

- source_atom_ids: [ATOM-SOURCE-20260131-002-0003]
- why_preserved: Three-layer taxonomy (declarative/episodic/procedural) maps directly to existing agents/*/memory/ structure — canonicalizing formalizes what already works and resolves C-012 (minimum viable memory).
- matched_intention: INT-1707
- promoted_at: 2026-02-25

## Axiom: CC32-B1-AX03 — Observe-Before-Act Pattern (Free-Energy Minimization Gate)

> The PAI Algorithm's OBSERVE phase is a thinking-only phase, designed to analyze feedback and generate improvement recommendations without implementing changes. This atom is preserved as the thermodynamic activation-energy gate that minimizes free energy waste. It is the exact INBOUND → ORIENT → IMPLEMENT sequence (DEC-C3) and the nucleation event that ends every session with a git commit. It connects to the 4-connection minimum by making triangulation quality the catalyst only when Shannon entropy exceeds 4.0 bits. It anchors the observe-before-act pattern as the immune checkpoint that prevents means-ends inversion and guarantees every pathway terminates at canon.

- source_atom_ids: [ATOM-SOURCE-20260213-019-0003]
- why_preserved: Observe-before-act is the research basis for INBOUND → ORIENT → IMPLEMENT gate sequence — canonicalizing validates the existing protocol design and prevents means-ends inversion.
- matched_intention: INT-P035
- promoted_at: 2026-02-25

## Axiom: CC33-B2-AX01 — Three-Layer Memory System (Hippocampal-Neocortical Consolidation Triptych)

> This axiom is preserved as the living Hippocampal-Neocortical dialogue that turns praxis/05-SIGMA buffer into canon/01-CANON neocortex. Layer 1 (Knowledge Graph) stores declarative entities, Layer 2 (Daily Notes) episodic logs, Layer 3 (MEMORY.md) procedural tacit patterns — exactly matching the minimum viable stack for the next 30 days. It enforces LTP/LTD pruning and weekly Sleep_Cycle consolidation, closing C-012.

- source_atom_ids: [ATOM-SOURCE-20260127-004-0003, ATOM-SOURCE-20260127-004-0009, ATOM-SOURCE-20260127-004-0013]
- why_preserved: Fuses three source views into one operational membrane that prevents memory drift and guarantees canon_delta growth. Consolidation per Oracle directive — three layers of single source into triptych axiom.
- matched_intention: INT-1707
- promoted_at: 2026-02-26

## Axiom: CC33-B2-AX02 — Agent Team Maturation Phases (Free-Energy Phase Transition)

> This axiom is preserved as the thermodynamic phase-transition model that minimizes free-energy waste in constellation maturation. Phase 1 (high correction overhead) → Phase 2 (feedback accumulation) → Phase 3 (rich context, minimal Sovereign input) directly maps to the 5-agent loop and OpenClaw activation sequence. It connects to the 4-connection minimum by making triangulation quality the catalyst only after entropy thresholds are crossed. It operationalizes C-004 triggers and prevents premature constellation dispatch.

- source_atom_ids: [ATOM-SOURCE-20260215-011-0009]
- why_preserved: Operationalizes C-004 triggers and provides empirical maturation timeline for constellation health. Syncrescendence at ~day 30 should be entering Phase 3 (compounding returns).
- matched_intention: INT-P035
- promoted_at: 2026-02-26

## Axiom: CC33-B2-AX03 — Polaris Constellation Architecture (Autopoietic Ensemble)

> This axiom is preserved as the autopoietic hypercycle blueprint for the 5-agent constellation (Commander COO, Psyche CTO, Ajna CSO, Adjudicator CQO, Cartographer CIO). Message-passing + constrained outputs enforce the Central Dogma and ontology gate as MHC self-recognition. It closes the Mac-mini offline fracture by sequencing OpenClaw activation only after Phase 3 maturation. It turns theoretical multi-agent design into the operational nervous system that makes Syncrescendence self-maintaining.

- source_atom_ids: [ATOM-SOURCE-20260203-010-0025]
- why_preserved: External validation of Syncrescendence constellation pattern from production medical AI (Hippocratic AI Polaris). Proves architecture at scale with constrained output spaces and specialized agents.
- matched_intention: INT-1804
- promoted_at: 2026-02-26
