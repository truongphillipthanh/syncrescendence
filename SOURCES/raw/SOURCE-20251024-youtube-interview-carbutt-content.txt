https://www.youtube.com/watch?v=twaNweVp1Ac
Alex Karpâ€™s BONKERS AI Bombshell!
17,223 views  Oct 24, 2025
Book a call with me to grow your business with YouTube - https://calendly.com/david-dcsocialme...
I generated 45M views + helped businesses generate $100k's from YouTube in 2024
Follow me on twitter -   / davidcarbutt_    

Contact me here for business or sponsorships opportunities - dcsocialmediadc@gmail.com

Want to join a private stocks group? Click here -https://www.fejeremy.com/2024-app-plt...

ðŸ“– Reccomended Palantir Substacks
Arny Trezzi - https://arnytrezzi.substack.com/
Either Square - https://eithersquare.substack.com/

America is already in an AI arms race, and most people do not realize it. In this interview, Palantir CEO Alex Karp explains why building AI infrastructure faster than adversaries is not just about innovation. It is about national security, global power, and preventing future wars. Karp breaks down how AI deployment, defense readiness, and peace through strength all connect. If the United States slows down, he argues, authoritarian regimes will lead the worldâ€™s most powerful technology. Watch to understand what is really at stake.

â€¢ The AI race is a geopolitical competition, not just a tech industry milestone
â€¢ Infrastructure and deployment speed determine which nation sets global rules
â€¢ Weakening AI development in America benefits adversaries like China
â€¢ Strength and technological superiority are essential to preventing war

This video explores Alex Karpâ€™s perspective on the AI arms race, Palantirâ€™s role in national defense, and why the United States must build AI infrastructure rapidly to stay ahead of rivals such as China. The discussion highlights key elements like computing power, secure data systems, and model deployment inside the Department of Defense. It explains how AI capability will determine global leadership and whether democratic values or authoritarian control shape future technology. The conversation illustrates why peace is best maintained through overwhelming technological strength.

Subscribe for more insights on AI, geopolitics, and national security. Watch next to stay informed on how technology is shaping the future of global power.

Alex Karpâ€™s Leaves Fox Host Speechless
Alex Karpâ€™s Bombshell Leaves Fox Host Speechless
Alex Karp Drops Hard-Hitting Truths on Fox
Internet Breaks w/Alex Karpâ€™s AI Bombshells!
Alex Karpâ€™s HUGE Message for Investors

---

0:00
Alex Carpa just dropped some bangers in
0:02
his latest interview. Check this bad boy
0:04
out.
0:05
There's basically the way they look at
0:06
it and the way I look at it, which is my
0:08
view, not uh not not anyone else's,
0:11
which is we're in a we're in a we're in
0:13
an arms race here. This is that's all
0:15
academic, super academic. It's like
0:18
we're going to either have AI and and
0:20
determine the rules or our adversaries
0:22
will have it and they'll determine the
0:23
rules. And it and so this is why these
0:26
infrastructure things are crazy
0:29
important because in order to make it
0:31
work, what do you need? You need
0:32
infrastructure that can actually run the
0:34
the models. So get the data there in a
0:36
secure and cheap enough way. You need to
0:38
make the models actually useful. You
0:40
need ontology to do that. Meaning you
0:42
have to deploy them where they're useful
0:43
and where they're not and and
0:45
orchestrate them. And if you start
0:47
putting impediments on this, de facto,
0:49
what's going to happen is our
0:51
adversaries will build it and we will be
0:53
buying everything from them, including
0:55
our ideas of how to run our country. And
0:57
so like my personal version, Palanteer,
1:00
what we represent at Palanteer, what we
1:02
do not impose on anyone else is we're
1:04
running. We're running like hell and
1:06
we're going to support anybody,
1:07
especially people on the front line who
1:08
can like galvanize this infrastructure.
1:11
and then our clients in the DoD
1:13
especially and help make the American
1:16
war fighter the most lethal in the
1:18
world.
1:18
Jen,
1:20
I mean, look, we're doing very well. I
1:22
mean, you know, and if if we're doing
1:24
things that are not valuable, then I
1:26
want to hear about that, too. So, I was
1:27
I was very supportive of those efforts.
1:29
Did you Did they tell you there was
1:30
something? Yeah. You know, we could trim
1:32
some of the volunteer stuff that we
1:33
have.
1:34
I I we have so many contracts. We're
1:36
doing very well. you know we we are
1:39
fully aligned with the US government and
1:40
if there were you know I I don't
1:42
actually no I don't think so but the
1:44
truth is um you know look our we have
1:47
we're do we become a very large business
1:50
actually surprisingly to most people
1:52
outside the US government and in US
1:54
industry which is where we're just you
1:56
know crushing it but also in the US
1:58
government and we're very aligned with
2:00
our this is one of the secrets of
2:02
Palunteer because we started in the US
2:03
government with full alignment when when
2:05
I show up I'm like I'm not saying pay me
2:07
and I'll do nothing. I'm like, hey,
2:09
we'll show you results and then pay us.
2:11
We are downstream from value creation.
2:13
And if downstream from value creation
2:14
means we're doing something that's not
2:16
valuable, like then I want to know
2:18
because it's not valuable for you and
2:19
tomorrow it's not going to be valuable
2:20
for
2:20
That's how we started. Alex came into my
2:22
office first. You were the first US CEO
2:24
to go to Ukraine after the war began.
2:27
Uh yes, that's true. And again, it's so
2:30
funny. I get yelled at in some places
2:32
because of Israel. I get yelled at some
2:33
places Ukraine. And
2:35
we're not yelling at No, I know you're
2:36
not. But it's fine. It's like to have
2:38
someone who welcomed is a rare um yeah,
2:41
you know, I I mean, by the way, just to
2:43
say the obvious, the Ukrainians are
2:44
tough and proud people and that's the
2:46
primary reason they're still fighting.
2:48
And um yeah, it's very hard to know what
2:51
will happen. I I'm happy, you know, as
2:53
we've seen, the president's fully
2:54
engaged and I think, you know, at some
2:56
point we might actually get a piece. I'm
2:58
really hopeful. It's a the war's going
3:00
on. It will cost a lot a lot of lives.
3:01
The truth is I don't know and I'm but I
3:03
am proud that we're able to support them
3:05
and they're I they're very very tough
3:08
people. I think they will you know
3:09
continue fighting until they can until
3:12
they can reach something that they feel
3:14
is they can accept.
3:15
President Trump has said that uh he's
3:17
not going to meet with Putin right now.
3:19
He really wants the war to stop, the
3:20
blood shed to stop and he's
3:22
well, you know what it No, I I really
3:24
respect that about the president that
3:25
he's actually a peace president and I,
3:27
you know, it's far less important, but
3:29
you know, we're not apparent here. The I
3:31
the idea and just what I very much
3:33
support is, you know, you you want to be
3:35
so strong that there are no wars. Wars
3:37
really really are bad.
3:39
America is in an arms race most people
3:41
don't even realize is happening. While
3:44
we debate AI safety and ethics, our
3:46
adversaries are building as fast as they
3:48
can with no restrictions. The country
3:50
that dominates AI infrastructure won't
3:52
just win economically, they'll determine
3:54
the rules for how the world operates.
3:57
And there's only one proven way to make
3:59
sure that competition doesn't turn into
4:01
actual war. Here's what Palanteer CEO
4:04
understands that most people miss. We're
4:06
in an AI arms race with our adversaries,
4:09
and if America puts restrictions on
4:11
building AI infrastructure, we'll lose.
4:13
and end up buying everything including
4:15
how to run our country from whoever
4:17
wins. Alex Karp says we're in an AI arms
4:20
race and it's either we have AI and
4:22
determine the rules or our adversaries
4:25
will. This is the most critical framing
4:27
of the AI competition that most people
4:29
miss. Everyone debates AI safety and
4:31
ethics and regulation like we're in a
4:34
vacuum making choices in isolation.
4:36
We're not. China is building AI
4:38
infrastructure as fast as possible with
4:40
zero concern for the debates happening
4:42
in Silicon Valley. The infrastructure
4:44
component is what determines who wins.
4:47
You can have the smartest researchers
4:49
and best algorithms, but if you can't
4:51
deploy them at scale with the compute
4:53
power, data systems, and orchestrational
4:55
needed, you'll lose. It's like having
4:58
the best tank design in 1940s, but no
5:00
factories to build them. Kob's point
5:02
about buying ideas on how to run our
5:05
country. If Chinese AI systems become
5:07
the dominant platform globally because
5:09
they built faster and bigger, then their
5:11
values and priorities get embedded into
5:13
the technology everyone else uses. This
5:15
is why Palanteer is running full speed
5:17
supporting anyone building this
5:19
infrastructure, especially defense and
5:21
frontline applications. They're not
5:23
debating whether AI should exist or
5:25
worry about perfect safety protocols.
5:28
They're operating under the assumption
5:29
that AI is coming regardless. And the
5:32
question is whether it's built by
5:33
America and its allies or its
5:35
adversaries. The concerns Karp's talking
5:38
about are all about regulatory proposals
5:40
and the AI pause movements, the calls to
5:43
slow down and make sure everything is
5:45
perfectly safe before deploying. Those
5:47
sound reasonable in isolation, but it
5:49
means disarming in an AI arms race.
5:52
China isn't pausing, they're
5:54
accelerating. Technological superity
5:56
determines geopolitical power. nuclear
5:59
weapons, satellite systems, internet
6:01
infrastructure. Whoever built it first
6:03
shaped how the world works. AI is the
6:06
next iteration of that pattern, except
6:08
the timeline is compressed, and the
6:10
impact is even broader. Palanteer's
6:12
position makes sense in this context.
6:14
They're not trying to be neutral.
6:16
They're explicitly aligned with making
6:18
sure the US and allies win the AI race
6:21
because they believe the alternative
6:23
authoritarian regimes controlling AI
6:25
infrastructure is not acceptable. And
6:28
that aggressive stance on AI dominance
6:30
connects directly to a larger philosophy
6:32
about how to prevent conflicts. The best
6:34
way to achieve peace is to be so
6:36
overwhelmingly strong that wars never
6:39
start because no one wants to fight you.
6:41
Wars are horrible, so prevent them
6:43
through strength. Alex says he respects
6:45
that President Trump is a peace
6:47
president who wants bloodshed to stop.
6:49
He adds what he supports at Palanteer is
6:52
you want to be so strong that there are
6:54
no wars because wars are really bad.
6:57
This is the peace through strength
6:58
doctrine that has been proven throughout
7:00
history but gets constantly criticized
7:02
as wararmongering. It's not. It's the
7:05
most effective way to prevent wars from
7:07
happening in the first place. Wars start
7:09
when aggressors believe they can win or
7:11
at least achieve objectives before the
7:13
costs become too high. If the calculus
7:15
is obviously we will lose badly and
7:17
quickly, rational actors don't start the
7:20
war. This is why NATO existed for
7:22
decades without direct US Soviet
7:24
conflict despite massive tensions. K
7:27
supporting Trump as a peace president
7:28
while simultaneously working to make the
7:30
American military more lethal isn't
7:32
contradictory. It's the same strategy.
7:35
You prevent wars by making fighting you
7:37
such a terrible idea that no one tries.
7:40
That requires actually having
7:42
overwhelming capability. The Ukraine
7:44
example shows both sides of this. Russia
7:46
invaded because they thought Ukraine was
7:48
weak and the West wouldn't respond
7:49
strongly. They miscalculated partly
7:52
because Ukraine had access to technology
7:54
like Palanteer systems that made them
7:56
far more capable than Russia expected.
7:58
That capability didn't start the war.
8:00
It's helping end it by making Russia's
8:02
victory much harder. Making the American
8:05
war fighter the most lethal isn't about
8:07
wanting to use lethality. It's about
8:09
ensuring that potential adversaries know
8:11
engaging in conflict with the US is
8:13
suicidal for their objectives. That
8:15
knowledge prevents conflicts from
8:17
starting. This connects back to the AI
8:19
arms race. If America has such dominant
8:21
AI capability that adversaries know they
8:23
can't win technologically, they're less
8:25
likely to start conflicts. If China
8:28
believes they're ahead in AI and can
8:29
leverage that advantage, they're more
8:31
likely to take aggressive actions.
8:33
Strength prevents conflicts. Weakness
8:36
invites it. One of our clients started
8:38
with zero audience. Now they're doing
8:41
$100,000 months thanks to YouTube. And
8:44
they're not alone. We've helped three
8:46
businesses hit that level just by
8:48
growing them a YouTube channel. Want to
8:49
see how this could work for your
8:50
business? Book a call with me below.