https://www.youtube.com/watch?v=JQjMXtEqze0
Tiny Recursive Model (TRM) Paper Explained
2,030 views  Oct 24, 2025
In this video, we break down the paper Less is More: Recursive Reasoning with Tiny Networks, which introduces the Tiny Recursive Model (TRM), a simplified version of the Hierarchical Reasoning Model (HRM).

With only 7 million parameters, TRM outperforms HRM and even top reasoning LLMs on challenging benchmarks such as ARC-AGI, Sudoku-Extreme, and Mazes.

Weâ€™ll break down its architecture and training process, and explore its results.

Written Review -  https://aipapersacademy.com/tiny-recu...
Paper - https://arxiv.org/abs/2510.04871
___________________
ðŸ”” Subscribe for more AI paper reviews!

ðŸ“© Join the newsletter â†’ https://aipapersacademy.com/newsletter/

Patreon -   / aipapersacademy  

The video was edited using VideoScribe - https://tidd.ly/44TZEiX
___________________
Chapters:
0:00 Introduction
1:36 TRM Results
3:10 TRM Architecture

---

Introduction
0:06
A couple of months back, we've reviewed
0:07
a new architecture called the
0:09
hierarchical reasoning model or HRM for
0:12
short that with just 27 million
0:14
parameters was able to beat top large
0:16
language models on some of the most
0:18
challenging reasoning benchmarks. Now, a
0:20
new paper titled Less is More, Recursive
0:23
Reasoning with Tiny Networks introduces
0:25
a new model architecture inspired by the
0:27
hierarchical reasoning model called Tiny
0:30
Recursive Model or TRM for short. With
0:33
only 7 million parameters and a simpler
0:35
architecture, tiny recursive model
0:37
achieves significant improvements over
0:39
the hierarchical reasoning model. As a
0:41
quick reminder, current
0:42
transformer-based large language models
0:44
rely on chain of thought reasoning.
0:46
Given an input prompt, the model
0:48
generates tokens that represent its
0:50
reasoning process, which are fed back
0:52
into the model and repeated until it
0:54
produces a final answer. However,
0:56
sometimes that's not enough. For
0:58
example, on RKGI 2, Gemini 2.5 Pro
1:02
achieves only 4.9% accuracy.
1:05
Additionally, generating long chain of
1:07
thought traces also comes with a cost.
1:09
Many forward passes with a growing
1:11
context window make the process slow and
1:13
expensive. Instead, the hierarchical
1:15
reasoning model and tiny recursive model
1:18
take a different approach based on
1:19
latent reasoning. Given a prompt, the
1:22
model performs its entire reasoning
1:23
process internally and outputs only the
1:26
final answer without the reasoning
1:27
traces. While this sounds like a
1:29
standard RNN, we'll see how it's
1:31
different when diving deeper into the
1:33
architecture. But before diving into the
1:35
architecture, let's look at the results.
TRM Results
1:37
Since the tiny recursive model is
1:39
evaluated on the same benchmarks as the
1:41
hierarchical reasoning model, we'll use
1:43
this figure from the hierarchical
1:45
reasoning model paper to illustrate the
1:47
types of reasoning tasks used for
1:49
evaluation. On the left is an ARC AGI
1:53
example, an IQ test-like puzzle where
1:55
the model needs to figure out rules from
1:57
a few examples to solve the puzzle
1:59
correctly. In the middle we see Sudoku
2:01
extreme, a data set the researchers
2:03
extracted from existing Sudoku data sets
2:06
and made it significantly harder to
2:08
solve. And on the right we have maze
2:10
solving problems where the model needs
2:11
to find the optimal path between two
2:13
points. Now in the following tables from
2:16
the paper we can see the results of the
2:18
tiny recursive model on these benchmarks
2:20
comparing to hierarchical reasoning
2:22
model and top reasoning models such as
2:24
Gemini 2.5 Pro and Claude 3.7. On the
2:28
Sudoku benchmark, we see an accuracy
2:30
jump of more than 30% with a model of
2:33
only 5 million params. The difference
2:35
between the two versions of the model is
2:37
that one uses self attention and the
2:40
other replaces that with an MLP block
2:42
inspired by the MLP mixer paper. For
2:45
Sudoku, that works well since the
2:47
context length is small and fixed,
2:49
smaller than the size of the model
2:50
dimension. For May solving, tiny
2:52
recursive model shows another 10.8%
2:55
improvement. And on the right, we can
2:57
see the improvement for ARC AGI 1 and 2.
3:00
Again, doing better than top reasoning
3:02
models, which are orders of magnitude
3:04
larger. Even though this is a
3:06
taskspecific model, that's still
3:08
impressive. So, how does it actually
TRM Architecture
3:10
work? Let's look at the architecture.
3:12
Let's start with the hierarchical
3:14
reasoning model diagram since the idea
3:16
is similar. First, the input goes
3:18
through a trainable embedding layer
3:20
which turns it into a representation.
3:22
The model can work with the hierarchical
3:24
reasoning model. Use two coupled
3:26
recurrent modules working together at
3:28
different time scales and use an analogy
3:30
where the highle module is the planner
3:32
and the low-level module is the doer.
3:34
The highle module handles abstract
3:37
reasoning and sets the overall direction
3:39
while the low-level module runs fast
3:41
detailed computations to follow the
3:43
highle plan and work out the specifics.
3:46
While this analogy helps to understand
3:47
the overall idea, it may not be an
3:50
entirely correct interpretation. The
3:52
tiny recursive model simplifies this by
3:55
using a single module that learns to
3:57
handle both roles. Note that although
3:59
the diagram shows multiple boxes, they
4:01
all share the same weights. It's a
4:03
single module applied repeatedly to
4:05
refine the reasoning. The names of the
4:07
latent features change as well. Instead
4:09
of Zh which represented the latent
4:11
features of the high-level module, we
4:13
now have Y which represents the
4:15
embedding of the current solution. We'll
4:18
see that it is refined by the model
4:20
until it's finally used to project the
4:22
output. Instead of ZL, which represented
4:24
the latent features of the low-level
4:26
module, we now have Z, which represents
4:29
the model's latent reasoning. As we'll
4:31
now see, both latent features Y and Zed
4:33
are recursively refined by the model. We
4:36
start by refining the latent reasoning
4:38
feature Zed. As input, the module takes
4:40
the input embeddings, the current latent
4:42
reasoning Z, and the current output
4:44
embedding Y. This allows the module to
4:47
update its internal reasoning Z based on
4:49
what it currently believes, what it has
4:51
produced so far, and the original
4:53
problem input. This step is repeated for
4:55
several recurrent steps noted as T, a
4:58
hyperparameter of the model. At each
5:00
step, the module consumes its current
5:02
latent reasoning Z from the previous
5:04
step together with the original input
5:06
embeddings and the output embedding Y,
5:08
which is still the initial one since we
5:10
haven't updated it yet. Once these steps
5:13
are done, we run a single step with a
5:15
different row. The model now processes
5:17
the refined latent reasoning Z along
5:19
with the current output embedding Y to
5:21
refine the output embedding. So here we
5:24
update Y. An important observation is
5:26
that when updating Y, the model doesn't
5:29
use the input embedding. This separation
5:31
helps the model clearly learn to
5:32
distinguish between its two roles of
5:34
reasoning refinement and output
5:36
refinement. This is a main reason for
5:38
why there is no need for two different
5:40
modules. We then repeat the same
5:42
process. The model runs another T steps
5:44
of refining the latent reasoning Z now
5:47
with the new output embedding Y and
5:49
afterwards again refineses Y using the
5:51
new latent reasoning zed. The diagram
5:53
only shows two cycles, but in practice,
5:56
this nested loop runs for n cycles,
5:58
another hyperparameter of the model.
6:00
Finally, the output embedding Y is fed
6:03
into a trainable output layer that
6:05
produces the final tokens. One thing
6:07
that's different from standard recurrent
6:09
networks is the use of two latent
6:11
features for different purposes. Another
6:13
difference lies in how the model is
6:15
trained. Normally, recurrent models are
6:17
trained using back propagation through
6:19
time or BPTT. In back propagation
6:22
through time, the loss is back
6:23
propagated through every single step
6:25
which requires huge memory and often
6:28
becomes unstable when the reasoning
6:29
chain is long. Let's start with how the
6:32
hierarchical reasoning model handles
6:33
this. Instead of using full back
6:36
propagation through time, hierarchical
6:38
reasoning model avoids it by applying a
6:40
one-step gradient approximation. That
6:42
means that instead of back propagating
6:44
through all the recursive steps over the
6:46
cycles, it only updates parameters based
6:48
on the current steps computation shown
6:50
in blue in this diagram. This has two
6:52
major benefits. First, no matter how
6:54
many reasoning steps we have, memory
6:56
stays the same. Second, training becomes
6:59
more stable since it avoids exploding or
7:01
vanishing gradients from long back
7:03
propagation chains. However, one-step
7:05
gradient approximation relies on a
7:07
strong mathematical assumption. In
7:09
short, it assumes that the model
7:11
converged to a fixed point. As the tiny
7:13
recursive model paper points out, that's
7:15
rarely guaranteed in practice. And the
7:17
hierarchical reasoning model never
7:19
actually checks if the model converged
7:21
before applying the update. To remove
7:23
this assumption, the tiny recursive
7:25
model takes a different approach. Tiny
7:27
recursive model back propagates through
7:29
a single full cycle, which includes one
7:31
step of output refinement and teps of
7:34
latent reasoning refinement. This
7:36
requires a few more backward passes
7:38
comparing to hierarchical reasoning
7:40
model, but it's still way more efficient
7:42
comparing to back propagation through
7:43
time since the model can run for many
7:45
cycles. By training over a full cycle,
7:48
the model learns to improve its
7:49
reasoning iteratively. In other words,
7:52
it starts each cycle with some initial Y
7:54
and Z inputs and learns to make them
7:56
better. This doesn't require a strong
7:58
mathematical assumption. During
8:00
inference, multiple forward cycles push
8:02
it progressively closer to the correct
8:04
solution. One more missing piece here is
8:06
adaptive halting after end cycles are
8:09
completed. The last hidden state of the
8:11
highle module is not just passed to the
8:13
output layer as drawn here. Instead, it
8:16
first passes via a halting head that
8:18
decides whether the model should stop or
8:20
reason for another n cycles. This way,
8:23
the model can dynamically adjust its
8:25
thinking time depending on task
8:26
complexity. For harder problems, it can
8:29
continue reasoning for more cycles,
8:30
while for easier ones, it stops early to
8:33
save compute. Before wrapping up,
8:35
there's an important nuance to mention.
8:37
The paper's title, less is more,
8:39
suggests that smaller might be better
8:41
for this architecture. However, these
8:43
results may actually reflect a fight
8:45
against overfitting since the model was
8:47
trained on very limited data. A smaller
8:49
network was possibly necessary to
8:51
prevent overfitting. So, in this case,
8:54
less really means just enough. Small
8:56
enough to generalize from scarce data,
8:58
yet still powerful thanks to its
9:00
recursive reasoning design. If you found
9:02
this content valuable, please subscribe
9:04
and hit the like button to support the
9:06
channel. We also send one minute read
9:08
summaries by mail about the papers we
9:10
review here. Thank you for watching and
9:12
stay tuned for more reviews of AI
9:14
papers.