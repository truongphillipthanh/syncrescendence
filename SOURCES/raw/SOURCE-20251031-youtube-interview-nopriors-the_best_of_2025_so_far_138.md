# No Priors: The Best of 2025 (So Far)

**Participants:** Sarah Guo and Elad Gil (hosts), with segments featuring Winston Weinberg (Harvey), Dr. Fei-Fei Li (World Labs), Brendan Foody (Mercor), Dan Hendrycks (Center for AI Safety), Noubar Afeyan (Flagship Pioneering), Brandon McKinzie and Eric Mitchell (OpenAI), Isa Fulford (OpenAI), Arvind Jain (Glean), and Dr. Shiv Rao (Abridge)

**Context:** A compilation of standout moments from No Priors podcast interviews throughout 2025, featuring conversations with leading founders and researchers in AI.

---

## Winston Weinberg on Leaning into New Capabilities

Let's start with a moment that captures the magic of leaning into new capabilities at the right time. Harvey CEO Winston Weinberg discovered an extraordinary opportunity hidden in plain sight.

**Winston Weinberg:** Gabe and I actually had met a couple years before and I definitely didn't know anything about the startup world and didn't have a plan of doing a startup. And what had happened was he showed me GPT-3, which at the time was public, and I was first of all just incredibly surprised that no one was talking about GPT-3 and no one was using it in any way, shape or form. And he showed me that and I showed him kind of my legal workflows and we started—the kind of aha moment was we went on r/legaladvice, which is basically a subreddit where people ask a bunch of legal questions and almost every single answer is "so who do I sue?" Almost every single time. And we took about a hundred landlord tenant questions and we came up with kind of some chain of thought prompts—and this is before anyone was talking about chain of thought or anything like that—and we applied it to those landlord tenant questions and we gave it to three landlord tenant attorneys and we just said nothing about AI. We just said here's a question that a potential client asked and here is an answer. Would you send this answer without any edits to that client? Would you be fine with that? Is that ethical? Is it a good enough answer to send?

And 86 out of 100 was yes. And actually we cold emailed the general counsel of OpenAI and we sent him these results and his response basically was, "Oh, I had no idea the models were this good at legal." And we met with the C-suite of OpenAI a couple weeks after.

## Dr. Fei-Fei Li on Spatial Intelligence

Now, from legal reasoning to spatial intelligence, the legendary Dr. Fei-Fei Li opened our eyes to an entirely different dimension of AI capability.

**Dr. Fei-Fei Li:** I think from a neural and cognitive science point of view that spatial intelligence is a really hard problem that evolution has to solve for animals. And what's really interesting is I think animals have solved it to an extent but not fully solved it. It's one of the hardest problems because what is the problem animals have to solve? Animals have to evolve the capability of collecting lights in something which we call eyes mostly. And then with that collection of eyes, it has to reconstruct a 3D world in their mind somehow so that they can navigate and they can do things and of course they can interact. For humans, we're the most capable animal in terms of manipulation. Then we can do a lot of things and all this is spatial intelligence. To me that's just rooted in our intelligence. 

What is interesting is it's not a fully solved problem even in animals. For example, for humans, if I ask you to close your eyes right now and draw out or build a 3D model of the environment around you, it's not that easy. We don't have that much capability to generate extremely complicated 3D models till we get trained. There are some of us whether they're architects or designers or just people with a lot of training and a lot of talent. And that's a hard thing to do. And imagine you do it at your fingertip much more easily and allow much more fluid interactivity and editability. That would just be a whole different world for people. No pun intended.

## Brendan Foody on AI Disruption in the Workforce

Data is the beast feeding the AI train. And thus, Mercor CEO Brendan Foody is working with major AI labs on how to build what's next. He gives a clear prediction about what's coming for the workforce.

**Brendan Foody:** I think displacement in a lot of roles is going to happen very quickly and it's going to be very painful and a large political problem. Like I think we're going to have a big populist movement around this and all the displacement that's going to happen. But one of the most important problems in the economy is figuring out how to respond to that, right? Like how do we figure out what everyone who's working in customer support or recruiting should be doing in a few years? How do we reallocate wealth once we have—once we approach super intelligence—for especially if the value and gains of that are more of a power law distribution. And so I spend a lot of time thinking about like how that's going to play out and I think it's really at the heart of—

**Interviewer:** What do you think happens eventually—x% of people get displaced from like collar work. What do you think they do?

**Brendan Foody:** I think there's going to be a lot more of the physical world. I think that there's also going to be a lot of niche—

**Interviewer:** What does the physical world mean?

**Brendan Foody:** Well, it could be everything ranging from people that are creating robotics data to people that are waiters at restaurants or are just like therapists because people want like human interaction—like whatever that looks like. I think all of—I think that automation in the physical world is going to happen a lot slower than what's happening in the digital world just because of so many of the like self-reinforcing gains and a lot of self-improvement that can happen in the virtual world but not physical one.

## Dan Hendrycks on the Geopolitics of Superintelligence

Which brings us to one of the biggest questions of our time. How do we navigate the geopolitical implications of super intelligence? Dan Hendrycks, the director of the Center for AI Safety, has an answer.

**Dan Hendrycks:** Let's think of what happened in nuclear strategy. Basically, a lot of states deterred each other from doing a first strike because they could then retaliate. So, they had a shared understanding that nuclear war would be mutually destructive. Now, with AI and superintelligence, the dynamics are different. First of all, you have the capability concentration—AI capabilities are being developed by a small number of actors, both state and non-state. Second, there's the question of whether these systems will be controllable once they reach certain capability thresholds. And third, there's the issue of speed—AI development is happening much faster than nuclear weapons development did.

So you need international coordination mechanisms that don't yet exist. You need verification protocols for AI development that are technically feasible but politically difficult. And you need to solve the problem of what happens when you have multiple actors racing toward superintelligence, each afraid that if they slow down, someone else will get there first and potentially use it against them. This is the alignment problem writ large at a geopolitical scale.

## Noubar Afeyan on Entrepreneurship

**Host:** Few people have shaped the biotech industry like Noubar Afeyan. As founder and CEO of Flagship Pioneering, he's been behind some of the most significant innovations in science, including co-founding Moderna. Here's what he had to say about the entrepreneurial mindset.

**Noubar Afeyan:** I think entrepreneurship is not about taking risks. It's about taking calculated leaps where you can see further than others see. Most people think entrepreneurship is about being comfortable with uncertainty, but I think it's actually about creating certainty in the midst of uncertainty. You do that by having a thesis about the future that you test rigorously and iteratively.

At Flagship, we don't start with a market need and then look for a technology to fill it. We start with "what if?" questions that seem unreasonable. What if we could program cells like we program computers? What if we could create medicines that don't exist in nature? And then we systematically de-risk those questions through scientific experimentation before we ever create a company.

The key is being willing to operate in the realm of the seemingly impossible. Most venture creation happens at the edge of what seems plausible. But real breakthroughs happen when you push into the territory of what seems implausible—and you do it with enough scientific rigor that you can defend why it might actually work.

## Brandon McKinzie and Eric Mitchell on Reasoning Models

**Host:** OpenAI researchers Brandon McKinzie and Eric Mitchell have been at the forefront of developing reasoning models. Here's what they shared about the latest advances.

**Brandon McKinzie:** What we're seeing with these reasoning models is fundamentally different from what we've had before. These models can actually think through problems step by step in a way that's much more deliberate. They're not just pattern matching—they're actually engaging in something closer to what we might call reasoning.

**Eric Mitchell:** The key insight is that if you give models time to think—if you allow them to generate intermediate reasoning steps before they arrive at an answer—they can solve much harder problems. We're seeing this with mathematical reasoning, with coding, with complex logical puzzles. The models are learning to break problems down, consider multiple approaches, and self-correct.

**Brandon McKinzie:** One of the most exciting things is that these models are starting to exhibit something like metacognition. They can reflect on their own reasoning process and identify when they might be going down the wrong path. That's a pretty significant capability.

**Eric Mitchell:** Though I should say—and this is important—these models still have significant limitations. They can sometimes appear to be reasoning when they're really just following learned patterns. And they can make mistakes that seem obvious in hindsight. There's still a lot of work to do.

**Brandon McKinzie:** Yeah, we're making progress, but we're not anywhere close to solving reasoning completely. Each breakthrough reveals new challenges.

## Isa Fulford on Training Deep Research

**Host:** Isa Fulford from OpenAI has been working on training models for deep research capabilities.

**Interviewer:** Can you talk about what you're building with deep research?

**Isa Fulford:** Yeah, it's really interesting. The idea is that you want models that can do the kind of research that a really good research assistant would do—someone who can go deep on a topic, find relevant sources, synthesize information, and come back with insights that actually move your understanding forward. That requires a different kind of training than what we've done before.

We're trying to train models that don't just retrieve information, but actually understand what makes a good research question, how to break it down into sub-questions, how to evaluate the quality of sources, and how to synthesize findings in a way that's coherent and useful.

**Interviewer:** What's the hardest part?

**Isa Fulford:** I think the hardest part is getting the models to understand what "depth" means. Like, when do you stop? When have you actually answered the question versus when are you just accumulating more surface-level information? That judgment is really hard to capture.

**Interviewer:** Have you been impressed with the results so far?

**Isa Fulford:** Yeah. It's the visceral experience of like, oh, the path is paved with strawberries or whatever.

**Interviewer:** Exactly.

**Isa Fulford:** But then sometimes some of the things that it fails at also surprising—like sometimes it will make a mistake where it will do such smart things and then make a mistake where I just thinking why are you doing that? Like stop. So I think there's definitely a lot of room for improvement. Yeah, we've been impressed with the model so far.

## Arvind Jain on Innovating Enterprise Search

One of the biggest surprises of AI and a core principle for us here at Conviction is how it can make bad markets suddenly good ones. The right technology can meet the right moment in unexpected ways. Arvind Jain built Glean in what everyone said was a graveyard market: enterprise search.

**Arvind Jain:** It was like a graveyard of all these companies that tried to solve the problem and it didn't. Part of it was just that I think search is a hard problem in an enterprise. Even getting access to all the data that you want to search was such a big problem in the pre-SaaS world. There was no way to sort of go into those data centers, figure out where the servers were, where the storage systems were, try to connect with information in them—it was a big challenge. So SaaS actually solved that issue. Most of the companies started in the pre-SaaS world—they failed because you just couldn't build a turnkey product. But SaaS actually allowed you to actually build something.

My insight was that look, the enterprise world has changed. We have these SaaS systems now and SaaS systems don't have versions. Everybody, all customers have the same version. They are open, they're interoperable, you can actually hit them with APIs and get all the content. I felt that the biggest problem was actually solved, which was that I could actually easily go and bring all the enterprise information and data in one place and build this unified search system on top. So that was actually a big unlock.

And by the way the origins of Glean is—so at Rubrik, we had this problem. We grew fast, we had lot of information across 300 different SaaS systems and nobody could find anything in the company and people were complaining about it in our pulse surveys. And I always run it in my startups. And so this is a complaint that came to me. I had to solve it. So I tried to buy a search product and I realized there's nothing to buy. I mean that's really the origins of how Glean got started as a company.

So SaaS made it easy to actually connect your enterprise data and knowledge to a search system. So that actually made it possible for us to for the very first time build a turnkey product. But there are a lot of other advances as well. Businesses have so much information and data. One interesting fact—one of our largest customers, they have more than 1 billion documents inside their company. Now hear this: when Larry and I, when we were working on search at Google in 2004, the entire internet was actually 1 billion documents. There's a massive explosion of content inside businesses. So, you have to build scalable systems and you couldn't build like a system like that before in the pre-cloud era.

## Dr. Shiv Rao on AI's Human Impact

Perhaps no story captures the human impact of this AI moment and its potential better than what's happening in healthcare. Here's Shiv Rao, CEO and founder of Abridge.

**Dr. Shiv Rao:** It's pretty heroic in general for a doctor to give you feedback like "hey this sucked and you got to do better." Like you didn't recognize the way I said this medication or I'm a gastroenterologist and I would never sequence my problems in my assessment and plan section of my note this way. It doesn't serve me well and makes me look terrible as a doctor or whatever. We get that feedback. We love it. It's oxygen.

But then we also get the feedback that's like, "Hey, this is amazing and I'm not going to retire anymore and I've got like years, decades left in my career now thanks to this technology." In this channel, love stories, all of that feedback—that positive feedback—we just get it programmatically funneled. So any one of our people inside of the company can always go into that channel and it's like purpose, you know? It's like fulfillment immediately. You immediately understand why we're all working so hard and why it makes sense because being on this very telephone pole journey these last couple years is obviously—it's new for so many of us and we're all kind of building new muscles—but it's a lot of pressure. 

But this is my favorite bit of feedback. So this love story comes from a doctor at Tanner Health, which is a rural health system, and she wrote to us—she wrote: "I was sitting at dinner last week and my son asked me, 'Mommy, why aren't you working right now?' I literally took my phone out and explained to him that Abridge is a new tool that lets mommy come home early and eat dinner with her family." I started to tear up and looked over at my husband who then said, "Mommy's going to be able to eat dinner with us every night now." 

And we get feedback like that every day. And so there's dopamine hits in hypergrowth and like those are awesome, but I think that they get us through sprints. But I think it's the oxytocin hits like this. It's the purpose. It's the fulfillment. It's like—that's I think what I think we're really after in this company. And so like everybody's mission driven out there, but I think this mission—like it hits me at least a little bit different.