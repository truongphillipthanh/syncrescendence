https://www.youtube.com/watch?v=zt0JA5rxdfM
AI Trends 2026: Quantum, Agentic AI & Smarter Automation
117,766 views  Dec 22, 2025  #automation #cloudcomputing #agenticai
Ready to become a certified watsonx AI Assistant Engineer v1 - Professional? Register now and use code IBMTechYT20 for 20% off of your exam â†’ https://ibm.biz/BdbTDQ

Learn more about AI Trends Shaping the Next 10 Years here â†’ https://ibm.biz/BdbTDT

What will define AI in 2026? ðŸš€ Martin Keen & Aaron Baughman explore groundbreaking trends like Agentic AI, cloud computing, automation, and quantum computing, plus innovations like Physical AI. Discover how these technologies will transform industries and drive the next wave of intelligence.

AI news moves fast. Sign up for a monthly newsletter for AI updates from IBM â†’ https://ibm.biz/BdbTDk

#agenticai #cloudcomputing #automation

---

0:00
What will be the most important trends in AI in  2026? Well, we take a stab at this every year  
0:06
with with some success, I would say. And this  time out, I have the knowledgeable assistance  
0:11
of my colleague, Aaron Baughman, to help us out.  Well, yeah. You know, after your prediction  
0:16
of infinite memory last year, I thought maybe  you could use just a little bit of help. Yeah,  
0:20
that's that's fair. Well, how about we each take  four trends each? That sounds good. How about you  
0:26
first? All right. Okay. So my number one trend  of 2026 is multi-agent orchestration. Now last  
0:36
year we said 2025 was the year of the agent.  AI agents that can reason and plan and take  
0:42
action on a task and agents I think it's fair  to say really delivered. There are new numerous  
0:47
agentic platforms for tasks like coding and basic  computer use but no single agent really excels at  
0:55
everything. So, what if you had a whole team of  agents working together? So, maybe we've got an  
1:01
agent here that kind of acts as a planner agent  that decomposes goals into steps. Maybe we have  
1:08
some worker agents here that do different  steps like one specializes in writing code,  
1:15
others call APIs and so forth. And then perhaps  we have a critic agent that evaluates outputs and  
1:22
flags issues. And these agents collaborate under  a coordinating layer that is the orchestrator.  
1:33
And multi-agent setups like this help introduce  cross-checking where one agent checks the other  
1:38
agents work and it can break problems into more  discrete verifiable steps. Well, great. So,  
1:45
how could I really follow that trend?  Well, I think I might just have one. So,  
1:49
the second one is going to be the digital labor  workforce. So now these are digital workers that  
1:56
are autonomous agents that can do a couple  of items. So the first one is they can parse  
2:01
a task by interpreting multimodal input. So after  preparation the worker then executes what's called  
2:08
a workflow. Now this is where at the end of an  action plan you know it would follow a sequence of  
2:15
steps but then it has to be integrated into some  sort of system that then in turn can take action.  
2:22
And these could be downstream components. Now  these systems are then further enhanced by what we  
2:27
call human-in-the-loop AI, which then provides a  couple of items. The first one would be oversight.  
2:33
The next one would be correction and then we're  looking at these strategic guidance or these rails  
2:38
um to ensure that all of these agents are doing  what they're supposed to be doing. Now this  
2:43
overall trend will create a force multiplying  effect to extend human capability. Now trend  
2:49
number three is physical AI. Now we all know that  large language models they generate text like ABC.  
3:00
And then there are other models as well. So for  example there are plenty of diffusion image models  
3:06
and they generate pixels. They generate images.  These are all operating in digital space. Now,  
3:14
physical AI is about models that understand and  interact with the world that we live in, the the  
3:21
real 3D world. And this is about models that can  perceive their environment, reason about physics,  
3:29
and that can take physical action like robotics.  So, previously getting a robot like this to do  
3:37
something useful meant programming explicit rules.  So if you see an obstacle, you should turn left,  
3:44
for example. And it was all done by humans. It  was up to yeah, smart guys like this to code these  
3:53
rules. Now, physical AI kind of flips that around.  So you train models in simulation that simulate  
4:03
the real world and it learns to understand  how objects behave in the physical world,  
4:08
how gravity works, how to grasp something without  crushing it. Now these models are sometimes called  
4:16
world foundation models. They're generative models  that can create and understand 3D environments.  
4:23
They can predict what happens next in a physical  scene. And in 2026, many of these world models are  
4:30
taking things like those humanoid robots that you  found there, Aaron, and they're taking them from  
4:36
research to commercial production. Physical AI  is scaling. Well, Martin, you just took my trend,  
4:43
but let's just go ahead and say number four is  about social computing. Now, this is a world  
4:49
where many agents and humans operate within the  shared AI fabric. So say if I have an agent here  
4:55
and then a human here. So they're going to be  connected through this fabric and here if I  
5:02
have information that flows between the two, they  begin to understand each other and then they can  
5:08
gather what the intent is going to be. And then  once they have the intent and information, they  
5:13
have actions. They can affect each other or maybe  even the environment of which they're in. But all  
5:19
of this flows seamlessly across this system. It's  this shared space that enables collaboration,  
5:25
context exchange as well as event effective  understanding. Now the outcome is really an  
5:30
empathetic emergent network of these interactions.  It's what we call this collective intelligence  
5:35
or this real world swarm computing. So teams of  agents, digital labor, humanoid robots, and tech  
5:43
that can understand me with effective computing.  2026 could be uh quite the year and we're only  
5:50
halfway through the trends. So trend number five  that is verifiable AI. Now the EU AI act is coming  
6:03
and by mid 2026 it becomes fully applicable.  And think of this a little bit like GDPR but for  
6:10
artificial intelligence. Now, the core idea here  is that AI systems, especially high-risk ones,  
6:17
need to be auditable and they also need to  be traceable. Now, what does that mean? Well,  
6:22
it means a few things. It means documentation.  So, if you're building high-risk AI, you need  
6:29
technical docs that demonstrate compliance to  how you tested the models and the risks that you  
6:34
identified. It means transparency. So, users need  to know when they're interacting with the machine.  
6:41
So things like synthetic text, they need to be  clearly labeled and it means data lineage. You  
6:48
need to be able to summarize where your training  data came from and prove you respected copyright  
6:53
optouts. And just like how GDPR has shaped global  privacy, not just folks in the EU, the EU AI act  
7:01
will probably set the template for AI governance  worldwide. Wow, that's great. And you know, trend  
7:07
number six, right? It really changes everything,  but it also changes nothing at the same time.  
7:13
And now this is where we put in quantum utility  everywhere. So 2026 is where we start to see this  
7:20
quantum computing to reliably start solving  real world problems better, faster, or more  
7:26
efficiently than classical computing methods. Now,  at this point, we have this quantum utility scale.  
7:32
is these systems that begin working alongside and  together with classical infrastructure to deliver  
7:37
these practical value in everyday workflows. Now,  this is going to help with optimization and then  
7:44
we'll also look at simulation and decision-making.  Now, all three of these tasks were previously  
7:50
out of reach within the classical realm. But this  hybrid quantum classical error, it will begin to  
7:56
transform quantum computing into this mainstream  paradigm as it's going to be woven into our  
8:01
everyday business operations. Now my trend number  seven is reasoning at the edge. Now last year, we  
8:10
talked about very small models, models with just  a few billion parameters that don't need huge  
8:14
data centers to run. They work on your laptop  or well maybe even your phone. Well, in 2026,  
8:21
those small models are learning to think. So, if  we think about the best models that we have today,  
8:27
the frontier models, well, pretty much all of them  now use something called inference time compute.  
8:36
They spend extra time thinking before giving you  an answer, working through problems step by step.  
8:42
Now, the trade-off for that is they need more  compute. But here's what's changing. Essentially,  
8:49
teams have figured out how they can distill all  of this reasoning information into smaller models.  
8:59
So now these smaller models can perform thinking  as well. You're taking massive reasoning models  
9:05
that generate tons of step-by-step solutions and  we're using that data to train the smaller models  
9:12
to reason the same way. And that's resulting  in reasoning models with only a few billion  
9:17
parameters. They work offline. Your data never  leaves your device. And there's no roundtrip  
9:22
latency to a data center. So for anything that's  real time or mission critical, having a model that  
9:28
can actually reason through a problem locally is  a pretty big deal. Yeah. So that's all very true,  
9:35
Martin. But now our last and final trend is number  eight. So this is what we're calling amorphous  
9:42
hybrid computing. So this is a future where both  AI model topologies and the cloud infrastructure,  
9:48
they blend into what's called a fluid computing  backbone. So AI models, they're shifting beyond  
9:53
just this pure transformer design, right? They're  beginning to evolve into these other architectures  
9:59
that integrate transformers and we call them  these state space models. And then in 2026,  
10:06
you're also going to see different emerging  algorithms that are combine both the state space  
10:11
and transformers and other elements together,  right? And that's going to be really fun to watch,  
10:17
very artful. And then at the same time, we have  this cloud computing piece that's becoming fully  
10:23
differentiated by combining many different  chip types. So we're going to have CPUs,  
10:29
GPUs, TPUs as well. And finally, what we just  talked about in trend six, quantum, we're going  
10:37
to have QPUs. I did also want to mention and  note that you'll see these neuromorphic chips  
10:42
that are coming out and those emulate the brain.  But all of these are going to be put together  
10:48
right into this unified compute environment  where parts of each of these types of models,  
10:53
they're going to be automatically mapped to  the optimal compute substrate. And this is  
10:57
really going to help to deliver this maximum  performance and efficiency. And you know what?  
11:02
Who knows? But at this pace, probably  not in 2026, but I think further out,  
11:07
you might see DNA computing entering into the  mix. Well, those are some lofty goals. And look,  
11:13
these are what we think are some of the biggest  AI trends in 2026. But what are we missing?  
11:21
Which AI trend do you expect to be a big deal in  2026? Yeah, let us know in the comments below.