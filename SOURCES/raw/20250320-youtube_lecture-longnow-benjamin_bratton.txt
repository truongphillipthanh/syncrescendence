https://www.youtube.com/watch?v=DlPMV5LJc-I
Benjamin Bratton | A Philosophy of Planetary Computation | Long Now Talks
8,688 views  Mar 20, 2025  Long Now Talks
We find ourselves in a pre-paradigmatic moment in which our technology has outpaced our theories of what to do with it. 

The task of philosophy today is to catch up.

Benjamin Bratton is a Professor of Philosophy of Technology and Speculative Design at University of California, San Diego and the Director of Antikythera, an cross-disciplinary think tank researching the philosophy of computation supported by Berggruen Institute. In his Long Now Talk, Bratton takes us on a whirlwind philosophical journey into the concept of Planetary Computation — a journey that began in classical Greece with the story of the Antikythera mechanism, the analog computer that gave his think-tank its name. But his inquiry stretches far beyond antiquity —  back to the very origins of biological life itself and forward to a present and future where we must increasingly grapple with artificial life and intelligence.

This talk was presented January 29, 02025 at the Cowell Theater in San Francisco. The event livestream is here:
https://youtube.com/live/zdy9K4UWplM

Episode notes: 
https://longnow.org/ideas/a-philosoph... 

To learn more about Antikythera’s work, visit 
https://antikythera.org/ 

This Talk is part of Long Now Talks.

Launched by Stewart Brand in 02003, Long Now Talks has invited more than 400 leading thinkers to share their civilization-scale ideas with a live audience and millions around the globe tuning in to our podcast and videos. Long Now Talks are brought to you by The Long Now Foundation, which has spent the last 25 years igniting cultural imagination around long-term thinking.

By inspiring thought and conversation about how we've been shaped by the last 10,000 years and what might be in store for us over the next 10,000 years, Long Now Talks seek to expand our collective sense of the present moment. Long Now Talks cover futurism and speculative fiction; time, nature, and contemplative practices; the intersection of the humanities and sciences; the evolution of counterculture to cyberculture; cultural imagination, land art and public monuments; and of course, long-term thinking and being a good ancestor.
In our age of compounding crises, The Long Now Foundation is a counterweight — our community of 12,000 strong across 65 countries over our first quarter century. We are a force that imagines new possibilities, thinks critically, and takes action over the long term. We believe that when we all come together, bound by commitment and curiosity, audacious things become possible. Will you join us?  https://longnow.org/join

---

0:01
[Music]
0:10
good evening and welcome to the long now Foundation my name is Patrick Dow and
0:16
I'm honored to introduce myself as the new board president of the long now foundation and host for your long Now
0:24
talks going forward [Applause]
0:32
tonight's conversation could not be more timely as Humanity's technological
0:37
capabilities Advance at an unprecedented Pace we need new Frameworks for
0:43
understanding them at larger scales of both time and space Benjamin Bratton our
0:48
speaker this evening offers exactly these kinds of deeper broader perspectives for us to consider
0:55
Benjamin's work challenges us to think Beyond current debates on AI toward
1:00
larger time scales where the very nature of intelligence life and Technology May
1:07
fundamentally transform our world please
1:17
enjoy um well thank you everyone I want to begin also just saying that um what a pleasure it is to be able to share some
1:24
of this work with you all at long now Foundation uh an institution that I've long admired
1:30
uh no no pun intended so take a moment perhaps to take a step back and away
1:36
from the persistent weirdness of of our times one in which we get free AI from a
1:43
hedge fund and $200 a month AI from a nonprofit
1:51
um never would have called that one um but more broadly
1:57
speaking I if you take one one sort of idea away from this is that I I genuinely think we are in a kind of pre
2:03
paradigmatic moment that a lot of ideas are floating around that increasingly
2:09
look kind of similar to one another and are coming together into something that may constitute a frame of reference uh
2:15
that may be more useful to us but this is a difficult process it's one that we'll kind of have to invent I'll put it
2:21
this way there's certain times in history when our uh our ideas of what it is that we would like to do are way
2:26
ahead of the technological capacity to do that and there are other times when
2:31
uh the technology is in essence ahead of our Concepts and um I think this is probably
2:37
more where we're at and in those moments what we call philosophy its job is to
2:42
invent try to conjure those Concepts and bring them into bring them into being so they may be put to some use
2:49
unfortunately I don't know that that's entirely what what's going on a lot of our most important epistemic
2:55
institutions such as such as universities I fear to report are a bit of a holding pattern in that the
3:00
Sciences are focused on a kind of do now think later mode where and the
3:06
humanities where I spend most of my time um it's more of a critique now um and
3:12
perhaps act later but we'll maybe not in other words this sort of this is
3:19
exactly the wrong time to not be inventing those Concepts uh and not be
3:24
setting the initial conditions for the the society to come and yet here we are so let's begin our topic is computation
3:33
as you'll see we sort of mean this in a somewhat idiosyncratic way it's less to do with mathematics and algorithms or
3:39
with these kind of little appliances that we've constructed um but rather as computation as a as a planetary
3:46
phenomenon not just something that humans do but indeed through humans something that the planet does our first
3:51
proposition for the evening would be that is this that computation was discovered as much as it was invented
3:57
and so we can make think of natural computation artificial computation Steven Wolfram recently published a
4:02
paper in which he argues that the entire universe is computational hypergraph and that time is the rate of refresh and
4:11
dark energy is the heat exhaust of the the big computation that is the universe and I don't know could be
4:19
I sure okay so but we think of computation
4:25
in terms of planetary system this is not only sort a new thing it's also really where it comes from the computation was born of cosmology and I mean that in the
4:32
both senses of the term cosmology which I'll talk a little bit about later this is the picture of the anti mechanism it
4:39
was from far as we know from about 200 BC it is probably apocryphally
4:44
understood as the first computer but it was not only a calculation device it was also an astronomical device it was used
4:51
to orient its user and through the stars in relationship to her situation
4:57
spatially but also temporally for allowing a kind of move simulated movement back and forward back and
5:03
forward in time and so the idea that computation begins with this orientation
5:10
of intelligence in relationship to its planetary condition seems to us a good starting point uh for this but
5:17
computation quickly became something more than this also a bit more practical than this it also became a kind
5:23
calculation as a kind of world ordering as societies became more complex the necessity to calculate and compose not
5:31
only what was happening right now but indeed what would happen in the past and what ha could happen in the future gave
5:36
rise to forms of computation like this Sumerian uniform which you know you find
5:41
this earliest form of writing you try to imagine what could possibly would be the first thoughts of humans put down in
5:49
writing and it turns out it's mostly uh receipts and so in a way all everything
5:58
we've done since then all sort of written language is sort of variations of uh accounting which i' like to remind
6:04
my friends in the literature department so where do when we talk about a kind of school of thought philosophy where we
6:10
might expect it to come from well a few Clues I mean one one way of thinking of this is that as I say Sciences are born
6:17
when philosophy learns to ask the right questions most of the things we call Sciences at least historically began as
6:23
philosophy and philosophy as philosophies are born when Technologies Force the birth of new languages which
6:30
is I hopefully where we are so what can happen in our present situation one in which as we might put it the new things
6:37
with which we are surrounded have outrun the available nouns that we have to
6:42
contain them this is Stanis Lem the polish science fiction author in terms of a distinction that LM makes between
6:49
what he called existential Technologies and instrumental Technologies we think of instrumental Technologies in terms of
6:55
tools their main social impact or impact on society is what they do is a tool so
7:00
bulldozers move dirt very well and so you can make cities faster there are other kinds of
7:06
Technologies much more rarified that when used properly change
7:13
how we understand how the universe works telescopes and microscopes are kind of obvious examples but as I will
7:21
argue and as a kind of key thesis of our program um and my work is that computation very much is both and that
7:28
preserving the space for computation as an existential technology think about the role of the telescope for Galileo uh
7:36
and ultimately for the deduction of heliocentrism without this technological alienation of seeing the world
7:42
perceiving the world in a way that would be otherwise impossible we really wouldn't know where we are and so there
7:47
is a a fundamental relationship between technology and what Freud called cernic
7:55
traumas cernic traumas are those Priceless moments Priceless accomplishments really by which we
8:03
deduce that the world the universe doesn't work quite the way it it looks like it might work and we decenter
8:09
ourselves or get outside ourselves and figure out again who what and where we are in some way now the cycle of this is
8:18
that because we have a a complex model of the world and how the world works we
8:24
build Technologies based on the implications of that model that would allow us to measure something or see something or
8:30
perceive something or calculate something based on the logic of that model but when we use that technology
8:37
properly we figure out that the model that made that technology possible is
8:43
wrong and there needs to be then a kind of resolution of the
8:49
implications uh with the model that ultimately gave rise to them U this in in a more General framework we might say
8:55
is the the role of of Technology more broadly now we speak speaking of this in sort of more historical terms but the
9:02
implications of this of antia Thea and the forms of planetary computation as an existential technology are actually
9:08
quite pressing I would make the argument that the scientific concept of climate change itself is an intellectual
9:15
accomplishment of planetary computation without the sensors and satellites and
9:20
oceanic temperature sensors and so forth and Ice cor samples and most importantly the supercomputing
9:26
simulations of climate past present and future we wouldn't have been able to perceive these temporal Dynamic
9:33
transformations in planetary systems in which we are embedded this in a rough
9:39
rough sense is really what planetary computation is for and now this obviously then has not
9:45
only scientific import but also philosophical and ethical import as well because we understand climate change we
9:52
come to cren and others came to reckon with the concept of anthropos scene you know problematic as as it may be
10:00
but for sure anthropos scene to the extent to which it arrives from climate Sciences which is predicated on
10:05
planetary computation is a kind of a second order concept derived from planetary computation it's a good
10:11
example of how it is that computation as an existential technology can give rise to um uh really fundamental shifts in in
10:19
our thinking and understanding of our agency uh as as a species in one way or another we transforming the planet and
10:26
only through the deduction of this by understanding and measuring how much we had artificialized the planet did the
10:33
possibility of recognizing agency become possible but I think this is actually an
10:38
important lesson we tend to think about it in philosophy that first you train subjectivity and that this will give
10:43
rise to better other forms of agency in many ways it often works the other way around the subjectivity and the
10:49
possibility of a subjectivity as a planetary subject only becomes possible once agency is mapped all
10:56
right let me speak a little bit about planetary computation this term that we use both what it is
11:02
and what it's for the lunar orbiter image from 1966 this is the first image
11:07
of the earth taken from the Moon and it was on the cover of every newspaper in 1966 it's a little bit forgotten but in
11:14
1966 it was quite a big deal so much so that when desel uh was interviewing the
11:22
notorious German philosopher Martin heiger they had presented him this image and asked him to comment upon it heiger
11:29
said that this image he was horrified by what he saw literally shaken and that he said we don't need nuclear weapons to
11:35
destroy the world because this image has destroyed the world already and what he meant was that a
11:43
kind of intuitive phenomenological egocentric perspectival
11:48
understanding of the world and and being as something that is properly manifested
11:53
by DET technologizing its relationship has now been overwhelmed and overcome by
11:58
this this allocentric perspective but we can never quite believe that the world
12:04
is the same way it was before now that we understand a little bit more where we are now for us this is a feature for him
12:11
it was the the biggest bug I suppose of all now another little thought
12:16
experiment though imagine the Blue Marble to this image 2018 the black hole image an image right is a Reconstruction
12:23
from a terabytes of data set but I would argue that this is actually just as important as image in terms of its
12:30
existential implications as Blue Marble and perhaps even more so part of it has to do with how the image was constructed
12:36
now if you want to take an image of something very very far away in this case 50 some million light years away you're going to need a very high
12:42
resolution image resolution is dependent upon the the aperture of the size of the camera that you're using and so what
12:48
would be the widest aperture camera you could possibly build on Earth it would be one that's the same diameter as Earth
12:54
itself so the ventor rizon telescope networked together several telescopes from the North Pole to the South Pole
13:01
and Link them together into a kind of new Optical sensory organ that would a
13:08
that over a period of time and even use the rotation of the planet as the kind of timing mechanism by which each of
13:14
these would work and so the planet itself was not only grew this new sensory surface but that it it even
13:20
became a part of the a part of the machine the implication is for us is that this locates humans who obviously
13:27
were the creatures responsible for the construction of the Event Horizon in a rather different position than blue
13:33
Marvel does blue Marvel implied a global village by putting Apex creationists in
13:38
charge of a mythical Garden black hole Demands a different planetary regime by
13:44
rendering humans as a privileged mediating residue that sets in motion further
13:51
generalized cognition the Two Worlds could not be more different this is a new profile for us and one that we'll
13:56
take some time getting used to this is a quote from the terraforming book imagine the Blue Marble image not as an image
14:02
but in essence as a as a movie a movie that expands the entire 4.7 billion year
14:07
career of the Earth but thankfully on a kind of super fast forward what you would see is the Earth spinning
14:13
volcanoes pangas in the very last instance of this you would see something extraordinary this little organism would
14:21
sprout a kind of exoskeleton this EP sensory epidermal exoskeleton of
14:27
satellites and various other sort of mechanisms by which it the surface of this organism can relay information from
14:34
one point to another this is where I want to sort of think about the location of planetary computation is not only
14:40
something that humans do in their industry but indeed something that the planet has done it's it needs to be
14:46
understood as part of the the evolution of the planet as a dynamic system well
14:52
to sort of dive right into the AI and in terms of our work AI has co-evolved with the philosophy of AI quite closely
14:59
that from Turing and sur's thought experiments that the the thought experiments about AI have driven the technology and of course in turn the
15:06
technology drives the philosophy there's a kind of double helix in the conjunction of these that you don't find
15:12
in other sorts of ways so another way of putting it is matter thinking about matter making matter that thinks that's
15:19
sort of what we're up to now our position on this is something like this
15:24
that ultimately AI will teach us as much about what thinking is than we will teach it that as you artificialized
15:32
something to artificialized something is indeed to discover what it is we learned the same the the lesson of climate
15:39
science is to artificialized a climate is in fact the way you wish you become eventually possible to even know you
15:44
have that agency and more recent piece called the five stages of AI grief is a map of the different ways in which uh
15:52
the discourses around AIS are finding different ways to be inadequate um to the task AI denial anger bargaining
16:00
depression and acceptance that is you can sort of read and just begin to think about it like oh yeah I know who's in
16:06
this category um and and it kind of goes as well it's one of those things where that kind of started as a bit of a joke
16:12
and then you realize actually um those are usually the best ones another sort of area of the
16:18
positions we take on this has to do with the question of alignment um and a somewhat contrarian position on this is that is you know alignment to what
16:25
exactly a lot of the discourse around AI alignment kind of presumes a relatively
16:30
naive image as I've seen sort of relatively naive image of what human needs desires values ethics are
16:36
sometimes a very spoken sometimes unspoken presumption that by simply amplifying unidirectionally um the manifestation of
16:43
those needs and desires that everything will sort of work out in the end this strikes me as a kind of inversion of the
16:49
cernic implications of AI and a reversion to uh an unnecessary
16:55
anthropocentrism and even anthropomorphism uh one way to think about this is in in terms of turing's
17:01
famous thought experiment where what churing had initially proposed as a kind of sufficient condition that is if the
17:07
computer can fool player a then at a functional level we have to sort of grant that there's something going on in
17:13
there and that's a sufficient condition unfortunately in many ways I think familiar the Turing test as a metaphor
17:20
has become more like a necessary condition that is unless the AI can perform Thinking the way that humans
17:27
think that humans think it is disqualified uh and this sort of uh over
17:34
normativism or the reflection of the human as a model I think it certainly senters too much of that AI the
17:41
alignment conversation also I think a lot of the alignment discussion here and again I'm not really talking about like yes if you ask AI to do something you
17:47
want it to do that thing and you know you don't want it to make chemical weapons you know these are sort of unpro
17:52
problematic and I'm not really arguing against these it's the presumption that like really that by making a
17:59
I reflect human exact sort of human culture human values human dependencies
18:06
like what humans are most likely to do and think as the kind of North Star for the artificial evolution of AI it's like
18:14
have you ever met humans are are you sure that that's kind of what you
18:19
want another basic just sort of what we call reflection ISM that is there's a part of discourse where on the one hand
18:24
you hear people say the problem is AI is enough like humans and hum decid and we need to bend it towards that that'll be
18:30
very you have others would basically say like no AI is only the manifestation of the socioeconomics systems of power of
18:38
human society and that's the problem so it's either exactly like us and that's the problem or it's not at all like us
18:43
and that's the problem and somehow you people will sort of say both at the same time which is usually a sign that
18:49
there's something a little bit of a foot now if you hold that the AI is an existential technology as a value that
18:56
you would want to hold on to in terms of these conversations that is there are ways in which it will teach us what
19:01
thinking is ways in which it will disclose the workings of the world in the universe and our own in our own
19:08
Dynamic processes our agency objectivity to us in ways in which we cannot possibly have imagined
19:14
yet it means that and once we discover these things it would transform our
19:20
cosmology in the anthropological sense in important ways implies at the very least alignment needs to be
19:27
bidirectional um both both in terms of AI to where we want to direct it and us to the outputs um that it might have so
19:35
another way of putting it is that the presumption that the greater societal risk comes from not regulating
19:40
AI may be quite wrong so just for the sake of argument you could think of
19:45
where we the area that we are exploring is a bit like this we're familiar with the quadrant of less less alignment more
19:52
bad more alignment more good it's the less alignment more good that we are we would like to account for at the very
19:59
least not only because it's probably underexplored but also because I think we make the case that alignment overfitting making AIS really do exactly
20:07
what people want in every sort of case is actually kind of the real risk the Pinnacle of human centered design
20:13
arguably is the slot machine um a a a mechanism that does exactly what the
20:18
human wants to do in s of Wonder like this is something to be avoided at all cost and so the the cultivation of what
20:24
we call productive disalignment is what we see is sort of part of of the agenda line here as well and it also I
20:30
think has to allow for otherwise unpredictable Cascades of causality that
20:35
the kinds of causal relationships between one thing and another in terms of those productive dis alignments are not always kind of what you would expect
20:42
now thinking of this that in relationship a little bit of what the Deep seek news um from last week you
20:47
might also think of some of these kinds of Cascades cheap energy produces cheap complexity this is sort of a you know a
20:54
truism of like Santa Fe Institute for example cheap complexity allow allows for cheap inference cheap inference
21:00
allows for cheap intelligence cheap intelligence allows for cheap energy these kinds of Cascades are are exactly
21:08
what I mean by the kinds of productive dis alignments to be protected it's also one in which s of an understanding of AI
21:14
and its relationship to governance and the composition of society is not necessarily one that that you know the
21:19
question of control and agency is a little bit undecided as we say AI is um less a tool of industrial policy than
21:26
industrial policy is a tool of AI but also in terms of the consolidation issues and where power lays with this
21:32
these are serious issues in terms of centralization and decentralization thinking about other kinds of means of production that have
21:38
structured Society um AI is one that's available for a monthly monthly subscription uh that may really be that
21:45
fact May really be the democratizing factor a couple of other productive dis
21:51
alignments I want to put on the table there's been you know an enormous interesting explosion of of work and
21:57
insights in in non-human cognition uh animal cognition plant intelligence and
22:04
this is happening at the same time by which we are of artificialized intelligence in a mineral substrate
22:11
through Ai and we're beginning to see like a similar kind of U comparative non-human cognition discourse by which
22:19
in in ways that are just beginning to come together in some ways and sometimes rather explicit um sharing and mirroring
22:25
these in ways I think that'll be increasingly very important it' be hard to get away from the in the
22:31
last few months the claim that next year it's going to be all about agential AI uh that it's all about agents that will
22:37
be making things sort s us and also that the the kind of consensus prediction that AGI will appear somewhere
22:45
2027 so you put these two things together and you have a potentially very
22:50
complicated scenario by which if you have an explosion of AI agents that are
22:56
roughly AGI level whatever whatever you take that to mean you can imagine um a
23:03
scenario by which you may have 8 billion human level Minds that are human and 80
23:11
billion human level Minds that are not human a ratio of 10 to
23:17
one and or later perhaps 100 to one thousand to one and in those cases what
23:24
even constitutes a society kind of goes back to First principles
23:29
so for us um it is these sort of Ed what we call the weirdness right in front of us from which we try to gain some some
23:36
sort of insights I want to make the case to you that technology literally evolves and it does so in ways in which it's
23:42
never really ever just a tool all Technologies are built built out of earlier Technologies there's a kind of
23:48
scaffolding process by one technology becomes the scaffold by which a yet more complex technology develops even
23:54
thinking more in terms of anthropogeny that with the beginning of humans that there's a always been a coupling between biogenesis and technogenesis literally
24:02
the shape of our anatomy like opposable thumbs for example um is a kind of imprint of earlier forms of making use
24:09
of the world U and for directed directed kinds of purposes and that this structural deepening becomes more
24:17
complex over time and ultimately becomes a way of mapping evolutionary time so again when we say evolves what do you
24:22
mean involves how one its component scaffolding towards more complexity
24:28
complex thing emerges it be it becomes a component something yet more complex which becomes a component something yet more complex we see adaptation and
24:35
acceptation that that not only are there niches into which certain kinds of Technologies were fit but also
24:40
technologies that were designed for one purpose then become very useful for completely other kinds of purposes nevertheless they become components for
24:47
things that are be well beyond their original intention um just like biological adaptations and that looking
24:53
at the maps we see both convergent Divergent path dependencies in terms of the directionality by which all these
24:59
things may be moving now everything that I've described in terms of technological evolution is also true biological
25:05
evolution which is kind of the interesting fact or as V neor puts in one of our work what if humans are a
25:11
phase in the history of Technology all right now evolution of computation or Evolution as computation um to move this
25:18
a little bit further along computation as a kind of technology is itself
25:24
evolving we can sort of map forms of intelligence uh you know complex
25:29
cognitive intelligence in in in this way this object um this is not my refrigerator by the way don't don't
25:35
worry um this complex object and the prefrontal cortex that that that wraps it around is one of the you know the
25:42
most the most remarkable accomplishments of biological evolution to produce an object that is capable of these Feats of
25:48
predictive information processing but in other words the planet over long periods of time the planet planet folded itself
25:55
in such a way to produce this object by which It ultimately came to deduce things about itself but now the
26:01
substrate of complex intelligence includes both the biosphere and the lithosphere we the fire Apes by folding
26:08
bits of metal and rock and running electric currents through it figured out how to make the Rocks think this is this
26:14
is news it's also then part of not only our evolutionary trajectory uh it is also part of the evolution trajectory of
26:21
the Rocks species that are good at artificialization do well it's part of
26:27
what evolution selects for if you're if a species is good at finding ways of building Technologies for example that
26:34
allow those species to capture more energy information in matter by artificialized its environment that
26:40
population can grow the capacity for artificialization is an is an Adaptive process another way of thinking of this
26:46
is the distinction autop poesis and alop poesis so autop poesis we learn from cybernetics is how it is that a a system
26:53
uses the external environment to reproduce itself alip say is the way in
26:59
which that agent uses the external environment to produce something extrinsic to itself let me make the case
27:05
then here that would try to locate AI within this a little bit more explicitly and give a bit of a timeline um that AI
27:12
is actually the artificialization of artificialization itself one of the arguments that Sarah Walker is going to make to you when she comes to speak is
27:18
it SE natural selection doesn't begin with Biology it actually begins with chemistry that certain kinds of
27:24
molecules are stable and are able to reproduce each other so the capacity for selection Evolution ultimately
27:29
stabilizes into certain forms of life that is entities that are capable of autop poesis and the internalization of
27:35
energy information and matter for reproduction of themselves to get really good at life it is selected for to get
27:42
really good at artificialization like in order to do autop poesis you need to get really good at alpis and the better you
27:48
get at alip poesis the better you will be at autop poesis you can by making things that allow you to capture more
27:53
information in matter that's extrinsic you can therefore take more that is in
27:58
intrinsic now to get really good at artificialization um you kind of have to be smart about it um not only
28:04
individually but collectively you need to be able to imagine future possible States and and and mechanisms by which
28:11
you can do alpis and so to get really good at artificialization you need to
28:16
evolve intelligence this right worthly I'm not really proposing this as kind of like the new scientific methods just like an imagine I'm like drawing you a
28:22
napkin sketch okay okay this well so um that's really how this is meant now to get really good good at intelligence um
28:29
you need to be able to communicate abstract ideas between um the nodes and the intelligence system that is each of
28:35
the individuals and so to get really good at intelligence something like symbolic language becomes very very uh
28:41
useful and again each of these things like the ability to do one sort of feeds back on the the the ability of the other
28:48
now to get really good at symbolic language and to use symbolic language uh
28:54
as a way to accelerate uh and collectivize to make into a kind of generative Dynamic the
29:00
artificialization of intelligence itself becomes becomes quite useful so there's a kind of casting sequence again so each
29:08
one of these things goes in a particular order and even the accomplishments of one in essence become scaffolds for the
29:13
other I would also say that there's a kind of feedback loop here as well like once you get good at this one it actually changes how that one works so
29:21
once artificialization um becomes robust it actually changes the Dynamics of symbolic language um in inevitably over
29:28
the next few years it will transform um the kinds of symbolic languages that we speak and work with and and that that
29:34
exist and in turn um the kinds of symbolic languages that we have have transformed the kinds of intelligence
29:40
that we work we think in languages and ways we may not have before and indeed this sort of recursive feedback would
29:46
likely continue and such back to here that that the ways in which AI changes
29:51
the language will change the forms of intelligence will ully change the capacities for artificialization itself
29:56
this is what I mean by the cheap intelligence equals you know cheap energy in that's way as well so this is
30:02
what I mean by AI is actually the artificialization of artificialization now locating then in
30:08
sort of past present and future and where to where situate this present point it's important to remember that
30:14
this is not the end of the end of the cycle as life becomes life becomes a scaffold for uh for autop poisa you
30:21
autop become a scaffold for alopa become a scaffold for you ultimate symbolic language so forth and so on what is all
30:28
of this a scaffold for what is it scaff and in turn what is that a scaffold for and in turn what is
30:34
that a scaffold for um and we'll have to wait for the end of the 10,000 years in
30:40
the future we we'll have some we have some idea but this is a way to sort of map in advance a little of what this might mean now when I mentioned earlier
30:47
that I think we're in a kind of pre-paradigmatic moment like let me give you one example of that um and that has
30:52
to do with the uh both functional and intellectual definitions of Life intelligence and Technology one of the
30:59
things you sort of you spend a lot of time thinking about this you sort of noticed is that increasingly contemporary definitions of Life as a
31:07
kind of autopoetic alip poetic phenomenon that uses predictive modeling to use environment to recurs it kind of
31:12
looks a lot like our most contemporary definitions of intelligence which kind of look a lot
31:17
like the more you know evolutionary theories of Technology they're beginning to look a lot like each other and
31:23
there's something to that um like technology and like intelligence life is is based on evolutionary scaffolds built
31:29
on past scaffolds in which itself is a scaffold for forms to come if both life
31:35
and Technology are not just kinds of matter categories of matter in the rilan sense but rather
31:41
processes that produce kinds of matter uh then in what ways and at what level
31:46
of abstraction are they in fact the same process I don't know we might presume
31:52
it's a way that any sufficiently advanced technology is indistinguishable from life and perhaps vice versa we'll find
32:00
out last two bits I'd like to share with you this evening um one is a very quick run through of the antia theor program
32:06
it's its rationale um is that as I've already sort of suggested to you that
32:11
there's a a rather potentially disastrous Gaff between the our capabilities and our Concepts a new
32:17
epistemic institutions forms of epistemic Institutions are needed in order to try to develop um what that
32:23
vocabulary would be we're uh incubated by The bruan Institute um which for a decade is or more has supported Cutting
32:30
Edge thinking in philosophy and politics some of the things we do we host conferences um just a few weeks ago we
32:36
were at MIT media lab where we brought together a lot of our our key researchers for over the course of over
32:41
the course of the whole day we host salons which are shorter one- day very intensive discussions with like-minded
32:48
Confederates in different cities the the main area though arguably like one of this s more more important areas of the
32:54
program is the studio the key idea here of this is like well architecture as a discipline has benefited from this
32:59
exploratory experimental Studio culture to the extent that Society now asks of software things that it used to ask of
33:06
architecture uh the organization of people in space and time software needs a similar kind of
33:12
Studio space to to organize and do projects from first principes our other sort of major initiative is a new
33:17
partnership with MIT press is a book series in a journal what is life is come out what is intelligence be the first
33:23
major title we also have a a peer-review journal the impetus behind the Journal is is to pair some of the most
33:30
interesting thinkers with some of the most interesting designers and to develop definitive
33:36
versions of those ideas uh in in a context by which we can take some of
33:41
this visual intelligence uh and include it as part of the ways in which we tell the story and also again exhibitions so
33:48
we will be at pazo dieo in May with an exhibition showing a lot of this a lot of the work an the is very much a
33:54
collaboration we are astrophysicists zoologist we we have faculty part of our network
34:00
from all of the major universities and companies and you want to sort of see the full roster of the people we we got to work with you can also see our site
34:07
okay last point one of the it'ses you sort of Imagine sort of the way in which the future was understood in the 20th
34:12
century was sort of something to be accomplished if we things come together we will have accomplished this idea of
34:18
the future the way my my son is 16 and watching the ways in which the future has been part of the pedagogy that he's
34:24
been exposed to it's presented more as something to be prevented when we talk about the year 2050 IPC
34:30
reports is how do we how do we make sure that future doesn't happen which there's some validity too
34:36
but I also think there's important to to think about the ways in which another faces forward I I just want to leave with this in terms of the situations
34:43
being remedy one is I as I have intimated a few times there is a a kind of dire disconnect at present between
34:51
cosmology and the astronomic sense and cosmology in the anthropological sense like when I talk to my friends in astrophysics I talk about cosmology it's
34:57
about black holes and dark energy when I talked to my friends in the anthropology department it's about how cultures
35:03
understand their position and significance traditionally I we as we
35:08
imagine it they sort of go in Long step this point there's as I say a kind of dangerous disconnect we know so much
35:15
more about how the universe works than than has been absorbed by our
35:23
the intelligence of our cultures now one way to think of this is the science needs to figure out how to how to bend
35:30
to the dispositions of the culture another is in essence that we need to update the culture to what it is
35:38
that we actually know to be true you might suspect I'm recommend the latter so where really are then thing
35:44
well you could put it this way lithosphere makes a biosphere that makes a technosphere that is now part of the
35:52
neosphere there you go that's the history of the Earth in 15 words that's the where and when that we might say
35:58
where we are in terms of where the agency constitutes going forward the argument I'm making is not one of
36:04
Mastery it's not one of Total Control it's not one of like if we increase
36:10
maximize intelligence that the normative decisions about what needs to happen or even the controllability of the outcome
36:17
of the Cascades of those conditions is something we can entirely control but nevertheless it's something where in
36:24
essence it's not optional because humans are doomed to compose their own Evolution and blessed to never truly
36:30
understand or control that process so back to think the issue we just sort of wrestle with is what are the conditions
36:36
by which complex planetary intelligence could exist for that and grow and Thrive for that 10,000 year
36:43
span what in essence are the um what would make it adaptive you could think
36:49
of it this way that in the short term complex intelligence as I showed you on the timeline is very very evolutionary
36:55
adaptive it allows for pces such as ourselves to do things that would otherwise be impossible but the
37:02
situation we're facing now is that there may be a point by which the the continuance of complex intelligence in
37:09
the form that it is taken may be the thing that ultimately undermines the possibility of the continuance of
37:14
complex intelligence it may be maladaptive in the long term which is an idea that many including Arthur C Clark
37:22
um had had posited so the question to be posed is what are the preconditions for
37:27
the long-term adaptiveness what would have to happen What would need to be worked what would
37:32
be the preconditions by which that long-term capability be possible this is where our work and long now foundations
37:38
work so profoundly overlaps one way I think to start with is understand that those preconditions
37:44
are one that will have to be artificially realized for the most part they may be ones to be discovered but they also may be ones that need to be
37:50
brought into existence um and understanding both the necessity of bringing them into existence and the
37:56
impossibility of of controlling the implications of bringing them into existence is traumatic as an idea but
38:04
imag this may be really the the most important cernic trauma at hand let me
38:09
leave you with um a little one piece that I'll read here as a way to sort of
38:15
um tie this up and then I appreciate your patience when James Lovelock knew that
38:22
he was dying when he wrote his last book novacene The Coming age of hyperintelligence and you can includes
38:28
his own personal life's work with a chapter that must startle many some of the more mystically minded admirers of
38:35
Gia the he calmly reports that Earth Life as we know it may be giving way to abiotic
38:41
forms of life and intelligence and that is far as he's concerned that's just
38:46
fine he tells us quite directly that he's happy to sign off from this Mortal coil knowing that Thea of the human
38:53
substrate for computational intelligence may be giving way to something else not as Transcendence not as magic not as
39:01
leveling up but simply as a phase shift in the very same ongoing process of selection
39:08
complexification and aggregation that is life that is us so
39:15
part of what made love luck at peace with this conclusion is I think that
39:20
whatever the AI cernic trauma means it does not mean that humans are irrelevant
39:27
are replaceable or are at war with their own Creations Advanced machine intelligence
39:34
does not suggest our Extinction neither as Noble abdication nor as bugs
39:41
screaming into the void it does mean however that human
39:46
intelligence is not what human intelligence thought it was all this time it is both something we possess but
39:54
which possesses us even more it exists not in individual brains but
40:00
even more so in the durable structures of communication between them for example in the form of
40:07
language like life intelligence is modular flexible and
40:12
scalar extending to the ingenious work of subcellular living machines and
40:18
through the depths of evolutionary time it also extends to much larger
40:23
aggregations of which each of us is a part and also which each of us is an
40:31
instant there's no reason to believe that the story would or should end with
40:36
us eschatology is useless the evolution of intelligence
40:42
does not Peak with one terraforming species of nomadic primates this I think is the happiest
40:50
news possible um and so like love loock grief
40:55
is not what I feel let me end there thank
41:04
you thank you thank you for that incredible presentation thank you my pleasure Benjamin we were so excited to
41:12
invite you to give the first talk of our first quarter Century because your work
41:17
with building this new school of thought is truly a long-term project and I want
41:23
to ask you some questions about building a school of thought in in this era and
41:29
in particular what do you see as the role of human thought and machine
41:35
thought and how the interplay of that might evolve over the next 25 years as
41:41
your project continues to grow and
41:46
Blossom that's a big was a big question um Let me let me let me answer it rather
41:52
directly and honestly this term school of thought um is something when people ask us what the anti cathal
41:59
program is about uh what it tries to accomplish the answer I will sometimes
42:05
give is that we want to establish a new school of thought around this for this
42:10
pre paradigmatic moment um one that would not necessarily have all the answers but would change the kinds of
42:17
questions that are asked um such that the right better answers are more likely
42:23
uh more likely to emerge and a lot of that has to do as I said about the role of you know generating the philosophy
42:29
from the direct encounter with the technology rather than projecting the philosophy onto the
42:35
technology is which we we have a lot of you know what would from certain certain
42:40
forms of like an AI ethics discourse or what would Kant think about driverless cars much more important is to
42:48
essentially invent the concepts bottom up from the technology itself and in
42:54
doing so constitute this language and I think it's a goal for the program if we
42:59
can get people speaking our language and using our language to define the problem space then even if
43:06
they disagree with us uh we win now in terms of the the the second
43:12
part of your question about this alignment of human thought and machine thought in some way because I guess I don't really see them as I don't have a
43:18
I don't really have a super like really strong dichotomous thinking of this as well like I I I kind of take as a given
43:25
that in this you know you know the anthropogenesis how humans became human technogenesis how Technologies evolve
43:32
that there's been a deep coupling of these going you know deep and deep in time um and the way like to think of
43:40
human thought as something that's separate from the Technologies of thought um is probably um is probably
43:47
the wrong like would be the the wrong starting point so it's not so much that you've got human thought here machine thought here and what happens when they
43:53
come together it's it's be more like now that they are coming together in this
43:58
very amazing and explicit way how does first how does this change our
44:04
understanding of like of that long-term trajectory of how we got here like it in essence it forces us to rewrite
44:11
history um but then perhaps gives a little bit Arc a little bit Arc um of of
44:16
this going forward in generally I would say you know I learned enough structuralism and
44:21
post structuralism as a graduate student to presume that you we speak Lang anguage but more
44:27
language speaks us uh and that language the fact that language turned out to be a repository
44:34
of intelligence like that you if you can model language you have this is general purpose capacity for intelligent uh
44:42
intelligent intelligence to be derived from this like why it was language that turned out to be the trick not games for
44:48
example the Deep Mind had a big bet on games it turned out to be language um shouldn't be so
44:54
surprising and so and in other words like the we we've constructed this language the language is the model by
44:59
which the language models are working it's all tied together it's interesting what you mention about language and
45:06
language models because we're living in a moment where people all around the world are discovering the magic of
45:12
generative AI for creating language and in many instances finding that they can
45:20
Outsource their thinking to these tools
45:25
so people are thinking less and less and at the same time you are making space
45:33
and time with your school of thought to think and create new ideas which seems
45:39
novel in the context of these llms being able to kind of see
45:45
and think of everything so what is the value of thinking now and how do you uh
45:52
conceive of that as a as a leader am I a
45:59
leader yeah um I I don't know that people are thinking less I don't know if
46:04
I agree with that I mean there's a um there's I'll speak to the gender of
46:09
AI think in a moment but you know when you were talking about reminded of there's a one of the dialogues Plato the
46:15
The Fad dialogues I think it's the one of the third but where Socrates is
46:21
um critiquing this new fangled technology called writing um
46:27
and he was really dismayed at like this because he thought it would destroy our capacity for memory because you're just
46:33
Outsourcing memory to this to this sort of thing as well that you couldn't have a direct dial Socratic dialogue with the
46:40
person who wrote this and so you're susceptible to all kinds of you know deception and even more he was concerned
46:46
like you could actually communicate with dead people which was horrifying for
46:51
him and and so the term he used to describe this this new thing which was
46:57
both amazing and horrible at the same time was was pharmacon from which the term Pharmacy
47:02
comes and what what pharmacon means is something that is both remedy and poison at the same time it's not it's it's not
47:10
we'll figure out whether it's Remedy or poison some later date it's will always be
47:15
both for sure AI is pharmacon um and that those those have
47:22
now for generative AI yeah I I mean I think the discussion around generative a needs ref like a lot
47:28
of this is a bit I think very short-term thinking um more generally I think we
47:34
should have imagine like everything you do from when you wake up in the morning to when you go to sleep um is training
47:40
data for the future's model of of the past it's a big
47:45
responsibility that you sort of have it's a bit of living in the third person um I I suppose but um it sort of
47:52
demonstrates in a way in which I think to think about jerve and not as a kind of instrument or tool but rather is a a
47:58
way in which collective intelligence is modeling itself over the long term one of the terms that you used that
48:06
I found really compelling was extrinsic philosophy and this being related to
48:12
alric allocentric as opposed to anthropocentric and what are some of the
48:19
ways that you could see culture being updated as you put it to reflect
48:25
allocentrism instead of anthropocentrism I mean maybe you know
48:31
first thing to sort of I again I'm sort of thinking in terms of my son like I think the issue is like we know so much
48:37
more about how in in s a way that hasn't really percolated in so I mean there's so many ways to think about how this
48:44
would sort of work you know even just very obvious things of like pedagogy
48:49
like uh you know I find it completely amazing bizarre but amazing that for the
48:57
most part UCSD is a bit of except but for the most part Pittsburgh to most philosophies Department don't teach any
49:05
Neuroscience why would you have a whole department about how is it that we think and how it is we might think and
49:12
completely ignore what we know about how we think and how we might think for
49:17
example um I think there's you kind of look around and you find more of these
49:22
these kinds of these sort things like just looking at like how you you see my point M
49:28
um how we teach you know how we teach astronomy how we teach Neuroscience how we teach genomics how we teach you know
49:35
my son's high school they're forbidden to use AI like I remember when I went to high
49:41
school in the in in the 14th century that if you use a calculator in class
49:47
you got in trouble and now you if you don't use a calculator in class you get in trouble but the but the end result of
49:53
putting calculators in the calculus in the class means that students are taking calculus a year earlier than they were
49:59
before because they don't do this busy work with the arithmetic they can focus on the concept the concepts and so I
50:06
mean I don't think they're thinking less now the question I think for AI is like okay given this like what the certain
50:12
degree of inevitability like what are the ways in which what's the analogy of that for all the things we teach the
50:18
Next Generation what's what's the putting the calculator in the class version version of this as well and I and I'm also
50:26
happen to be on a University of California committee for what should be
50:31
the policy for AI in the classroom at the UC and this is also a committee where I when I spend time in there I
50:36
feel like pulling my hair out um because most of the discussion is like how do we what are the ways in which we can
50:42
prevent and forbid this like as if you know as if that's even
50:47
possible the way I see it is as a teacher like when I teach my undergraduates like it's up to me to
50:52
presume they're using the large language models and to like build better assignments
50:58
like the types of things people are capable of doing with these kinds of tools like we need to rethink this in
51:03
this sort of way so I don't know there's bigger ways bigger picture ways of answering your question and I think there's other ways in which you know a
51:09
lot of it's just right in front of us I'm curious why you have constructed
51:15
your your program with antia in the way you have instead of within a traditional
51:21
University context for instance and how is this working for you yeah I mean it's not entirely
51:27
outside we're a bit of a kind of you know a kind of pirate ship that kind of moves sort of in and out of different
51:32
ports in in different ways um and kind of can shuttle things hopefully not rats
51:39
um from one port to another but you know I am an Academia right I'm a professor
51:44
at University of California San Diego you know it's thing to be but it would be absolutely impossible to the main answer question it would be impossible
51:51
there's just no way there's no economic format for doing the kind of work that we do within the within the univers
51:58
within the university I tried I'm curious uh what would be your response to Our Community member Jessie Kate's
52:05
question who she asks as an archetypical pattern of relative Association how
52:12
might you read institutions through the lens of planetary computation and what
52:18
could be the future of Institutions it's a good question um yeah I mean I I you know the value
52:26
value of Institutions to a certain extent is is their durability that there are ways in which people can come together to construct a system for um
52:36
the solving of particular kind of problem the cultivation of particular kinds of of of of questions that that
52:42
that grows and over time and that every iteration by which that that institution
52:48
runs its cycle uh it evolves but it evolves in a certain way that that it
52:53
also has scaffolds internal to itself so it does something that becomes a component to something it does later
52:59
that becomes something a component it does later more complex that is an evolution and that takes time that takes
53:06
time um and so yeah it's not so I don't think it's so complicated like in a
53:11
world in which things are sort of Li seem to be liquefying at such a at such a pace doing so in a way in which you
53:17
know pushing against things that are that have a bit more uh bit more durability remain remain sort of
53:23
important um but there's different kinds of in tions like I would extend the institution not only to be things like
53:29
you know institutions that are built of humans and institutions that have Boards of directors but you know there are
53:35
technical institutions there are you know forms of forms of of structure that operate in a very similar kind of way we
53:42
were in the lobby before we were talking about the metric system um as a kind of platform like what what this allows you
53:48
to do is like you don't have to decide how wide things are going to be um it's essentially it's it's it becomes a way
53:54
in which you don't have to do that work work um that you can get on with it and get on with this one way or another and
54:01
I think the the the best kinds of intuitions are ones that not only are are doing the work but they're doing the
54:08
work so that everyone else can get on with it well Benjamin thank you so much for
54:14
being with us tonight to uh introduce anthera to our community
54:20
we look forward to collaborating with you and cheering you and the the school
54:25
of thought on over the next quarter Century thank you Ben appreciate it very much thank [Applause]
54:41
[Music]
54:55
you what