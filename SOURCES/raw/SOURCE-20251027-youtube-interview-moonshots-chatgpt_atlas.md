# The OpenAI Internet Browser Has Arrived: ChatGPT Atlas

**Host:** Peter Diamandis  
**Panelists:** Dave Blundin (Founder & GP, Link Ventures), Dr. Alexander Wissner-Gross (Computer Scientist, Founder of Reified)  
**Recorded:** October 25, 2025  
**Episode:** Moonshots WTF Just Happened in Tech

---

**Peter:** Everybody, welcome to Moonshots, another episode of WTF Just Happened in Tech. I'm here with my moonshot mates Dave Blundin and AWG Alex Wissner-Gross. Good morning, gentlemen.

**Dave:** Hey, good morning.

**Alex:** Hey.

**Peter:** A huge shout out to the team. We were going to shoot this podcast last night and Alex had so much material that happened in the last three days that we just needed to get in here. Things are changing so quickly. The team pulled an all-nighter last night to pull together these stories and it's epic. So, thank you team behind the scenes.

Right now, our fourth Moonshot mate, Salim, is on an airplane. I just spent the last four days with him here in Calamigos in Malibu for XPRIZE Visioneering 2025, which is a story I want to open up with. Dave, I wish you were here. Alex, I wish you were here. It was awesome.

For those who don't know, XPRIZE every year gets together our brain trust and our benefactors and we debate and we discuss what are the problems that aren't being solved that need to be solved or what are the challenges that are too far out and we need to accelerate them and bring them forward—that's visioneering. It was an amazing four days in total, but two and a half days in which we raised—Dave, you're on my board here at XPRIZE—we raised $3.5 million in capital last night.

**Dave:** Do that every night. That's a billion dollars a year.

**Peter:** Yeah, that would be awesome. And someday we will. Just so the audience knows the sacrifices Peter makes to bring you all of this information—so he's on stage all day yesterday, tomorrow boards a flight to Riyadh, so we'll be in Saudi. He'll be on stage the day after that with Eric Schmidt kicking off that event. That's 10 time zones away. So watch the footage of him from Riyadh and see what that looks like.

**Peter:** How wired will I be on caffeine?

**Dave:** Oh my god.

**Peter:** But we announced yesterday our impact report for XPRIZE and the numbers are staggering. We have massive detailed report and every dollar invested in a prize we get a 60x return. So a million-dollar prize is driving $60 million of R&D invested by all the teams. They're all optimists. They all think they can win and they're all sort of like a Darwinian evolution to go and solve these problems. Super pumped about that.

But I want to report—this is the first group to hear about it—on who won XPRIZE visioneering. We enter the two and a half day program with about 20 concepts. We have five different domains, five different grand challenge areas and we've got four concepts per. We narrow it down to two and then down to one which leaves us with five that enter the battle royale as we call it. We go from five to three and then last night we got down to—let me just show you the numbers here.

XPRIZE visioneering winners for 2025. We were expecting to just have one of these prizes get funded to go into development. It turned out all three of these got funded to go into development. Let me mention what they are because I'm very proud of them.

The first prize is called Abundance—got to love the name. It was actually two of our Abundance 360 members who proposed this and raised the capital to get this going. What is the Abundance XPRIZE? It is deliver to a community food, water, housing, electricity, and bandwidth for $250 a month. That's the goal.

The conversation last night—we can talk about healthcare too because you know at Abundance 360 healthcare becomes free at the margin or near free. How fast can you do that? Is it a 5-year period? Is it a 10-year period? But I love the concept that you know a community will actually compete to deliver the entire set of services for $250 a month. And there's going to be a billionaire in the room who's funding that with two others. Super cool.

The second prize is called Aqua Abundance. It's to deliver unlimited desalination—1 million gallons per day or more—at a cost per gallon that is less than the cost of existing fresh water. Effectively making fresh water and desalination effectively free. That's so important when you think about a California and drought-ridden areas around the world.

The third XPRIZE goes into a different mode. We're now looking at breakthrough technology that's either going to give us abundance or reduce suffering. The third prize that was voted on is called Quantum Breakthrough. What the group was looking at is we're going to see quantum computing roll out, quantum networking roll out. A lot of folks in the technology sector don't really understand it. We're going to run a competition to basically create a quantum problem—some computation—that an existing supercomputer can solve, but then demonstrate that quantum can do it much faster, much more efficiently, opening up people's eyes to what's actually possible with this extraordinary technology.

**Dave:** That's all amazing. What an amazing weekend. For those who weren't there, I mean, there were a lot of moving parts. It was almost like watching a startup with like 150 people. Very, very cool stuff. And the presentations by the people like presenting their ideas for prizes were of TED Talk quality—better than TEDx, TED level, which was like really, really good. Probably your best visioneering ever.

**Peter:** It was spectacular. We had like, let me just mention this. Elon sent a crew of SpaceX engineers. We had two from NVIDIA, one from Anthropic, a number from Google, Meta, Microsoft. I mean, it's spectacular. Anyway, onward. Let's turn it over to you, Alex.

**Alex:** I think the big story of the week, one of the big stories of the week—it's a big story every single week now—but is about AI chips and data centers and the competition among all of the major companies to get more and more AI training and inference compute power. We've been following this now for several months. I think we're all at the point where the numbers are so big that we can't comprehend them anymore and we've kind of resorted to gallows humor about whether we've run out of numbers.

But there was a very important Bloomberg article that ran and was updated this week where they reported that Amazon, Meta, Microsoft, and Google collectively are on track to spend a combined $300 billion on AI infrastructure this year. That's for 2025. That is so much more than was spent in prior years. So just to give you some rough numbers for context: in 2024, it was estimated to be around $200 billion, $210 billion total expenditure by these four companies on data centers and AI infrastructure. In 2025, it looks like it's going to be around $300 billion. So that's roughly a 50% increase.

Now, some of this is connected to the fact that some projects got delayed because of power availability issues and component availability issues. But still, the growth rate there is just extraordinary. This is over and above what they're already spending on maintaining their existing services and platforms. This is incremental spending, increasingly driven by a kind of AI arms race—an AI infrastructure arms race.

This is not just about training frontier models. This is also about all of the inference compute that's going to be needed to run all of the agents and all of the AI applications that are being rolled out at scale by these companies. I think it's important to recognize that this is now entering—I mean, it's been in the territory of multiple percentage points of GDP in the US already—and increasingly becoming a kind of national priority-level expenditure in multiple countries around the world.

**Peter:** Yeah, I'm looking at the article here. It says analysts expect total spending on data centers by these four companies this year to approach $300 billion, up almost 50% from 2024. You know it's funny—everyone's talking about the next administration, how are they going to drive GDP growth? Well, this is it, folks. This is what's driving it.

**Dave:** A lot of the markets when they reported earnings in the last few days have been disappointed. But the reason they've been disappointed is not because the earnings weren't high, but because they said, "Hey, we're going to spend way more money than we told you we were going to spend." The market's like, "Oh my gosh, you're really spending $300 billion and you're all competing against each other—can this possibly be profitable?" 

But at the end of the day, I think they're all making the bet. Someone's not going to win because they're all competing in the same space against each other for basically supremacy in AI. And I think the data center is such an important component of this because even when you actually get to the point where you can train—or sorry, you can infer—on your own device, it's going to be driven by a data center because not everyone's going to have those chips in their computer. It's way too expensive. By the time you go buy a cheap computer, it's going to be ten years before it has a ten TOPS chip in it or whatever. So you're still going to need to actually do most of the compute—especially for anything real-time—in a data center.

**Peter:** Yeah. Alex, to that point, one of the things I've been speculating on is we're seeing OpenAI launch Atlas as a browser, which is just extraordinary. Their ability to gather your data—what you do with the browser, what queries you have—it's incredibly valuable. We're seeing Google launch—in alpha right now—Jarvis, which is an AI agent that goes and does things. I think the race is really around who builds that personal AI that is smart enough to do the things I want in the background, whether it's planning my trip, booking my flights, doing my research, comparative shopping.

And I was having a conversation last night with Ray Kurzweil. I said, "Ray, what do you think? Is it the browser that's the way you get data?" He said, "Well yeah, it's one of the ways. The other way is your personal AI in the cloud." Right now you can get your personal GPT in ChatGPT. You go and you can upload all your documents to it. But if your personal AI is living in the cloud in Google or OpenAI, that's also a place for them to gather a huge amount of information about you, your documents, what you care about.

My sense is—and I'd love to hear your guys' thoughts—we're going to have an AI that is our personal portal into everything. And I'm not going to care what browser I use. I'm just going to be able to have a conversation with my AI and it will pull up the data from wherever it is, whether it's using super intelligence from OpenAI or Google.

**Dave:** A hundred percent. I was actually chatting with my partner Sunil about this—he does a lot of our frontier tech stuff. His point was he doesn't think we should think of it as a product. He thinks we should think of it as a distribution channel for OpenAI's super intelligence. This is basically another way for OpenAI to get the training data and to get the inference data and to gather more data about what people are doing to make it such that if Sam wins the data aggregation race, if he falls behind for a month or a year in the AI race, he still has your data and he's still getting more and more data about what's happening in the real world—what people want, what they're clicking on, what websites they're going to, how they use browsers.

You know, I think there's also an OpenAI play here to become the operating system. Forget about like—you know, like they obviously want to build hardware. They're working with Johnny Ive and they've got a bunch of stuff happening. But if you can become the actual operating system—like if you're on a computer and it just all goes through ChatGPT and you don't ever see other things—you become much, much, much more powerful than even Google and all the trillions of dollars they have and all the computing power they have.

**Alex:** I think having a local agent mode is potentially transformative. Because in the video that OpenAI released announcing Atlas, which is now live—people can use it in alpha—they showed some interesting features. They showed, among other things, the browser being able to automatically fill out forms and being able to manipulate the contents of websites and pages for you in ways that are personalized. Now, I mean, Google has some of this built into their existing browser infrastructure with Chrome already, but what's interesting about the Atlas launch is it seems like there's an ambition to make this a much more comprehensive agent mode where you can actually do a lot more automation and a lot more agentic behavior on your behalf through this browser.

I think the competitive positioning versus Google is basically all-out war. Google presumably is going to come in and do at least this and take back any market share they lose. But what's interesting is the browser wars have now become an AI product race. It's no longer just about who can render web pages fastest or who has the most add-ons—it's now about who can build the smartest AI agent that lives in your browser and can act on your behalf.

**Peter:** You know, the other thing—and I'll mention this because it's relevant—there's massive concern right now about privacy. If you're using the OpenAI browser, they can see everything you're doing. If you're using the Google browser, they can see everything you're doing. The question is: how much do you trust these companies? Are they using it just for training their models, or are they going to use it for advertising, for selling products to you?

I think we're going to see a differentiation where some companies say, "Listen, we're not going to use your data for advertising. We're using it purely to make your AI smarter." Others are going to monetize through advertising because that's their business model. I think it's going to be really interesting to see how that plays out and whether people vote with their feet—whether they say, "I want the AI that's not going to advertise to me," or whether they say, "I'm okay with that because it's free."

**Dave:** I actually think people don't care as much as we think they do about privacy in this realm, which is really unfortunate. Because I think when you actually get to AGI and you have all this data and you have all these things happening, privacy becomes incredibly important. But right now, people are like, "Cool, I'll just let you take all my data because I want the better product."

The thing I'm most interested in—and Peter, you mentioned this—is the local agent component. And one of the things that I think is going to be really important is: can these agents actually book my flights? Can they actually go do the things I need them to do? And the answer right now is kind of yes and kind of no. They can do some things but they can't do everything.

**Peter:** Let's move on. Alex, where do you want to go next?

**Alex:** Well, I think there's been a lot of discussion—and we've talked about this on prior shows—about the role of AI in the life sciences and in particular in biology and in longevity. There was a very interesting article that came out in Nature this week about how AI is being used to accelerate drug discovery and also to discover new biological mechanisms.

What's particularly interesting about this article is it highlights how the speed of discovery in biology is now being limited not by our ability to generate hypotheses or even by our ability to run experiments, but by the rate at which we can synthesize new molecules and test them. The computational side has gotten so fast with AI that now the bottleneck has shifted to the physical lab work.

This is creating a really interesting dynamic where there's now enormous pressure to automate lab work, to build robotic systems that can synthesize and test compounds much faster. Companies like Recursion, companies like Insitro, companies like many others in the AI-for-drug-discovery space are all racing to build out this physical automation infrastructure.

What's fascinating is this is creating a kind of convergence between the AI infrastructure race we were just talking about and the physical automation race in biology. Because ultimately, if you want to fully leverage AI for biology, you need both the compute infrastructure to run the models and the robotic infrastructure to actually execute the experiments that the AI is designing.

**Peter:** It's so true. You know, I'm on the board of a company called Cradle that does protein design using AI. They can design a protein—new enzymes, new proteins—in silico in a matter of hours or days that would have taken years before. But then to actually synthesize that protein and test it still takes weeks or months.

I'm also on the board of a company called Asimov, which does genetic circuit design. Same thing—they can design genetic circuits computationally very quickly, but then building them and testing them in cells takes time. There's a massive push now to automate the wet lab side of things.

**Dave:** I think the other thing that's really interesting here is we're starting to see AI being used not just to design new drugs or new proteins, but to actually understand fundamental biological mechanisms that we didn't understand before. There was a paper that came out—I think it was in Cell—where they used AI to discover a completely new mechanism for how cells regulate their metabolism. This was something that had been missed by decades of traditional biology research because it was too complex to see without AI.

I think we're going to see more and more of this where AI is not just accelerating the things we already know how to do, but actually discovering new fundamental biology that opens up entirely new therapeutic avenues.

**Peter:** That's huge. What else, Alex?

**Alex:** Well, I think related to the theme of knowledge generation and AI, there was an important essay that came out this week from several prominent AI researchers and philosophers about what they're calling the "knowledge bottleneck" in AI development. The argument they're making is that as we scale up AI systems, we're increasingly running into a fundamental constraint, which is that the amount of high-quality knowledge available to train these systems on is finite.

They point out that we've already trained on essentially the entire internet, we've trained on all published books, we've trained on all scientific papers—and while there's still some data sources that haven't been fully exploited, we're rapidly approaching a point where we've consumed all available high-quality human-generated knowledge.

This is creating pressure to do several things: one is to generate synthetic training data using AI itself; another is to build systems that can learn from experience and interaction rather than just from passive consumption of text; and a third is to build systems that can actually participate in the generation of new knowledge rather than just learning from existing knowledge.

**Peter:** It's so interesting because it relates to something we've talked about before—this idea that AI might become the primary driver of new scientific discovery, not just because it can process existing knowledge faster, but because it can actually generate genuinely new knowledge through simulation, through experimentation, through exploration of hypothesis spaces that humans wouldn't think to explore.

**Dave:** I mean, we're already seeing this with AlphaFold and protein structure prediction. That's a case where AI didn't just speed up something humans could do—it actually solved a 50-year-old grand challenge in biology that humans had fundamentally failed to solve. And now we're seeing similar things happening in materials science with things like GNoME from Google DeepMind discovering hundreds of thousands of new stable materials that had never been predicted before.

I think the question is: at what point does AI become not just a tool for knowledge generation but the primary source of knowledge generation? And what does that mean for human scientists? Do they become more like curators and directors of AI research programs rather than doing the actual discovery work themselves?

**Peter:** Yeah, we're going to have to explore that. There's a whole podcast on that subject. Alex, let's keep going.

**Alex:** So there were several other interesting AI developments this week. Uber announced something quite innovative—they're using their vast fleet of drivers and their vast dataset of navigation data to help train AI models for autonomous driving. But what's particularly clever about their approach is they're essentially crowdsourcing the labeling and validation of this data by having their human drivers implicitly provide feedback through their driving behavior.

So rather than having to hire thousands of people to sit in rooms and label data, they're using the fact that they have millions of drivers already out there navigating complex scenarios every day. The drivers don't even know they're helping to train the AI—their driving behavior is automatically being used to validate and improve the models.

**Peter:** That's brilliant. I mean, they've got millions of drivers generating data every single day in every city around the world. That's an incredible dataset. And the fact that they can use the drivers' implicit behavior as a labeling mechanism is really clever.

**Dave:** What I think is interesting about this is it shows how companies that have large-scale physical operations in the real world have an inherent advantage in the AI age. Google has an advantage because of search traffic. Meta has an advantage because of social media engagement. Uber has an advantage because of their driver network. These real-world data moats are becoming incredibly valuable.

**Peter:** Absolutely. What else?

**Alex:** DeepSeek, which is a Chinese AI company, announced a major breakthrough in optical character recognition—OCR. They've built a model that can extract text from images with significantly higher accuracy than previous systems, even for complex cases like handwritten text, text in low-light conditions, text with complex backgrounds.

What's particularly notable about this is that DeepSeek has been making a series of important contributions to AI research despite having, by most accounts, significantly less funding than Western AI labs. This is part of a broader trend where Chinese AI companies are becoming increasingly competitive with Western labs, particularly in computer vision and multimodal AI.

**Peter:** You know, we talked about this before—China has certain advantages in AI. They have massive amounts of data because of their population and their digital infrastructure. They have strong government support. They have a lot of very talented researchers. The question has always been: can they compete at the frontier? And I think we're seeing increasingly that the answer is yes.

**Dave:** I think what's concerning from a Western perspective is that we've been assuming that the US would maintain a lead in AI because of superior compute resources and superior talent. But if Chinese companies can achieve comparable results with less compute—which is what DeepSeek seems to be doing—that changes the calculation significantly.

**Alex:** I think it's also worth noting that this isn't just about competition. There are positive spillovers from having multiple competing AI research ecosystems around the world. DeepSeek publishes their work, Western labs publish their work, and everyone learns from everyone else. The global pace of AI progress is probably faster because of this competition and collaboration.

**Peter:** Agreed. What else?

**Alex:** OpenAI published a blog post this week outlining their vision for what they call "automation at scale." They're basically arguing that within the next few years, AI will be capable of automating a significant fraction of knowledge work—not just specific tasks but entire workflows and job functions.

What's interesting about the post is they're quite explicit about the economic and social implications. They acknowledge that this will be disruptive and they're calling for proactive planning around how to manage the transition. They're proposing things like universal basic income, massive investment in retraining programs, new educational models focused on skills that complement AI rather than compete with it.

**Peter:** You know, Sam Altman has been talking about this for a while—this idea that we're going to need to fundamentally rethink our economic system as AI becomes capable of doing more and more of the work. I think he's right that we need to start planning for this now rather than waiting until it's already happening.

**Dave:** The challenge is that the transition is going to happen much faster than our political systems can adapt. Like, if in five years AI can do 30% of knowledge work, that's going to put enormous pressure on labor markets and on social systems. And I'm not sure we're moving fast enough to prepare for that.

**Peter:** Yeah, it's a huge challenge. What else?

**Alex:** Google announced Genie 3, which is their latest world model. This is a system that can generate interactive 3D environments from text descriptions or from images. You can basically describe a scene—say, "a medieval castle on a cliff overlooking the ocean"—and Genie 3 will generate a full 3D environment that you can explore and interact with.

What's particularly impressive is the level of physical realism and consistency. Earlier world models would generate environments that looked good but had weird physics or inconsistencies. Genie 3 seems to have largely solved those problems. The physics work correctly, the lighting is consistent, the geometry is coherent.

**Peter:** This is huge for gaming, right? Like, imagine being able to just describe the game world you want and have it generated automatically.

**Dave:** It's huge for gaming but I think it's even bigger for things like training simulation for robotics, for virtual reality experiences, for architectural visualization. Any application where you need to create 3D environments, this could be transformative.

**Alex:** I think what's particularly interesting is this is moving us toward a future where the line between real and synthetic environments becomes very blurred. If you can generate photorealistic interactive environments on demand, what does that mean for our relationship with physical versus virtual space?

**Peter:** Yeah, we're entering some really interesting territory there. What else?

**Alex:** Meta announced this week that they're planning to spend $65 billion on AI infrastructure in 2025. This is up from their previous guidance of around $40 billion. So that's a massive increase—more than 60% increase over their prior plans.

What's driving this is their ambition to build what they're calling "the world's largest AI supercluster." They want to have more compute capacity than anyone else, which they believe will give them a decisive advantage in training frontier models and in deploying AI features across their platforms.

**Peter:** Zuckerberg is really going all-in on AI. I mean, $65 billion—that's an extraordinary bet.

**Dave:** I think what's interesting is this is Meta saying, "We're not going to let ourselves get left behind like we did with mobile. We're going to make sure we're at the frontier of AI." And they're willing to spend whatever it takes to get there.

**Peter:** You know, the thing that's striking to me is when you add up all these numbers—Meta at $65 billion, the $300 billion from the big four, other companies—we're probably talking about close to half a trillion dollars being spent globally on AI infrastructure in 2025. That is just a staggering amount of capital.

**Dave:** And the question is: is this sustainable? Like, at what point do these investments need to generate returns? Or are we in a situation where everyone's in an arms race and nobody can afford to stop investing even if the economics don't necessarily make sense?

**Alex:** I think the bet all these companies are making is that whoever wins the AI race will have a monopoly or near-monopoly on intelligence, which is arguably the most valuable commodity in the economy. So even if the investment levels seem crazy, if you believe that thesis, it actually makes sense to invest as much as you can.

**Peter:** That's a great point. What else?

**Alex:** Oracle announced that they're building what they're calling a "next-generation AI supercomputer" in partnership with NVIDIA. The specifications are pretty extraordinary—they're talking about exascale computing power, which means they're aiming for systems capable of at least one exaflop of performance.

What's interesting about Oracle's approach is they're focusing heavily on the database and data management side of AI infrastructure. They're arguing that as AI systems become more complex, the ability to efficiently manage and query massive datasets becomes just as important as raw compute power.

**Peter:** That makes sense. I mean, we've been so focused on compute, but data storage and data management at these scales is also a massive technical challenge.

**Dave:** I think Oracle is also making a play for the enterprise AI market. Like, a lot of the infrastructure being built by Meta and Google is for consumer applications, but Oracle is saying, "Hey, enterprises need AI infrastructure too, and we can provide that."

**Peter:** What else?

**Alex:** Anthropic announced that they're expanding their compute capacity significantly. They're building out new data centers and they're also partnering with cloud providers to get access to more GPU capacity. This is part of their push to remain competitive with OpenAI and Google in the frontier model race.

What's interesting is Anthropic is also emphasizing their focus on AI safety and interpretability. They're arguing that as they scale up their models, they're going to continue to invest heavily in understanding how the models work and in building in safety features.

**Peter:** Claude has been really impressive. I mean, I use it alongside ChatGPT and I think it's competitive, maybe even better in some domains.

**Dave:** I think Anthropic represents an important alternative approach to AI development—one that's more cautious and more focused on safety. The question is whether that approach can remain competitive with companies that are willing to move faster and take more risks.

**Peter:** Yeah, it's a real tension. Okay, what's next?

**Alex:** So there's a pretty wild concept that came out this week called Star Cloud, which is a proposal to build data centers in space. The idea is that space offers several advantages for data centers: abundant solar energy, natural cooling because space is very cold, and freedom from terrestrial constraints like land availability and power grid limitations.

The proposal is coming from a consortium of space companies and data center operators. They're envisioning launching modular data centers into orbit that would be powered by solar panels and cooled by radiating heat into space.

**Peter:** That's fascinating. I mean, the economics would have to work out, but the physics makes sense. In space you have unlimited solar power and perfect cooling.

**Dave:** The challenge is launch costs and latency, right? Like, even with SpaceX making launch much cheaper, it's still expensive to put mass into orbit. And latency could be an issue for some applications, though for training large models where you're doing batch processing, latency might not matter as much.

**Alex:** I think this is one of those ideas that sounds crazy now but might be inevitable in the long run. As our demand for compute continues to grow exponentially, at some point we're going to run out of good places to put data centers on Earth, and space starts to make sense.

**Peter:** I love it. It's very sci-fi but also very practical. What else?

**Alex:** There was news about Elon's latest chip project—the A15 chip, which is being developed for use in Tesla's autonomous driving systems and potentially for other AI applications. Reports suggest this is going to be significantly more powerful than previous generations and optimized specifically for inference workloads.

What's interesting is this represents another example of a company vertically integrating into chip design because they believe they can build better, more specialized chips for their specific use cases than what's available from general-purpose chip vendors.

**Peter:** Tesla's been doing custom chips for a while now, right? But this sounds like a significant step up.

**Dave:** I think the trend of vertical integration into chips is really important. Apple does it, Google does it with TPUs, Tesla does it, and even Microsoft and Amazon are starting to do it. Everyone's realizing that if you want optimal performance for your specific AI workloads, you need custom silicon.

**Peter:** What else?

**Alex:** Amazon announced this week that they're developing smart glasses for their delivery drivers. These would use augmented reality to provide turn-by-turn navigation within buildings, to show optimal package delivery routes, and to scan packages hands-free.

What's interesting about this is it's a very practical, pragmatic application of AR technology. It's not trying to be a consumer product—it's focused on a specific use case where the benefits are clear and quantifiable.

**Peter:** I think this makes a lot of sense. Amazon's delivery network is enormous and any efficiency gains get multiplied across millions of deliveries. If smart glasses can make each driver 5% more efficient, that's a huge win for Amazon.

**Dave:** I also think this could be a proving ground for AR technology. If Amazon can get this working well for their drivers, it validates the technology and potentially opens up other enterprise applications.

**Peter:** Absolutely. What else?

**Alex:** So Google announced what they're calling a quantum breakthrough this week. They published a paper in Nature showing that their Willow quantum processor can perform certain calculations in minutes that would take classical supercomputers longer than the age of the universe.

Now, I should be clear—these are very specific benchmark calculations, not general-purpose computing. But what's significant is they're demonstrating exponential quantum advantage for these specific problems, and they're also showing progress on error correction, which has been one of the major obstacles to practical quantum computing.

**Peter:** Error correction is the key, right? Because quantum systems are inherently noisy and errors accumulate. If you can't correct errors, you can't build large-scale quantum computers.

**Dave:** The question I have is: how far away are we from practical quantum computers that can solve real-world problems that businesses actually care about? Like, demonstrating quantum advantage on academic benchmarks is cool, but when do we get quantum computers that can, I don't know, optimize supply chains or break encryption or discover new drugs?

**Alex:** I think the honest answer is we're still several years away from broad practical applications. But I think we're getting close to the point where quantum computers will be useful for specific problems in materials science, in chemistry, in optimization. Maybe three to five years before we see the first real commercial applications.

**Peter:** And just to clarify for folks listening—quantum computers aren't going to replace classical computers. They're going to be specialized tools for specific types of problems where quantum algorithms have an advantage. For most everyday computing, classical computers will continue to be better.

**Dave:** Right, it's not like your laptop is going to become a quantum computer. It's more like certain problems that currently can't be solved at all, or take too long to solve, will become solvable with quantum computers.

**Peter:** Great. What else?

**Alex:** So I think we should talk about nuclear energy because there's been a lot of activity in that space this week. There was an interesting article about the state of nuclear energy in the US. The US currently has about 93 operating nuclear reactors providing about 20% of the country's electricity. But most of these reactors were built in the 1970s and 1980s and they're aging.

The article discusses the challenges around building new nuclear plants—the regulatory hurdles, the high upfront costs, public concerns about safety. But it also talks about the renewed interest in nuclear because of climate change and the need for reliable baseload power, especially for data centers.

**Peter:** You know, I've been a huge proponent of nuclear for a long time. I think the safety concerns are largely overblown—modern reactor designs are extremely safe. And when you look at deaths per terawatt-hour of energy produced, nuclear is actually one of the safest forms of energy, much safer than fossil fuels.

**Dave:** I think the big challenge with nuclear has been economic. Like, it's taken so long to build nuclear plants and they've gone so far over budget that they've been hard to finance. But I think we're seeing a shift now where the combination of climate pressure and energy demand from AI is creating renewed interest in nuclear.

**Peter:** There's also a lot of excitement around small modular reactors—SMRs. These are smaller, factory-built reactors that can be deployed more quickly and cheaply than traditional large reactors. Companies like NuScale and X-energy are developing these.

**Alex:** I think SMRs are promising but they're still several years away from large-scale deployment. The first commercial SMRs are probably going to come online in the late 2020s. But I think by the 2030s we could see significant deployment of SMRs, especially for powering data centers and industrial facilities.

There's also fusion, which had some interesting developments this week. Several fusion companies reported progress toward net energy gain. We're still not there yet—fusion has been "20 years away" for decades—but I think we're genuinely getting close now. Maybe by the mid-2030s we'll see the first commercial fusion reactors.

**Peter:** You know, the joke in the fusion community is that fusion is the energy source of the future and always will be. But I actually think we're at an inflection point. There's been enormous progress in the last few years, both on the magnetic confinement side with tokamaks and on the inertial confinement side with laser fusion.

**Dave:** I think we're going to see a continued mix. I sure hope that the government does start backing solar and backing SMRs and backing fusion more. We need to accelerate our energy production beyond just natural gas and coal and other areas.

**Peter:** I agree. Alright, let's end with something different. Alex, you found a weird science article. It's called butt breathing—a real medical option. Do you want to take this?

**Alex:** Sure, I'll take the hit for ending on a low note. But in all seriousness, this is a transformative breakthrough or at least the beginnings of a transformative breakthrough for people suffering from severe respiratory failure who can't breathe through their lungs.

If folks have seen The Abyss, the science fiction movie where there's a famous scene where a character is consuming an oxygen substitute liquid—breathing liquid basically deep underwater—they'll have some familiarity with novel forms of respiration and blood oxygenation. This was also the subject of last year's Ig Nobel Prize for discovering that non-human animals could oxygenate their blood supply by consuming oxygen via the other end as it were.

**Peter:** The intestines are a very blood-rich large surface area part of your body. And so if you're able to put a hyper-oxygenated fluid enema, let's call it that, then you can perhaps oxygenate your blood supply and get enough of your red blood cells oxygenated to get to your brain.

**Dave:** The only reason I like this story and I wanted it in the podcast is because every time Salim says something in the future, we have the option to say, "Oh, he's butt breathing."

**Alex:** To try to elevate a little bit—there's been interest over the decades in nanobots that would help with oxygenating the blood, so-called respirocytes. To the extent that it's possible, and I should add also parenthetically, sci-fi scenarios like enabling humans to be able to hold their breath underwater for hours on end. There's been persistent sci-fi pressure to discover new ways to oxygenate the blood in environments that are less than hospitable.

**Dave:** You're really reinforcing the theory that you're an AI.

**Peter:** All of this materializes on the backside of nanotechnology and one of these times I really want to dive into not wet nanotechnology where we're using DNA origami but Drexlerian assemblers that just opens up everything. Respirocytes are fantastic. Literally BCI enabled through nanobots in the brain. I can't wait.

I'm going to get Ray Kurzweil on our podcast so we can have the conversations with him. Ray's been a dear friend and a mentor for so many years. At the end of the day, his prediction is nanobots by the early mid-2030s, so 2033. That's going to unlock high bandwidth BCI but unlocks basically longevity escape velocity—or I don't like using the term immortality because it sort of hits so many different negative buttons—but if you can repair on a cellular and subcellular level all parts of your body, that is an incredible future.

**Dave:** If you get Ray and Alex on the same podcast, that podcast could also be immortal. That would be something I would kill to see.

**Peter:** We'll do that for sure. And to all of our friends listening, I hope you've enjoyed this episode of WTF. If you're not a subscriber, please join us. We'll let you know—it's interesting, we're putting out news as it breaks. So while we try and do this once a week, sometimes it comes out twice a week and you'll get a notice of that.

Other than butt breathing, we hope this helps you understand how fast the world is changing and that we're living in this extraordinary time where we can solve any grand challenge. Congratulations to the visioneering XPRIZE teams for winning visioneering and to the entire XPRIZE organization for really accelerating these grand challenges. I'd love to know in the notes here if you have an XPRIZE that you'd love to see in the future. Let us know what it is.

Dave, I'm heading to the airport in I think two hours to head to Saudi.

**Dave:** Crazy. It's going to be fun. I'll see you and Imaad and Salim there.

**Peter:** Alex, we will miss you. You'll be there either digitally or in spirit, but we have quite the week lined up meeting with the top CEOs from all the AI and tech companies. It's going to be fun. Any favorite meetings you're looking forward to, Dave?

**Dave:** Well, you're kicking it off with the big shots. You've got Eric Schmidt, Larry Fink, just the big money people and the big vision people. That's going to be such a fast start. But then backstage, it's just a who's who of incredible people. I'll be backstage the whole time. It's going to be wild.

**Peter:** Yeah, I chair FII out of Saudi—the Future Investment Initiative—and I'm on the board there and I chair their AI activities. One of the things that's going to be interesting this year is we have 20-something heads of state and I'm going to be co-chairing a conclave with Ann Miura from A16Z and we're going to be talking about how to use AI to accelerate governance for countries.

One of the biggest challenges we have—we'll talk about this when we come back—is that the speed of change is so extraordinary and so disruptive in terms of AI and humanoid robots and longevity that countries out there are having a difficult time trying to understand what policies do they put in place, what do they do best for their nation state, for their citizenry. We're going to be announcing a program called Sovereign AI Governance Engine. We'll talk about what that means, but it's really to help people around the world deal with the disruptive change and disruptive opportunity at the speed of AI versus the speed of governing governments and PDFs.

**Dave:** Yeah, and the reason that's coming out in Saudi Arabia at FII in Riyadh is because the deployment rate of ideas like that can be very fast in those countries because they make decisions in a very tight-knit, very fast-moving group. And so that'll be a huge bellwether for Western democracies because it'll happen there long before it happens in the US and Europe.

**Peter:** Alex, what's the week like for you buddy?

**Alex:** It's in some sense the same as every week for me, which is trying to accelerate and smooth out the gentle singularity.

**Peter:** I love that. By the way, our episode on the singularity has just done incredibly well. People—I've had faculty at UCLA and others saying they've assigned this to all of their students to listen to that podcast.

**Dave:** It's really done—it's gone viral. So if you haven't heard that episode, "The Singularity Is Now," go listen to it. It's the Moonshot Mates at their best.

**Peter:** Love you guys. See you on the other side of the pond. Dave, Alex, see you in a week when we're back.

**Dave:** All right, sounds great.

**Alex:** All right, take care all.