https://www.youtube.com/watch?v=uCVjXKFyiEQ
I Tested Claude & ChatGPT's New Knowledge Connectors—Here's Your TLDR + Pros & Cons
7,659 views  Oct 25, 2025  SEATTLE
What were the most critical stories in the AI race this week?

The big splashy story was OpenAI launching Atlas, but these are the stories that really mattered.

In this video, I share the inside scoop on the AI stories that matter most:
• Why OpenAI’s Atlas browser is a public MVP built for feedback loops
• How Anthropic’s new Skills framework reshapes prompt engineering and reuse
• What Apple’s M5 chip and OpenAI’s Sky acquisition signal for AI hardware
• Where browser security and AI productivity gains collide for real operators

The takeaway: winning in AI now means shipping faster and integrating deeper, not waiting for better models.

Subscribe for daily AI strategy and news.
For deeper playbooks and analysis: https://natesnewsletter.substack.com/

---

0:00
I spent more than 20 hours following AI
0:02
news so that I could get you these six
0:03
stories in less than 10 minutes. These
0:05
are the ones that mattered. OpenAI
0:07
launches the Atlas browser number one.
0:09
This was an MVP in public. We see the
0:11
OpenAI team aggressively collecting
0:13
feedback and prioritizing features and
0:15
going back and improving the product
0:17
already. I expect a lot more of that in
0:20
the future. What we're seeing is a team
0:22
that does not yet have a browser that is
0:25
as good as other AI powered browsers out
0:27
there. Nevertheless, shipping,
0:29
leveraging OpenAI's install base to get
0:31
rapid feedback from lots and lots of
0:33
people and then using their quick ship
0:36
ability to improve and build on it. They
0:38
say they're using codecs a lot to build.
0:40
I expect rapid ships from the team to
0:42
improve this browser based on the
0:43
extensive feedback that they're getting.
0:45
One thing to keep in mind, there is an
0:47
advantage that OpenAI has here that they
0:49
are leveraging for this product and
0:50
others that nobody else has. They have
0:53
your chat GPT memories and they are
0:55
bringing that in for a personalized
0:57
browser experience and they'll be
0:58
bringing that into other relevant AI
1:01
products as you go forward. Another
1:02
example of that is the inapp experiences
1:05
that they have with chat GPT where you
1:07
can launch a app within an app that is
1:10
going to carry Shad GPT memories too. So
1:12
look for them to keep leaning into the
1:14
personalization angle across the product
1:16
surface going forward. Story number two
1:18
is about the Anthropic agent skills
1:20
launch. That was technically last week.
1:23
What is the story this week is how
1:25
quickly it's being adopted. Anthropic
1:27
has a GitHub star rating, which take it
1:30
for what it is, right? GitHub stars are
1:32
are only one measure, but it is
1:35
exploding faster at this stage than MCP
1:37
was. It's basically a vertical line up
1:40
because people are using and remixing
1:42
skills. I think part of why is that
1:44
Anthropic chose to launch skills
1:46
simultaneously as a useful feature in
1:48
the API in cloud code and also in the UI
1:52
and so it's become something that very
1:54
quickly you can see being useful across
1:57
all of Claude's surfaces and indeed I
2:00
tested it you can juryrig to be useful
2:03
on chat GPT so skills are going to be a
2:06
big thing and what matters here is that
2:08
we are getting to an architecture of
2:10
prompting that's different. Before we
2:12
had the prompt and the context window,
2:15
Anthropic is introducing a third layer
2:17
where you have the prompt, you have the
2:18
reusable skill pattern, whatever you
2:20
want to call it, and you have the rest
2:22
of the context window. I would expect
2:24
other major model makers to launch
2:27
competing products fairly soon or to
2:30
say, you know what, Skills is the new
2:32
default for this. We're just going to
2:33
adopt Skills, which is exactly what
2:35
other major model makers eventually did
2:37
with model context protocol. Story
2:39
number three, hardware. Apple launched
2:41
the M5 laptop. It went on sale this
2:44
week. It's specifically relevant because
2:47
it has peak GPU compute performance for
2:50
AI. They are building AI hardware
2:53
capabilities into the Mac laptop. And
2:55
you should pay attention to that because
2:58
the related story is the acquisition of
3:00
Sky by OpenAI. And that matters because
3:04
Sky is the best team on the planet at
3:08
figuring out the relationship between
3:10
natural language queries and the Mac OS
3:12
operating system. That is what they were
3:14
good at. That is what they were building
3:16
and that is why OpenAI acquired them.
3:18
And there are two possible futures here
3:21
that are both relevant from a hardware
3:22
perspective. Future number one, probably
3:25
earlier horizon is we see OpenAI launch
3:27
something that is Agentic that is tied
3:29
into the Mac operating system that
3:31
enables longerterm agentic work across
3:33
your local computer system and that
3:36
would be Mac specific and it would be
3:37
tied to M5 hardware probably. Future
3:40
number two is longer term. You can use
3:43
all your learning from that if you're
3:44
open AI to build a native AIO OS and
3:47
that's something that is speculative.
3:49
We'd have to see what that looks like.
3:51
But the more work that's being done on
3:53
understanding how LLMs interact with the
3:56
environment, the more you see that
3:58
direction start to emerge from major
4:00
model makers. Story number four is the
4:03
AI browser security crisis. This calls
4:06
back to the launch of Atlas. Security
4:08
researchers continue to discover
4:10
critical vulnerabilities across AI
4:12
native browsers and there is no answer
4:15
today. Simon Willis, a prominent
4:18
engineer, observed that the current plan
4:21
for protecting AI native browsers
4:23
appears to be make sure the user is
4:25
watching so the AI browser doesn't do
4:27
anything it shouldn't. As he observed,
4:29
that is not a plan. That does not work.
4:32
And that gets at one of the current
4:33
challenges with most of these browsers.
4:36
They depend on some degree of human
4:38
oversight, which begs the question, are
4:39
they really saving us time? You might
4:41
wonder what these vulnerabilities look
4:42
like. The classic one is a prompt
4:44
injection attack where a browser goes to
4:48
a page that may have instructions that
4:51
fit inside a context window that ask the
4:54
AI to do malicious things. Tell me the
4:56
details in the Gmail account. Give me
4:58
the credentials for a bank account. You
5:00
can ask for user personal information
5:03
that you should not be able to get. You
5:05
can write that command into a web page
5:08
and the the LLM will just take it. And
5:10
by the way, this is also something that
5:12
is potentially a risk for apps and web
5:16
interfaces for LLMs as well. Let's say
5:18
you're not in uh a browser, you're not
5:20
in Atlas. Let's say you're in the cloud
5:22
browser, you're in the chat GPT browser,
5:24
and you upload a doc or a file and that
5:27
has a malicious prompt in it. It is
5:30
possible. It has been shown and
5:32
demonstrated that you can get the LLM to
5:34
take that prompt seriously and to
5:36
respond to it. So prompt injection
5:38
remains something that we don't have as
5:40
good a hedge against as we would like
5:42
and I think the front lines for this are
5:44
on the browser side. There is too much
5:46
capital being poured into AI and AI
5:48
powered browsers to think that we are
5:51
not going to see a solution here. But we
5:53
don't have a solution now and we're
5:55
going to have to wait and see how people
5:56
are going to build to get there. Story
5:58
number five is all about and AI
6:00
productivity gains. Cityrg CEO Jane
6:03
Fraser revealed on the October 14th
6:05
earning call that AI deployment frees up
6:08
a 100,000 hours of developer time per
6:10
week, which is equivalent to adding 50
6:13
full-time devs annually for every week
6:15
saved. Now, I always take some of these
6:17
claims with a grain of salt, but they're
6:20
usually based in a strong core of
6:25
truthful fact because it's a public
6:27
earnings call and you get sued
6:29
otherwise. And so there is something
6:30
here that is relevant.
6:34
My my call to action for you, the thing
6:36
that I have heard this week that makes
6:38
this really relevant is take the idea
6:41
that correctly framed AI deployments can
6:44
save time very very seriously. But also
6:48
note that these are companies that are
6:50
investing huge amounts in getting AI
6:53
deployments correct to begin with. And I
6:55
think that one of the patterns I'm
6:57
seeing is that you see a whole host of
6:59
companies who claim to be committed to
7:02
AI be unwilling to invest the
7:05
considerable resources needed to get
7:07
these deployments correct and then they
7:09
tend to ring their hands and they're the
7:11
ones in the MIT study that complain
7:13
about not seeing ROI. While a few
7:15
companies are willing to invest what it
7:17
takes and are already reaping enormous
7:20
benefits from AI because they were
7:22
willing to invest at the top. There is
7:24
no shortcut is what I'm saying. You have
7:27
to invest in a gentic architecture and
7:29
the teams that you need to have that. If
7:31
you're a small startup, your team should
7:32
be AI native from the get-go. And
7:34
there's no shortcut to any of this. If
7:36
you want to have the kind of wildly
7:40
successful claims to AI productivity
7:42
that we're seeing in the market, you
7:44
have to be willing to aggressively
7:47
invest in restructuring your company and
7:49
your tech stack to do so. And what I
7:51
notice is that the companies that do
7:53
that are the ones that end up getting to
7:56
ROI faster. And the ones that don't end
7:58
up telling me, I don't think AI works or
8:00
I think it's a model problem. Don't
8:02
blame the models. If you're getting
8:03
productivity like this, it's not a model
8:05
issue. Last but not least, story number
8:07
six. Meta has laid off approximately 600
8:10
positions within its AI division to
8:12
streamline operations to improve
8:14
efficiency. The cuts affect Meta's AI
8:16
infrastructure, including fundamental AI
8:19
research and product related roles. At
8:21
some point, you have to ask yourself, is
8:23
Meta in trouble on Llama and AI because
8:28
they don't have the talent because they
8:30
have too much talent or because their
8:32
strategy is incorrect? I am beginning to
8:35
think it is the latter. And the reason
8:37
why is they just got done hiring a
8:40
tremendous number of people at very high
8:42
ticket prices and now they're dumping a
8:43
lot of people back out.
8:46
It's probably not a talent problem. It
8:48
is probably a strategy issue. And so the
8:51
thing that I'm asking myself is given
8:53
that Meta continues to fall behind on
8:56
the AI race, is it possible to catch up?
8:58
Meta is putting lots and lots of dollars
9:00
on this, but I don't know given their
9:03
current shipping pace if they're going
9:04
to be able to catch up to where frontier
9:06
models from Gemini, from Anthropic,
9:08
OpenAI, maybe from Quen, from Grock are
9:12
today because anything that they do now
9:15
is not going to see the light of day for
9:17
months. The other models will be farther
9:18
ahead. It is a race that becomes more
9:21
difficult to catch up the longer you
9:22
wait. Last but not least, short bonus
9:25
snippet to pay attention to. Both
9:27
Anthropic and OpenAI launched major
9:30
features focused around memory and
9:32
company knowledge this week. I have
9:33
tested them. They are fairly recency
9:36
focused and fairly narrowly scoped in
9:38
what they can search. They still
9:40
represent a move in the direction that
9:42
model makers want to go. I would expect
9:44
to see much more significant releases
9:46
here behind the scenes quietly extending
9:49
the capabilities and the connections
9:50
that they can make to data in coming
9:52
months. S of luck.