https://www.youtube.com/watch?v=gnUxZA7Ew1E
AI is here. The future is brighter than you think. with Sean Grove | Everything NYC 2025
178 views  Oct 29, 2025
AI is evolving fast but its real power isn't about replacing humans, it's about amplifying us. In this thought-provoking keynote from Everything NYC 2025, Sean Grove (OpenAI + Netlify) explores how the next wave of AI breakthroughs will come from systems that help us express what we mean, uncover hidden gaps, and sharpen ideas until they're crystal clear. Discover why the future of AI collaboration is brighter than you might think.

‚è© Chapters

00:00 - The Token Wave
01:30 - From Steam to Tokens
05:40 - Building Infrastructure for AI
08:00 - Becoming Conductors, Not Coders
10:00 - The Four Core Skills: Express, Shape, Prove, Trust
11:40 - Demo: Specifying and Designing with Agents
19:00 - Trust Through Evidence, Not Vibes
22:40 - Scaling Without Fear
28:00 - Expressing Intent and Redefining Roles
30:50 - Leadership and the Human Factor
32:40 - Doing It for the Love of It

üéØ Key Takeaways

AI's true value lies in amplification rather than replacement of human capabilities
The most powerful AI systems help clarify intent and uncover hidden gaps in thinking
Future AI breakthroughs will focus on human-AI collaboration rather than autonomous systems
Content operations benefit from AI that makes human intent stronger and outcomes more trustworthy
Organizations should focus on building AI systems that enhance rather than replace human workflows

üë§ About Sean Grove

Sean Grove is a respected thinker and coder working at the intersection of OpenAI and Netlify. With extensive experience in both AI development and practical implementation, Sean brings unique insights into how technical teams can leverage AI to enhance content operations while maintaining human creativity at the center of the process. Follow him on Twitter @sgrove and GitHub at github.com/sgrove.

üì∫ More from Everything Podcast Series

   ‚Ä¢ Everything Podcast Series  

Read the docs üëâ https://www.sanity.io/docs
Get started for free üëâ https://www.sanity.io

---

The Token Wave
0:00
- All of us should have dozens of agents in our pocket running, working for us. Right now.
0:12
I am here to talk a bit about writing the Coming Token wave.
0:18
And in particular like the meaning of this is, is how are we all going to be able to wield great power at scale compared to
0:25
what we are able to do today. So a quick bit about me. My name is Sean.
0:31
I previously worked at In Alignment Research at OpenAI.
0:37
Before that, I started and sold some companies. And my background is very much in sort of developer tooling,
0:43
compilers testing. The common thread is in making the intentions in our work
0:50
much more visible and automating a lot of the drudgery.
0:55
And this is actually a continuation of a previous talk I gave this. This is a self-contained talk, but if you're interested in sort of like the context
1:01
and the origin of, say, for example the model spec or the impetus to actually use it,
1:09
this is some additional context and I'll talk about coding. Coding, but this talk is actually not about coding.
1:16
This is about sort of the universal interface that all humans have to use to understand the domain
1:22
of the problem, to communicate their intent, and to actually solve problems at scale.
1:28
So with that, let's start with the new utility. These numbers seem fanciful, but they are real.
From Steam to Tokens
1:35
In the next five to 10 years, literally trillions of dollars will be invested in generating tokens at
1:42
great, great scale. And in addition to those, the dollars, millions of hours
1:47
of hugely capable, very motivated researchers and engineers are gonna be working hard at pouring their
1:54
lives into this for our benefit. And that means that per token, over the next couple
2:00
of years, the intelligence, the speed, and the ability to represent the things we care about in our
2:05
world is going to skyrocket. And at the same time, the cost, the latency
2:11
and the waste per token is going to drop. And the net effect of this is
2:16
that there will literally be waves of tokens washing through data centers and across the internet.
2:24
And just like any other wave, if you're able to sort of capture and harness the power in that wave,
2:29
it's a greatly empowering feature. Just like we've done with say rivers, with hydropower,
2:34
steam power, solar power, we're sort of entering into an age where we have an abundant source of cognitive power.
2:42
But the challenge there is like how do you actually harness that to make things better? How do you actually move forward with that?
2:49
Can we turn tokens into a form of propulsion? So analogy to think of here, especially given the venue is sort of the steam engine,
2:58
steam trains literally transformed society. But it's kind of ironic because a steam power
3:04
by itself is very impotent. It can't do anything on its own.
3:09
It only works because humanity literally changed the shape of the earth
3:15
to accommodate this and then changed their problems to fit into a train shape.
3:20
So first we covered the earth in tracks. We literally drilled holes through mountains
3:27
and then to, to make it so that the, the trains could actually move quickly. And then as a follow up, we changed all of our problems,
3:35
the problems that we work on to fit into a train shape, say a container adhering to sort
3:42
of weight restrictions and whatnot. And we got, we, we iterated through this so much
3:48
that at some point it got to the, the the point where if you just added more steam that turned into more goods
3:55
or good peoples delivered. And with the token powered system, we actually have
4:01
to do the same thing where we actually have to build the infrastructure that allows sort
4:06
of the token power to access our world. So connectors that allow these tokens to perceive our data
4:13
and to modify it in ways that we care about, we have to be able to monitor, to understand the bottlenecks,
4:19
to identify problems. And then once we get there, we actually have to figure out
4:25
how to shape our problems in a way that can be pushed forward on this new infrastructure.
4:30
And the nice thing is that LLM, the AI labs are all putting a lot of money in and are all very, very motivated to understand what is
4:38
that shared infrastructure to make it so that those LLMs can reach and perceive everything.
4:43
So they are working hard to un hobble the LLMs at scale. And that means your leverage is going to be at understanding
4:51
how do you un hobble an LLM in your specific domain? How do you make it so that the LLM understands
4:57
what you're trying to do and can power the changes that you want to see happen? And we, we need to get to the point in each of our domains,
5:06
it's all of our responsibilities to figure out how do we make it so that we add more tokens, we add more compute, and we get a better and better
5:13
and better solution. So, and this is important 'cause if we have to actually shape our problems in a way
5:20
that can accommodate tokens, you know, in the same way that, you know, if you were to take a, a train
5:26
and put up, you know, lots of containers and then run it over a rocky terrain over, you know, a mountain of terrain without rails,
5:33
it wouldn't do much good. We actually have to be able to figure out how to add more tokens to a problem
5:39
and get ever increasingly better solutions. And you know, if you're a content writer or a developer,
Building Infrastructure for AI
5:45
there's a question you should be asking yourself, which is why are you not running an LLM all
5:50
of the time just generating billions of tokens every day? Does anyone want to do that right now?
5:57
That sound like a good idea. Well, it's not really an issue. I mean maybe it's cost, you could argue,
6:03
but you know, tokens are gonna go basically to become free. So the issue is sort of more like, even if it were free,
6:09
you probably wouldn't want to do this. This seems like a potentially very destructive idea
6:14
because at some point the LLM agent is actually generating the tokens that are doing more harm to your, your content
6:20
or to your source code than actually it's doing good. You know, if you, for example,
6:25
you ask a coding agent at night, make me this feature and you describe what you want and you go to sleep, it's very unlikely that you wake up to a complete
6:32
and nice feature, a nice surprise, maybe more likely that you wake up to a broken computer.
6:39
But we should aspire to run agents all of the time. All of us should have dozens
6:44
of agents in our pocket running, working for us right now. The challenge is we don't know how to direct
6:51
that power in a way that we can trust at scale. So the way to harness this is to sort of think of ourselves
6:58
as conductors in this world where, you know, everyone else is providing just tremendous amounts
7:04
of virtuosos and scaled laborers and whatnot. And at some point, all of us are going to have hundreds
7:11
of thousands or millions of agents working for us individually, personally. And these numbers seem, I know fanciful,
7:18
but if you were to take the number of transistors we have or the amount of memory that we all, you know, carelessly carry in our carry in our pocket back
7:24
to say 19 60, 19 80, they would not have believed you with these numbers. They would've said that's, you know, podcast bro numbers.
7:32
But you know, if we have these many agents working for us, we are not going to be able to outcompete sort
7:38
of the sheer skillset and the, the, the range of abilities that they have.
7:43
So it becomes our job to be able to put together an ensemble of these and to figure out how to express our intent
7:51
and convert that into an outcome that we actually care about, powered by these specialists.
7:57
And the thing about a, like a conductor in an orchestra is they are actually like a master of dozens of skills,
Becoming Conductors, Not Coders
8:04
dozens of instruments. And in addition to that, they know sort of the addition, the way to put them together and make art out of that.
8:14
And in the same way, domain expertise is even more important in this world
8:19
where you as the expert who has done, you know, a tremendous amount of work in your, your career, you know,
8:26
the purpose of this work, how is it going to be applied in the real world? What problems is it going to solve?
8:33
You know, how to actually arrange your agent, arrange your team so that they make forward progress on it.
8:39
And at the end of the day when the work comes in, you know how to review it and see is this is the result faithful
8:45
to your vision and to your intent. So taste and judgment matter tremendously in this world.
8:53
It just operates at a tremendously larger scale. So I would say that there were four things
9:00
that are required. This is really general to sort of any human problem, but in this new world, the four things that you need to do
9:08
as someone who is a conductor of this is you need to be able to express very clearly what it is that you want.
9:15
And this is way more difficult than it sounds. You know, if you've ever been given sort of a,
9:21
a product description that you have to go and implement, and by the time you actually write it down, you realize that you're missing half of the information that you need
9:27
to imple to implement it correctly. This is incredibly important.
9:33
Then after you know what you want, you actually have to shape the problem so that you can apply the tokens to it
9:40
and you get monotonically increasingly good results. And then if you have hundreds of thousands
9:46
or millions of agents working on your behalf doing all of this, they're going to generate a tremendous amount of artifacts.
9:54
So you need to find some way in the small to be able to prove that the work that they're doing is working towards
The Four Core Skills: Express, Shape, Prove, Trust
10:00
faithfully your vision. And then once you can prove in sort of that, that tight inner loop, then you,
10:07
you can literally just turn up the amount of tokens that you pour into the system and you'll get a better
10:12
and better system at scale. So I'm gonna show a quick demo of
10:17
what I think it might look like and there's gonna be a, a sort of common thread where the first step is extracting out from the
10:25
user what is it you want to do. And, you know, if you've ever prepared a talk
10:31
or written a blog post, there's very often a step where you give this to an editor where you debate
10:39
with a friend and you go back and forth. You have an interrogative partner who pulls out highly
10:46
clear thought from you. And then once you've captured that, or once you, you know what you want, you capture that inside
10:53
of a a document, a specification. And this spec the specification is a living document that
10:59
contains the decisions, the implementation details and whatnot.
11:05
And once you have that and you send it off to, for someone to implement the work needs to come back
11:10
and needs to sort of relate to this document, you need to be under, under able to understand when you're looking at your document, what part of the, the report, what part
11:18
of the result proves to me that this is actually implemented correctly. And then once you have that, the system needs to be able
11:24
to just drive millions of agents at scale. So in this demo, I'm just, it's a very simple interface,
11:33
but I'll explain it. On the left, we're gonna have a chat, like a chat interface we, we are all familiar with.
11:39
In the middle we'll have a specification document, and on the right we'll have some sort of introspection tools that help us understand what we're working on.
Demo: Specifying and Designing with Agents
11:46
So in this document, so this, this is a tool that's meant to help me sort of vibe code at scale.
11:52
So I'm gonna describe the application I wanna build. I'm gonna go back and forth in a,
11:58
a conversation with the system. It's going to highlight things that maybe I didn't realize about it.
12:04
And then it's going to start to amplify my intent.
12:09
So this is just a demo, but you can see over here we have like a little
12:14
chat interface like I mentioned. And it's just gonna ask me like in one or two sentences, what are you building today?
12:20
And I'm gonna say I wanna build a collaborative coloring book app for my daughter and it should work on mobile.
12:28
I want it to be able to generate coloring book images via an LLM and then she can color it in with brushes,
12:36
fills and stickers that she loves stickers. So once we have this, you know, it's gonna start
12:42
to take some notes and it's like, all right, well what are the the features we should target first?
12:48
What priority?
12:57
All right, so I'll send off this, and while this is working, you sort of, it's going to be trying to figure out these questions up here.
13:03
The same thing that if you were to sit down and work with some partner, you're gonna try to figure out like, alright, what do you wanna build?
13:09
What's the name of it? What are the technical decisions that we need to make up here? And so it's gonna like, work out these different things.
13:17
And you can tell it's, it's a little bit annoyed with me. It's like, what are the image styles and constraints? And it's just taking these notes
13:24
and as it's doing this, I'm gonna say, I know that there's a visual component to this app obviously,
13:30
so I have like a, a sort of aesthetic feel in mind. So I'm gonna come over here and, and generate a style guide.
13:36
So I want it to be fun, maybe bold, I'll get some new suggestions here.
13:42
I want it to be anime inspired, fired manga characters.
13:47
Definitely not neo brutalist, but let's say warm. Warm looks good. So now I'm gonna generate
13:54
just a couple of ideas. So based off of this, you know, high level description,
13:59
maybe I don't really know exactly what I want, but I have a general gist of it and I'm gonna get back some suggestions.
14:05
So I'll skip over to pre-generated one. At the end of the interview,
14:13
we're gonna summarize everything and, and create a highly structured document of sort of a problem statement, an overview
14:18
of what we're actually building. And you can see over here, here are some of the sort of mood boards that it has generated.
14:26
So in this case I like say this one the most. And if I like that, I can actually say, all right,
14:32
let's go ahead and pin that. And now all future generations, all sort of images that are generated are going to be driven via this style.
14:40
So I'm able to express my intent sort of very vaguely at first, but then iteratively narrow down what it is
14:46
that I want and what I require. And then you can see here that, you know, I, I've described sort of the user journeys and,
14:53
and what not should happen inside of this. And it's actually gone through and detected, you know, what are the screens
14:59
that are involved in this, just like if you were to work with a designer and based off of
15:04
that it's generated some mockups. So these are again, generated and driven via that style board that we,
15:11
or mood board that we generated previously. And these look kind of good to me. I think, yeah, it, I would be happy if the app
15:17
looked like that. That's certainly better than I could do. And so inside of this specification
15:22
and the screen summaries, it sort of has put these in here. And so I can go through and describe what I want
15:29
to have happen in this app, start to visualize it, and this becomes sort of the ground truth that's going
15:34
to drive the generation of this app. But you know, we talked about it's hard to know
15:39
what you want and part of that is yes, the visual design, but I actually think of a larger part is the
15:45
rigor of thought. So if you have ever translated a product requirement into an actual application, it con it turns out
15:53
that it is much denser to write code. You have to think about all of the edge cases, all the contradictions, the ambiguities.
15:59
And so what we can do here is we can actually walk over the specification document and we can extract out the atomic indivisible claims.
16:06
Like what, what are you saying you want the world to look like when this application is built?
16:12
And then we can walk over and say, well, some of this is a bit ambiguous. So for example, if I look at maybe the claims,
16:19
I look at the ambiguities, you can see here it said, well I want kid friendly,
16:25
but I didn't mention anything about like age range or content standards, accessibility, whatever that might be.
16:30
And that's a perfectly good point, like maybe I don't care about it in this case and I can intentionally say, you know what,
16:35
this doesn't matter, this is a little minor app, but maybe it actually does matter at some point. And I can say, okay, well go ahead
16:42
and show me where I, I've done this and or, you know, see easy coloring on mobile.
16:47
And so I have lots and lots of different claims here. And then some of them actually worse than ambiguity
16:53
might be contradictions. So in this case, you know, I've described an application which is publicly accessible,
17:00
has no accounts, and sort of has like a little bit of interaction. So you can see here where it's like, well, you know,
17:06
you're allowing anonymous users to free draw and publish directly to public galleries. This is probably a bad idea, right?
17:13
So it's sort of extracting out the contradictions, the ambiguities, the things
17:18
that would cause problems if I were to launch a thousand agents and go code this up right now. So we get to fix those problems immediately rather than when
17:26
it's the fastest and the freshest in our mind.
17:31
And then you can go further with this, right? So in this case, I've generated a mockup for this
17:37
and for this, this screen. But you can say like, I actually don't want it
17:43
to be quite like this. So I, I can use a model to actually extract the component structure, the thing
17:49
that you would code from the screenshot. Maybe this is a UI screenshot, maybe it's a mockup. And I can just sort of grab it
17:55
and say, well, this card component, I want this to be full width and I want this vertical list to actually
18:00
become horizontal and go down here. And then just by sort of like physically manipulating the
18:08
the component tree structure of this, you can then compile out something that looks like this.
18:14
So you can actually just compile out in the con instructions for a image model to generate a new version of this
18:23
and then looks something like this. So you can see how like all of the details have been kept, and I've sort of said these things need to be moved around
18:30
and it has respected that. And so this is just like sort of working with a really good designer,
18:35
but in person on a like really high fidelity whiteboard where you have to go back and forth, express your intentions
18:41
and get this thing out, and then this becomes part of your source code specification.
18:49
And once you have disambiguated it, you've figured out all the contradictions on how to fix them.
18:55
And you've put that in. The thing is, this is now a closed loop because the, at this point,
Trust Through Evidence, Not Vibes
19:04
the agent, so I can see the mockups, I can see the, the images, the agent can see these image images
19:10
as they're implementing it. Whenever they're done implementing it, they can actually see what the implementation looks like.
19:16
I can see what it looks like. The agent can compare it and see like, did it mess up?
19:21
And if it messed up, it can actually flag that for its own subagent to fix.
19:27
And so you've turned this into the problem where you just keep pouring more tokens into it, you pour more compute into it, and it iterates more and more and more.
19:34
And it knows that this is going to be judged according to the source specification. So by the time it gets to me is almost certainly going
19:42
to be adhering, at least visually to the thing I care about. And depending on how well I have specified the rest
19:48
of my specification, it will actually be doing that as well. So the, the thing that we, we care about in this world is not the code,
19:56
but it's the properties that we, we expect the code to exhibit and that's what I want to be convinced of.
20:01
I don't care how you formatted the code, I wanna make sure that it's safe or that it's, it has the functionality
20:07
or that it's secure or that it's performance. These, there are high level attributes that I care about that I need to be convinced of rather than reading the code.
20:15
And it turns out like English is a reasonably good programming language, just sort of missing like a compiler and a tool chain and linter and whatnot.
20:23
And like I said, we wanna fix any problems way early in the process as early as possible.
20:29
You know, if you have ambiguity and you launch a million agents and you wake up in the morning, you are likely
20:35
to have a very bad time and evidence, you know, like I said, evidence beats vibes.
20:41
The evidence is what is going to convince us to take a, a big pr. So in this case, I'm gonna skip here, what would it take
20:49
for you to trust a 14 million line PR that touches something incredibly
20:55
sensitive and business critical? Like right now, nothing is probably gonna be able
21:00
to convince you of that, right? But at some point you could imagine that there is a system that is able to prove to you that this, the, the code
21:08
that it has generated exhibits, properties that you care about, those properties are derived from the
21:13
specification from the com, the chats that you had and it has, it's able to prove it to you in a way
21:19
that would take you years, right? Maybe it does like exhaustive property based testing or you know, formalized language or whatever it might be.
21:27
It's able to do these things at scale. And the, the, the goal here is like we have to make big changes legible, where
21:37
as a domain expert we can sort of look at the high level properties, poke at it, try to break it, understand it,
21:43
and then build up confidence, right? Where, where we have like a sort of muscle intuition of like, okay, I, I know that this tends to fail
21:50
around here, I'm gonna go check that these properties tend to hold, okay, I feel comfortable allowing this 14 million
21:59
line change so that we can get to the point where we can scale without fear. 'cause otherwise, if you are sort of the human in the loop
22:05
and you are rubber stamping a 14 million pr, what that is about, that's about a liability sink, right?
22:12
The reason that we have a human in the loop is just so we have someone to blame if something goes wrong. It's not about like amplifying humans.
22:18
So what we need to do is we need to be able to actually scale with the token power, with the trillions
22:24
of dollars that are being invested in this, we need to be able to ride that wave. And so ultimately it's not about the size of the change,
22:32
it is about the legibility of the change. If you don't understand a small change, you probably shouldn't accept it.
22:37
And if you understand the properties of a large change should be perfectly fine. And this actually applies to almost every single domain,
Scaling Without Fear
22:45
you know, whether it's product research or operations finance. And I, I, I think like an interesting exercise
22:50
for like say a marketing VP is what would it take for you to approve a million dollar like ad spend budget based off
22:58
of what the agents have gone out and done. So you, you, you release 10,000 agents, they go do product research, market research, demographics,
23:05
user interviews, and they come back to you with a proposal that says, all right, we're ready to launch this thing,
23:10
it's gonna be a million dollars. What do you need to feel comfortable to sign off on that?
23:16
Are you gonna read all of the user's reviews? Probably not, but there's gonna be some evidence that you
23:21
as the domain expert will know this is required in order to be able to sign off on something as big as this.
23:29
So the takeaways here are, in order to scale with the tokens, with the amount of investment
23:35
that is going in, you need to be able to express very clearly what it is that you want. You have to be able to shape the domain to fit
23:45
or the problem to fit this new power source. You have to be able to prove
23:50
that the result is actually iterating closer towards your vision in a faithful manner.
23:55
And then you have to be comfortable letting it loose at scale. So go ahead and build the infrastructure
24:00
that connects the LMS to your domain and judge the tools by the evidence they produce, not
24:05
that the artifacts themselves is about the properties that the artifacts exhibit.
24:12
So please go shape your problems to take advantage of this new amazing data source and be a million times more productive.
24:19
Thank you.
24:26
- Hi Sean. Hello. Great talk. Thank you. I have some questions about this way of working.
24:33
What would we call this way of working by the way? Smart. I think. Is it spec based?
24:41
Is it specification based? - It's, it's about like starting with the intentions and then knowing what is it? Like what, what is the
24:46
impact that you wanna see in the world? If we talk about leadership, like a leader is someone whose intents affect the world.
24:52
They are amplified through other people and systems and they affect the world in some way. So the core is like knowing what is your intention,
24:59
what is the, the change that you want to see? And then being confident in like that the system has actually achieved that.
25:05
- I'm quite excited about this way of working personally, but when I talk to other programmers,
25:11
a common complaint I hear from them is, why would I labor over this specification when it just feels
25:19
much quicker and immediate to just go make the - Change? Yeah, I think there are, there are a couple
25:24
different things here, right? So this is a valid, valid criticism, but it's sort of like you have to ask where is the source
25:31
of friction coming from in that world, right? So because we are so capable, we spent a long time in this craft, we know how
25:39
to just go and do the thing. And that's actually maybe faster than describing the thing we want to have done and then checking to see if it was done correctly.
25:47
But it's very hard to scale in that way. You can imagine that like there are times where you need
25:53
to sort of change the problem to fit the power sources available.
25:58
An example of this might be sort of GPU programming, like Cuda, you know, you, you have
26:03
to change the way you express your problem in order to be able to take care of this massive, massive parallelism.
26:10
But you know, if you do, then you basically just add more GPUs and it gets faster and faster and faster.
26:15
So it depends on like how, like what niche you wants to sort of live in.
26:20
I think in, in the future. - You sort of broke down a process here of some, some,
26:26
some phases of this way of working. It was express and shape, prove and trust.
26:32
So where do you think the biggest friction here is compared to today's way of working in adopting this?
26:38
- So yeah, sort of to your, your previous question as well. There, there's something about thinking
26:44
and writing that is very painful. It's very hard. I I, you know, whenever you write a talk you think, oh, I,
26:49
I I know what I'm gonna talk about. And you go to sit down and you have a blank canvas and you think, oh, why did I agree to this? This is terrible. And it's the same way, sort
26:56
of like if you're thinking about a product or a feature or whatever it might be. And one of the nice things about like code is it allows you
27:02
to iteratively express and explore. So I think that right now, if you just sit down in front
27:08
of a blank canvas with like, and write out a specification, that's going to be the highest source of friction is knowing
27:13
what you want and being able to express it. And that's why I think the tool tooling sort of has to pull it out of you
27:18
and has to make it really easy to iterate. So, you know, I, I want a, a drawing app for my daughter
27:24
and like, I actually haven't thought it all the way through. I maybe I think I have, but then it starts to ask me questions about like, well what's the tech stack?
27:30
And you know, what about safety and are there accounts? And I think, well these are good questions and maybe some of the things I think,
27:36
you know what, I don't care. You do whatever you, you want. But sometimes I think, well, we'll put a pin in that
27:41
and we'll come back or we think, or I think, you know, this is really important, I need to, to fix this right now.
27:47
So I think that that right now is the biggest friction and because we haven't had systems that sort of allow us
27:54
to scale to millions of developers of ourselves, I think it's very hard to sort of envision the benefits
Expressing Intent and Redefining Roles
28:01
given sort of the, the current system. If you haven't experienced, then it's like, well, why would I go through this extra effort?
28:07
Yeah. And, and so for dubious returns, - I'm curious how roles change in that, right?
28:12
Because speaking as a programmer, I'm used to translating product requirements to code, right?
28:19
That's, that's part of my skill And I see that as translating one layer of abstraction down
28:25
to another layer of abstraction, right? And the product manager who's writing those requirements
28:30
might be translating a higher level abstraction business goals and opportunities into products, right?
28:37
So there's these translations that are happening by very specific roles like CEOs, product people, engineers, et cetera.
28:45
This though seems to add another sort of abstraction layer at the top where it's all a common language, right?
28:52
It is natural language is English or whatever your native language might be. Does that also sort of blend the roles together
29:00
or are they the, the traditional roles all working together sort of in the same layer at that point, if you know what I mean?
29:06
- I, I think it's, I think there, there's definitely a blending, but it's sort of like an amplification of each individual.
29:11
So, you know, in this, this scenario I'm generating mockups of a screen, but you can imagine, and that that's
29:17
because like I'm not good at, you know, making visual mockups of, of screens, but maybe a designer knows really well how to express
29:25
what they want in say the Figma and they can import that, but they're not really sure about the tech stack or the distribution method
29:31
or you know, the, the partnerships that they should come up with. And so it sort of enables them to,
29:38
to some degree blend it together, but through the lens that they feel most comfortable expressing themselves in. - Hmm. It kind of reminds of leadership as well, right?
29:47
'cause you're here, you're, you're, you're, you're, you're driving at some outcomes and you're sort of going about it in a structured way trying
29:54
to, to to realize what the, you're trying to do. Not the mechanics necessarily of doing it,
30:00
but the way that leaders enable teams to go out and build things without micromanaging like, oh,
30:06
this should be a class or this should be a, a functional thing, right? In programming. - Yeah. - So how does that, how does this way
30:12
of working sort of relate to, to leadership in general, do you think? - Well I think we all, I mean, if you have a hundred
30:19
thousand agents or a million agents working for you are by definition a leader, like one of the most powerful leaders in the history of humanity.
30:27
And so like we all become leaders in this, this world.
30:32
So yeah, I I think there's no getting away from it, like you, you have to sort of think at a much more impact.
30:38
Like what is the impact that you're going to have with, with the effort And like, you know, the, the common thread through all of this is that the biggest bottleneck
30:44
and the most precious bottleneck is like human life and human time, human attention. And this, you know, if, if you can just sort
Leadership and the Human Factor
30:52
of speak anything into existence, it it, it makes you like think about what do I want
30:58
to spend my life doing? What is the impact that I want to have? And like that is the definition of being a leader.
31:04
- I think that segues nicely into this other thought on not everyone is sort
31:13
of either cut out to be or want to step into sort of leadership and think of themselves as a leader and,
31:19
and figuring out all the difficult questions of why are we doing things and to what end.
31:24
So what do you say to those that sort of don't necessarily wanna step out into that kind of a role
31:30
and who are just enjoying like building things, picking tickets and just like laboring over code
31:35
that they might be proud of and think that that's what gives them joy in their life? What would you say to them? - Well, I think it's, it's very important
31:41
to do the things that give you joy. You know, it's like one of my, my favorite terms is amateur
31:48
and we use it as like a pejorative right now. But the meaning is really beautiful. It's, it's someone who does something for the love
31:54
of it, right? So if you love programming, if you love, you know, a Norwegian demo scene, you know,
31:59
and you, you're gonna go, you can throw yourself into that and really enjoy it. But a professional is someone who gets paid
32:05
to do something for some outcome. And so I think it's nice that those things sort of become separated. Like, if you don't want to do this professionally,
32:12
then don't do it professionally. But it will probably be somewhat difficult to compete
32:17
as say, an amateur. There, there are industries where, you know, this, this happens, you know, an artisanally made hat or,
32:23
or belts, you know, or some couture or something. I, I don't know if the market will exist for artisanal code.
32:31
It's possible. But you know, maybe there, there's something about like if you enjoy it, do it
32:37
for the love of it and if you like want to have an impact then with it, then you can go ahead
Doing It for the Love of It
32:43
and do it for professionally. - For sure there will be some sort of handcrafted, locally produced code product.
32:49
- Yeah. Great. Yeah, all of that. It probably - Cost more if I make you feel better. Yeah, I dunno. Okay, I think that's a good note to end on,
32:56
Sean, grower, everyone, thank you very much.