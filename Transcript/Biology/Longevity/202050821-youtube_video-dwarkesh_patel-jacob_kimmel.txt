https://www.youtube.com/watch?v=XCLODgdCmKA
Evolution designed us to die fast; we can change that ‚Äî Jacob Kimmel
65,060 views  Aug 21, 2025  Dwarkesh Podcast
Jacob Kimmel thinks he can find the transcription factors to reverse aging. We do a deep dive on why this might be plausible and why evolution hasn‚Äôt already optimized for longevity. We also talk about why drug discovery has been getting exponentially harder, and what a new platform for biological understanding to speed up progress would look like. As a bonus, we get into the nitty gritty of gene delivery and Jacob‚Äôs controversial takes on CAR-T cells. For full disclosure, I am an angel investor in NewLimit. This did not impact my decision to interview Jacob, nor the questions I asked him.

ùêÑùêèùêàùêíùêéùêÉùêÑ ùêãùêàùêçùêäùêí
Transcript: https://www.dwarkesh.com/p/jacob-kimmel
Apple Podcasts: https://podcasts.apple.com/us/podcast...
Spotify: https://open.spotify.com/episode/3xUw...

ùêíùêèùêéùêçùêíùêéùêëùêí
Hudson River Trading uses deep learning to tackle one of the world's most complex systems: global capital allocation. They have a massive in-house GPU cluster, and they‚Äôre constantly adding new racks of B200s to ensure their researchers are never constrained by compute. Explore opportunities at https://hudsonrivertrading.com/dwarkesh

Google‚Äôs Gemini CLI turns ideas into working applications FAST, no coding required. It built a complete podcast post-production tool in 10 minutes, including fully functional backend logic, and the entire build used less than 10% of Gemini‚Äôs session context. Check it out on Github now: https://goo.gle/4mw9BNg

To sponsor a future episode, visit https://www.dwarkesh.com/advertise

ùêìùêàùêåùêÑùêíùêìùêÄùêåùêèùêí
00:00:00 ‚Äì Three reasons evolution didn't optimize for longevity
00:12:48 ‚Äì Why didn't humans evolve their own antibiotics?
00:26:08 ‚Äì De-aging cells via epigenetic reprogramming
00:45:24 ‚Äì Viral vectors and other delivery mechanisms
01:07:03 ‚Äì Synthetic transcription factors
01:10:13 ‚Äì Can virtual cells break Eroom's Law?
01:32:13 ‚Äì Economic models for pharma

---

Three reasons evolution didn't optimize for longevity
0:40
Today I have the pleasure of interviewing Jacob  Kimmel, who is the president and co-founder of   NewLimit, where they're trying to epigenetically  reprogram cells to their younger states. 
0:48
Jacob, thanks so much for coming on the podcast. Thanks so much for having me. Looking   forward to the conversation. All right, first question.   What's the first principles argument for  why evolution just discards us so easily? 
0:58
I know evolution cares about our kids. But if we have longer, healthier lifespans,  
1:03
we can have more kids, right? We can care for them longer,   we can care for our grandkids. Is there some pleiotropic effect that an  
1:12
anti-aging medicine would have which actually  selects against you staying young for longer? 
1:18
I think there are a couple  different ways one can tackle this.  One is you have to think about what's  the selective pressure that would  
1:23
make one live longer and encode for  higher health over longer durations.  Do you have that selective pressure present? There's another which is, are there any  
1:30
anti-selective pressures that are  actually pushing against that?  There's a third piece of this, which is  something like the constraints of your optimizer. 
1:37
If we think about the genome as a set  of parameters and the optimizer is   natural selection, then you've got some  constraints on how that actually works. 
1:44
You can only do so many mutations at a time. You have to spend your steps that   update your genome in certain ways. Tackling those from a few different directions,  
1:51
what would the positive possible selection be? As you highlighted, it might be something like,   "If I'm able to extend the lifespan of an  individual, they can have more children,  
1:58
they can care for those children more effectively. That genome should propagate more   readily into the population." One of the challenges then‚Äîif you're  
2:06
trying to think back in a thought experiment style  of evolutionary simulation here‚Äîwould be: What  
2:13
were the conditions under which a person would  actually live long enough for that phenotype to   be selected for, and how often would that occur? This brings us back to some very hypothetical  
2:22
questions. Things like,   what was the baseline hazard rate during  the majority of human and primate evolution? 
2:28
The hazard rate is simply, "What is the likelihood  you're going to die on any given day?" That   integrates everything. That's diseases from aging,  that's getting eaten by a tiger, that's falling  
2:36
off a cliff, that's scraping your foot on a rock  and getting an infection and dying from that.  From the best evidence we have, the  baseline hazard rate was very, very high. 
2:45
Even absent aging, you're unlikely to actually  reach those outer limits of possible health  
2:51
where aging is one of the main limitations. The number of individuals in the population that   are going to make it later in that lifespan, where  using some of your evolutionary updates to try and  
3:01
push your lifespan upward, is relatively limited. The amount of gradient signal flowing back to   the genome then is not as high  as one might intuitively think. 
3:10
On that, often people who are trying  to forecast AI will discuss how hard  
3:16
evolution tried to optimize for intelligence,  and what were the things which optimizing for   intelligence would have prevented evolution  from selecting for at the same time? 
3:25
So even if intelligence were a relatively  easy thing to build in this universe,  
3:30
it would have taken evolution so long  to get at human-level intelligence.  And, potentially, if intelligence were really  easy, then it might imply that we're going to get  
3:38
superintelligence and Jupiter-level intelligence,  etc. The sky's the limit. One argument is birth  
3:46
canal sizes, etc., or the fact that we had to  spend most of our resources on the immune system. 
3:53
But what you just hinted at is an independent  argument that if you have this high hazard rate,  
3:59
that would imply you can't be a kid for too long. Kids die all the time and you have to become an  
4:06
adult so that you can have your kids. You‚Äôve got to contribute   resources back to the group. You can't just be a freeloader.  You need to get calories, go out  in the jungle, get some berries. 
4:15
If you're just hanging out learning stuff for  50 years, you're just going to die before you   get to have kids yourself. Obviously, humans have  
4:21
bigger brains than other primates. We also have longer adolescences,   which help us make use potentially of  the extra capacity our brain gives us. 
4:30
But if you made the adolescence too long, then  you would just die before you get to have kids. 
4:36
If that's going to happen anyways, what's  the point of making the brain bigger?  AKA, maybe intelligence is easier  than we think, and there's a bunch  
4:42
of contingent reasons evolution didn't churn  as hard on this variable as it could have.  I entirely agree with that particular thesis. In biology in general, when you're trying  
4:49
to engineer a given property, be it being  healthier longer or be it making something   more intelligent‚Ä¶ This is true even at the  micro-level of trying to engineer a system  
4:57
to manufacture a protein at high efficiency. You always have to start by asking yourself, "Did   evolution spend a lot of time optimizing this? If yes, my job is going to be insanely hard. 
5:07
If not, potentially there  are some low-hanging fruit."  This is a good argument for why, potentially,  intelligence wasn't strongly selected for. 
5:14
The lifespan argument plays back  into intelligence to a degree.  You start to ask, "If I have intelligence that's  able to compound over time and for instance, in  
5:22
some hypothetical universe, my fluid intelligence  lasts much longer into my lifespan‚Ä¶" If the number   of people who are reaching something like  65 is very small in a population, you're not  
5:31
necessarily going to select for alleles that lead  to fluid intelligence preservation late into life.  This is part of my own pet hypothesis around  some of the interesting phenomenology in when  
5:40
discoveries are made throughout lifespans. There  are some famous results. For instance‚Äîand I'm   going to get the exact age a little bit wrong‚Äîbut  in mathematics, most great discoveries happen  
5:47
roughly before 30. Why should that be true?  That doesn't make sense. You can put down   a bunch of societal reasons for it. Maybe you become staid in your ways. 
5:56
Your teachers have caused you to  restrict your thinking by that point.  But really, that's true across centuries? Is that true across many different  
6:03
unique cultures around the world? That's true in both cultures from   the East and cultures from the West? That seems  unlikely to me. A much simpler explanation is that  
6:10
for whatever reason, our fluid intelligence is  roughly maximized at the time where the population   size during human evolution was maximal. If you had to pick an age at which fluid  
6:20
intelligence was selected most strongly  for, it's probably around 25 or 30. 
6:25
That's probably about the age of the adults  in the large populations that were being   selected for during most of evolution. There's a lot of reason here to think  
6:33
that there's interplay between many features  of modern humans and how long we were living,  
6:38
and how that dictates some of the features that  occur that rise and fall throughout our lives.  In one way, this is a very interesting RL problem. It's a long-horizon RL problem, a 20-year horizon  
6:49
length, and then there's a scalar value of how  many kids you have, I guess that survive, etc. 
6:57
If you've heard from your friends about  how hard RL is on these models for just   very intermediate goals that last an hour  or a couple of hours, it's surprising that  
7:06
any signal propagates across a 20-year horizon. On the point about fluid intelligence peaking,  
7:12
it‚Äôs not only the case that in many  fields achievement peaks before 30. 
7:18
In many cases, if you look at the greatest  scientists ever, they had many of their greatest   achievements in a single year. Yeah, the annus mirabilis. 
7:25
Yeah, exactly. Yeah, exactly.  Newton, what is it? Optics,  gravity, calculus at 21.  Do you know the Alexander von Humboldt story? No. 
7:32
Alexander von Humboldt is one  of the most famous scientists in   history who is kind of forgotten now. He had this one expedition to South  
7:38
America where he climbed Mount Chimborazo at  a time when very few Europeans had done that.  He was able to observe various  ecological layers that were  
7:46
repeated across latitudes and across altitudes. It caused him to formulate an understanding of   how selection was operating on plants  at different layers in the ecosystem. 
7:56
That one expedition was the  basis of his entire career.  When you see something named Humboldt, just  to give you a sense of how famous this guy is,  
8:02
it's usually Alexander von Humboldt. It's not like this is some massive,   prosperous German family name that just happens  to be really common. It's this one guy. So really  
8:10
it was like this singular year in which he  conceived a lot of our modern understanding   of botany and selective pressure. Interesting. So that's one out of  
8:17
three components of the evolutionary story. The next piece of the evolutionary story is,   "Is there anything selecting against longevity?" Let's just pretend everything I said was wrong. 
8:25
Can I still make an argument that maybe evolution  hasn't maximally optimized for our longevity? 
8:31
One argument that comes up, and I'll  caveat and say I don't know how strong   some of the mathematical models  that people put together here are. 
8:36
You can find people using the same  idea to argue for and against.  But there's this notion of  what's called kin selection. 
8:41
If you take a selfish gene view of the world‚Äîthat  really this is the genome optimizing for the   genome's propagation, it's not trying to optimize  for any one individual‚Äîthen actually optimizing  
8:51
for longevity is a pretty tricky problem  because you have this nasty regularization term. 
8:57
If you're able to make a member of the  population live longer, but you don't also   counteract the decrease in their fitness over  time‚Äîmeaning you maybe extend maximum lifespan  
9:05
but you haven't totally eliminated aging‚Äîthen  the number of net calories contributed to the   genome as a function of that person's marginal  year and their own calorie consumption is less  
9:14
than if you were to allow that individual  to die and actually have two 20 year olds,   for instance, that follow behind them. So there is a notion by which a population being  
9:23
laden demographically with many aged individuals,  even if they did have fecundity persisting out  
9:28
some period later in life, is actually net  negative for the genome's proliferation   and that really a genome should optimize for  turnover and population size at max fitness. 
9:37
I love this idea of aging as a length regularizer. People might be familiar with the idea that when  
9:44
companies are training models, they'll have a  regularizer for, "You can do chain of thought,   but don't make the chain of thought too long." You're saying how many calories you consume over  
9:52
the course of your life, is one such regularizer?  That's interesting. The third point was... 
10:00
The third piece is basically  optimization constraints.  So this is where another ML analogy is helpful. Well, actually a two-layer neural network is  
10:08
technically a universal approximator, but we can  never actually fit them in such a way. Why does   that occur? People will wave their hands, but it  basically comes down to the fact that we don't  
10:16
really know how to optimize them, even  if you can prove out in a formal sense   that they are universal approximators. I think we have similar optimization  
10:23
challenges with our genome as the parameters  and evolution as the optimization algorithm.  One of those is that your mutation rate  basically bounds the step size you can take. 
10:31
So if you imagine that at each  generation, you get some number of inputs,   you can select for some number of alleles. The max number of variations in the genome  
10:39
is set by your mutation rate. If you dial your mutation rate   up too high, you probably get a bunch  of cancers, so you're selected against. 
10:45
If you have it too low, you  can't really adapt to anything.  You end up with this happy medium,  but that limits your total step size. 
10:50
Then the number of variants  you can screen in parallel is   basically limited by your population size. So for most of evolution, there are lots  
10:56
of forces constraining population size as well. One of the dominant sources of selection on the   genome is really prevention of infectious disease. It seems like when you study the history of early  
11:05
modern man, infectious disease is actually what  shaped a lot of our population demographics.  There's a lot of pressure pushing for those  step sizes, those updates to the genome,  
11:14
really to be optimizing for protection against  infectious disease rather than other things.  Even if you imagine that maybe the arguments  on the first and the second of these possible  
11:25
positive selection being absent for longevity  and potentially some negative selection existing,   you could construct a reasonable argument  for why humans don't live forever and why  
11:33
the genome hasn't optimized for that, simply  based on these optimization constraints.  You have to imagine not only that the  positive selection is there and the  
11:39
negative selection is absent, but that when you  think about the weighted loss term of all the   things the genome is optimizing for, that the  weight on longevity is high enough to matter. 
11:48
Even if you imagine it's there, if you simply  imagine that the lambdas are dialed toward   infectious disease resilience more effectively,  then you can construct an argument for yourself. 
11:56
And so I think really when you start  to ask "why don't we live forever,   why didn't evolution solve this?" you actually  have to think about an incredibly contingent  
12:03
scenario where both the positive selection is  there, the negative selection is absent, and you   have a lot of our evolutionary pressure going  toward longevity to solve this incredibly hard  
12:11
problem in order to construct the counterfactual  in which longevity is selected for and does arise  
12:17
in modern man and in which we are optimal. So I think that puts human aging and longevity   and health really in this category of problems  in which evolution has not optimized for it. 
12:26
Ergo, it should be, relatively speaking,  relative to a problem evolution had worked on,  
12:32
easy to try and intervene and provide health. In many ways, the existence of modern medicines,   which are incredibly simplistic‚Äîwe are targeting  a single gene in the genome and turning it off  
12:41
everywhere at the same time‚Äîthe fact that these  provide massive benefit to individuals is another   sort of positive emission or piece of evidence. Antibiotics are an even more clear case  
Why didn't humans evolve their own antibiotics?
12:50
of that because here's something that  evolution actually cares a lot about.  It feels like antibiotics should be‚Ä¶ Why didn't humans evolve their own antibiotics? 
12:57
Yeah. It's an excellent question that I haven't   heard posed before. Where do antibiotics come  from? To your point, we could synthesize them. 
13:03
They're just metabolites, largely  of other bacteria or other fungi.  You think about the story of penicillin. What  happens? Alexander Fleming finds some fungi  
13:10
growing on a dish. The fungi secrete   this penicillin antibiotic compound. So there's no bacteria growing near the fungi. 
13:16
He says he has this light bulb moment  of, "Oh my gosh, they're probably   making something that kills bacteria." There's no prima facie reason that you  
13:22
couldn't imagine encoding an antibiotic  cassette into a mammalian genome.  Part of the challenge that you run into is  that you're always in evolutionary competition. 
13:30
There's this notion of what's  called the Red Queen hypothesis.  It's an allusion to the story in Lewis  Carroll's Through the Looking Glass,  
13:36
where the Red Queen is running  really fast just to stay in place.  When you look at pathogen-host interactions or  competition between bacteria and fungi that are  
13:44
all trying to compete for the same niche, what  you find is they're evolving very rapidly in   competition with one another. It's an arms  race. Every time a bacteria evolves a new  
13:51
evasion mechanism, the fungus that occupies  the niche will evolve some new antibiotic.  Part of why there is this competitiveness  between the two is they both have very  
14:00
large population sizes in terms of number of  genomes per unit resource they're consuming.  There are trillions of bacteria in a  drop of water that you might pick up. 
14:08
There's trillions of copies of the genome. Massive  analog parallel computation. And at the same time,  
14:13
they can tolerate really high mutation rates  because they're prokaryotic. They don't have   multiple cells. If one cell manages to mutate too  much and it isn't viable, or it grows too fast,  
14:24
it doesn't really compromise the  population and the whole genome.  Whereas for metazoans like you and I, if  even one of our cells has too many mutations,  
14:30
it might turn into a cancer and  eventually kill off the organism.  What I'm getting at, and this is a long-winded  way of getting there, is that bacteria and other  
14:38
types of microorganisms are very well adapted to  building these complex metabolic cascades that are  
14:44
necessary to make something like antibiotics. It's necessary to maintain that same mutation  
14:50
rate and population size in order  to maintain the competition.  Even if our human genome stumbled into making  an antibiotic, most pathogens probably would  
14:57
have mutated around it pretty quickly. That should imply that through evolutionary  
15:04
history there are millions of "naive  antibiotics" which could have acted as  
15:10
antibiotics, but now, basically, all  the bacteria have evolved around it.  Do we see evidence of these historical  antibiotics that some fungi came up  
15:19
with and the bacteria revolved around and  there's evidence for remnants in their DNA?  I'm going a bit beyond my own knowledge  here, but my strong hypothesis would be yes. 
15:28
I can't point to direct evidence today. There are some examples of this.  For instance, bacteria that fight  off viruses that infect them,  
15:35
bacteriophages, have things like CRISPR systems. You can actually go and look at the spacers,   the individual guide sequences that tell  the CRISPR system, "Which genome do you  
15:44
go? Where do you cut?" And you find some  of these guides that are very ancient.  It seems like this bacterial genome  might not have encountered that  
15:50
particular pathogen for quite a while. So you can actually get an evolutionary   history of what the warfare was like, what the  various conflicts were throughout this genomic  
15:58
history just by looking at those sequences. In mammals where I do know a bit better,   we do have examples of this where there  is this co-evolution of pathogen and host. 
16:06
Imagine you have some antipathogen gene A fighting  off some virus X. Well you then actually update.  
16:12
Now you have virus X‚Äô and antipathogen gene A‚Äô. Now virus X‚Äô goes away, but actually virus X  
16:18
still exists and we've lost our ability to fight  it. Those examples really do happen. There's a   prominent one in the human genome. We have a gene called TRIM5alpha. 
16:26
It actually binds an endogenous retrovirus that is  no longer present, but was at one point actually  
16:32
resurrected by a bunch of researchers. It was demonstrated that this is the case.  We have this endogenous gene which basically fits  around the capsid of the virus like a baseball  
16:40
in a glove and prevents it from infecting. It turns out if you look at the evolutionary   history of that gene and you trace it  back through monkeys, you can actually  
16:46
find that a previous iteration inhibited  SIV, which is the cousin of HIV in humans. 
16:52
Old World monkeys actually can't get SIV, whereas  New World monkeys can and humans can, obviously. 
16:58
So it seems like what happened‚Äîand you  can actually make a few mutations in   TRIM5alpha and find that this is true‚Äîis  that TRIM5alpha once protected against an  
17:06
HIV-like pathogen in the primate genomes. And then there was this challenge from   this massive endogenous retrovirus. It was so bad that the genome lost the  
17:15
ability to fight off these HIV-like viruses in  order to restrict this endogenous retrovirus.  You can see it because that  retrovirus integrates into our genome. 
17:22
There are latent copies, like the half bodies  of this virus all throughout our DNA code.  Then this particular retrovirus went extinct. Reasons unknown, no one knows why. 
17:31
But we didn't re-update that piece of our  host defense machinery to fight off HIV again.  So we're in a situation where you can  go in and take human cells and make just  
17:39
a couple edits in that TRIM5alpha gene. It's currently protecting against a virus   which no longer exists. You can edit it back to  
17:45
actually restrict HIV dramatically. So there are plenty of examples.  You could imagine the same thing for  antibiotics where like, "hey, this  
17:51
particular defense mechanism went away because  the pathogen evolved its own defense to it."  Well, the pathogen might have  lost that defense long ago. 
17:58
If you could extract that historical  antibiotic, that historical antifungal,   potentially it actually has efficacy. Isn't the mutation rate per base pair per  
18:06
generation like one in a billion or something? It's quite low.  You're saying that in our genomes we can find  some extended sequence which encodes how to bind  
18:17
specifically to the kind of virus that SIV is. The amount of evolutionary signal you would need  
18:23
in order to have a multiple base pair sequence‚Ä¶  So each nucleotide consecutively would have to  
18:29
mutate in order to finally get the sequence that  binds to SIV. That seems almost implausible.  
18:36
I guess evolution works, so we can come up  with new genes, but how would that even work? 
18:41
A great explanation for understanding a lot of  evolution and how you're able to actually adapt   to new environments, new pathogens, is that gene  duplication is possible. This explains a whole  
18:52
lot. If you look at most genes in the genome,  they actually arise at least at some point in   evolution from a duplication event. That means you've got gene A,  
19:00
it's performing some job, and then some  new environmental concern comes along.  Maybe it's a lack of a particular source of  nutrient, maybe it's a pathogen challenging you. 
19:09
Maybe gene A, if it were to dedicate all  of its energies, so to speak and you were   to mutate it to solve this new problem, could  be adapted with a minimal number of mutations. 
19:17
But then you lose its original function. So we have this nice feature of the genome   which is that it can just copy and paste. So occasionally what will happen in evolution  
19:24
is you get a copy paste event. Now I've got two copies of gene   A and I can preserve my original  function in the original copy. 
19:30
Then this new copy can actually mutate  pretty freely because it doesn't have a   strong selective pressure on it. So most mutations might be null. 
19:36
I've got two copies of the gene, I can  have lots of mutations in it accumulate.  Nothing bad really happens because  I've got my backup copy, my original. 
19:43
So you can end up with drift. You're saying that even though   the per base pair mutation rate might be one in  a billion, if you've got 100 copies of a gene,  
19:50
then the mutation rate on a gene, or on a  low Hamming distance sequence to the one  
19:58
you're aiming for, might actually be quite high,  and you can actually get the target sequence.  It's not that the base rate goes up. It's not like DNA polymerase is more  
20:06
erroneous or that you're just doubling it. That is true, but I don't think   it's the main mechanism. One of the main mechanisms  
20:13
that just makes it difficult for evolution to  solve a problem is if a mutation breaks a gene. 
20:18
Somewhere along the path of edits, imagine  there are three edits that take a host defense   gene from restricting SIV to restricting  this new nasty PT endogenous retrovirus. 
20:28
Well, if one edit just breaks the gene, two edits  just breaks the gene, three edits fixes it, it's  
20:33
really hard for evolution to find a path whereby  you're actually able to make those first two edits   because they're net negative for fitness. So you need some really weird  
20:42
contingent circumstances. Through duplication, you can create a scenario   where those first two edits are totally tolerated. They have no effect on fitness. 
20:49
You've got your backup copy, it's doing its job. Even though the mutation rate is low, some of   these edits actually aren't that large. I'm going to forget the number of edits,  
20:57
for instance in TRIM5alpha, for this  particular phenomenon, but it's in the tens. 
21:02
It's not that you need massive  kilobase scale rearrangements.  It's actually a fairly small number of edits. Basically you can just align the sequence of  
21:11
this gene in New World versus Old World  monkeys and then for humans and you find   there's a very high degree of conservation. Conceptually, is there some phylogenetic  
21:20
tree of gene families where you've got the  transposons and you've got the gene itself,   but then you've got the descendant  genes which are low Hamming distance? 
21:30
Is there some conceptual way  in which they're categorized?  You can arrange genes in the human  genome by homology to one another. 
21:35
What you find is even in our current genome,  even without having the full historical record,   there are many, many genes which are  likely resulting from duplication events. 
21:43
One trivial way that you can check this for  yourself is just go look at the names of genes.  Very often you'll see something  where it's like gene one, gene two,  
21:50
gene three or type one, type two, type three. If you then go look at the sequences,   sometimes those names arise from the fact that  they were discovered in a common pathway and they  
21:58
have nothing to do with each other. A lot of the time it's because the   sequences are actually quite darn similar. Really what probably happened is they evolved  
22:04
through a duplication event and then maybe  did some swapping with some other genes.  And you ended up with these  quite similar, quite homologous  
22:11
genes that now have specialized functions. So when evolution has a new problem to solve,   it doesn't have to start from scratch. It starts from what was the last copy  
22:18
of the parameters for encoding a gene  that is getting close to solving this.  Okay, let's do a copy paste on that and then  iterate and fine-tune on those parameters as  
22:26
opposed to having to start with "ab initio,  some random stretch of sequence somewhere   in the genome has to become a gene." This is fascinating. Back to aging.  
22:36
You‚Äôll have to cancel your evening plans. I've got so many questions for you.  Keep going man. So the second reason you gave was that there's  
22:47
selective pressure against people who get old but  still keep living, but they're slightly less fit. 
22:57
They‚Äôre suboptimal from a calorie input  perspective, the number of calories they can   gather for the population is lower. That's how people love  
23:03
thinking about their grandpas. Suboptimal calorie provider right there. 
23:10
A concern you might have about the effects  of longevity treatments on your own body   is that you will fix some part of the  aging process, but not the whole thing. 
23:20
It seems like you're saying that you actually  think this is the default way in which an  
23:25
anti-aging procedure would work, because that's  the reason evolution didn't optimize for it. 
23:31
We're only fixing half of the aging  process and not the whole thing.  Whereas sometimes I hear longevity proponents  be like, "No, we'll get the whole thing. 
23:40
There's going to be a source that  explains all of aging and we'll get it."  Whereas, your evolutionary argument  for why evolution didn't optimize  
23:47
against aging relies on the fact that aging  actually is not monocausal and evolution  
23:55
didn't bother to just fix one cause of aging. That's correct. I don't think that there is a   single monocausal explanation for aging. I think there are layers of molecular  
24:05
regulation that explain a lot. For instance, I have dedicated   my career now to working on epigenetics  and trying to change which genes cells  
24:11
use because I think that explains a lot of it. But it's not that there is some upstream "bad   gene X" and all we have to do is turn  that off and suddenly aging is solved. 
24:19
The most likely outcome is that when we eventually  develop medicines that prolong health in each of   us, it's not going to fix everything all at once. There's not going to be a singular magic pill. 
24:29
Rather you're going to have medicines that  add multiple healthy years to your life,   years you can't otherwise get back. But it's not going to fix  
24:35
everything at the same time. You are still going to experience, for the   first medicine, some amount of decline over time. This gives you an example, if you think about  
24:44
evolution as a medicine maker in this sort  of anthropomorphic context, of why it might   not have been selected for immediately. So evolution didn't select for aging. What are you  
De-aging cells via epigenetic reprogramming
26:12
doing? What's your approach at NewLimit that you  think is likely to find the true cause of aging? 
26:19
We're working on something called epigenetic  reprogramming, which very broadly is using   genes called transcription factors. I like to think about these as the  
26:25
orchestra conductors of the genome. They don't perform many functions   directly themselves, but they bind specific  pieces of DNA and then they tell which  
26:33
genes to turn on, which genes to turn off. They eventually put chemical marks on top   of DNA, on some proteins that DNA surrounds. This is one of the answers, this particular  
26:41
layer of regulation called the epigenome. It's the answer to this fundamental biological   question of how do all my cells have the same  genome but ultimately do very different things? 
26:49
Your eyeball and your kidney have the same code,  and yet they're performing different functions.  That may sound a little bit simplistic, but  ultimately, it's kind of a profound realization. 
26:57
That epigenetic code is really what's  important for cells to define their functions.  That's what's telling them which  genes to evoke from your genome. 
27:04
What has now become relatively apparent is that  the epigenome can degrade with age. It changes.  
27:10
The particular marks that tell your cells  which genes to use can shift as you get older.  This means that cells aren't able to  use the right genetic programs at the  
27:17
right times to respond to their environment. You're then more susceptible to disease, you have  
27:22
less resilience to many insults  that you might experience.  Our hope is that by remodeling the epigenome back  towards the state it was in when you were young  
27:30
right after development, that you'll be able  to actually address myriad different diseases   whose one of strong contributing factors is  that cells are less functional than when you  
27:38
were at an earlier point in your life. We're going after this by trying to find   combinations of these transcription factors that  are able to actually remodel the epigenome so  
27:47
that they can bind to just the right places in the  DNA and then shift the chemical marks back toward   that state when you are a young individual. If you're just making these broad changes to  
27:57
a cell state through these transcription factors  which have many effects, are there other aspects  
28:03
of a cell state that are likely to get modified at  the same time in a way that would be deleterious. 
28:08
Or would it be a straightforward  effect on cell state?  How I wish it were straightforward. No, it's very  likely. Each of these transcription factors binds  
28:19
hundreds to thousands of places in the genome. One way of thinking about it is if you imagine the   genome as the base components of cell function,  then these transcription factors are kind of like  
28:28
the basis set in linear algebra. It's different combinations and   different weights of each of the genes. Most of them are targeting pretty broad programs. 
28:35
There are no guarantees that aging actually  involves moving perfectly along any of  
28:40
the vectors in this particular basis set. And so it's probably going to be a little   tricky to figure out a combination  that actually takes you backward. 
28:47
There's, again, no guarantees from  evolution that it's just a simple reset.  It's actually a critical part of the process  that we run through as we try to discover these  
28:54
medicinal combinations of transcription factors  we can turn on, ensuring that they not only are  
29:00
making an aged cell revert to a younger state... We measure that a couple different ways.  One is simply measuring which  genes those cells are using. 
29:06
They use different genes as they get older. You can measure that just by sequencing all   of the mRNAs, which are really  the expressed form of the genes  
29:12
being utilized in the genome at a given time. You see that aged cells use different genes.  Can I revert them back to a younger state? Colloquially, we call this a "looks like" assay. 
29:20
Can I make an old cell look like a  young one based on the genes it's using?  More importantly, we go down and  drill to the functional level. 
29:25
We measure, "Can I actually make an aged cell  perform its functions, its object roles within   the body, the same way a young cell would?" These are the really critical things  
29:32
you care about for treating diseases. Can I make a hepatocyte, a liver cell in Greek,   function better in your liver so it's able to  process metabolites like the foods you eat,  
29:40
how it's able to process toxins  like alcohol and caffeine?  Can I make a T cell respond to pathogens and other  antigens that are presented within your body? 
29:48
These are the ways in which we measure age. We need to ensure that not only does the   combination of TFs that we find actually  have positive effects along those axes. 
29:56
But we then want to also measure any  potential detrimental effects that emerge.  There are canonical examples where you  can seemingly reverse the age of a cell,  
30:04
for instance, at the level of a  transcriptome, but simultaneously, you   might be changing that cell's type or identity. Shinya Yamanaka was a scientist who won the Nobel  
30:12
in 2012 for some work he did in about 2007,  where he discovered that you could just take   four transcription factors and actually, just by  turning on these four genes, turn an adult cell  
30:20
all the way back into a young embryonic stem cell. It's a pretty amazing existence proof that shows   that you can reprogram a cell's type and a cell's  age simultaneously, just by turning on four genes. 
30:30
Out of the 20,000 genes in the genome, the  tens of millions of biomolecular interactions,   just four genes is enough. That's a shocking  fact. We actually have known for many years  
30:39
now that you can reprogram the age of a cell. The challenge is that simultaneously, you're doing   a bunch of other stuff, as you alluded to. You're changing its type,  
30:46
and that might be pathological. If you did that in the body, it would probably   cause a type of tumor called a teratoma. So we measure not only at the level  
30:52
of the genes a cell is using. Do you still look like the right type   of cell? Are you still hepatocyte? Are you still a  T cell? If not, that's probably pathological. You  
30:59
can also use that same information to check for  a number of other pathologies that might develop.  Did I make this T cell hyperinflammatory  in a way that would be bad? 
31:07
Did I make this liver cell potentially  neoplastic, proliferate too much even  
31:12
when the organism's healthy and undamaged? You can check for each of those at the level   of gene expression programs  and likewise, functionally. 
31:18
Before you put these molecules in a human, you  actually just functionally check in an animal.  You make an itemized list of the  possible risks you might run into. 
31:24
Here are the ways it might be toxic,  here are the ways it might cause cancer.  Are we able to measure deterministically and  empirically that that doesn't actually occur? 
31:32
This is a dumb question, but it will help me  understand why an AI model is necessary to do  
31:38
any of this work. You mentioned the Yamanaka  factors. From my understanding, the way he  
31:43
identified these four transcription factors was  that he found the 24 transcription factors that  
31:52
have high expression in embryonic cells, and then  he just turned them all on in a somatic cell. 
31:58
Basically, he systematically removed from  this set until he found the minimal set that  
32:04
still induces a cell to become a stem cell. That doesn't require any fancy AI models. 
32:11
Why can't we do the same things for the  transcription factors that are expressed more in  
32:16
younger cells as opposed to older cells, and then  keep eliminating from them until we find the ones   that are necessary to just make a cell young? I wish it were so easy. You're entirely right.  
32:25
Shinya Yamanaka was able to do  this with a relatively small team,   with relatively few resources, and achieve  this remarkable feat. It's entirely worth  
32:33
asking. Why can't a similar procedure work for  arbitrary problems in reprogramming cell state?  Whether it be trying to make an aged cell act like  a young one, a disease cell act like a healthy  
32:42
one, why can't you just take 24 transcription  factors and randomly sort through them?  There were two features of Shinya's  problem that I think make it amenable  
32:49
to that sort of interrogation that aren't  present for many other types of problems.  This is why he's such a remarkable scientist. Most of science is problem selection. 
32:56
You don't actually get better at pipetting  or running experiments after a certain age,   but you do get better at picking what to do.  He's amazing at this. The first feature is that  
33:03
measuring your success criterion is trivial  in the particular case he was investigating.  He's starting with somatic cells that, in this  case, were a type of fibroblast, which literally  
33:12
is defined as cells that stick to glass and  grow in a dish when you grind up a tissue.  It sounds fancy, but it's a very simplistic thing. He's starting with fibroblasts, you can look  
33:20
at them under a microscope, and you can see  they‚Äôre fibroblasts just based on how they look.  Then the cells he's reprogramming  toward are embryonic stem cells. 
33:27
These are tiny cells, they're mostly nucleus. They  grow really fast. They look different, they detach  
33:33
from a dish, they grow up into a 3D structure. They express some genes that will just never be  
33:38
turned on in a fibroblast by definition. How he ran the experiment was he just   set up a simple reporter system. He took a gene that should never be  
33:46
on in a fibroblast, should only be on in  the embryo, and he put a little reporter   behind it so that these cells would actually  turn blue when you dumped a chemical on them. 
33:53
Then he ran this experiment in many, many  dishes with millions upon millions of cells. 
33:58
The second really key feature of the  problem is this notion that those   cells he's converting into amplify. They divide and grow really quickly. 
34:05
In order for you to find a successful  combination, you don't actually   need it to be efficient almost at all. The original efficiency Yamanaka published,  
34:12
the number of cells in the dish that convert from  somatic to an induced pluripotent state, back into   a stem cell, is something like a basis point  or a tenth of a basis point, so 0.01%, 0.001%. 
34:24
If these cells were not growing and  they were not proliferating like mad,   you probably would never be able to detect that  you had actually found anything successful. 
34:32
It's only because success is easy to  measure once you have it and‚Äîeven being   successful in very rare cases, one in a  million‚Äîamplifies and you can detect it,  
34:41
that this was amenable to his particular approach. In practice, what he would do is dump these  
34:46
factors or this group of 24 minus some  number, eventually whittling it down to four.  He would dump these onto a group of cells  and over the course of about 30 days,  
34:55
just a few cells in that dish, like a countable  number on your fingers, would actually reprogram.  But they would proliferate like mad. They form  these big colonies. It's a single cell that  
35:04
just proliferates and forms a bunch of copies of  itself. They form these colonies. You can see with   your eyeballs by holding the dish up to the light  and looking for opaque little dots on the bottom. 
35:13
You don't need any fancy instruments. Then you could stain them with this   particular stain and they would turn blue  based on the genetic reporter he had. 
35:19
We look at those key features of the problem and  we pick any other problem we're interested in.  I'm interested in aging, so that's the  one I'm going to pick for explanation. 
35:26
How difficult is it to measure the  likelihood of success or whether   you've achieved success for cell age? It turns out age is much more complicated  
35:33
in terms of discriminating function than  actually just comparing two types of cells.  An old liver cell and a young liver cell,  prima facie, actually look pretty darn similar. 
35:42
It's actually quite nuanced the  ways in which they're distinct.  There isn't a simple, trivial system where you  just label your one favorite gene or you can just‚Ä¶ 
35:50
Give the young cells cancer. They'll grow. Just make the old ones cancer,   and then they'll grow. Dwarkesh, you've solved it for me. 
35:58
There's no trivial way that you can  tell whether or not you've succeeded.  You actually need a pretty  complex molecular measurement. 
36:03
For us, a real key enabling technology‚ÄîI  don't think our approach would really   have been possible until it emerged‚Äîwas  something called single-cell genomics. 
36:10
You now take a cell, rip it open,  sequence all the mRNAs it's using.  At the level of individual cells, you can actually  measure every gene that they're using at a given  
36:18
time and get this really complete picture  of a cell's state, everything it's doing,   lots of mutual information to other features. From that profile, you can train something  
36:25
like a model that discriminates young and  aged cells with really high performance.  It turns out there's no one gene that  actually has that same characteristic. 
36:33
Unlike in Yamanaka's case, where a single gene  on or off is an amazing binary classifier,   you don't have that same feature of  easy detection of success in aging. 
36:41
The second feature is, as you highlighted,  we can't just turn these into cancer cells.   Success doesn't amplify. In some ways, the bar  for a medicine is higher than what Yamanaka  
36:50
achieved in his laboratory discovery. You can't just have 0.001% success and  
36:55
then wait for the cells to grow a whole bunch in  order to treat a patient's disease or make their   liver younger, make their immune system  younger, make their endothelium younger. 
37:02
You need to actually have it be fairly  efficient across many cells at a time.  Because of this, we don't have the same luxury  Yamanaka did of taking a relatively small  
37:11
number of factors and finding a success case  within there that was pretty low efficiency. 
37:17
We actually need to search a much broader  portion of TF space in order to be successful.  And when you start playing that game,  and you think "How many TFs are there?" 
37:25
Somewhere between 1000 and 2000, it  depends on exactly where you draw the line.  Developmental biologists love to argue about  this over beer, but let's call it 2000 for now. 
37:33
You want to choose some combination. Let's say you guess somewhere between one   and six factors might be required. The number of possible  
37:39
combinations is about 10^16. If you do any math on the back of a napkin,   in order to just screen through all of those, you  would need to do many orders of magnitude more  
37:47
single-cell sequencing than the entire world has  done to date cumulatively across all experiments.  It's just not tractable to do exhaustively. That's where actually having models that  
37:57
can predict the effect of  these interventions comes in.  If I can do a sparse sampling, I can test  a large number of these combinations. 
38:03
I can start to learn the relationship  of what a given transcription factor   is going to do to an aged cell. Is it going to make it look younger? 
38:09
Is it going to preserve the same type? I can learn that across combinations.  I can start to learn their interaction terms. Now I can use those models to actually predict  
38:17
in silico for all the combinations I haven't seen,  which are most likely to give me the state I want.  You can actually treat that as a generative  problem and start sampling and asking which  
38:25
of these combinations is most likely to take my  cell to some target destination in state space.  In our case, I want to take an old  cell to a young state, but you could  
38:32
imagine some arbitrary mappings as well. As you get to these more complex problems,   you don't have the same features that Shinya  benefited from, which were the ability to  
38:40
measure success really easily‚Äîyou can see it  with your bare eyes, you don't even need a   microscope‚Äîand two, amplification, as you  get into these more challenging problems. 
38:47
You're going to need to be able to search a larger  fraction of the space to hit that higher bar.  So we can think of these transcription  factors as these basis directions,  
38:55
and you can get a little bit of this thing, a  little bit of that thing and some combination.  And evolution has designed these  transcription factors to‚Ä¶Is that your claim? 
39:04
They have relatively modular, self-contained  effects that work in predictable ways with  
39:10
other transcription factors and so we  can use that same handle to our own ends? 
39:18
That would be very much my contention. One piece of evidence for this is   that's the way development works. It's a crazy thing to think about,  
39:24
but you and I were both just a single cell. Then we were a bag of undifferentiated cells   that were all exactly alike. Somehow we became humans with  
39:31
hundreds of different cell types  all doing very different things.  When you look at how development  specifies those unique fates of cells,  
39:37
it is through groups of these transcription  factors that each identify a unique type. 
39:42
In many cases, the groups of transcription  factors, the sets that specify very different   fates, are actually pretty similar to one another. Evolution has optimized to just swap one TF in  
39:53
or swap one TF out of a combination  and get pretty different effects.  You have this sort of local change in sequence  or gene set space leading to a pretty large  
40:03
global change in output. Likewise, many of these   TFs are duplicated in the genome. Because mutations are going to be  
40:10
random and they're inherently small changes  at the level of sequence at a given time,   evolution needs a substrate where, in order to  function effectively, these small changes can  
40:19
give you relatively large changes in phenotype. Otherwise it would just take a very long time  
40:25
across evolutionary history for enough  mutations to accumulate in some duplicated   copy of the gene for you to evolve a  new TF that does something interesting. 
40:32
I think we're actually in most cases in  biology‚Äîdue to that evolution constraint,   small edits need to lead to meaningful phenotypic  changes‚Äîin a relatively favorable regime for  
40:42
generic, gradient-like optimizers. It would be a little bit overstating   to say evolution is using the  gradient, but there is a system. 
40:51
If you've heard of evolution strategies, where  basically the way you optimize parameters   is you can't take a gradient on your loss. So you make a bunch of copies of your parameters,  
40:58
you randomly modify them, and then you compute  a gradient on your parameters against your loss,   and so you can take a gradient in that space. That's how I imagine evolution is working. 
41:06
So you need lots of those little edits to actually  lead you to have meaningful step sizes in terms of  
41:11
the ultimate output that you have. Interesting. You're just like   designing a little LoRA that goes on top. In a way. Maybe this is getting too  
41:23
giga-brained about it, but why does the  genome even have transcription factors?   What's the point? Why not just have it so every  time you want a new cell type, you engineer some  
41:31
new cassette of genes or some new, totally de  novo set of promoters or something like this? 
41:36
One possible explanation for their existence,  rather than just an appreciation for their  
41:41
presence, is that having transcription  factors allows a very small number of  
41:47
base pair edits at the substrate of the genome  to lead to very large phenotypic differences.  If I break a transcription factor, I can  delete a whole cell type in the body. 
41:55
If I retarget a transcription factor  to different genes, I can dramatically   change when cells respond and have hundreds  of their downstream effector genes change  
42:03
their behavior in response to the environment. It puts you in this regime where transcription   factors are a really nice substrate to  manipulate as targets for medicines. 
42:11
In some ways they might be evolution's levers  upon the broader architecture of the genome. 
42:16
By pulling on those same levers that evolution  has gifted us, there are probably many useful   things we can engender upon biology. You're sort of hinting that if we  
42:26
analogize it to some code base, we're  going to find a couple of lines that   are commented out that's like, "de-aging,"  and then "un-hyphen" or "un-parenthesize." 
42:34
I don't know about that, but I can give you a  real cringe analogy that sometimes I deploy.  It requires a very special audience. I think you'll probably be one who fits into it. 
42:41
You're flattering our listeners. "Only  cringe listeners will appreciate it,   but your audience will love this." I don't know about your audience, but you will. 
42:51
You can think about it like this. If you think about how attention works‚Äîqueries,   keys, values‚ÄîTFs are like the queries. The genome sequences they bind to are like  
43:00
the keys. Genes are like the values. It turns  out that that structure then allows you to very  
43:06
efficiently, in terms of editing space, change  just one of those embedding vectors, in this case   one of those sequences, and get dramatically  different performances or total outputs. 
43:15
So I do think it's interesting how these  structures recur throughout biology,   in the same way that the attention mechanism  seems to exist in some neural structures. 
43:24
It's interesting that you can very easily  see how that same sort of querying and  
43:29
information storage might exist in the genome. Interesting. A previous guest and a mutual friend,   Trenton Bricken, had a paper in grad school  about how the brain implements attention. 
43:39
Eddie Chang has found positional encodings  probably exist in humans using neuropixels,   if you haven't read these papers. He implants these neuropixel probes  
43:46
into individuals and then he's able to talk  to them, look at them as they read sentences.  What he finds is that there seem to be  certain representations which function  
43:53
as a positional encoding across sentences. They fire at a certain frequency and it just   increases as the sentence goes on and then resets. It seems exactly like what we do when  
44:03
we train large language models. It's so funny the way we're going   to learn how the brain works is just trying to  first-principles engineer intelligence in AI. 
44:11
Then it just happens to be the case that each  one of these things has a neural correlate. 
Viral vectors and other delivery mechanisms
45:24
If you're right that transcription factors are  the modality evolution has used to have complex  
45:31
phenotypic effects, optimize for different  things... Two-part question. One, why haven't  
45:37
pathogens, which have a strong interest in  having complex phenotypic effects on your body,  
45:43
also utilized the transcription factors as the  way to fuck you over and steal your resources? 
45:52
Two, we've been trying to  design drugs for centuries.  Why aren't all the big drugs, the  top-selling drugs, ones that just  
46:02
modulate transcription factors? Why don't we have a million of these pills?  I'll try and take those in stride. They're pretty  different answers. The first answer is that there  
46:09
are pathogens that utilize transcription  factors as part of their life cycle.  A famous example of this is HIV. HIV encodes a protein called Tat,  
46:17
and Tat actually activates NF-Œ∫B. HIV, to back up a little bit, is a retrovirus. 
46:22
It starts out as RNA, turns itself into DNA,  shoves itself into the genome of your CD4+ T cells 
46:28
It needs this ornate machinery to  actually control when it makes more   HIV and when it goes latent so it can hide  and your immune system can't clear it out. 
46:36
This is why HIV is so pernicious. You can kill every single cell in the body that's   actively making HIV with a really good drug. But then a few of them that have lingered  
46:45
and hunkered down just turn back on. People call this the latent reservoir.  Similar to Hep B, right? Hep B, Hep C, can both  
46:51
do this sort of latent behavior. HIV is probably the most pernicious of these. 
46:57
One way it does it is that this gene  called Tat actually interacts with NF-Œ∫B.  NF-Œ∫B is a master transcription  factor within immune cells. 
47:04
Typically if I'm going to horribly reduce  what it does, and some immunologists can   crucify me later, it increases the  inflammatory response of most cells. 
47:12
They become more likely to attack given  pathogens around them on the margin.  It'll turn on NF-Œ∫B activity and then  use that to drive its own transcription  
47:21
and its own life cycle. I can't remember quite   all the details now exactly of how it works. But part of this circuitry is what allows it  
47:28
to‚Äîin some subset of cells where some of that  upstream transcription factor machinery in the   host might be deactivated‚Äîit goes latent. As long as the population of cells it's  
47:37
infecting always has a few that are turning  off the transcription factors upstream that   drive its own transcription, then HIV is  able to persist in this latent reservoir  
47:45
within human cells. It's just one example  offhand. There are a number of other pathogens.  Unfortunately, I don't have quite as  much molecular detail in some of these. 
47:52
But they will interface with other parts of the  cell that eventually result in transcription  
47:57
factor translocation to the nucleus and  then transcription factors being active.  This actually segues a little  bit to your second question on  
48:04
why there aren‚Äôt more medicines targeting TFs. In a way many of our medicines, ultimately  
48:09
downstream, are leading to changes in TF activity,  but we haven't been able to directly target them  
48:15
due to their physical location within cells. So we go several layers upstream.  If you think about how a cell works in sensing its  environment, it has many receptors on the surface. 
48:23
It has the ability to sense mechanical  tension and things like this.  Ultimately, most of what these signaling pathways  lead to is to tell the cell, "Use some different  
48:31
genes than you're using right now." That's  often what's occurring. That ultimately leads   to transcription factors being some of the  final effectors in these signaling cascades. 
48:39
A lot of the drugs we have that, for instance,  inhibit a particular cytokine that might bind a   receptor, or they block that receptor directly,  or maybe they hit a certain signaling pathway‚Ä¶  
48:49
Ultimately, the way that they're exerting  their effect is then downstream of that   signaling pathway, some transcription factor  is either being turned on or not turned on. 
48:56
You're using different genes in the cell. We're kind of taking these crazy bank shots   because we can't hit the TFs directly. That sort of begs the question,  
49:04
"Why can't you just go after the TF directly?" Traditionally, we use what are called small   molecule drugs, where they're  defined just by their size. 
49:10
The reason they have to be small is they  need to be small enough to wiggle through   the membrane of a cell and get inside. Then you run into a challenge. 
49:16
If you want to actually stick a small molecule  between two proteins that have a pretty big   interface‚Äîmeaning they've got big swaths on  the side of them that all sort of line up and  
49:26
form a synapse with one another‚Äîthen you would  need a big molecule in order to inhibit that.  It turns out that TF's binding  DNA is a pretty darn big surface. 
49:35
Small molecules aren't great at disrupting  that and certainly even worse at activating it.  Small molecules can get all  the way into the nucleus,  
49:41
but they can't do much once they're there.  They're just too small. The other classic   modalities we have are recombinant proteins. We make a protein like a hormone in a big vat. 
49:49
We grow it in some Chinese hamster ovary  cells, we extract it, we inject it into you.  This is how, for instance, human  insulin works that we make today. 
49:56
Or you make antibodies  produced by the immune system.  These run around and find proteins that  have a particular sequence, they bind to it,  
50:02
and often they just stop it from working  by glomming a big thing onto the side.  Those are too big to get  through the cell membrane. 
50:08
Then they can't actually get to  a TF or do anything directly.  So we take these bank shots. What changes that today, and why  
50:14
I think it's pretty exciting, is we now have new  nucleic acid and genetic medicines where you can,   for instance, deliver RNAs to a cell that can get  through using tricks like lipid nanoparticles. 
50:23
You wrap them in a fat bubble. It looks kind of like a cell membrane.  It can fuse with a cell, and  put the mRNAs in the cytosol. 
50:28
You can make a copy of a  transcription factor there,   and then it translocates to the nucleus the same  way a natural one would and exerts its effect. 
50:34
Likewise, there are other ways to do  this using things like viral vectors,   but we've only very recently actually gotten the  tools we need to start addressing transcription  
50:42
factors as first-class targets rather  than treating them as maybe some ancillary   third-order thing that's going to happen. Interesting. So the drugs we have can't  
50:51
target them, but your claim is that a lot  of drugs actually do work by binding to   the things we actually can target and those  have some effect on transcription factors. 
51:01
This brings us to questions about delivery,  which is the next thing I want to ask you.   You mentioned lipid nanoparticles. This  is what the COVID vaccines were made of. 
51:09
The ultimate question if we're going to work on  de-aging‚Ä¶ Even if you identify what is the right  
51:17
transcription factor to de-age a cell, and even  if they're shared across cell types, or you figure  
51:22
out the right one for every single cell type, how  do you get it to every single cell in the body? 
51:30
How do you deliver stuff?  How do you get them in there?  There are many ways one could imagine solving it. I'll narrow the scope of the problem. 
51:37
Delivering nucleic acid is a  pretty good first-order primitive.  Ultimately, the genome is nucleic acids, the  RNAs that come out of it are nucleic acids. 
51:44
If you can get nucleic acid into  a cell, you can drug pretty much   anything in the genome effectively. You can reduce this problem to asking,  
51:50
"How do I get nucleic acids wherever I want  them to any cell type very specifically?"  Today, there are two main modalities that  people use, both of which have some downsides. 
51:59
The first one that we've touched on already  is lipid nanoparticles. These are basically   fat bubbles. By default, they get taken up  by tissues which take up fat, like the liver. 
52:08
They can be used like trojan horses. They can release some arbitrary nucleic   acid‚Äîusually RNA, maybe encoding your  favorite genes, in our case, transcription  
52:15
factors‚Äîinto the cell types of interest. You can play with the fats, and you can   also tie stuff onto the outside of the fat. You can attach part of an antibody, for example,  
52:22
to make it go to different cell types in the body. The field is making a lot of progress on being  
52:27
able to target various different  cell types with lipid nanoparticles.  Even if nothing else worked for the next  several decades, companies like ours would  
52:36
have more than enough problems to solve  with the cells that we can actually target.  Another prominent way people go  after this is using viral vectors. 
52:42
The basic idea being viruses  had a lot of evolutionary   history and very large population sizes. They've evolved to get into our cells. 
52:48
Maybe we can learn something from  them, even better than Trojan horses.  One type of virus people use a lot is called an  AAV. Those AAVs carry DNA genomes. You can get  
52:58
genes, whole genes, into cells. They've  got some packaging sizes. You can think   of it like a very small delivery truck, so  you can't put everything you want into it. 
53:04
They can go to certain cell types as well. On top of just where you actually get the   nucleic acid to begin with, you can  engineer the sequences a bit, and that  
53:11
basically allows you to add a NOT gate on it. You can make it turn off the nucleic acid in  
53:17
certain cell types, but you're never  going to use the sequence engineering   to get nucleic acid into cells where it  didn't get delivered in the first place. 
53:23
You can start broad with your delivery vector  and then use sequence to narrow down to make it   more specific, but not the other way around. Both of those methods are super promising. 
53:33
If nothing else emerged for decades, we'd  still have tons and tons of problems as a   therapeutic development community  to solve, even using just those. 
53:40
I have one very controversial opinion  which people can roast me for later.  You have just one? You're trying to  solve aging and you have only one? 
53:48
I have many controversial opinions. One of  them is that both of these probably in the   limit will not be the way that we're  delivering medicines in the year 2100. 
53:57
If you think about viral vectors, no matter what,   they're always going to be  some amount of immunogenic.  You're always going to have your  immune system trying to fight them off. 
54:04
You can play tricks, you can try and cloak  them, etc., but they're always going to have   some toxicity risk. They also don't go everywhere.  It's not that we have examples of a single viral  
54:12
species that infects every cell type in the body  and we just need to engineer it to make it safe.  We would have to also engineer the virus  to go to new cell types. There's some  
54:20
limitations there. LNPs likewise have some  problems. They can go to tons of cell types.  That's largely what we're working on.  We're super excited about it. But there  
54:27
are some physical constraints. They just have a certain size.  They have to get from your bloodstream out of  your bloodstream toward a given target cell,  
54:34
and they have to not fuse into any  of the other cells along the way.  There's a whole gamut they have to run. Ultimately, we're probably going to have  
54:41
to solve delivery the way that  our own genome solved delivery.  We have the same problem  that arose during evolution. 
54:47
How do I patrol the body, find  arbitrary signals in the environment,   and then deliver some important cargo  there when some set of events happens? 
54:55
How do I find a specific place and only  near those cell types release my cargo? 
55:01
The problem was solved by the immune system. We have cell types in our body,   T cells and B cells, which are effectively  engineered by evolution to run around,  
55:10
invaginate whatever tissues they need to. They can climb almost anywhere in the body.  There's nowhere they can't get access to, almost. Once they sense a particular set of signals‚Äîand  
55:18
they've got a very ornate circuitry to  do this, they run basically an AND gate   logic‚Äîthey can release a specified payload. Right now, the way our genome sets them up,  
55:27
the payload they release is largely either  enzymes that will kill some cell that they're  
55:32
targeting or kill some pathogen, or some signal  flares that call in other parts of the immune   system to do the same thing. So that's super  cool. But you can think about it as a modular  
55:40
system that evolution's already gifted us. We've got some signal and environmental   recognition systems so we can find particular  areas of the body that we want to find. 
55:48
Then we have some sort of payload delivery system. I can deliver some arbitrary set of things.  I imagine if we were to Rip Van Winkle  ourselves into 2100 and wake up,  
55:57
the way we will be delivering these nucleic acid  payloads is actually by engineering cells to do   it, to perform this very ornate function. Those cells might actually live with you. 
56:05
You probably will get engrafted with them, and  they might persist with you for many years.  They deliver the medicine only  when the environment within your  
56:12
body actually dictates that you need it. You actually won't be seeing a physician   every time this medicine is active. Rather, you'll have a more ornate,  
56:19
responsive circuit. The other exciting thing about cells   is that they're big and they have big genomes. You actually have a large palette to encode  
56:27
complex infrastructure and complex circuitry. You don't need to limit yourself to the very small   RNAs you can get in that might encode a gene or  two, or in our case, a few transcription factors. 
56:36
You don't have to limit yourself to this  tiny AAV genome that's only a few kilobases.  You've got billions of base pairs to play  with in terms of encoding all your logic. 
56:44
So I think that's ultimately  how delivery will get solved.  We've got many, many stepping  stones along the way.  But if I could clone myself and work on an even  riskier endeavor, that's probably what I would do. 
56:54
In a way, we treat cancer this  way with CAR-T therapy, right?  We take the T cells out and then we tell them to  go find a cancer with this receptor and kill it. 
57:04
Is the reason that works that the cancer  cells we're trying to target are also free   floating in the blood? Is that what it  targets? Basically, could this deliver to  
57:13
literally every single cell in the body? Not literally every single cell. I'll   asterisk it there. For example,  T cells don't go into your brain. 
57:21
They can, but it's generally a  pathology when they get in there.  It's not literally every cell, but  almost every cell in your body is  
57:27
surveilled by the immune system. There are very, very few what we   call immune-privileged compartments in your body. It's things like the joints of your knees and your  
57:35
shoulders, your eyeball, and your brain. There might be a couple of others.  The ear probably falls into that category. A funny way of thinking about this is that all  
57:42
the gene-therapy people using viruses, they want  to deliver to the immune-privileged compartments   because their drugs are immunogenic, and they're  limited to a very, very small set of diseases. 
57:51
In a way, it's like the shadow of all the  diseases you can't address with viruses   is what you can address with cells. Given the complementarity between them,  
57:58
you can probably cover the entire body.  They can't literally go everywhere. But your   analogy to the CAR-T work is very apt as well. You can think about that two-component system. 
58:07
I've got some detection mechanism for  the environment I want to sense to   perform some function, and then I have  some sort of payload that I deliver. 
58:15
CAR-Ts engineer the first of those and leave the  second exactly the same as the immune system does.  They engineer‚Äîgo recognize this other  antigen that you wouldn't usually target,  
58:23
some protein on the surface of a cell, for  instance‚Äîand then deliver the payload you would   usually deliver if it was infected by a virus  or if you saw that it was foreign in some way. 
58:31
Whereas cancer cells usually  don't actually look that foreign.  Most of their genes are the same genes that are  in your normal genome, and that's why it's hard  
58:37
for the immune system to surveil it. Interesting. Interesting. It's funny   that whenever we're trying to cure infectious  diseases, we just have to deal with, "Fuck,  
58:44
viruses have been evolving for billions of years  with our oldest common ancestor, and they know  
58:49
exactly what they're doing, and it's so hard." Then whenever we're trying to do something else,   we're like, "Fuck, the immune system has been  evolving for billions of years, and it knows  
58:58
what it's doing, and how do we get past it?" The Red Queen race is quite sophisticated. 
59:03
If you want to just throw a new  tool into biology, you somehow have   to get around one side of that equation. Given the fact that it's somewhere between  
59:12
impossible and very far away but it's necessary  for full curing of aging, does that mean that in  
59:22
the short run, in the next few decades, we'll  have some parts of our body which will have  
59:27
these amazing therapies, and then other parts  which will just be stuck the way they are? 
59:33
You mentioned hepatocytes are some of the  cells that you're able to actually study in   or deliver to. These are our liver cells. So  you're saying, "Look, I can get drunk as much  
59:43
as I want and it's not going to have an impact on  my long-run liver health because then you'll just   inject me with this therapy." But for the rest of my body,  
59:50
it's going to age as normal? What is the implication of the   fact that the delivery seems to be lagging  much behind your understanding of aging? 
1:00:01
Just to give the delivery folks  credit, they're currently ahead.  There are currently no reprogramming  medicines for aging, and there are  
1:00:06
medicines that deliver nucleic acids. They're still winning the race against   us right now, but to your point, I hope the  lines cross. I hope we outcompete them. Even  
1:00:16
if you were able to only target some subsets of  cells, it's not that you would see this strange,  
1:00:21
Frankensteinian benefit in health in some  aspects and lack of benefit entirely in others. 
1:00:27
What we've found across the history  of medicine is that the body's an   incredibly interconnected, complex system. If you're able to rescue function even in  
1:00:36
one cell type in one tissue, you often  have knock-on benefits in many places   that you didn't initially anticipate. One way we can get examples of this  
1:00:44
is through transplant experiments. Both in bone marrow and in liver,   for example, we have fairly common  transplant procedures that occur in humans. 
1:00:54
We can compare old humans who get livers  from young people or old people and ask a   pretty controlled question. What occurs as a function  
1:01:01
of just having a young liver? Is it that, for example, you can eat a   lot of fatty food and drink a lot and be fine? Or is it that you see broader benefits? 
1:01:09
The latter seems to be true. They have reduced risk of   several other diseases and overall better  survival as a function of having a younger  
1:01:16
liver than they do for an older one. Suggesting that because these tissues   are so interconnected, many of  these organs like the liver,  
1:01:22
like your adipose tissue, are endocrine organs. They're also sending out signals to many other   places in your body, helping coordinate  your health across multiple tissue systems. 
1:01:30
Even just one tissue can benefit other tissue  systems in your body at the same time. HSCs are  
1:01:36
another example. These are mostly examples taken  from a wonderful book by Frederick Appelbaum,  
1:01:44
who trained with Don Thomas, the physician  who invented human bone marrow transplants. 
1:01:49
There are many circumstances where patients  got a bone marrow transplant and actually   cured another disease they had as a result,  maybe unanticipated, where it's even just the  
1:01:58
replacement of this one special cell type, HSCs,  that has knock-on effects throughout the body.  There were symptoms of these diseases that  presented in myriad ways throughout their  
1:02:06
system, but ultimately, its root  cause was even just a single cell.  There are counterexamples as well where you  can go into animals and break even just one  
1:02:14
gene in one specific subset of T cells. You can break a gene in there that encodes   for a transcription factor in their  mitochondria called TFAM, and you  
1:02:22
dramatically shorten the lifespan of mice. One gene in one special type of T cells  
1:02:27
can give you that type of pathology. So it implies the inverse may also exist.  Is this related to why Ozempic has so  many downstream positive effects that  
1:02:35
seem even not totally related to its  effects just on making you leaner? 
1:02:42
I think it's one example. It is a hormone,  and your endocrine system coordinates a lot  
1:02:48
of the complex interplay between your tissues. I don't think the story is fully written yet  
1:02:53
on exactly why GLP-1 and GIP-1, broadly  incretin mimetic medicines like Ozempic,  
1:02:59
have so many knock-on benefits, but  they're a great example of this phenomenon.  If someone told you, "I'm going to find a  single molecule, and I'm going to drug it,  
1:03:06
and it's not only going to have benefits for  weight loss but also for cardiovascular disease,   also possibly for addictive behavior, and  maybe even preventing neurodegeneration,"  
1:03:14
you would have told them they were crazy. Yet, just by acting on the small number of   cells in your body which are receiving this  signal, the interplay and the communication  
1:03:22
between those cells and the rest of your body  seems to have many of these knock-on benefits.  It's just one existence proof that  very small numbers of cells in your  
1:03:29
body can have health benefits everywhere. Even if cellular delivery does not emerge by 2100,  
1:03:34
as I imagine it will, I still think that  you're going to have the ability to add   decades of healthy life to individuals  by reprogramming the age of individual  
1:03:43
cell types and individual tissues. How big will the payload have to be?  How many transcription factors? I  think it's just a countable number. 
1:03:50
Some of those that we've found today that have  efficacy are somewhere between one and five. 
1:03:56
That's a small enough number that you can  encapsulate it in current mRNA medicines.  Already in the clinic today, there are medicines  that deliver many different genes as RNA. 
1:04:05
There are medicines where, for instance, it's  a vaccine as a combination of flu and COVID   proteins, and they're delivering 20 different  unique transcripts all at the same time. 
1:04:14
When you think about that already as a  medicine that's being injected into people   in trials, the idea of delivering just a few  transcription factors is seemingly quotidian. 
1:04:22
Thankfully, I don't think we'll be limited by  the size of the payloads that one can deliver. 
1:04:27
One other really cool thing about transcription  factors is that the endogenous biology is   very favorable for drug development. The expression level of transcription  
1:04:36
factors in your genome relative  to other genes is incredibly low.  If you just look at the rank-ordered list of what  are the most frequently expressed genes in the  
1:04:45
genome by the count of how many mRNAs are in the  cell, transcription factors are near the bottom.  That means you don't actually need to get  that many copies of a transcription factor  
1:04:53
into a cell in order to have benefits. What we've seen so far, and what I   imagine will continue to play out, is that  even fairly low doses of these medicines,  
1:05:02
which are well within the realm of what folks  have been taking for more than a decade. 
1:05:07
They are able to induce really strong efficacy. We're hopeful that not only will the actual size  
1:05:13
of the payload in terms of number  of base pairs not be limiting,   but the dose shouldn't be limiting either. Would it have to be a chronic treatment,  
1:05:19
or could it just be a one-time dose? In principle, it could be one time.  I think that would be an overstatement for today. I can talk you through the evidence from the  
1:05:28
first principles back to the reality of  what's the hardest thing we have in hand.  Epigenetic reprogramming is basically how the  cell types in our bodies right now are able  
1:05:36
to adopt the identities that they have. The existence proof that those epigenetic   reprogramming events can last decades is that my  tongue doesn't spontaneously turn into a kidney. 
1:05:45
These epigenetic marks can persist for  decades throughout a human life, or hundreds   of years if you want to take the example of a  bowhead whale which uses the same mechanism. 
1:05:56
We also know that with very targeted edits,  other groups have done this, folks like Luke   Gilbert now at the Arc Institute, who I think of  as one of the great unsung scientists of our time,  
1:06:05
have been able to make a targeted edit in  a single locus and then show that you can   actually make cells divide 400-plus times over  multiple years in an incubator in the lab. 
1:06:14
Imagine a hothouse where you're just trying  as hard as you can to break this mark down,   and it can actually persist for many years. Other companies have actually now dosed  
1:06:23
some editors similar to the ones that  Luke developed in his lab in monkeys   and shown they last at least a couple of years. In principle, the upper bound here is really long. 
1:06:31
You could potentially have one dose and it  lasts a very long time, potentially decades, as   long as it took you to age the first time maybe. We don't have data like that today. I don't want  
1:06:39
to overstate. We do have data that these positive  effects can last several weeks after a dose. 
1:06:46
You could imagine, even without many leaps  of faith up toward this upper bound limit   of what's possible just from the data we have in  hand now, that you could get doses every month,  
1:06:55
every few months and actually have really  dramatic benefits that persist over time,   rather than needing to get an IV every  day, which might not be tractable. 
Synthetic transcription factors
1:07:03
We've got 1600 transcription  factors in the human genome.  Is it worth looking at non-human TFs  and seeing what effects they might have,  
1:07:10
or are they unlikely to be the right search space? I think it's less likely. I think you have a prior  
1:07:17
that evolution has given you a reasonable  basis set for navigating the states that   human cells might want to occupy. In our case, we know that the state  
1:07:25
we're trying to access is encoded  by some combination of these TFs.  It does arise in development obviously. We're trying to make an old cell look young,  
1:07:32
not look like some Frankenstein  cell that's never been seen before.  That said, we don't have any guarantees that the  way aging progresses is by following the same  
1:07:40
basis set of these transcription factor programs  in the genome that are encoded during development. 
1:07:45
I don't think it's unreasonable to ask, "Would  your eventual ideal reprogramming medicine   necessarily be a composition of the natural TFs,  or would it include something like TFs from other  
1:07:55
organisms, as you posit, or even entirely  synthetic transcription factors as well?"   Things like Super-SOX. Super-SOX is  a particular publication from Sergiy  
1:08:05
Velychko where they mutated the SOX2 gene and  they made more efficient iPSC reprogramming. 
1:08:11
They could take somatic cells and turn them  into pluripotent stem cells more effectively   than you could with just the canonical Yamanaka  factors, which are Oct-4, Sox2, KLF4, and Myc. 
1:08:22
iPSC reprogramming never happens in nature,  so there's no reason to necessarily believe   that the natural TFs are optimal. So even really simple optimizations,  
1:08:30
like just mutagenizing one of the four  Yamanaka factors we already know about   or swapping some domains between a few  TFs, seem to improve things dramatically. 
1:08:37
I think that's a pretty good signal that  actually there's a lot of gradient to climb   here and that potentially for us, the end-state  products we're developing in 2100 are more like  
1:08:47
synthetic genes that have never existed, rather  than just compositions of the natural set.  What about the effects of aging? Your skin starts to sag because of the  
1:08:57
effects of gravity over the course of decades? Is  that a cellular process? How would some cellular  
1:09:02
therapy deal with that? The best evidence is   that it's probably not cellular. The reason your skin sags is there's a protein   in your skin called elastin, which does exactly  what you'd think it would based on the name. 
1:09:11
It kind of keeps your skin elastic-y, like  a waistband, and holds it to your face.  You have these big polymerized  fibers of elastin in your face. 
1:09:18
As far as we understand it, you only polymerize  it and form a long fiber during development.  Then the rest of your life, you make  the individual units of the polymer,  
1:09:26
but for reasons no one as far as I can  tell understands, they fail to polymerize.  You can't make new long cords to  hold your skin up to your face. 
1:09:34
So the eventual solution for something like  that is likely that you need to program cells   to states that are extra-physiological. There might not be a cell in your body. 
1:09:42
It's not just like a young skin cell from a  20-year-old is better at making these fibers.  As far as we can tell, they don't. But you could probably program a cell to  
1:09:50
be able to reinvigorate that polymerization  process, to run along the fiber and repair   it in places where it's damaged. Obviously these things get made  
1:09:58
during development, so it's totally  physically feasible for this to occur.  Maybe there's even a developmental  state which would be sufficient to  
1:10:04
achieve this. I don't think anyone knows. But  that would be the kind of state that one might   have to engineer de novo, even if our genome  doesn't necessarily encode for it explicitly. 
1:10:12
Interesting. Okay, what is Eroom's Law? Eroom's Law is a funny portmanteau created  
Can virtual cells break Eroom's Law?
1:10:18
by a friend of mine, Jack Scannell. He inverted the notion of Moore's Law,   which is the doubling of compute density  on silicon chips every few years. 
1:10:27
Moore's Law has graciously given  us massive increases in compute   performance over several decades. Eroom's Law is the inverse of that. 
1:10:34
In biopharma, what we're actually seeing  is that there's a very consistent decrease   in the number of new molecular entities,  new medicines that we're able to invent,  
1:10:41
per billion dollars invested. This trend actually starts way   back in the 1950s and persists through many  different technological transitions along the way. 
1:10:49
It seems to be an incredibly consistent  feature of trying to make new medicines. 
1:10:54
In a weird way, Eroom's Law is actually  very similar to the scaling laws you   have in ML, where you have this very  consistent logarithmic relationship. 
1:11:03
You throw in more inputs and you get  consistently diminishing outputs.  The difference, of course, is that this trend  in ML has been used to raise exponentially more  
1:11:15
investment and to drive more hype towards AI. Whereas in biotech, modulo NewLimit's new round,  
1:11:22
it has driven down valuations,  driven down excitement and energy.  With AI at least you can internalize the extra  cost and the extra benefits because there's  
1:11:31
this general purpose model you're training. This year you spend $100 million training   a model, next year $1 billion,  the year after that, $10 billion. 
1:11:36
But it's one general purpose model, unlike, "We  made money on this drug and now we're going to   use that money to invest in 10 different  drugs in 10 different bespoke ways." 
1:11:44
I was gearing up to ask you, what would a general  purpose platform‚Äîwhere even if you had diminishing  
1:11:50
returns, at least you can have this less bespoke  way of designing drugs‚Äîlook like for biotech? 
1:11:55
I'm going to slightly dodge your question  first to maybe analyze something really   interesting that you highlighted. You have these two phenomena:  
1:12:01
ML scaling and then scaling in terms  of the cost for new drug discovery.  Why is it that the patterns of  investment have been so different? 
1:12:08
There are probably two key features  that might explain this difference.  One is that the returns to the scaled  output in the case of ML actually are  
1:12:15
expected to increase super exponentially. If you actually reach AGI, it's going to be a much  
1:12:20
larger value than just even a few logs back on  the performance curve that people are following. 
1:12:25
Whereas in the life sciences thus  far, each of those products we're   generating further and further out on the  Eroom's Law curve as time moves forward,  
1:12:32
haven't necessarily scaled in their potential  revenue and their potential returns quite so much.  You're seeing these increased costs  not counterbalanced by increased ROI. 
1:12:40
The other piece of it that you highlighted is  that it‚Äôs unlike building a general model where   potentially by making larger investments, you can  be able to solve a broader addressable market,  
1:12:49
moving from solving very narrow  tasks to eventually replacing large   fractions of white collar intelligence. In biotech, when you're traditionally  
1:12:56
able to develop a medicine in a given  indication‚Äî"I was able to treat disease   X"‚Äîit doesn't necessarily engender you to be  able to then treat "disease Y" more readily. 
1:13:05
Typically where these biotech firms in general  have been able to develop unique expertise is on   making molecules to target particular genes,  so "I'm really good at making a molecule  
1:13:13
that intervenes on gene X or gene Y." It turns out that the ability to make   those molecules more rapidly isn't actually  reducing the largest risk in the process. 
1:13:22
This means that the ability to go from  one or two outputs one year to then   four the next is much more limited. This brings us then to the question  
1:13:29
of what the general model would be in biology. I think it reduces down to how do you actually  
1:13:35
imbue those two properties that create the ML  scaling law curve of hope and bring those over  
1:13:41
to biology so that you can take the Eroom's  law curve and potentially give it the same   sort of potential beneficial spin. There are a few different versions  
1:13:49
of this you could imagine. But I'll address the first point.  How do you get to a place where you're  actually able to generate more revenue per  
1:13:55
medicine so that potentially the outputs  you're generating are more valuable,   even if each output might cost a bit more? Traditionally, when we've developed medicines,  
1:14:03
we go after fairly narrow indications, meaning  diseases that fairly small numbers of people get. 
1:14:09
That's actually increased, in terms of the  narrow scope of what medicines are addressing,   as we've gone forward in time. This is sort of an ironic situation  
1:14:17
where we've gone from addressing pretty broad  categories of disease, like infectious disease,   to narrower and narrower genetically-defined  diseases that have small patient populations. 
1:14:25
Because these only affect a few people‚Äîif you  think about the value function of a medicine as   how many years of healthy life it gives how many  people‚Äîif the "how many people" is pretty small,  
1:14:33
it just really bounds the amount  of value you're able to generate.  You need to then be able to find  medicines that treat most people. 
1:14:39
All of us will one day get sick and die. So arguably, the TAM for any really successful   medicine could be everybody on planet Earth. We need to find a way to be able to route  
1:14:48
toward medicines that address  these very large populations.  The second piece then is, how do we  actually build models that enable us  
1:14:55
to take the success in one medicine we've  developed and lead that to an increased   probability of success on the next medicine? Traditionally, we haven't been able to do that. 
1:15:03
Maybe you're better at making an antibody for gene  Y because you made one for gene X five years ago.  But it turns out making an antibody isn't  really the hard part of drug discovery. 
1:15:11
Figuring out what to make an antibody to  target is the hard thing about drug discovery.  What gene do I intervene upon in order to  actually treat a disease in a given patient? 
1:15:19
Most of the time, we just don't know. That's why even if a given drug firm   becomes very good at making antibodies to  gene X and they have a successful approval,  
1:15:27
when they then go to treat disease Y they  don't necessarily know what gene to go after.  Most of the risk is not in how to make an antibody  to treat my particular target, it's in figuring  
1:15:36
out what to target in the first place. I'm not sure how to understand this  
1:15:41
claim that we know how to engage with  the right hook, we just don't know  
1:15:49
what that hook is supposed to do in the body. I don't know if that's the way you describe it.  Another claim that I've seen is that with small  molecules we have this Goldilocks problem. 
1:15:57
They have to be small enough to percolate  through the body and through cell walls,   etc., but big enough to interfere  with protein-protein interactions that  
1:16:07
transcription factors might have. There it seems like getting the   hook is the big problem. In this particular case,  
1:16:14
if we bound ourselves to, "We must use small  molecules as our modality," then there are lots   of targets which are very difficult to drug. There are many other modalities by which you  
1:16:22
can drug some of these genes. I would say‚ÄìI don't have formal   way of explaining this‚Äìif you were to write  out a list of well-known targets that many,  
1:16:30
many folks would agree are the correct genes to  go after and to try and inhibit or activate in   order to treat a given set of diseases‚Äîand  the only reason we don't have medicines is  
1:16:39
that we can't figure out a trick in order to  be able to drug them‚Äîit's a fairly small list.  It would probably fit on a single page. Whereas the number of possible indications  
1:16:46
that one could go after, and the number  of possible genes that one could intervene   upon especially when you consider  their combinations, is astronomical. 
1:16:54
The experiment you could run here is if you  lock 10 really smart drug developers in a room.  You tell them to write down some incredibly  high-conviction target disease pairs where  
1:17:03
they're sure if they modulate this biology,  these patients are going to benefit.  All they need is some molecular hook, as  you put it, in order to do this. It's a  
1:17:11
relatively short list. What you're not going  to get is anything approximating the panoply   of human pathologies that develop. You can actually look for this. 
1:17:18
There are some existence proofs you  can look for out in the universe.  If the only problem was that we didn't have  the ability to drug something using current  
1:17:26
therapeutics that we can put in humans, we  should still be able to treat it in the best   animal models of that disease because we  can use things like transgenic systems. 
1:17:34
You can go in and you can engineer  the genome of that animal.  This gives you all sorts of superpowers that  you don't have in patients, but allow you to,  
1:17:40
for instance, turn on arbitrarily complex groups  of genes in arbitrarily specific or broad groups  
1:17:45
of cells in the organism, at any time you  want, at any dose you want in the animal.  For the majority of pathologies, we  just don't have many of those examples. 
1:17:55
What is the answer to what is the general purpose  thing where every marginal discovery increases the  
1:18:01
odds you make the next discovery? There are multiple ways one might   approach this problem. The most common today,  
1:18:08
this is often what people are describing  when they talk about a virtual cell.  This is a very nebulous idea, sometimes numinous,  if you'll let me describe it in that way as well. 
1:18:18
Concretely, what most people are trying  to do is measure some number of molecules,   or perceived emissions like the morphology of  a cell, and then perturb it many times, turn  
1:18:28
some genes on, turn some genes off, and measure  how that molecular morphological state changes. 
1:18:33
The notion is that there's a lot  of mutual information in biology.  If I measure something, most commonly all the  genes the cell is using at a given moment,  
1:18:40
which you can get by RNA sequencing,  I get a decent enough picture of   most of the other complexity going on. I can take a bunch of healthy cells and a bunch  
1:18:50
of cells that are in a diseased or aged state. I'm able then to compare those profiles and say,   "Okay, my diseased cells use these  genes, my healthy cells use these. 
1:18:58
Are there any interventions that I'm  able to experimentally find in the   lab that shift one toward the other?" The hope would be that, because you're  
1:19:05
never going to be able to scan combinatorially all  the possible groups of genes to make it concrete. 
1:19:10
There's something like 20,000 genes in the genome. You can then choose however many  
1:19:15
genes in your combination you want. It's not crazy to think of hundreds at a time.   That's what transcription factors control. That's  how development works. So the number of possible  
1:19:22
combinations is truly astronomical. You just can't test it all.  The hope would be that by doing some sparse  sampling of those pairs‚Äîwhat your inputs are,  
1:19:29
here's what the cell looked like  beforehand, here's the particular   genes I perturbed‚Äîyou have some measurement  then of the state that the cell resulted in. 
1:19:36
Here's which genes went  up, here's which went down.  Once I've trained a model to predict from  the perturbations to the output on the cell  
1:19:44
state, you can start to ask what would happen  for some arbitrary combinations of genes.  Now in silico I can search all possible  things that one might do and potentially  
1:19:51
discover targets that take my diseased  cells back to something like healthy cells.  So that's another version  of what an all-encompassing  
1:19:58
model would look like where you actually  have compounding returns in drug discovery.  You basically described one of the models  you guys are working on at NewLimit. 
1:20:07
You're training this model based  on this data where you're taking   the entire transcriptome and just labeling  it based on how old that cell actually is. 
1:20:17
If you've got all this data you're collecting  on how different perturbations are having   different phenotypic effects on a  cell, why only record whether that  
1:20:29
effect correlates with more or less aging? Why can't you also label it with all the other  
1:20:36
effects that we might eventually care about  and eventually get the full virtual cell? 
1:20:41
That's a more general purpose model, not just the  one that predicts whether a cell looks old or not. 
1:20:48
Absolutely, we actually do both today. We can train these models where the inputs  
1:20:54
are a notion of what that cell looked like at  the starting place, here's what a generic old   cell looked like, and then representations  of the transcription factors themselves. 
1:21:02
We derive those from protein foundation models. They're language models trained   on protein sequences. It turns out that gives you a  
1:21:08
really good base level understanding of biology. The model's starting from a pretty smart place. 
1:21:13
Then you can predict a number of different targets  from some learned embedding, the same way you   could have multiple heads on a language model. One of those for us is actually just predicting  
1:21:21
every gene the cell is expressing. Can I just recapitulate the entire state   and guess what effect these transcription  factors will have on every given gene? 
1:21:28
You can think about that as an objective  rather than a value judgment on the cell.  I'm not asking whether or not I  want this particular transcriptome. 
1:21:35
I'm just asking what it will look like. Then we also have something more like   value judgments. I believe that that  
1:21:42
transcriptome looks like a younger cell. I'm going to select on that and train ahead   to predict it where I can denoise across  genes and then select for younger cells. 
1:21:49
But you could do that for arbitrary  numbers of additional heads.  What are some other states you might want? Do I want to polarize T cells to a less  
1:21:56
inflammatory state in somebody  with an autoimmune disease?  Do I want to make liver cells more functional  in a patient who's suffering from certain  
1:22:03
types of metabolic syndrome, maybe even  orthogonal to the way that they age?  Do I want to go in and change the way a neuron  is functioning to a different state to treat a  
1:22:10
particular type of neurodegenerative disease? These are all questions you can ask.  They're not the ones we're going after, but  that is the more general, broader vision. 
1:22:16
This is so similar to, in LLMs, you first have  imitation learning with pre-training that builds  
1:22:23
a general-purpose representation of the world. Then you do RL about a particular objective in  
1:22:31
math or coding or whatever that you care about. You are describing an extremely similar   procedure where first you just learn  to predict perturbations in genes to  
1:22:43
broad effects on the cell. That's the pre-training,   just learning how cells work. Then there's another afterward  
1:22:52
layer of these value judgments of, "How would  we have to perturb it to have effect X?" 
1:22:58
That actually seems very similar to "How  do we get the base model to answer this   math problem or answer this coding problem?" I don't know if people usually put it this way,  
1:23:08
but it actually just seems extremely similar. That makes me more optimistic on this. LLMs   work and RL works. Yeah, they do. I  
1:23:16
think the conceptual analogy is very apt. We don't actually use RL at the moment,   so I don't want to overstate the  level of sophistication we've got. 
1:23:22
But I think the general problem  reduces down in a similar way.  You can think about your earlier  question of what does the general  
1:23:28
model look like that enables you to actually  have compounding returns in drug discovery.  You might have something like this base model,  which as you said, just predicts this object  
1:23:36
function of, "How are these perturbations  hitting these targets going to change which   genes are turned on and off in this cell?" Then there's an entirely other task, which is,  
1:23:44
well, which genes do you want to turn on and off? What state do I want the cell to adopt?  Our lens on that is that across many  different diseases people have, age is  
1:23:54
one of the strongest predictors of how they're  going to progress, whether that disease arises.  In many, many circumstances you have  evidence in humans where you can say,  
1:24:02
"Ah, if I could make the cell younger, maybe  that's not a perfect fix, but that's going to   dramatically benefit not only patients who have a  diagnosed disease, but it might actually help most  
1:24:09
of us stay healthier longer, even subclinically  before anyone would formally say that we're sick." 
1:24:15
Now that's another more general function. The same way that in LLMs, you might have   to create these particular RLHF environments,  you need to have places where you can state a  
1:24:24
value function of the particular task  that you're trying to optimize for.  In drug discovery, you would then need  to know, "Well, what are the cell states  
1:24:31
I want to engineer for?" That's kind of the next   generation of what a target might be. Beyond just which genes do I want to move  
1:24:36
up and down, and which gene perturbations  do I put in, you then need to know what   cell state am I engineering for? What do I want this T cell to do? 
1:24:41
You‚Äôll have a bunch of labelers in Nigeria  clicking different pictures of cells.  Like, "Oh, this one looks  young. This one looks old." 
1:24:47
"This one looks really great. I love that  one." Potentially. Potentially. It's more   like developmental biologists locked in a  room, as my friend Cole Trapnell would say. 
1:24:55
It seems like what you're describing  seems quite similar to Perturb-seq.  I don't know when it was done, what year was it? There were three papers almost  
1:25:04
simultaneously in 2016. Okay, so almost a decade.   We're still waiting, I guess, for the  big breakthroughs it's supposed to cause. 
1:25:12
This is the same procedure, so why  is this going to have an effect?  Why has this taken so long? Good  question. The original procedure  
1:25:21
was created by a bunch of brilliant folks. There was a group in Ido Amit's lab at the   Weizmann Institute, Aviv Regev's lab at the Broad,  where Atray Dixit, a friend of mine, helped work  
1:25:29
on this, and then Jonathan Weissman's lab at UCSF,  where Britt Adamson did a lot of the early work.  They all constructed this idea  where you can go in and you label a  
1:25:37
perturbation that you're delivering to a cell. This is typically a transgenic perturbation,   meaning you're integrating some  new gene into the genome of a cell. 
1:25:44
That turns another gene on or off. They used CRISPR, but there's lots of   ways to do it and the concept's pretty general. Then you attach on that new transgene, that new  
1:25:52
gene you put into the genome of the cell, some  barcode that you can read out by DNA sequencing.  Now when you rip the cells open, you're able  to not only measure every gene they're using,  
1:26:00
but you also sequence these barcodes, and you  know which genes you turned on and which are off.  You can then start to ask questions like,  "Well, I've turned on genes A, B, and C,  
1:26:06
what did it do to the rest of the cell?" That's the general premise of the technology.  It's useful to just set that up because it  explains why this didn't all happen earlier. 
1:26:14
The actual readout, ripping the cells open  and sequencing them, used to be pretty bad   and it used to be really expensive. It's gotten much better over time. 
1:26:21
The metric people often think about  here is like cost per cell to sequence.  It used to be measured in dollars  and now it's measured in cents,  
1:26:27
and down to the fractions of cents, because  that cost curve has improved dramatically. 
1:26:33
The cost of sequencing has likewise come down. So even beyond the actual reagents necessary to   rip the cell open and turn its mRNAs into  DNAs that are ready for the sequencer,  
1:26:40
now the sequencer is cheaper. The other piece is, actually getting   these genes in and then figuring out which  ones are there, it started out pretty bad. 
1:26:48
When we started with this technology,  it was a beautiful proof of concept,   but I don't think anyone would tell  you it was 100% ready for prime time. 
1:26:54
When you sequenced a cell, only  about 50% of the time could you   even tell which perturbation you put in. Sometimes you just wouldn't detect the barcode  
1:27:01
and you'd have to throw the cell away. Or you detect the wrong barcode and   now you've mislabeled your data point. This might sound like a trivial sort of  
1:27:08
technical piece, but imagine you're running  this experiment the old-fashioned way.  You test different groups of genes  in different test tubes on a bench. 
1:27:14
Now imagine you hired someone who  every other tube labels it wrong.  When you then collect data from your experiment,  you basically have no idea what happened,  
1:27:22
because you've just randomized all  your data labels. You wouldn't do much   science. You wouldn't get very far that way. A lot of those technologies have improved to  
1:27:29
the point where you had a number of processes  which are pretty inefficient and you multiplied   a lot of these things together and ended  up with a very small outcome of successful  
1:27:37
cells you could actually sequence. They've all improved to the degree   where now you can actually operate at scale. Groups like ours have had to do a bunch of  
1:27:44
work in order to actually enable combinatorial  perturbations, turning on more than just one gene   at a time, which it turns out is much, much harder  for the same reason we were just alluding to. 
1:27:52
Imagine you're having trouble figuring  out which one gene you put in this cell   and turned on or off. Now imagine you have to  
1:27:57
do that five times correctly in a row. Well, if you start out with the original   performance where you could detect roughly 50%  of them, then the fraction of cells that would  
1:28:06
be correctly labeled is like 1/2^n, where n is  the number of genes you're trying to detect.  Very quickly more of your data  is mislabeled than is labeled. 
1:28:14
There's lots of technical reasons like  this that have gotten worked out over time.  Only now are we really able to scale up where  we're able to run experiments that are in the  
1:28:22
millions of cells in just a single day at,  for instance, a small company like NewLimit. 
1:28:27
There was a point even just six or seven  years ago where the companies that made   these reagents were publishing the very  first million-cell data set just as a  
1:28:35
proof of concept and only they could do  it as the constructors of the technology.  Now two scientists in our labs  can generate that in an afternoon. 
1:28:42
If it actually is the case that this is  very similar to the way LLM dynamics work,  
1:28:52
then once this technology is mature and you  get the GPT-3 equivalent of the virtual cell,  
1:28:58
what you would expect to happen is you get  many different companies, at least a couple,   that are doing these cheap, Perturb-seq-like  experiments and building their own virtual cells. 
1:29:11
Then they're leasing this out to other people  who then have their own ideas about, "We want  
1:29:17
to see if we can come up with the labels for this  particular thing we care about and test for that." 
1:29:24
What it seems like is happening right now  is, at least at NewLimit, you are like,   "We know the end use case we're going after." It would be as if Cursor in 2018 was like, "We're  
1:29:35
going to build our own LLM from scratch so that  we can enable our application," rather than some  
1:29:40
foundation model company being like, "We don't  care what you use it for, we're going to build   this." Does that make sense? It seems like you're  combining two different layers of the stack. 
1:29:50
Because nobody else is doing the other  layer, you're just doing both of them.  I don't know to what extent this analogy maps on. To play with the analogy a bit, imagine that  
1:30:00
you think about NewLimit as an LLM company. If I'm going to put us in the shoes of Cursor,   which oh I so wish, imagine we're  trying to, in 2018, create Cursor Tab,  
1:30:09
but we're not trying to create a full LLM. I don't know enough about the underlying   mechanics to know if that would have been  feasible, but it's a much more feasible problem  
1:30:17
than trying to create the most recent Cursor agent  or compete with modern Claude Code. That's roughly  
1:30:22
the equivalent. The problem we're breaking off is  a subset of the more general virtual cell problem. 
1:30:29
We're trying to predict, "What do  groups of transcription factors do   to the age of very specific types of cells?" We only work on a few cell types at NewLimit  
1:30:37
because those are some of the only cell types  today with which we believe we can get really   effective delivery of medicines. We think they're just more  
1:30:45
important because we can act on them today. If we solve the problem of what TFs to use,   we can make a medicine pretty quickly. In a way, we're carving out a region of  
1:30:52
this massive parameter space and saying, "If we  can learn the distribution of effects even just   in this small region, it's going to be really  effective for us, and we can make really amazing  
1:31:01
products, unlike the world has ever seen." Over time, we can expand to the corpus  
1:31:06
of predicting every possible gene  perturbation in every possible cell type.  I think that's maybe the way the  analogy maps on, but it is true that  
1:31:13
we are vertically integrating here. We're generating our own data in a   way that's proprietary. We think we have a much,  
1:31:18
much larger data set for this particular  regime than the rest of the world combined.  That enables us to build what  we think are the best models. 
1:31:25
In many cases, what we found is that unlike  with LLMs, where a lot of the data that was  
1:31:30
necessary to build these was a common good‚Äîit was  produced as a function of the internet and shared  
1:31:35
across everyone, it's pretty common across all  the domains everyone wants to use it for‚Äîthis   biological data is still in its infancy. Imagine we're in the early 1980s and we  
1:31:46
are just now thinking about trying to create some  of the first web pages. That's the era we're in.  
1:31:51
We're going after and generating some of our own  data in this very niche circumstance, building   the very high-quality corpus, the Wikipedia that  you might train your overly analogized- LLM on,  
1:32:02
and then building the first products based  on that and then expanding from there.  We think that's necessary  because of where we are today. 
1:32:08
There isn't this Internet-like equivalent of data  that everyone can go out and reap rewards from.  Interesting. This is more a question about the  broader pharma industry rather than just NewLimit. 
Economic models for pharma
1:32:19
In the future, how are people going to make money? With the GLPs, we've got peptides from China that  
1:32:28
are just a gray market that  people can easily consume.  Presumably, with these future AI models,  even if you have a patent on a molecule,  
1:32:36
finding an isomorphic molecule or an  isomorphic treatment is relatively easy.  If you do come up with these crazy treatments and  if pharma in general is able to come up with these  
1:32:44
crazy treatments, will they be able to make money? The gray market piece, I'll put aside and say  
1:32:50
that‚Äôs IP enforcement at a geostrategic  level that I'm not qualified to speak to. 
1:32:57
It comes down to IP enforcement effectively. For that gray market piece, another reason that  
1:33:04
the traditional pharmaceutical industry will still  continue to reap the majority of rewards here is   that most of the payment in the United States,  which provides most of the revenue for drug  
1:33:14
discovery in the world, goes through a payment  system that is not just direct-to-consumer. It   goes through payers. If you have the opportunity  to either order a sketchy vial off of some website  
1:33:24
from some company in Shenzhen, or you can go  through your doctor and get a prescription  
1:33:29
with a relatively low co-pay for Tirzepatide, the  real thing, most patients will go for Tirzepatide. 
1:33:35
You and I probably live in a milieu of people who  are much more comfortable with ordering the vials   from Shenzhen than most people might be. I don't consider that to be a tremendous  
1:33:43
concern writ large. The broader point is,   if you have medicines with very long-term  durability, how do you reimburse them? 
1:33:52
If the benefits are very long term and accrue  in the out-years‚Ä¶ A challenge we have in  
1:33:58
the US system is that the average person  churns insurers every three to four years.  That number fluctuates around, but  that's the right order of magnitude. 
1:34:05
That means that if you had a medicine  which dramatically reduced the cost   of all other healthcare incidents, but it  happened exactly five years after you got  
1:34:12
dosed with it, no insurer is technically  economically incentivized to cover that.  I think there are a couple of  models here that can make sense. 
1:34:20
One is something called pay-for-performance where,  rather than reimbursing all of the cost of the  
1:34:26
drug upfront, you reimburse it over time. Say you get a medicine that just makes you  
1:34:31
generically healthier and you can measure the  reduced rates of heart attack and reduced rates   of obesity and various other things, and you  get this one dose and it lasts for 10 years. 
1:34:40
Each year you would pay something like a tenth  of the cost of the medicine contingent on the   idea that it was actually still working for  you and you had some way of measuring that. 
1:34:47
That's a big challenge in this industry. How would you demonstrate that any one of   these medicines is still working for the patient? In the few examples we have today, these are  
1:34:55
things like gene therapies where you can just  measure the expression of the gene and it‚Äôs like,   "Okay, the drug is still there." It gets more complicated when you  
1:35:02
have some of these longer-term net benefits. The idea would be that then each insurer is   incentivized to just pay for the time  of coverage that you're on their plan. 
1:35:10
We already have a framework for this  post-Affordable Care Act in the US where   pre-existing conditions no longer really exist. Patients are able to freely move between payers,  
1:35:19
and you could sort of treat the presence  of one of these therapeutics lowering   this patient's overall healthcare costs the  same way we treat a pre-existing condition. 
1:35:28
This is something that the system  is still overall figuring out.  What I'm saying here is one hypothesis  about what the future might look like,  
1:35:34
but there are alternative clever approaches  people might think about for reimbursement.  I think over time we're going to move  more toward a direct-to-consumer model  
1:35:43
for many of these medicines which preserve and  promote health rather than just fixing disease.  You're seeing what are really some of the  most innovative examples of this right now  
1:35:51
from Lilly around the incretin mimetics,  where they actually launched LillyDirect.  For the first time, rather than going to  a pharmacy, which interacts with a PBM,  
1:35:58
which interacts with your primary care physician‚Ä¶  You can get a prescription from your doctor,   go straight to Lilly, the source of the good  stuff, and you're able to order high-quality  
1:36:06
drugs from them, and not involve some  intermediary compounder in the middle that   might not even make your molecules properly. As these medicines develop that have actual  
1:36:16
consumer demand‚Äîbecause you feel it in your daily  life and you're actually seeing a benefit from it,   it's not just something that your  physician is trying to get you to  
1:36:23
take‚Äîthat model will start to dominate. That means that this payment over time for   some of these long-term benefits might be able  to be abstracted away from our current payer  
1:36:33
system where it churns every few years. A payment-over-time plan, the same way we  
1:36:38
finance other large purchases  in life, seems very feasible.  The reason I'm interested in this is  that healthcare is already 20% of GDP. 
1:36:46
It's grown notable percentages  in the last few years. 
1:36:52
This is a fraction that is quickly growing. The overwhelming majority of this is going  
1:37:02
towards administering treatments  that have already been invented.  That‚Äôs good, but nowhere near as good as  spending this enormous sum of resources  
1:37:13
towards coming up with new treatments that  in the future will improve the lives of   people that will have these ailments. One question is just how do we make it  
1:37:23
so that more‚Ä¶ If we're going to spend 20%  of GDP on healthcare, it should at least go   towards coming up with new treatments rather  than just paying nurses and doctors to keep  
1:37:32
administering stuff that kind of works now. Two, if the cost of drugs, at least from the  
1:37:40
perspective of the payer, ends up being,  you need a doctor to give you some scan  
1:37:45
before he can write you a prescription and  then they need to administer it and they  
1:37:51
need to make sure that you're doing okay,  etc‚Ä¶ Even if for you to manufacture this  
1:37:58
therapy it might cost tens of dollars per patient,  for the healthcare system overall, it might be  
1:38:05
tens of thousands of dollars per patient. I'm curious if you agree with those   orders of magnitude. I think that's correct. I  
1:38:10
think the stat is something like drugs  are roughly 7% of healthcare spend.  I could be a little bit wrong  on that, but the OOM is right. 
1:38:17
Basically, even if we invent de-aging technology,  or especially if we invent de-aging technology,   how should we think about the way  it will net out in the fraction  
1:38:25
of GDP that we have to spend on healthcare? Will that increase because everybody's lining   up at the doctor's office to get a prescription  and you gotta go into the clinic every week? 
1:38:34
Or will that decrease because the other downstream  ailments from aging aren't coming about?  I think the latter is much more  likely to be the case. Here are some  
1:38:42
quick heuristics. There are many reasons  that healthcare costs so much in the US.  One of them is something like Baumol's  cost disease, which is very unrelated to  
1:38:51
pharmaceutical discoveries but is something  that we will have to solve in the system.  Part of it's the disintermediation of the  actual customer and the actual provider. 
1:39:00
These are things that biotech probably isn't  going to be able to solve as an industry alone.  That's probably a larger economic problem. But when you think about how this will affect  
1:39:10
the total amount of healthcare  that will need to be delivered.  If you have more of these medicines for everyone,  medicines that keep you healthier longer rather  
1:39:18
than medicines that only fix a problem once you're  already very sick, I think you actually avoid  
1:39:23
a lot of the types of administration costs. It‚Äôs not just administration like admins at   hospitals, but the cost of administering existing  medicines and therapies to you. That‚Äôs going down.  
1:39:32
One stat on why I think that's true. Something like a third of all Medicare costs are   spent in the final year of life, which is shocking  when you realize that the average person on  
1:39:40
Medicare is probably a decade-plus covered by it. There's an incredible concentration of the actual  
1:39:47
expenses once someone is already terribly sick. Helping prevent you from ever having to access  
1:39:53
the intensive healthcare system, something like  an inpatient hospital visit, if you can prevent   even just a couple of those visits over a long  period of someone's life with a medicine like  
1:40:02
an incretin mimetic, like a reprogramming medicine  that keeps your liver, your immune system younger,   on net that actually starts to drive healthcare  spend down because you're shifting some of  
1:40:11
that burden from the administration  system to the pharmaceutical system.  The pharmaceutical system is  the only piece of healthcare  
1:40:17
where technology has made us more efficient. As drugs go generic, the cost of administering  
1:40:22
a given unit of healthcare is going down. The grand social contract is   that they eventually go generic. That's the way our current IP system works. 
1:40:30
So if you were to get the question of, "When would  you like to be born as a patient?" you always want   to be born as close to today as possible. Because for a given unit in terms of  
1:40:38
pharmaceuticals, for a given dollar unit of  expense, you can access more pharmaceutical   technology today than has ever been possible  in history, even as healthcare costs  
1:40:48
everywhere else in the system have shot up. Pharmaceuticals are the one place where,   because of the mechanism of things going  generic and the fact that our old medicines  
1:40:55
continue to work and persist over time,  you're able to get more benefit per dollar. 
1:41:01
Okay, final question. Pharma is spending billions  of dollars per new drug it comes up with. 
1:41:08
Surely they have noticed that the lack  of some general platform or some general   model has made it more and more expensive  and difficult to come up with new drugs. 
1:41:16
You say Perturb-seq has existed since 2016. As far as you can tell, you have the most  
1:41:21
amount of that kind of data which would  feed into a general-purpose model. 
1:41:27
What is the traditional pharma  industry on the other coast up to? 
1:41:33
If I went to the head of R&D at  Eli Lilly or Pfizer or something,   do they think that this is like they have some  different idea of the platform that needs to  
1:41:42
be built or they're like, "No, we're all in  on the bespoke game, bespoke for each drug?" 
1:41:47
I'll just correct one thing to  make sure I'm not overstating.  We have way more data for the limited  subproblem we're tackling, which is  
1:41:53
overexpressing TFs in combinations. We have way more data than anyone,   full stop, there. But even more specifically, I feel very,  
1:42:00
very confident we have more data than anyone  looking at trying to reprogram a cell's age.  That's where we're way larger  than the rest of the world. 
1:42:07
When we think about just general single-cell  perturbation data of various flavors,  
1:42:12
there are other groups which have  very large data sets as well.  We're still differentiated because we  do everything in human cells with the  
1:42:18
right number of chromosomes, whereas it's very  common to do things in cancer cell lines which   have 200 chromosomes. Is that human? I don't know.  Depends on how you actually quantify these things. 
1:42:27
So then, if you‚Äôre going to go ask the leaders  of some of the traditional pharmaceutical firms,   "Are you trying to build a general model?" I think some of them have in-house AI  
1:42:35
innovation teams that are working on this. There are really smart people there.  But as a general trend, you  can think about some of the  
1:42:42
modern pharmas a bit like venture capital firms. They've over time externalized a lot of their R&D. 
1:42:49
They often have divisions of external  innovation, which you can think of as   the corp dev version of venture capital. They work with the biotech ecosystem to  
1:42:57
have a number of smaller, nimble firms explore  really pioneer ideas, the types of things we're  
1:43:04
working on, and then eventually partner with them  once they have assets that are later downstream. 
1:43:09
The industry has sort of bifurcated  where smaller biotechs like ours   take on most of the early discovery. I'm going to get it a little bit wrong  
1:43:17
from memory, but it's something like 70% of  molecules approved in a given year come from   originally small biotechs rather than large  pharmas, even though you look at the actual  
1:43:24
dollars of R&D spend on the balance  sheet and it's largely in big pharma.  Another level of disintermediation. Part of the reason for that difference in  
1:43:34
cost is they're running most of the trials. Most people partner with pharma to run   trials where a lot of the costs are incurred. It's not just that all large pharmas are horribly  
1:43:41
inefficient or anything like that. Some of them would tell you,   "These ideas are really exciting. We have an external innovation department, if we  
1:43:49
don't have one internally, or we're collaborating  with a startup that's doing something similar."  You can think of the market structure like you  have a bunch of biotechs, which are the startups  
1:43:58
in your ecosystem, and then they're working  with something like an oligopsony of pharmas.  It's a limited number of buyers for  this particular type of product,  
1:44:06
which is a therapeutic asset that is  ready for a phase one, phase two trial.  There's a very liquid market for the phase  one, phase two assets, and that's the point at  
1:44:13
which these partnerships can come to fruition. That's what a lot of those leaders would say. 
1:44:19
By contrast, for instance, Roche  bought Genentech back in 2013.  R&D is currently run by Aviv Regev, one of  the scientists I admire most in the world,  
1:44:26
who's like a thousand times smarter than me. She's one of the people who invented this   technology and has a big group  doing this sort of work there. 
1:44:33
So it's not like every pharma takes  that view, but that's a general trend.  Full disclosure, I am a small  angel investor in NewLimit now,  
1:44:42
but that did not influence the decision to have  Jacob on. This is super fascinating. Thanks so   much for coming on the podcast. Awesome. Thanks, Dwarkesh.