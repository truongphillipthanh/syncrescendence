https://www.youtube.com/watch?v=v8WAV_y5iIQ
10 Papers Every Future AI Engineer Must Read
51,552 views  Oct 15, 2025  ‚ú™ Members first on October 15, 2025  3 products
Marina Wyss - AI & Machine Learning tagged products below. Learn more

Activation Functions T-Shirt (White) 5XL
$24.99
gratitudedriven.myshopify.com/products/unisex-classic-tee-2?variant=47304279851250&country=US&currency=USD&utm_medium=product_sync&utm_source=google&utm_content=sag_organic&utm_campaign=sag_organic&srsltid=AfmBOorgtWULoCJWRc99x5tYfRKFpWT-cwL9Ki9ayQN4Xz7h1vbOReZXxVE
 

Activation Functions T-Shirt (Black) 5XL
$24.99
gratitudedriven.myshopify.com/products/activation-functions-t-shirt-black?variant=47304293187826&country=US&currency=USD&utm_medium=product_sync&utm_source=google&utm_content=sag_organic&utm_campaign=sag_organic&srsltid=AfmBOopO6azqlPujpIhIyZ0TY8QN74DSLWPfjdnYrSajCZTsPTG5ANEPXvg
 

Activation Functions Mug
$17.99
gratitudedriven.myshopify.com/products/activation-functions-mug?variant=47304271233266&country=US&currency=USD&utm_medium=product_sync&utm_source=google&utm_content=sag_organic&utm_campaign=sag_organic&srsltid=AfmBOoohGS7WvVY4zArjJESo1EuQb9bRZ3_Bu8cTfrcD4ssT6hTC5QvofII
FREE Agentic AI Webinar: https://learn.interviewkickstart.com/...

Free resources:
FREE Salary Analyser (Know your worth): https://interviewkickstart.com/ai-sal...
FREE Resume Analyser: https://ikiq.interviewkickstart.com/r...

‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
Timestamps ‚è∞
00:00 The top 10 papers to understand AI engineering 
00:46 Paper #1 https://arxiv.org/pdf/1706.03762
01:37 Paper #2 https://arxiv.org/pdf/2005.14165
02:40 Paper #3 https://arxiv.org/pdf/2203.02155
04:17 Paper #4 https://arxiv.org/pdf/2106.09685
05:17 Paper #5 https://arxiv.org/pdf/2005.11401
06:19 Paper #6 https://arxiv.org/pdf/2309.07864
07:16 Paper #7 https://arxiv.org/pdf/2101.03961
08:12 Paper #8 https://arxiv.org/pdf/1910.01108
08:50 Paper #9 https://arxiv.org/pdf/2208.07339
09:54 ‚ÄúPaper‚Äù #10 https://www.anthropic.com/news/model-...

----------------------------------------
Want to become an AI Engineer? Download my AI Engineering Skills Checklist here: https://www.gratitudedriven.com/c/ai-...

üí¨ Want to talk 1:1? Book time to chat with me here: https://topmate.io/marina_wyss

üíÄ Follow my second channel for more on mindset, productivity, and meaning:    / @gratitudedriven  

ü©∑ Join the channel membership community for priority comment replies and early access to videos!    / @marinawyssai  

‚òï If you'd like to support my work, you can buy me a coffee (thank you!): https://ko-fi.com/marinawyss 
----------------------------------------
üé• Other videos you might like:

AI Engineering in 76 Minutes (Complete Course/Speedrun!)
   ‚Ä¢ AI Engineering in 76 Minutes (Complete Cou...  

AI Engineering: A Realistic Roadmap for Beginners
   ‚Ä¢ AI Engineering: A *Realistic* Roadmap for ...  

Machine Learning Roadmap 2025 - What Skills Should You Learn First?
   ‚Ä¢ Machine Learning Roadmap 2025 - What Skill...  

----------------------------------------
ü¶´ About me
I am a Senior Applied Scientist (basically, a blend of Data Scientist/Machine Learning Engineer) at Twitch/Amazon. Outside of my full-time job I'm a 1:1 career coach for people looking to break into the field, with a focus on those from non-traditional backgrounds. 

I‚Äôm also a Certified Personal Trainer, always busy with too many interests, and really, deeply happy with my life. I hope to be able to help others achieve these things, too. 

Instagram:   / gratitudedriven  
----------------------------------------
‚úâÔ∏è Contact
Instagram:   / marina.wyss  
Twitter/X: https://x.com/iammarinawyss
Leave me a comment here on YouTube!
Business email: business@gratitudedriven.com
----------------------------------------
‚öñÔ∏è Disclaimer
The views and opinions expressed in this video are my own and do not reflect the official policy or position of Twitch/Amazon or any other company I have worked for. All advice and insights shared here are based on my personal experiences and should be considered as such.

Thank you to Interview Kickstart for sponsoring this video!

This description may contain affiliate links. If you make a purchase I may make a small commission at no cost to you.

---

The top 10 papers to understand AI engineering
0:00
In this video, we're talking about the
0:02
top 10 papers you need to read to
0:03
understand AI engineering today. I'll go
0:05
over the most important papers that
0:07
shaped this new and evolving industry.
0:09
From model architecture to fine-tuning
0:12
to applications like rag and agents,
0:14
I'll share a quick overview of the paper
0:16
itself and the most important takeaways.
0:18
So, you will know how these systems work
0:20
and how we got here. Starting from the
0:22
first breakthroughs all the way to the
0:24
more recent advancements. This is
0:25
exactly the kind of thing you need to
0:26
know for AI engineering interviews. So,
0:28
take notes. Let's get started. When most
0:30
of us think about AI, we think about
0:32
large language models, which are a kind
0:33
of neural network. But neural networks
0:35
were invented in the 1940s. So why did
0:38
this become such a big deal in the last
0:39
couple of years? One of the main reasons
0:41
is a breakthrough in 2017. That year,
0:44
researchers from Google released the
0:45
famous attention is all you need paper,
Paper #1
0:47
which introduced the transformer
0:49
architecture. Before transformers, we
0:51
relied on recurrent and convolutional
0:53
networks that processed text step by
0:56
step. That meant kind of slow training,
0:58
trouble with long range dependencies
1:00
like connecting details that appear far
1:01
apart in documents, and difficulty
1:03
parallelizing across GPUs, which matters
1:06
because training speed and cost scale
1:08
with how well you can split the work
1:10
across many chips. Transformers replaced
1:12
that with self attention, which lets the
1:14
model look at all the words in a
1:16
sentence at once and learn which ones
1:18
matter to each other. Training became
1:20
massively parallel, context handling
1:22
improved, and scale suddenly became more
1:24
favorable for engineers. This paper was
1:26
a big deal. It changed the shape of the
1:28
whole field and today almost every
1:30
modern language model descends from this
1:32
design. Now a few years later in 2020 we
1:34
get another big leap with language
Paper #2
1:37
models are few shot learners the GPT3
1:39
paper. The surprising finding was that
1:41
if you scale transformers up enough they
1:43
start to perform new tasks from just a
1:46
few examples in the prompt. No task
1:48
specific fine-tuning required. You can
1:50
just describe what you want and show a
1:51
couple of patterns and the model figures
1:53
it out surprisingly well. The team
1:54
discovered this by training a very large
1:57
decoderonly transformer and
1:58
systematically evaluating it on many
2:01
tasks by only changing the text prompt.
2:03
Zero shot meaning just instructions, one
2:05
shot, one example, and few shot a
2:08
handful of examples. The breakthrough
2:09
wasn't a new architecture or anything.
2:11
It was demonstrating that scale plus
2:13
prompting unlocks in context learning,
2:16
meaning that the model can infer a task
2:18
just from patterns in the prompt. For
2:20
practitioners, this reframed how we
2:21
build systems. Instead of training a new
2:23
model for each task, we can often prompt
2:25
a general model to do what we need. But
2:27
since then, we've learned that just
2:28
scaling up forever doesn't solve all our
2:30
problems. Instruction tuning and
2:32
reinforcement learning from human
2:34
feedback made these models far more
2:35
consistent and helpful. In 2022,
2:37
researchers at OpenAI released a paper
2:39
titled training language models to
Paper #3
2:41
follow instructions with human feedback,
2:43
aka the instruct GPT paper. This paper
2:45
tried to improve models that respond in
2:47
unhelpful or toxic ways by tuning the
2:49
model with reinforcement learning from
2:50
human feedback. Basically, you first
2:52
fine-tune on examples of good behavior
2:54
called supervised instruction tuning.
2:56
Then you train a reward model to prefer
2:58
better answers over worse ones based on
3:00
human rankings. And finally, you adjust
3:03
the base model to produce answers the
3:04
reward model prefers. The main finding
3:07
from this paper was that a smaller
3:08
aligned model could be preferred over a
3:10
much larger unaligned one because it
3:12
follows directions and respects user
3:14
intent. Since then, there have been new
3:16
advances in the areas of model
3:17
alignment. For example, you'll hear
3:19
about DPO or direct preference
3:21
optimization which learns directly from
3:23
ranked preferences without an explicit
3:25
reward model. Now, it's one thing to
3:26
read these papers, but building reliable
3:28
AI systems is a different challenge
3:30
altogether. Back when I was mentoring at
3:32
Interview Kickstart, I saw so many
3:34
people who could explain the theory, but
3:36
struggled to design systems that would
3:38
actually work in the real world. That's
3:39
exactly why Ike put together the Aentic
3:41
AI career boost program. It's 14 weeks
3:44
of hands-on projects guided by mentors
3:46
from top tech companies. So, you can
3:47
move from just understanding the
3:49
research to actually building production
3:50
systems, things like agentic systems
3:52
with orchestration, multi-agent systems,
3:54
and guardrails. You complete two guided
3:56
live projects in the program so you
3:58
build something tangible for your
3:59
portfolio in the end. If this sounds
4:01
interesting to you, check out the free
4:02
webinar link in the description. This is
4:04
a great opportunity to check it out, ask
4:06
any questions, and see if it's a good
4:07
fit for you. I had a really good
4:08
experience mentoring with Ike, so it's
4:10
certainly worth your time to check out
4:11
the free webinar if you're interested in
4:12
AI engineering. Now, back to the papers
4:14
because we have a lot more interesting
4:15
stuff to cover. Okay, so even if we have
Paper #4
4:17
a model that's aligned, it might not
4:19
perform well on our specific tasks. For
4:21
example, maybe we want to return
4:23
responses in a particular format or use
4:25
language from a specific domain like
4:27
legal or medical texts. Besides in
4:29
context learning, aka prompt
4:31
engineering, another approach to
4:32
teaching the model how you want it to
4:33
respond is fine-tuning. When we
4:35
fine-tune, we continue training the
4:37
model on examples of the behavior we
4:39
want, so it internalizes those patterns.
4:41
Full fine-tuning updates all the
4:42
weights, which is time and compute
4:44
inensive. In 2021, the Laura paper gave
4:47
us a practical way to fine-tune really
4:48
large models cheaply. Instead of
4:50
updating all the weights, you insert
4:52
small low rank adapters, which are tiny
4:54
matrices that nudge the big weight
4:56
matrices in a lowdimensional direction,
4:58
and just train those. you keep the base
5:00
model frozen, which results in 10,000
5:03
times fewer trainable parameters and
5:04
about three times lower GPU memory than
5:06
full fine-tuning on certain setups.
5:08
Laura turned fine-tuning from a research
5:10
project into something you can do on a
5:11
single GPU. Over time, we've combined
5:13
Laura with quantization coming up in
5:15
paper 9 for even bigger savings. Even
Paper #5
5:17
once we fine-tuned, one of the
5:19
challenges from these models was having
5:21
limited access to information from
5:22
outside of their training data. We need
5:24
some way to be able to access new
5:26
information from after the training data
5:28
end date or something like private
5:29
company data. The paper retrieval
5:31
augmented generation for knowledge
5:33
inensive NLP tasks from 2020 proposed a
5:36
solution. Before the model answers, have
5:38
it retrieve relevant documents and let
5:40
the model read them before it responds.
5:42
This attempts to address two issues at
5:43
once, old knowledge and hallucination.
5:46
Instead of relying on whatever the model
5:47
memorized during pre-training, you can
5:49
plug it into your internal database or
5:50
the public web and have it site what it
5:52
finds. This is the pattern used by many
5:54
production LLM systems today. Over time,
5:56
we've learned that retrieval quality is
5:57
really important. The approaches you use
5:59
for chunking, indexing, search ranking,
6:01
and query rewriting often matter more
6:03
than the specific base model you choose.
6:05
We've also moved from just grabbing the
6:06
top K best matches and hoping for the
6:08
best to a multi-step pipeline that
6:10
iteratively asks better questions and
6:13
adds all the information together across
6:14
many sources with evaluation methods
6:16
that check faithfulness and site those
6:18
sources. So now we have these powerful
Paper #6
6:20
models and we can give them access to
6:22
real data, but they still don't do
6:24
anything by themselves. That's where
6:25
agents come in. I'm cheating a little
6:27
with our list because this next paper is
6:28
a survey. The rise and potential of
6:30
large language model based agents, but
6:32
it's a useful summary of the space as of
6:34
2023. The survey lays out a simple way
6:37
to think about agents. Brain, the LLM
6:39
plans and decides what to do next.
6:41
Perception, the agent reads what's going
6:43
on. Tool results, files, web pages,
6:46
memory, that kind of thing. and action.
6:47
It takes a step like call an API, run a
6:50
tool or write something. Then looks at
6:51
the result and repeats. The survey walks
6:53
through common setups like single agent,
6:55
multi- aent teams, and agents working
6:57
with humans, plus fun ideas like agent
7:00
societies where behaviors emerge from
7:01
many agents interacting. It also notes
7:04
the practical stuff that actually makes
7:05
agents work, like clear tool schemas,
7:07
guardrails to stop runaway loops, and
7:09
checks to verify the final result.
7:11
Finally, it covers how to evaluate
7:12
agents and lists open problems in the
7:14
space. Let's switch gears to scale and
Paper #7
7:16
efficiency. The paper switch
7:18
transformers scaling to trillion
7:20
parameter models with simple and
7:21
efficient sparity took the transformer
7:23
and made it sparse using a mixture of
7:25
experts. Basically, imagine having many
7:28
specialized mini networks. These are the
7:30
experts. For each incoming token, a
7:32
small router decides which single expert
7:34
is most relevant and only that expert
7:37
runs. You still store lots of
7:38
parameters, but you only use a small
7:40
fraction for any one token. So, it's
7:42
faster and cheaper. The paper showed
7:43
that conditional computation or only
7:45
computing what you need when you need it
7:47
can push scale much farther than dense
7:48
models that run every parameter on every
7:50
token. That matters because it lets you
7:52
build larger capacity without paying for
7:54
all of it on every forward pass. What
7:56
we've learned since then is that serving
7:58
sparse models is an engineering
7:59
challenge because we have to think about
8:01
things like balancing traffic across
8:02
experts, keeping latency low, and
8:04
avoiding bottlenecks. Many teams today
8:06
choose moderately sized dense models
8:09
plus retrieval and good tooling because
8:11
the total effort is lower. Now let's
Paper #8
8:13
think about making models really small.
8:14
The 2019 distilbert paper showed that
8:17
you could compress a model using
8:18
knowledge distillation. This is when we
8:20
teach a smaller student model to mimic a
8:22
larger teacher model. Ideally, this
8:24
helps us retain most of the accuracy of
8:26
the bigger model, but at a fraction of
8:28
the cost. The paper showed that general
8:29
knowledge distillation during
8:30
pre-training resulted in about 40% fewer
8:32
parameters and about 60% faster,
8:35
retaining 97% of birds language
8:37
understanding. This matters for things
8:38
like deployment to edge devices where
8:40
you have tight latency budgets, limited
8:42
memory, and maybe privacy constraints or
8:44
no internet access. A compact model can
8:46
run on a phone unlocks a lot of
8:48
practical use cases. Another way to make
Paper #9
8:50
models smaller is a technique called
8:51
quantization. In simple terms,
8:53
quantization stores numbers with fewer
8:55
bits like 8-bit integers instead of 16
8:58
or 32-bit floats. So, the model takes
9:00
less memory and math is faster. The
9:02
challenge is doing that without hurting
9:03
accuracy. Quantization has been around
9:05
for a long time, but the 2022 LLM.8
9:08
paper was the first to show a method
9:10
that keeps transformer performance
9:11
intact at multi-billion parameter scale.
9:13
It does this by being outlier aware.
9:15
Their key observation is that a tiny
9:17
number of outlier features which are
9:19
individual channels with unusually large
9:21
activations especially in attention or
9:23
feed forward layers are what break naive
9:26
int8ate quantization. Their solution is
9:28
to quantize most features at int8ate and
9:30
outlier features at FP16 or BF-16. This
9:33
mixed precision trick preserves quality
9:35
while roughly having memory for the
9:37
largest components making single GPU
9:39
inference feasible for models that
9:41
previously needed a small cluster. In
9:43
practice, it lowers serving cost and
9:44
accelerates prototyping, often with
9:46
negligible accuracy loss. It also pairs
9:48
well with parameter efficient
9:49
fine-tuning like Laura for when you need
9:51
task specific behavior to be efficient.
9:53
And last but not least, I wanted to
‚ÄúPaper‚Äù #10
9:54
include MCP in this list despite the
9:56
fact that it was not announced via a
9:58
paper. So, we're using the announcement
9:59
docs instead. MCP or model context
10:02
protocol is Anthropic's 2024 open
10:04
standard for connecting models to the
10:05
world. The basic idea is that instead of
10:07
hand coding a one-off integration for
10:09
every database, API, or developer tool
10:11
you want your model to interact with,
10:13
you run or connect to MCP servers that
10:14
expose tools, resources, and prompt in a
10:16
standard schema. Any MCP capable client
10:19
like an IDE, an agent runtime, or a chat
10:21
app, can discover those capabilities,
10:23
call tools, stream results, and keep
10:24
shared context. So, that's our list. It
10:26
was hard to pick just 10. There are so
10:28
many other important papers. Some areas
10:30
we didn't talk about at all are things
10:32
like scaling laws, infrastructure, and
10:33
system design. There's a lot going on in
10:35
this space as you can imagine, but
10:36
hopefully this gives you a good starting
10:38
point to this exciting field. If you
10:39
want a step-by-step guide on how to
10:41
become an AI engineer, check out my
10:42
roadmap video on that that's coming up
10:44
next. Thank you so much for watching and
10:45
I'll see you next time.