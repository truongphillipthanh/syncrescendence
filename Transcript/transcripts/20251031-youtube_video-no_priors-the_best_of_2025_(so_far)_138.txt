https://www.youtube.com/watch?v=OdEJjJq1I28
No Priors Ep. 138 | The Best of 2025 (So Far) with Sarah Guo and Elad Gil
932 views  Oct 31, 2025  No Priors Podcast
2025 has thus far been a year of great leaps and advances in AI technology. And Sarah and Elad have spoken with some of the most enterprising founders and scientific minds in the field of AI today. So we’re revisiting a few of our favorite conversations on No Priors so far in 2025 – Winston Weinberg (Harvey), Dr. Fei-Fei Li (World Labs), Brendan Foody (Mercor), Dan Hendrycks (Center for AI Safety), Noubar Afeyan (Flagship Pioneering), Brandon McKinzie and Eric Mitchell (OpenAI o3), Isa Fulford (OpenAI), Arvind Jain (Glen), and Dr. Shiv Rao (Abridge). 

Sign up for new podcasts every week. Email feedback to show@no-priors.com

Follow us on Twitter: @NoPriorsPod | @Saranormous | @EladGil 

Chapters:
00:00 – Episode Introduction
0:21 – Winston Weinberg on Leaning into New Capabilities
02:01 – Dr. Fei-Fei Li on Spatial Intelligence
04:13 – Brendan Foody on AI Disruption in the Workforce
06:10 – Dan Hendrycks on the Geopolitics of Superintelligence
08:06 – Noubar Afeyan on Entrepreneurship  
10:38 – Brandon McKinzie and Eric Mitchell on Reasoning Models
12:41 – Isa Fulford on Training Deep Research
13:49 – Arvind Jain on Innovating Enterprise Search
16:21 – Dr. Shiv Rao on AI’s Human Impact
18:58 – Conclusion

---

Episode Introduction
0:05
2025 has been another remarkable year in
0:07
AI. This week on No Priors, we're
0:09
sharing our favorite moments from the
0:10
podcast from the year so far. We've
0:12
talked to visionary leaders at Harvey,
0:15
OpenAI, Glean, A Bridge, and more. We
0:17
also talked to legends of science like
0:18
Dr. Fay Feay Lee and Nubar Fayen. But
Winston Weinberg on Leaning into New Capabilities
0:21
first, let's start with a moment that
0:22
captures the magic of leaning into new
0:24
capabilities at the right time. Harvey
0:26
CEO Winston Weinberg discovered an
0:28
extraordinary opportunity hidden in
0:29
plain sight.
0:30
Gabe and I actually had met a couple
0:33
years before and I definitely didn't
0:35
know anything about the startup world
0:36
and didn't have a plan of of doing a
0:38
startup. And what had happened was he
0:41
showed me GBD3 which at the time was you
0:43
know public and and I was first of all
0:46
just incredibly surprised that no one
0:47
was talking about GPD3 and no one was
0:49
using it in any way, shape or form. Um,
0:52
and he showed me that and I showed him
0:54
kind of my legal workflows and we
0:57
started the the kind of aha moment was
1:00
we went on uh our/legal advice which is
1:04
basically you know a subreddit where
1:06
people ask a bunch of legal questions
1:08
and almost every single answer is so who
1:10
do I sue um almost every single time and
1:13
we took about a hundred landlord tenant
1:15
questions and we came up with kind of
1:18
some chain of thought prompts and this
1:19
is before you know anyone was talking
1:21
about chain of thought or anything like
1:23
that and we applied it to those landlord
1:25
tenant questions and we gave it to three
1:27
landlord tenant attorneys and we just
1:29
said nothing about AI. We just said
1:31
here's a question that a potential
1:33
client asked and here is an answer uh
1:36
would you send this answer without any
1:37
edits to that client. Would you be fine
1:39
with that? You know, is that ethical? Is
1:41
it a a good enough um answer to to send?
1:44
And 86 out of 100 was yes. Um, and
1:48
actually we cold emailed the general
1:50
counsel of OpenAI and we sent him these
1:52
results and his response basically was,
1:55
"Oh, I had no idea the models were this
1:56
good at legal." Um, and we we met with
1:59
the the seuite of OpenAI a couple weeks
Dr. Fei-Fei Li on Spatial Intelligence
2:01
after.
2:02
Now, from legal reasoning to spatial
2:03
intelligence, the legendary Dr. Fay Lee
2:06
opened our eyes to an entirely different
2:08
dimension of AI capability. I think from
2:11
a neural and cognitive science point of
2:14
view that spatial intelligence is a
2:17
really hard problem that evolution has
2:19
to solve for animals. And what's really
2:22
interesting is I think animals have
2:25
solved it to an extent but not fully
2:27
solved it. It's one of the hardest
2:29
problem because um what is the problem
2:32
animal has to solve? Animals have to
2:37
evolve the capability of collecting
2:39
lights in something which we call eyes
2:44
mostly. And then with that collection of
2:47
eyes, it has to reconstruct a 3D world
2:51
in their mind somehow so that they can
2:55
navigate and they can do things and of
2:58
course they can interact. For humans,
3:00
we're the most capable animal in terms
3:03
of manipulation. then we can do a lot of
3:05
things and all this is spatial
3:08
intelligence. To me that's um that's
3:11
just rooted in in our intelligence. What
3:14
is interesting is it's not a fully
3:18
solved problem even in animals. We uh
3:21
for example uh for humans right um if I
3:25
ask you to close your eyes right now and
3:28
draw out or or or build a 3D model of
3:31
the environment around you it's not that
3:34
easy we don't have that much capability
3:37
to generate
3:39
extremely complicated 3D model till we
3:42
get trained you know there are some of
3:44
us whether they're architects or or
3:48
designers or just people with a lot of
3:50
training and a lot of talent. And that's
3:53
that's a that's a hard thing to do. And
3:55
imagine you do it at your fingertip much
3:58
more easily and allow much more uh fluid
4:04
uh interactivity and editability. That
4:07
would just be a whole different uh world
4:10
for people. No pun intended.
Brendan Foody on AI Disruption in the Workforce
4:13
Data is the beast feeding the AI train.
4:15
And thus, Merkore CEO Brendan Foody is
4:17
working with major AI labs on how to
4:20
build what's next. He gives a clear
4:22
prediction about what's coming for the
4:24
workforce.
4:25
I think displacement in a lot of roles
4:28
is going to happen very quickly and it's
4:31
going to be very painful uh and a large
4:36
political problem. Like I think we're
4:38
going to have a big populist movement
4:40
around this and all the displacement
4:42
that's going to happen. But one of the
4:44
most important problems in the economy
4:46
is figuring out how to respond to that,
4:49
right? Like how do we figure out what
4:51
everyone who's working in customer
4:53
support or recruiting should be doing in
4:55
a few years? How do we reallocate wealth
4:58
uh once we have once we approach super
5:01
intelligence um for especially if the
5:04
value and gains of that are more of a
5:07
power law distribution um and so I spend
5:10
a lot of time thinking about like how
5:12
that's going to play out um and I think
5:14
it's really at the heart of
5:15
what do you think happens eventually x%
5:17
of people get displaced from like color
5:19
work
5:20
what do you think they do
5:22
I think there's going to be a lot more
5:23
of the physical world I think that
5:25
there's als also going to be a lot that
5:27
of like niche.
5:28
What does the physical world mean?
5:30
Well, it could be everything ranging
5:33
from people that are creating robotics
5:35
data to people that are waiters at
5:38
restaurants or um or are just like
5:42
therapists because people want like
5:43
human interaction uh like whatever that
5:47
looks like. I think all of I think that
5:49
automation in the physical world is
5:52
going to happen a lot slower than what's
5:56
happening in the digital world just
5:58
because of so many of the like
6:00
self-reinforcing
6:02
uh gains and uh a lot of yeah
6:06
self-improvement that can that can
6:07
happen in in the virtual world but not
6:09
physical one
Dan Hendrycks on the Geopolitics of Superintelligence
6:10
which brings us to one of the biggest
6:12
questions of our time. How do we
6:13
navigate the geopolitical implications
6:15
of super intelligence? Dan Hendris, the
6:18
director of the Center for AI Safety,
6:19
has an answer.
6:20
Let's think of what happened in in
6:22
nuclear strategy. Basically, a lot of a
6:25
lot of states deterred each other from
6:27
doing a first strike because they could
6:29
then retaliate. So, they had a shared
6:31
vulnerability. So, there they were,
6:33
we're not going to do this really
6:34
aggressive action of trying to make a
6:37
bid to wipe you out because that will
6:39
end up causing us to be damaged. And we
6:42
have a somewhat similar situation later
6:44
on um when AI is more salient when it is
6:47
viewed as pivotal to the future of of a
6:50
nation when the people are on the verge
6:52
of making a super intelligence more when
6:54
when they can say automate you know
6:56
pretty much all AI research. I I think
6:59
states would try to deter each other
7:00
from trying to leverage that to um
7:04
develop it into something like a super
7:06
weapon that would allow the other
7:08
countries to be crushed or use those AIs
7:10
to do um uh some really rapid automated
7:14
AI research and development loop that
7:16
could um have it bootstrap from its
7:18
current levels to something that's um
7:20
super intelligent, vastly more capable
7:21
than than any other system out there. I
7:24
think that later on it becomes so
7:26
destabilizing that China just says we're
7:28
going to do something preemptive like do
7:31
a cyber attack on your data center and
7:33
the US might do that to China um and
7:35
Russia get coming out of Ukraine will
7:37
you know reassess the situation see um
7:41
get get situationally aware think oh
7:43
what's going on with the US and China oh
7:45
my goodness they're so head on AI AI is
7:47
looking like a big deal let's say it's
7:48
later in the year when you know a big
7:50
chunk of software engineering is is
7:51
starting to be impacted by AI Hi. Uh, oh
7:54
wow, this is looking pretty relevant.
7:55
Hey, if you try and use this to crush
7:58
us, we will prevent that by doing a
8:00
cyber attack on you and we will keep
8:01
tabs on your projects because it's
8:03
pretty easy for them to do that
8:04
espionage.
8:05
Nubara Feyen has been thinking about how
Noubar Afeyan on Entrepreneurship
8:07
biotech gets built and how to change the
8:09
game for three decades. His
8:11
breakthroughs have impacted global
8:12
health. He's the founder and CEO of
8:14
Flagship Pioneering and the co-founder
8:15
of Madna. He wants to make
8:17
entrepreneurship a scientific effort,
8:19
not a random one. And he thinks AI can
8:21
help. The motivation for flagship uh
8:24
stems from what I was doing before which
8:26
was that I started a company in 1987
8:29
when 24year-old immigrants didn't start
8:32
companies in this country but instead it
8:35
was kind of like former Merc senior
8:37
executives or IBM senior executives were
8:39
the only ones who were entrusted with
8:41
the massive amounts of venture capital
8:44
namely $23 million per round used to go
8:46
into venture capital. So this was very
8:48
early days and I had the the kind of
8:51
chance opportunity to start a company
8:53
right out of my graduate school and
8:55
ended up raising quite a bit of venture
8:57
money and eventually um kind of went
9:00
down a path of entrepreneurship along
9:02
the way. One of the things that
9:04
interested me was why it is that kind of
9:07
the entrepreneurial process was supposed
9:10
to be random, improvisational,
9:13
kind of idiosyncratic, almost emotional,
9:16
gamy, all of those things I kind of
9:19
thought was bit of a put off uh when it
9:22
comes to actually doing things in a
9:25
serious professional way. And I kind of
9:27
used to go around in the very early 90s
9:28
saying why isn't entrepreneurship a
9:30
profession? And if it was going to be a
9:32
profession, how could it be a
9:34
profession?
9:34
What do you mean by gamy?
9:36
Because it's like supposed to fail most
9:38
of the time and once in a while you win
9:40
and then you celebrate the win. And what
9:42
I mean is like it it
9:43
it's random.
9:44
But not only random, but there's like
9:46
winners and losers and keeping score. I
9:49
don't know. It's maybe the wrong word,
9:50
but I just mean like people even call
9:52
gamification in the in in the software
9:54
space. There is a version of this like I
9:57
don't mind being playful cuz if you're
10:00
overly serious sometimes you miss
10:01
things. But it can't just all be play.
10:03
We take hard-earned money. We deploy it
10:07
to do things that are damn near
10:08
impossible. Once in a while we reduce
10:11
them to practice so they become not only
10:12
possible but valuable. And yet people
10:15
treat it like oh well you know it didn't
10:17
work. There's 20 different things we
10:18
tried. One of them worked. And that I
10:20
don't know as an engineer by background
10:22
as a scientist I just thought that what
10:24
we do especially listen in healthcare
10:27
especially in climate especially in kind
10:29
like agriculture food security you can't
10:32
think of this as you know like shots on
10:34
goal and this you've got to kind of say
10:36
hey we can get better at this
Brandon McKinzie and Eric Mitchell on Reasoning Models
10:38
reasoning is the biggest paradigm shift
10:39
in AI architecture since the transformer
10:41
Brandon McKenzie and Eric Mitchell from
10:43
OpenAI explained a crucial insight about
10:45
reasoning models
10:46
I can give maybe very concrete cases for
10:49
like the visual reasoning side of
10:51
things. The uh there's a lot of cases
10:53
where and back to al also the model
10:55
being able to estimate its own
10:56
uncertainty. You'll you'll give it some
10:58
kind of question about an image and the
11:00
model will very transparently tell you
11:02
in a thought like I I I don't know. I
11:04
can't really see the thing you're
11:05
talking about very well or like it
11:07
almost knows like that its vision is not
11:08
very good. And uh but what's kind of
11:12
magical is like when you give it access
11:13
to a tool it's like okay well I got to
11:15
figure something out. uh let's see if I
11:16
can like manipulate the image or crop
11:18
around here or something like this. And
11:20
um what that means is that it's it's
11:22
it's like much more productive use of
11:24
tokens as it's doing that. And so your
11:26
test time scaling slope, you know, goes
11:28
from something like this to, you know,
11:29
something much steeper. And uh we've
11:31
seen exactly that like the the the test
11:34
time scaling slopes for without tool use
11:36
and with tool use for for visual
11:38
reasoning specifically are very
11:39
noticeably different.
11:40
Yeah. Yeah, I also say like for like
11:42
writing code for something like um there
11:45
are a lot of things that an LLM could
11:48
try to figure out on its own but would
11:50
require a lot of uh attempts and
11:54
self-verification
11:56
that you could write a very simple
11:58
program to do in like a verifiable and
12:01
and you know much faster way. So um you
12:05
know I hey I do some research on this
12:07
company and like use this type of you
12:09
know valuation model to tell me like you
12:11
know what the valuation should be like
12:14
you could have the model like try to
12:16
crank through that and like fit those
12:18
coefficients or whatever in its context
12:21
or you could literally just have it like
12:23
write the code to just do it the right
12:25
way um and just know what the actual
12:27
answer is. And so um yeah, I think like
12:30
part of this is you can just allocate
12:32
compute a lot more efficiently because
12:34
you can defer stuff that the model
12:36
doesn't have comparative advantage to
12:38
doing to a tool that is like really well
12:40
suited to doing a thing.
Isa Fulford on Training Deep Research
12:41
Sometimes the most profound moments in
12:43
AI development aren't the grand
12:44
theoretical breakthroughs. They're based
12:46
on taste, data generation, and grinding
12:48
work. The visceral experience of
12:50
watching something you hoped would work
12:51
actually come to life. Issa Falford from
12:53
Opening Eye captures that moment
12:54
perfectly. Here she's describing the
12:56
training that went into deep research.
12:58
It really was one of those things where
13:00
we thought that, you know, training on
13:02
browsing tasks would work. You know,
13:04
felt like we had good conviction in it.
13:06
But actually the first time you train a
13:09
model on a new data set using this
13:12
algorithm and seeing it actually working
13:14
and playing with the model was pretty in
13:16
incredible even though we thought it
13:19
would work. So honestly, just that it
13:22
worked so well was pretty surprising.
13:25
Mhm.
13:25
Even though we thought it would, if that
13:27
makes sense.
13:27
Yeah. Yeah. It's the it's the visceral
13:29
experience of like, oh, the path is
13:31
paved with strawberries or whatever.
13:33
Exactly. But then sometimes some of the
13:34
things that it fails at also surprising
13:37
like sometimes it will make a mistake
13:38
where it will do such smart things and
13:40
then make a mistake where I just
13:41
thinking why are you doing that? Like
13:43
stop. So I think there's definitely a
13:45
lot of room for improvement. Yeah, we've
13:47
been impressed with the model so far.
Arvind Jain on Innovating Enterprise Search
13:49
One of the biggest surprises of AI and a
13:52
core principle for us here at Conviction
13:54
is how it can make bad markets suddenly
13:56
good ones. The right technology can meet
13:58
the right moment in unexpected ways.
14:00
Arvin Jane built Glean in what everyone
14:02
said was a graveyard market. Enterprise
14:04
search.
14:05
It was like a graveyard like you know of
14:07
all these companies that tried to solve
14:08
the problem and it didn't. Part of it
14:10
was just that I think search is a hard
14:12
problem in an enterprise like even
14:14
getting access to all the data that you
14:16
want to search it was such a big problem
14:19
in the pre-SAS world the there was no
14:22
way to sort of go into those data
14:23
centers figure out where the servers
14:25
were where the storage systems were try
14:27
to connect with information in them was
14:29
a big it was a big challenge so SAS
14:30
actually solved that issue so like
14:32
search products like most of them most
14:34
of the companies started in the pre-SAS
14:35
world they failed uh because you could
14:37
just couldn't build a turnkey product
14:38
but SAS actually allowed you to to
14:40
actually build something you know uh
14:42
which is my insight was that like look
14:45
you know the enterprise world has
14:46
changed we have these SAS systems now
14:49
and SAS systems don't have versions like
14:51
everybody all customers have the same
14:53
version you know that they are open
14:55
they're interoperable you can actually
14:57
hit them with APIs and get all the
14:59
content I felt that the biggest problem
15:01
was actually solved which was that I
15:03
could actually easily go and bring all
15:05
the enterprise information and data in
15:07
one place uh and build this unified
15:09
search system on top. So that was
15:11
actually a big unlock and by the way the
15:12
origins of glean is so at rubric you
15:14
know we had this problem like you know
15:16
we grew fast we had lot of information
15:18
across 300 different SAS systems and
15:20
nobody could find anything in the
15:21
company and people were complaining
15:23
about it in our pulse surveys and I and
15:24
I was you know I always run it in my
15:27
startups and so this is a complaint that
15:29
you know came to me like I had to solve
15:30
it so I tried to buy a search product
15:32
and I I realized there's nothing to buy
15:34
I mean that's that's really the origins
15:35
of how how green got started as a
15:37
company and so that was like you know
15:38
one big issue like you know uh so SAS
15:41
made it easy for to actually connect you
15:44
know your enterprise data and knowledge
15:45
to a search system. So that actually
15:47
made it possible for us to for the very
15:49
first time build a turnkey product. But
15:51
there are a lot of other advances as
15:52
well you know one is you know like look
15:54
you know businesses have so much
15:55
information and data. One interesting
15:57
you know fact one of our largest
15:58
customers they have more than 1 billion
16:01
documents inside their company. Now hear
16:03
this, you know, when LR and I, you know,
16:05
when we were working on search at
16:06
Google, you know, in 2004, the entire
16:09
internet was actually 1 billion
16:10
documents. You know, there's a massive
16:12
explosion of content like inside
16:14
businesses. So, you have to build
16:16
scalable systems and you couldn't build
16:18
like a system like that before in the
16:20
pre-cloud era.
Dr. Shiv Rao on AI’s Human Impact
16:21
Perhaps no story captures the human
16:23
impact of this AI moment and its
16:24
potential better than what's happening
16:26
in healthcare. Here's Shiva, CEO and
16:28
founder of a bridge. It's pretty heroic
16:31
in general for a doctor to give you
16:33
feedback like hey this sucked and you
16:34
got to do better like um you didn't
16:36
recognize the way I said this medication
16:38
or uh I'm a gastronenterologist and I
16:41
would never you know sequence my
16:43
problems in my assessment and plan
16:44
section of my note this way. It doesn't
16:46
serve me well and makes me look like
16:48
terrible as a doctor or whatever. We get
16:49
that feedback. We love it. It's oxygen.
16:51
But then we also get the feedback that's
16:53
like, "Hey, this is amazing and I'm not
16:55
going to retire anymore and I I've got
16:56
like years, decades left in my career
16:59
now thanks to this technology." But in
17:01
this channel, love stories, all of that
17:03
feedback, that positive feedback, we
17:04
just get it like programmatically
17:05
funneled. So any one of our people
17:07
inside of the company can always go into
17:09
that channel and it's like purpose, you
17:12
know? It's like fulfillment immediately.
17:13
like you immediately understand why
17:15
we're all working so hard and why it
17:18
makes sense because like being on this
17:20
very telephone pole like journey these
17:22
last couple years uh is obviously like
17:24
it's new for so many of us and we're all
17:27
kind of building new muscles but it's
17:28
it's a lot of pressure but this is my
17:31
favorite bit of feedback so this love
17:32
story comes from a doctor at Tanner
17:34
Health which is a rural health system
17:36
and she wrote to us she wrote I was
17:38
sitting at dinner last week and my son
17:40
asked me mommy why aren't you working
17:42
right now I literally took my phone out
17:44
and explained to him that a bridge is a
17:46
new tool that lets mommy come home early
17:48
and eat dinner with her family. I
17:50
started to tear up and looked over at my
17:52
husband who then said, "Mommy's going to
17:54
be able to eat dinner with us every
17:55
night now." And we get feedback like
17:58
that like every day, you know, and so
18:00
like there's there's dopamine hits, you
18:03
know, in hyperrowth and like those are
18:05
awesome, but I think that they get us
18:06
through like sprints. But I think it's
18:08
the oxytocin hits like this. It's the
18:10
purpose. It's the fulfillment. It's like
18:12
that's I think what I think we're really
18:14
after in this company. And so like
18:16
everybody's mission driven out out
18:17
there, but I think this mission um like
18:20
it hits me at least a little bit
18:21
different.
18:21
These conversations remind us that we're
18:23
living through a hinge moment in
18:25
history. Stay tuned as we have more
18:27
conversations with the builders and
18:28
thinkers leading the way for the rest of
18:30
the year. If you like what we're doing,
18:31
leave us a review on Apple Podcasts or
18:33
Spotify, comment on YouTube, or let us
18:35
know who we should have as a guest.
18:37
Thanks for listening.
18:39
[Music]
18:40
Find us on Twitter at no prior pod.
18:43
Subscribe to our YouTube channel if you
18:45
want to see our faces. Follow the show
18:47
on Apple Podcast, Spotify, or wherever
18:49
you listen. That way, you get a new
18:51
episode every week. And sign up for
18:52
emails or find transcripts for every
18:54
episode at no-briers.com.