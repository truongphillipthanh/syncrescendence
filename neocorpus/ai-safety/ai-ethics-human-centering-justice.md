# AI Ethics, Human-Centering & Justice

> The normative stakes of AI development — who it dignifies, who it extracts from, and who gets to decide — are contested across constructive, critical, and technical-safety registers, but the three source files in this corpus cluster provide only fragmentary coverage: two sparse atom sets and one entirely unrelated document.

---

## Source Fidelity Warning

This entry is written under strict nucleosynthesis rules: every claim must trace to a specific source file; nothing may be fabricated. The three designated sources contain significantly less substantive content than the concept framing implies. This entry faithfully synthesizes what the sources actually contain — and explicitly flags what is absent.

---

## Fei-Fei Li: Human-Centered AI as Constructive Frame (01240)

Source 01240.jsonl contains four atoms from a Fei-Fei Li source (source_id: SOURCE-20251106-1157). The substantive content is:

**Core normative claim**: "Ethics must be a core component of every technological breakthrough in AI." (01240, ATOM-0001). This is presented with high confidence and framed as consensus — the chaperone marks it `context_type: consensus`, `argument_role: claim`.

**Definitional atom**: "Human-Centered AI is an approach to artificial intelligence that aims to preserve human dignity, purpose, and creativity in an increasingly automated world." (01240, ATOM-0002). This is the operational definition of the Human-Centered AI framework. It centers three values: dignity, purpose, creativity. The chaperone marks this as `context_type: method` — positioning HCAI as a methodological orientation, not merely a normative aspiration.

**Credentialing atom**: "Dr. Fei-Fei Li's work in computer vision AI has been instrumental in shaping how machines perceive and interpret the world." (01240, ATOM-0004). This establishes Li's technical authority as the substrate for her ethical prescriptions — her ethics arguments are grounded in practitioner experience, not external critique.

**Epistemic status of 01240**: These four atoms capture Li's constructive, reform-oriented position. The source contains no development of the specific mechanisms by which human dignity is preserved, no treatment of power distribution, and no engagement with structural critique. The framing is optimistic and practitioner-facing.

---

## Kate Crawford: AI as Political Economy and Infrastructure (01297)

Source 01297.jsonl contains three atoms from a Kate Crawford source (source_id: SOURCE-20251113-1149). All three atoms are biographical-credentialing claims, not substantive argument atoms:

- Crawford holds professorships at USC and the University of Sydney, a Senior Principal Researcher position at Microsoft Research Labs New York, and the inaugural visiting chair of AI and Justice at the École Normale Supérieure in Paris. (01297, ATOM-0001)
- Crawford founded multiple research centers globally and currently leads the interdisciplinary lab "Knowing Machines." (01297, ATOM-0002)
- Crawford's book *Atlas of AI* has been translated into twelve languages and received multiple international prizes, including the Sally Hacker Prize from the Society for the History of Technology and the ASSI&T Best Information Science Book Award, and was recognized as a best book by The Financial Times and New Scientist. (01297, ATOM-0003)

**Epistemic status of 01297**: This source contains zero substantive argument atoms. It establishes Crawford's institutional position and the reception of *Atlas of AI*, but no claims about AI political economy, extraction, infrastructure, or justice from the book itself are present in this corpus file. The entry cannot synthesize Crawford's critical framework from this source without fabrication.

What can be inferred from credentialing context alone: Crawford's dual positioning — inside Microsoft Research while holding a chair in "AI and Justice" — reflects the institutional tension her work inhabits. The "Knowing Machines" lab name signals an epistemological orientation (inquiry into how AI systems construct knowledge) rather than a pure ethics frame. These inferences from institutional context are noted with appropriate tentativeness.

---

## 09860.md: Not a Meredith Whittaker / Signal Source

Source 09860.md is entirely unrelated to Meredith Whittaker or Signal's privacy-first position. It is a transcript summary of the "Dr Waku Christmas Special 2025," a YouTube video published 2025-12-31 by a channel called Dr Waku, in which the host discusses:

- A personal career update: transition to a new job in AI safety advising
- Collaboration with Rob Miles AI Safety
- Channel refocus toward AI safety education for a general audience
- A new YouTube shorts channel called "Steering the Frontier"
- Community building via Discord group calls and mentorship

The video's substantive content concerns the AI safety community ecosystem and science communication — not privacy, digital rights, or Meredith Whittaker's framework. No Whittaker content can be synthesized from this source.

---

## Productive Tensions Present vs. Absent

**Tension that CAN be traced to sources**: The constructive vs. critical positioning is directionally visible even from the sparse material. Li's definition of HCAI ("preserve human dignity, purpose, and creativity") operates at the level of individual human flourishing in an automated world (01240). Crawford's institutional positioning — chair in "AI and Justice," lab named "Knowing Machines" — signals a structural and epistemological frame that interrogates how AI systems construct knowledge and distribute power (01297). These are genuinely different analytic registers, even if the Crawford source provides only biographical, not argumentative, evidence.

**Tension that CANNOT be traced to sources**: The specific Crawford critique of AI as resource extraction from labor, land, and data (the *Atlas of AI* thesis); the Whittaker/Signal position that privacy is the precondition for all other rights in an AI-surveilled world; any direct engagement between the three thinkers — none of this is present in the designated source files.

---

## What This Corpus Cluster Needs

For a complete nucleosynthesis entry on this concept, the following source material is absent from the current corpus:

1. Substantive argument atoms from Crawford's *Atlas of AI* — specifically her infrastructure analysis (AI as mines, warehouses, labor extraction) and her critique of AI as political-economic regime.
2. Any source containing Meredith Whittaker's arguments on surveillance capitalism, privacy as precondition, or Signal's design philosophy.
3. More developed Li source material — her HAI Stanford work, her specific programmatic proposals for human-centered AI design.

The current sources support a biographical sketch of two figures and a definitional frame from one. They do not support a three-way normative synthesis.

---

## Sources Fused

| File | Content | Atoms | Substantive Coverage |
|------|---------|-------|---------------------|
| `corpus/ai-safety/01240.jsonl` | Fei-Fei Li: HCAI ethics atoms | 4 | Ethics as core component of AI; HCAI definition (dignity, purpose, creativity); Li's computer vision authority |
| `corpus/ai-safety/01297.jsonl` | Kate Crawford: Atlas of AI atoms | 3 | Biographical/credentialing only — USC/Sydney professorships, Microsoft Research, École Normale Supérieure chair, "Knowing Machines" lab, *Atlas of AI* reception. Zero argument atoms. |
| `corpus/ai-safety/09860.md` | Dr Waku Christmas Special 2025 (YouTube) | N/A | Unrelated — AI safety science communication, career update, community building. No Whittaker/Signal content. |
