{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "4420d61d-3b69-5d81-aa2d-17d1ef0a92d1", "timestamp": "2026-02-24T00:53:15.130729+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260127-237-0001", "source_id": "SOURCE-20260127-237", "category": "claim", "content": "Artificial superintelligence must be stopped, as argued by Eliezer Yudkowsky and Nate Soares in their book \"If Anyone Builds It, Everyone Dies.\"", "line_start": 10, "line_end": 11, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.2, 0.7, 0.2, 0.4], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260127-237", "entity_type": "Claim", "name": "Artificial superintelligence must be stopped, as argued by Eliezer Yudkowsky and", "content": "Artificial superintelligence must be stopped, as argued by Eliezer Yudkowsky and Nate Soares in their book \"If Anyone Builds It, Everyone Dies.\"", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260127-237", "line_start": 10, "line_end": 11, "atom_id": "ATOM-SOURCE-20260127-237-0001"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.2, 0.7, 0.2, 0.4], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "4f95702b-29d0-54b1-ab3f-8ef31ae80d66", "timestamp": "2026-02-24T00:53:15.130729+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260127-237-0002", "source_id": "SOURCE-20260127-237", "category": "claim", "content": "The core argument against artificial superintelligence is that \"If Anyone Builds It, Everyone Dies,\" implying catastrophic risks.", "line_start": 12, "line_end": 13, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.4, 0.7, 0.3, 0.8, 0.1, 0.3], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260127-237", "entity_type": "Claim", "name": "The core argument against artificial superintelligence is that \"If Anyone Builds", "content": "The core argument against artificial superintelligence is that \"If Anyone Builds It, Everyone Dies,\" implying catastrophic risks.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260127-237", "line_start": 12, "line_end": 13, "atom_id": "ATOM-SOURCE-20260127-237-0002"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.4, 0.7, 0.3, 0.8, 0.1, 0.3], "opposes_atom_ids": []}, "extensions": {}}}
