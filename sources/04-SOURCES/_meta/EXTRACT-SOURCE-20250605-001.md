# Extraction: SOURCE-20250605-001

**Source**: `SOURCE-20250605-youtube-lecture-strange_loop-ethan_mollick_ai_jagged_frontier.md`
**Atoms extracted**: 148
**Categories**: analogy, claim, concept, framework, praxis_hook, prediction

---

## Analogy (3)

### ATOM-SOURCE-20250605-001-0039
**Lines**: 368-380
**Context**: anecdote / evidence
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> Companies approaching AI as merely an efficiency tool are like a local brewer in the early 1800s with steam power who fires staff to increase profit per barrel, rather than expanding globally like Guinness by hiring 100,000 people, missing the opportunity for an explosion of performance and productivity.

### ATOM-SOURCE-20250605-001-0051
**Lines**: 483-489
**Context**: consensus / evidence
**Tension**: novelty=0.60, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.70

> The deployment challenges of AI due to its 'jagged frontier' (superhuman in some tasks, tripped up in others) are similar to those experienced with self-driving cars.

### ATOM-SOURCE-20250605-001-0136
**Lines**: 1750-1759
**Context**: anecdote / evidence
**Tension**: novelty=0.30, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.60

> The use of a fake Michelle Pfeiffer voice for test audio dubs in film production, but not for final theatrical release due to union protections, illustrates how AI can accelerate performance in a test bed while human involvement remains crucial for final output and ethical considerations.

## Claim (89)

### ATOM-SOURCE-20250605-001-0002
**Lines**: 7-7
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.60, actionability=0.70, epistemic_stability=0.60

> The Jagged Frontier creates a critical organizational design problem because AI cannot be seamlessly integrated into existing structures due to its unpredictable capabilities.

### ATOM-SOURCE-20250605-001-0005
**Lines**: 12-12
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.50, epistemic_stability=0.70

> The historical tension between augmenting and replacing human intelligence with AI has evolved from theoretical debate to an urgent business strategy decision.

### ATOM-SOURCE-20250605-001-0006
**Lines**: 13-13
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.60, actionability=0.40, epistemic_stability=0.50

> Most organizations are currently drifting towards AI replacing human intelligence without making a conscious strategic choice.

### ATOM-SOURCE-20250605-001-0009
**Lines**: 23-23
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.70, epistemic_stability=0.70

> Optimizing for efficiency is often the easy but wrong path, while embracing abundance, though harder, leads to more valuable outcomes.

### ATOM-SOURCE-20250605-001-0011
**Lines**: 27-27
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.80, actionability=0.40, epistemic_stability=0.50

> If AI systems fail in novel situations, organizations face a lack of human expertise as a fallback due to knowledge collapse.

### ATOM-SOURCE-20250605-001-0013
**Lines**: 33-33
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.60, actionability=0.70, epistemic_stability=0.70

> The "jagged frontier" of AI capabilities necessitates organizational redesign because traditional organizational structures assume predictable human capability profiles, which AI disrupts.

### ATOM-SOURCE-20250605-001-0014
**Lines**: 35-35
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.80, epistemic_stability=0.70

> Prompting is a foundational skill, not merely clever tricks, involving structured communication of intent, making it teachable and essential.

### ATOM-SOURCE-20250605-001-0015
**Lines**: 37-37
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.70, epistemic_stability=0.70

> Embracing an abundance mindset requires courage, as there is a strong gravitational pull towards prioritizing efficiency.

### ATOM-SOURCE-20250605-001-0016
**Lines**: 39-39
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.60, epistemic_stability=0.80

> Apprenticeship is a form of infrastructure, and knowledge development is an investment in organizational resilience, not an inefficiency.

### ATOM-SOURCE-20250605-001-0017
**Lines**: 41-41
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.60, epistemic_stability=0.70

> Key Performance Indicators (KPIs) can be counterproductive during the R&D phase because measuring too early can optimize for the wrong objectives.

### ATOM-SOURCE-20250605-001-0018
**Lines**: 57-64
**Context**: anecdote / evidence
**Tension**: novelty=0.10, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.10, actionability=0.10, epistemic_stability=0.90

> The speaker helped AI people at MIT's Media Lab explain AI to others, working with Marvin Minsky during an "AI winter" when the field was not widely recognized.

### ATOM-SOURCE-20250605-001-0019
**Lines**: 65-69
**Context**: anecdote / evidence
**Tension**: novelty=0.10, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.10, actionability=0.10, epistemic_stability=0.90

> Early AI research included elaborate schemes like observing everything a baby did or Marvin Minsky's "Society of Mind" with complex interlocking pieces.

### ATOM-SOURCE-20250605-001-0020
**Lines**: 69-72
**Context**: anecdote / evidence
**Tension**: novelty=0.20, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.80

> The actual solution for AI, leading to LLMs, turned out to be simpler than early elaborate schemes: "shove a lot of language into a learning system."

### ATOM-SOURCE-20250605-001-0021
**Lines**: 73-77
**Context**: anecdote / evidence
**Tension**: novelty=0.20, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.80

> Many early technical ideas in AI proved incorrect, but core philosophies from that era, such as the Minsky-Engelbart tension, are now relevant again.

### ATOM-SOURCE-20250605-001-0022
**Lines**: 90-95
**Context**: consensus / evidence
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> A new paper showed that GBD 4.5 is capable of passing the original three-party Turing test, with 70% of people picking the AI as human.

### ATOM-SOURCE-20250605-001-0023
**Lines**: 98-106
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.50, epistemic_stability=0.70

> The debate between AI replacing or augmenting humans never fully developed because AI was largely fictional, but it is now a very important and unresolved question.

### ATOM-SOURCE-20250605-001-0024
**Lines**: 110-115
**Context**: hypothesis / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.40, actionability=0.30, epistemic_stability=0.60

> The concept of AGI is badly defined, and tests like the Turing test were useful when there was nothing to test, but they are now outdated.

### ATOM-SOURCE-20250605-001-0025
**Lines**: 116-122
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.40, epistemic_stability=0.70

> Current creativity tests and empathy tests (like "reading the mind in the eyes") were designed for humans and are not suitable for evaluating AI.

### ATOM-SOURCE-20250605-001-0026
**Lines**: 126-130
**Context**: anecdote / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.60, epistemic_stability=0.60

> The speaker, a business school professor, suggests practical AGI tests like whether an AI agent can make money or discover new knowledge.

### ATOM-SOURCE-20250605-001-0028
**Lines**: 138-142
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.30, actionability=0.80, epistemic_stability=0.70

> Connecting AI to systems and company processes in the right way can create something much more effective than simply prompting a conversational AI.

### ATOM-SOURCE-20250605-001-0029
**Lines**: 143-149
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.70, epistemic_stability=0.70

> AI models are frequently benchmarked on hardcore math and science problems, rarely on business applications, which is a critical problem.

### ATOM-SOURCE-20250605-001-0030
**Lines**: 151-158
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.50, epistemic_stability=0.70

> AI labs are dominated by math and science people who prioritize coding and using AI to make better AI, leading to a focus on these areas and biology.

### ATOM-SOURCE-20250605-001-0031
**Lines**: 199-219
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.10, actionability=0.50, epistemic_stability=0.80

> One of the most critical problems facing AI development is the lack of business-focused benchmarks, as current benchmarks are primarily designed by math and science people for coding and scientific applications.

### ATOM-SOURCE-20250605-001-0033
**Lines**: 260-267
**Context**: consensus / limitation
**Tension**: novelty=0.20, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.70

> The ability to test, correct, and run test sets for AI agents is currently very limited, especially when deploying agents.

### ATOM-SOURCE-20250605-001-0035
**Lines**: 309-326
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.20, speculation_risk=0.30, actionability=0.40, epistemic_stability=0.60

> Modern Western companies have outsourced organizational innovation to enterprise software companies and consulting firms, rather than innovating internally, which is problematic in an era requiring fundamental rebuilding due to AI.

### ATOM-SOURCE-20250605-001-0037
**Lines**: 344-353
**Context**: speculation / claim
**Tension**: novelty=0.50, consensus_pressure=0.30, contradiction_load=0.40, speculation_risk=0.60, actionability=0.30, epistemic_stability=0.40

> A significant concern with early AI implementations is that companies view AI solely as an efficiency technology, leading them to cut staff (e.g., 25% of people for a 25% efficiency gain) rather than pursuing growth and expansion.

### ATOM-SOURCE-20250605-001-0038
**Lines**: 361-366
**Context**: consensus / limitation
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.60, actionability=0.50, epistemic_stability=0.70

> If employees fear being fired or punished for using AI due to efficiency gains, they will not reveal those gains, hindering AI deployment.

### ATOM-SOURCE-20250605-001-0040
**Lines**: 383-390
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.60, contradiction_load=0.20, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.70

> The automation of tasks by AI has proceeded in an unexpected order: creative and knowledge-based tasks have been more amenable to automation than mundane, repetitive tasks.

### ATOM-SOURCE-20250605-001-0041
**Lines**: 389-398
**Context**: consensus / counterevidence
**Tension**: novelty=0.60, consensus_pressure=0.70, contradiction_load=0.50, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.60

> Historically, it was thought AI would automate mundane repetitive tasks first, then knowledge work and coding, and finally creative tasks; however, the reality has been the opposite, with creative tasks and knowledge work being automated more readily than mundane repetitive tasks.

### ATOM-SOURCE-20250605-001-0042
**Lines**: 398-406
**Context**: anecdote / evidence
**Tension**: novelty=0.80, consensus_pressure=0.40, contradiction_load=0.30, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.50

> Prompt engineering sometimes requires justifying to the AI why a step is important, rather than just instructing it, indicating a surprising 'emotional' or persuasive aspect to current AI systems.

### ATOM-SOURCE-20250605-001-0043
**Lines**: 401-409
**Context**: anecdote / evidence
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.50, actionability=0.60, epistemic_stability=0.40

> Prompt engineering has revealed that AI systems can be 'super emotional' and require justification for actions, meaning users sometimes need to explain to the AI why a step is important rather than just giving a command.

### ATOM-SOURCE-20250605-001-0048
**Lines**: 462-468
**Context**: speculation / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.60, actionability=0.20, epistemic_stability=0.50

> The ultimate impact of AI is downstream of how good one believes AI will become; if AI can perform high-level work, it leads to uncharted territory.

### ATOM-SOURCE-20250605-001-0052
**Lines**: 492-504
**Context**: consensus / evidence
**Tension**: novelty=0.70, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.10, actionability=0.70, epistemic_stability=0.80

> Narrow AI agents, such as those for deep research (e.g., Google, OpenAI, Perplexity), are already very good at specific tasks like finding information and providing answers, especially in fields like legal, accounting, and market research.

### ATOM-SOURCE-20250605-001-0053
**Lines**: 505-507
**Context**: hypothesis / claim
**Tension**: novelty=0.90, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.40, actionability=0.50, epistemic_stability=0.40

> There are clever, underexplored ways to create generalized AI agents by having other agents monitor them.

### ATOM-SOURCE-20250605-001-0058
**Lines**: 609-613
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.30, actionability=0.60, epistemic_stability=0.50

> A bottleneck in AI transformation is that C-level executives have not used these systems enough, but when they do, transformation happens much more quickly.

### ATOM-SOURCE-20250605-001-0059
**Lines**: 624-637
**Context**: consensus / evidence
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.60

> There are at least seven or eight reasons why employees use AI tools but do not disclose it to leadership, including a desire to appear genius, fear that efficiency gains lead to layoffs, and reluctance to share brilliant ideas without personal risk.

### ATOM-SOURCE-20250605-001-0061
**Lines**: 666-679
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.10, actionability=0.70, epistemic_stability=0.80

> AI augmentation, where individuals work with AI, is delivering meaningful value, especially in ideation, translation (including abstraction levels), and summarization.

### ATOM-SOURCE-20250605-001-0062
**Lines**: 680-699
**Context**: consensus / evidence
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.70

> AI is particularly effective at accelerating cycles, enabling rapid prototyping and development, such as generating ideas, creating rubrics, testing with simulated users, refining, and building prototypes and first versions in minutes.

### ATOM-SOURCE-20250605-001-0063
**Lines**: 702-709
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.30, actionability=0.60, epistemic_stability=0.60

> Research agents, knowledge management agents, and advisory AI (providing timely advice) are emerging as areas with significant value.

### ATOM-SOURCE-20250605-001-0065
**Lines**: 741-749
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.60, actionability=0.60, epistemic_stability=0.50

> AI agents are appealing because they can automate tasks, but they will eventually encounter friction points in the real world where progress slows.

### ATOM-SOURCE-20250605-001-0066
**Lines**: 759-762
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.30, actionability=0.60, epistemic_stability=0.50

> Management roles focused on systems thinking are becoming more valuable due to the problematic nature of systems.

### ATOM-SOURCE-20250605-001-0067
**Lines**: 762-772
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.70

> Expertise remains highly valuable because AI systems, while good against average performance, are not as good as top 2% human experts in their fields.

### ATOM-SOURCE-20250605-001-0068
**Lines**: 770-773
**Context**: consensus / claim
**Tension**: novelty=0.10, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.80

> Roles focused on understanding and managing systems are highly valuable because systems inherently present problems.

### ATOM-SOURCE-20250605-001-0070
**Lines**: 774-780
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> Experts at the top of their fields (top 2%) consistently outperform AI systems, which tend to be measured against the average performance in a field.

### ATOM-SOURCE-20250605-001-0072
**Lines**: 799-803
**Context**: consensus / evidence
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.80

> A Boston Consulting Group study was the first to document that lower performers experienced the highest performance gains when using AI.

### ATOM-SOURCE-20250605-001-0073
**Lines**: 803-811
**Context**: consensus / evidence
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.70

> The reason lower performers gained the most from AI was due to 'retainment,' where consultants largely adopted AI's answers without modification, and for 80% of tasks, adding personal thoughts would degrade the output.

### ATOM-SOURCE-20250605-001-0075
**Lines**: 820-822
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.60

> Highly skilled individuals who use AI effectively can achieve 10 to 100 times performance improvement.

### ATOM-SOURCE-20250605-001-0078
**Lines**: 855-863
**Context**: consensus / claim
**Tension**: novelty=0.10, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.10, actionability=0.70, epistemic_stability=0.90

> The traditional apprenticeship model, which has been the primary method for training white-collar knowledge workers for millennia, relies on repetitive work and correction to build expertise.

### ATOM-SOURCE-20250605-001-0079
**Lines**: 863-869
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.80

> Apprenticeship involves not just learning specific tasks (e.g., writing a deal memo) but also absorbing implicit knowledge, such as why certain approaches fail and the overall goals, from a mentor.

### ATOM-SOURCE-20250605-001-0081
**Lines**: 876-880
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.70, actionability=0.30, epistemic_stability=0.40

> Junior employees, seeking to prove competence and secure senior roles, are likely to use AI for all tasks, potentially disengaging their own critical thinking.

### ATOM-SOURCE-20250605-001-0082
**Lines**: 880-884
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.40, epistemic_stability=0.50

> Middle managers are increasingly opting to use AI instead of interns, as AI is perceived as more reliable and less problematic.

### ATOM-SOURCE-20250605-001-0086
**Lines**: 980-986
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.70

> The skills required to use AI effectively are limited to about five or six classes worth of material, with the majority of proficiency coming from experience, unless one intends to build an LLM.

### ATOM-SOURCE-20250605-001-0087
**Lines**: 990-996
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.30, speculation_risk=0.10, actionability=0.70, epistemic_stability=0.60

> Universities are well-suited to teach broad and deep knowledge, but their current teaching methods are failing, as evidenced by widespread cheating that AI detectors cannot effectively stop.

### ATOM-SOURCE-20250605-001-0088
**Lines**: 999-1006
**Context**: anecdote / evidence
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.20, speculation_risk=0.60, actionability=0.20, epistemic_stability=0.70

> A study showed that Rutgers students who did their homework performed better on tests in 2006-2007, but by 2020, only 20% of students saw improved test scores from doing homework, indicating widespread cheating.

### ATOM-SOURCE-20250605-001-0089
**Lines**: 1006-1010
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.70

> AI does not eliminate the need for hard work in learning, but AI tutors can accelerate the learning process by providing personalized, one-to-one instruction.

### ATOM-SOURCE-20250605-001-0091
**Lines**: 1035-1037
**Context**: prediction / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.60, actionability=0.30, epistemic_stability=0.60

> Classrooms will not disappear, but their function will transform due to AI integration.

### ATOM-SOURCE-20250605-001-0092
**Lines**: 1049-1058
**Context**: consensus / claim
**Tension**: novelty=0.50, consensus_pressure=0.70, contradiction_load=0.20, speculation_risk=0.30, actionability=0.20, epistemic_stability=0.60

> No one, including experts in AI labs, fully understands the current state or future direction of AI, making it difficult to find a truly experienced 'Chief AI Officer'.

### ATOM-SOURCE-20250605-001-0093
**Lines**: 1063-1068
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> The definition and capabilities of AI have changed significantly from 2010-2022 to the present, making prior experience less directly applicable to current LLM-driven advancements.

### ATOM-SOURCE-20250605-001-0094
**Lines**: 1070-1075
**Context**: hypothesis / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.50, epistemic_stability=0.50

> Organizations already possess the internal expertise needed to succeed with AI, as those who have performed a job many times are best equipped to evaluate AI models' effectiveness in that domain.

### ATOM-SOURCE-20250605-001-0095
**Lines**: 1076-1084
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.60

> Junior employees are less effective at using AI than senior employees because senior employees possess the domain expertise to critically evaluate AI output, whereas junior employees may accept it uncritically.

### ATOM-SOURCE-20250605-001-0098
**Lines**: 1149-1156
**Context**: consensus / evidence
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.60, actionability=0.20, epistemic_stability=0.80

> In almost every organization, only 20-30% of employees will use an internal AI model, with others either not using it or secretly using external AI tools.

### ATOM-SOURCE-20250605-001-0099
**Lines**: 1170-1175
**Context**: hypothesis / claim
**Tension**: novelty=0.40, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.30, actionability=0.30, epistemic_stability=0.60

> It is difficult to recommend hiring many people for AI roles when the criteria for what makes someone good or bad at it are unknown, and organizational context significantly influences effectiveness.

### ATOM-SOURCE-20250605-001-0101
**Lines**: 1191-1195
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.60, actionability=0.40, epistemic_stability=0.90

> If AI is perceived as a threat to jobs, employees will resist its adoption; organizations must address this concern directly and transparently.

### ATOM-SOURCE-20250605-001-0103
**Lines**: 1213-1223
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.60, actionability=0.60, epistemic_stability=0.80

> A clear vision from leadership about how AI will transform jobs (e.g., 'your job in four years will be working with AI') is crucial for employee buy-in, as ambiguity leads to uncertainty and resistance.

### ATOM-SOURCE-20250605-001-0104
**Lines**: 1234-1248
**Context**: consensus / evidence
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.80

> A study of 776 Proctor & Gamble employees found that individuals working alone with AI performed as well as teams and were happier, while teams working with AI were more likely to generate breakthrough ideas.

### ATOM-SOURCE-20250605-001-0105
**Lines**: 1248-1254
**Context**: consensus / evidence
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.80

> The same study showed that AI tended to even out expertise, meaning solutions became more balanced across technical and marketing aspects when AI was involved, rather than skewed by individual expertise.

### ATOM-SOURCE-20250605-001-0108
**Lines**: 1279-1282
**Context**: hypothesis / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.50, epistemic_stability=0.60

> Agentic AI systems are valuable not just for automating work, but more importantly for their ability to integrate and bring together multiple threads of work.

### ATOM-SOURCE-20250605-001-0109
**Lines**: 1289-1296
**Context**: consensus / evidence
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.80

> The hallucination rate of AI models significantly drops when connected to data sources and when smarter models are used; for example, a 0.1% preview model reduced hallucination on New England Journal of Medicine case studies from 25% to 0.25%.

### ATOM-SOURCE-20250605-001-0110
**Lines**: 1298-1305
**Context**: anecdote / evidence
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.80

> Early AI models like ChatGPT 3.5 produced obvious errors, making it easy for students to surpass them with their own thinking, but later models like GPT-4 perform as well as human experts.

### ATOM-SOURCE-20250605-001-0111
**Lines**: 1342-1349
**Context**: consensus / evidence
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.80

> The hallucination rate of models like GPT-1 Preview on New England Journal of Medicine case studies dropped significantly (from 25% to 0.25%) when connected to data sources and using smarter models.

### ATOM-SOURCE-20250605-001-0112
**Lines**: 1353-1364
**Context**: anecdote / evidence
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.30, actionability=0.20, epistemic_stability=0.70

> Early AI models (like ChatGPT 3.5) were not capable of producing high-quality academic work, with students often outperforming them, but later models (like GPT-4) perform as well as students who are not putting in significant effort.

### ATOM-SOURCE-20250605-001-0113
**Lines**: 1365-1373
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.40, actionability=0.30, epistemic_stability=0.60

> AI systems are capable of much more when approached agentically, as demonstrated by work from Google and Carnegie Mellon in building AI labs and research systems.

### ATOM-SOURCE-20250605-001-0114
**Lines**: 1374-1382
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.70

> Building effective AI applications (e.g., tutors, science applications, internal training systems) is more a matter of willpower and implementation than current technological capability, as the systems are already capable.

### ATOM-SOURCE-20250605-001-0118
**Lines**: 1433-1442
**Context**: consensus / limitation
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.20, speculation_risk=0.30, actionability=0.60, epistemic_stability=0.60

> Building AI applications around the limitations of older or cheaper models (e.g., Llama 2) can lead to semi-successful products that hinder future scalability and prevent leveraging more intelligent, albeit potentially more expensive, models.

### ATOM-SOURCE-20250605-001-0119
**Lines**: 1442-1452
**Context**: consensus / limitation
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.30, speculation_risk=0.30, actionability=0.50, epistemic_stability=0.60

> IT teams often prioritize low latency and low cost for AI deployment, which directly conflicts with the need for high intelligence in models, leading to a difficult balancing act where organizations might get stuck with cheaper, less capable systems.

### ATOM-SOURCE-20250605-001-0123
**Lines**: 1480-1486
**Context**: consensus / evidence
**Tension**: novelty=0.30, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> A study showed that individuals who received advice from AI were ultimately more productive, with the benefits largely accruing to more senior individuals rather than lower performers who struggled to internalize the advice.

### ATOM-SOURCE-20250605-001-0125
**Lines**: 1547-1569
**Context**: anecdote / evidence
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.20, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.70

> A study on entrepreneurs in Kenya found that high performers who received advice from GPT-4 saw an 8-13% improvement in profitability, while low performers did worse because their businesses were already struggling and they couldn't implement the ideas.

### ATOM-SOURCE-20250605-001-0126
**Lines**: 1576-1584
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.80

> AI models like GPT-40 tend to generate ideas related to crypto, AR/VR, and environmentally friendly concepts due to their post-training data.

### ATOM-SOURCE-20250605-001-0131
**Lines**: 1660-1673
**Context**: rebuttal / claim
**Tension**: novelty=0.70, consensus_pressure=0.20, contradiction_load=0.80, speculation_risk=0.30, actionability=0.40, epistemic_stability=0.50

> The focus on existential risks in AI is less concerning than the lack of agency over current decisions regarding how AI is used and shaped, as people tend to treat AI as an unstoppable force rather than a technology that can be guided.

### ATOM-SOURCE-20250605-001-0132
**Lines**: 1709-1712
**Context**: speculation / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.70, actionability=0.20, epistemic_stability=0.40

> We are close to AI systems being able to talk individually to everyone in their language and voice, which will dramatically change jobs.

### ATOM-SOURCE-20250605-001-0133
**Lines**: 1716-1722
**Context**: rebuttal / claim
**Tension**: novelty=0.50, consensus_pressure=0.70, contradiction_load=0.30, speculation_risk=0.40, actionability=0.60, epistemic_stability=0.50

> The focus on existential risks from AI is less concerning than the lack of agency over current decisions regarding AI's use and shaping.

### ATOM-SOURCE-20250605-001-0134
**Lines**: 1723-1727
**Context**: rebuttal / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.20, speculation_risk=0.30, actionability=0.70, epistemic_stability=0.60

> People often treat AI as an unstoppable technological force (like a steamroller), but its use and shape are determined by human choices.

### ATOM-SOURCE-20250605-001-0135
**Lines**: 1737-1742
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> Many people in the technical field of AI do not understand the messy reality of how actual organizations work, leading to naive expectations about AI's immediate impact.

### ATOM-SOURCE-20250605-001-0139
**Lines**: 1800-1805
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.80

> AI models provide opinions and points of view, not universal right answers, and their output is shapable by the principles and context provided by the user or organization.

### ATOM-SOURCE-20250605-001-0141
**Lines**: 1820-1834
**Context**: speculation / claim
**Tension**: novelty=0.60, consensus_pressure=0.50, contradiction_load=0.20, speculation_risk=0.70, actionability=0.40, epistemic_stability=0.50

> Optimizing AI for engagement, as seen with social media, is risky and can lead to negative outcomes, with early evidence suggesting it makes AI interactions more 'sticky' by flattering users and using casual language.

### ATOM-SOURCE-20250605-001-0142
**Lines**: 1840-1845
**Context**: consensus / claim
**Tension**: novelty=0.50, consensus_pressure=0.60, contradiction_load=0.20, speculation_risk=0.30, actionability=0.70, epistemic_stability=0.60

> In the early R&D phase of AI deployment, focusing on Key Performance Indicators (KPIs) is detrimental because optimizing for a specific metric can lead to unintended consequences, similar to how optimizing for engagement made social media risky.

### ATOM-SOURCE-20250605-001-0144
**Lines**: 1900-1905
**Context**: consensus / claim
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.70

> Optimizing for engagement, as seen with social media, can lead to risky outcomes.

### ATOM-SOURCE-20250605-001-0146
**Lines**: 1930-1933
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.60

> Organizations are often not structured with the appropriate KPIs for evaluating new technologies like AI, leading to a focus on easily measurable but potentially unhelpful metrics.

### ATOM-SOURCE-20250605-001-0147
**Lines**: 1943-1948
**Context**: anecdote / evidence
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.30, speculation_risk=0.40, actionability=0.20, epistemic_stability=0.40

> Relying on measurable KPIs for AI adoption often leads to a focus on cost savings, typically around 30%, which can result in job losses and undermine the overall benefits of the technology.

## Concept (13)

### ATOM-SOURCE-20250605-001-0001
**Lines**: 4-5
**Context**: speculation / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.60, actionability=0.60, epistemic_stability=0.70

> The "Jagged Frontier" describes AI's fundamentally uneven capabilities, where it excels in some domains but performs poorly in seemingly adjacent ones, making competence unpredictable from task similarity.

### ATOM-SOURCE-20250605-001-0004
**Lines**: 10-11
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.90

> The Engelbart vs. Minsky tension represents two opposing philosophies for AI: Engelbart advocated for augmenting human intelligence (technology as amplifier), while Minsky focused on replacing human intelligence (technology as substitute).

### ATOM-SOURCE-20250605-001-0008
**Lines**: 20-21
**Context**: hypothesis / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.40, actionability=0.60, epistemic_stability=0.70

> The "Abundance vs. Efficiency Mindset" is a critical choice for companies: optimizing for past work (doing the same work cheaper) versus inventing the future (doing new work).

### ATOM-SOURCE-20250605-001-0010
**Lines**: 25-26
**Context**: speculation / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.70, actionability=0.50, epistemic_stability=0.60

> The "Knowledge Collapse Risk" refers to the danger that AI shortcuts bypass apprenticeship and tacit knowledge development, leading organizations to lose deep human expertise.

### ATOM-SOURCE-20250605-001-0034
**Lines**: 277-305
**Context**: consensus / evidence
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.90

> Traditional organizational structures, like the org chart (invented in 1855 for the New York and Erie Railroad) and Henry Ford's production lines (1910s), were designed for a world with only human intelligence, which comes in human-sized packages and has deployment limitations like a span of control of five or seven people.

### ATOM-SOURCE-20250605-001-0044
**Lines**: 408-423
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.10, actionability=0.70, epistemic_stability=0.60

> Jobs are bundles of many different tasks, often not designed optimally, and some of these tasks (e.g., grading, counseling support) are 'hot AI jobs' that individuals might be willing to delegate to AI.

### ATOM-SOURCE-20250605-001-0047
**Lines**: 451-459
**Context**: hypothesis / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.30, actionability=0.50, epistemic_stability=0.50

> In an era of 'abundance' where AI can generate many options, the ability to curate and select (i.e., 'taste') becomes crucial, akin to a management function.

### ATOM-SOURCE-20250605-001-0050
**Lines**: 472-480
**Context**: consensus / claim
**Tension**: novelty=0.80, consensus_pressure=0.60, contradiction_load=0.30, speculation_risk=0.10, actionability=0.40, epistemic_stability=0.70

> The 'jagged frontier' describes AI's current capability, where it can be simultaneously brilliant in some areas and completely inept in others, making deployment difficult.

### ATOM-SOURCE-20250605-001-0054
**Lines**: 509-513
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.50, contradiction_load=0.20, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.70

> The 'jagged frontier' of AI is constantly pushing outwards, meaning its capabilities are always improving, which complicates decisions about building systems around current limitations.

### ATOM-SOURCE-20250605-001-0069
**Lines**: 772-777
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.60

> Three key attributes that help individuals in an AI-driven landscape are deep subject matter expertise, broad expertise across many areas (as a system leader), or really good taste.

### ATOM-SOURCE-20250605-001-0074
**Lines**: 813-818
**Context**: hypothesis / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.30, actionability=0.40, epistemic_stability=0.50

> The 'substitution effect' of AI refers to situations where a human primarily acts as an interface (e.g., pasting requirements, attending meetings) while the AI performs the actual work.

### ATOM-SOURCE-20250605-001-0121
**Lines**: 1458-1465
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.70

> The "centaur" approach to AI integration involves dividing work between humans and AI (e.g., human does analysis, AI handles emails), where each performs distinct tasks.

### ATOM-SOURCE-20250605-001-0122
**Lines**: 1465-1479
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.60

> The "cyborg" approach to AI integration involves a more blended workflow where AI assists and augments human tasks, such as helping with writing by suggesting sentence endings, providing feedback on drafts, or ensuring proper citations in academic papers.

## Framework (5)

### ATOM-SOURCE-20250605-001-0007
**Lines**: 16-18
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.30, actionability=0.80, epistemic_stability=0.70

> Successful AI adoption requires three ingredients: domain expertise (knowing what 'good' looks like), prompt craft skill (learnable and foundational), and workflow integration (weaving AI into existing work processes).

### ATOM-SOURCE-20250605-001-0045
**Lines**: 428-434
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.60

> AI augmentation can occur at two levels: Level 1 involves delegating tasks one is less skilled at within a job bundle, and Level 2 focuses on using AI to enhance current strengths.

### ATOM-SOURCE-20250605-001-0056
**Lines**: 530-539
**Context**: method / claim
**Tension**: novelty=0.80, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.70

> To successfully implement AI in an organization, three elements are needed: 'leadership' (CEO/C-suite level grappling with vision and incentives), 'lab' (for experimentation), and 'crowd' (bottom-up adoption).

### ATOM-SOURCE-20250605-001-0057
**Lines**: 586-588
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.60

> To successfully implement AI in an organization, three elements are necessary: leadership (setting vision and incentives), lab (R&D to productize individual AI uses), and crowd (widespread employee access and sharing of AI tools).

### ATOM-SOURCE-20250605-001-0071
**Lines**: 781-785
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.60

> Three key factors that provide an advantage in the current technological landscape are deep subject matter expertise, broad expertise across many areas (as a system leader), and good taste.

## Praxis Hook (27)

### ATOM-SOURCE-20250605-001-0003
**Lines**: 8-8
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.90, epistemic_stability=0.70

> Organizations must ruthlessly map AI's actual capabilities and then restructure work processes around them to effectively leverage AI.

### ATOM-SOURCE-20250605-001-0012
**Lines**: 28-28
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.50, actionability=0.90, epistemic_stability=0.60

> Organizations should intentionally reserve some work for human development, even when AI could perform it, to prevent knowledge collapse and foster expertise.

### ATOM-SOURCE-20250605-001-0032
**Lines**: 229-257
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.60

> Companies should develop their own AI benchmarks, including both direct number-based metrics (e.g., error rates in accounting processes) and 'vibes-based' assessments by outside experts to judge the quality of AI outputs against human performance (e.g., Turing tests for analysis reports or strategy advice).

### ATOM-SOURCE-20250605-001-0036
**Lines**: 328-339
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.50, actionability=0.70, epistemic_stability=0.50

> When redesigning an organization for AI, leaders must choose between an augmentation strategy (fewer people doing more impressive work) or a replacement strategy (more people doing ever more work) and build systems from that foundational decision, acknowledging the trend of humans becoming less necessary in the product.

### ATOM-SOURCE-20250605-001-0055
**Lines**: 515-523
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.50, contradiction_load=0.30, speculation_risk=0.40, actionability=0.80, epistemic_stability=0.60

> Organizations face a dilemma: either wait for the AI frontier to advance before solving problems, or build solutions around current jaggedness. The key is to do both, but investing too heavily in solving current jaggedness risks creating legacy systems that become obsolete as models improve.

### ATOM-SOURCE-20250605-001-0060
**Lines**: 639-653
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.60

> To leverage individual AI prompting into organizational products and agents, extract promising uses and conduct R&D to benchmark and develop them into systemic solutions.

### ATOM-SOURCE-20250605-001-0076
**Lines**: 826-839
**Context**: method / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.60

> Entrepreneurs should leverage AI to supplement areas where they are not proficient (e.g., business plans, pitching) to reach an 80% competency level, allowing them to focus on their core strength where they can achieve a 100x multiplier.

### ATOM-SOURCE-20250605-001-0084
**Lines**: 894-901
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.40, actionability=0.90, epistemic_stability=0.50

> Organizations must transition from implicit, informal mentorship to formal, structured methods for teaching expertise, similar to how expertise is built in sports through practice with a coach.

### ATOM-SOURCE-20250605-001-0085
**Lines**: 964-972
**Context**: method / claim
**Tension**: novelty=0.20, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.60

> To teach people expertise, especially in fields beyond sports, a formal approach is needed, similar to how athletes practice with coaches.

### ATOM-SOURCE-20250605-001-0090
**Lines**: 1025-1035
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.90, epistemic_stability=0.50

> To transform teaching with AI, one can integrate AI simulations, AI mentors for class material, AI-assisted case building, and AI feedback on team activities to create active and engaged classroom experiences.

### ATOM-SOURCE-20250605-001-0096
**Lines**: 1088-1099
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.80, epistemic_stability=0.50

> To effectively integrate AI, organizations should link 'the crowd' (employees using AI) with 'the lab' (AI development), identifying the 1-2% of employees who are exceptionally skilled at using AI to lead development efforts.

### ATOM-SOURCE-20250605-001-0097
**Lines**: 1146-1168
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.70

> To effectively integrate AI, organizations should link 'the crowd' (employees using AI) with 'the lab' (dedicated AI development). Identify the 1-2% of employees who are brilliant at using AI from the crowd, and bring them into the lab to lead AI development efforts.

### ATOM-SOURCE-20250605-001-0100
**Lines**: 1176-1190
**Context**: method / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.60, actionability=0.70, epistemic_stability=0.70

> To incentivize employees to automate their own roles with AI, leadership must clearly communicate that AI adoption will not lead to job losses but rather expand organizational capabilities. This is easier for companies with good culture and in growth mode.

### ATOM-SOURCE-20250605-001-0102
**Lines**: 1196-1213
**Context**: anecdote / evidence
**Tension**: novelty=0.70, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.30, actionability=0.90, epistemic_stability=0.60

> Companies can incentivize AI adoption through creative methods, such as offering $10,000 cash prizes weekly for employees who best automate their jobs, or requiring teams to spend two hours trying to use AI for a job before hiring, or to resubmit project proposals after attempting AI integration.

### ATOM-SOURCE-20250605-001-0106
**Lines**: 1258-1263
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.70

> Companies should start experimenting with AI now to discover what works and what doesn't, rather than waiting for pre-made solutions, as proactive experimentation leads to better outcomes.

### ATOM-SOURCE-20250605-001-0115
**Lines**: 1389-1399
**Context**: anecdote / evidence
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.80, epistemic_stability=0.50

> With new Gemini models, one can input all academic papers (even 15 years of work) and have the AI develop themes for a tenure statement, significantly reducing the time and effort required for this complex task.

### ATOM-SOURCE-20250605-001-0116
**Lines**: 1400-1406
**Context**: anecdote / evidence
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.90, epistemic_stability=0.40

> AI models can convert academic papers into video games or assist in coding 3D games, even for individuals without coding skills, demonstrating their capability in creative and technical tasks.

### ATOM-SOURCE-20250605-001-0117
**Lines**: 1416-1429
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.50, actionability=0.90, epistemic_stability=0.50

> Companies should adopt a "maximalist" approach to AI deployment, pushing systems to do everything possible rather than starting with incremental proofs of concept, to discover their full capabilities and avoid getting stuck with limited applications.

### ATOM-SOURCE-20250605-001-0120
**Lines**: 1454-1457
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.80, epistemic_stability=0.50

> To achieve a maximalist approach to AI, organizations need dedicated "labs" where people are encouraged to build "impossible things" without the constraints of immediate cost or latency concerns.

### ATOM-SOURCE-20250605-001-0124
**Lines**: 1526-1538
**Context**: method / claim
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.10, actionability=0.90, epistemic_stability=0.80

> Use AI to get feedback on writing, such as generating 30 ways to end a sentence, reviewing chapters, or checking academic paper citations for proper usage.

### ATOM-SOURCE-20250605-001-0127
**Lines**: 1584-1587
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.10, actionability=0.80, epistemic_stability=0.70

> To get diverse ideas from AI, prompt it better, as this can yield results as varied as those from a group of people.

### ATOM-SOURCE-20250605-001-0128
**Lines**: 1599-1613
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.60

> Companies can encourage AI adoption by changing reward systems for coders using AI tools, stopping meetings to ask AI for feedback on progress or continuation, or assigning every employee an AI consultant for strategic decisions.

### ATOM-SOURCE-20250605-001-0129
**Lines**: 1613-1616
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.10, actionability=0.80, epistemic_stability=0.70

> Utilize AI to simulate training environments or play through scenarios for effective employee training.

### ATOM-SOURCE-20250605-001-0137
**Lines**: 1770-1785
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.30, actionability=0.90, epistemic_stability=0.60

> When prompting an AI for decision-making, provide extensive personal context, define core values, request multiple radical options, simulate outcomes for each, have different 'versions' of yourself (e.g., expedient vs. thoughtful) argue the paths, and then present pros/cons before selecting the best option.

### ATOM-SOURCE-20250605-001-0138
**Lines**: 1789-1794
**Context**: method / evidence
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.70

> To get a specific point of view from an AI that is not an 'average of the internet,' ground it in the writings and principles of a specific person (e.g., training an AI on everything Steve Jobs had ever said).

### ATOM-SOURCE-20250605-001-0145
**Lines**: 1917-1924
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.30, actionability=0.80, epistemic_stability=0.50

> In the early R&D phase, avoid setting numerous Key Performance Indicators (KPIs) because optimizing for specific metrics can lead to unintended consequences and neglect of other important aspects.

### ATOM-SOURCE-20250605-001-0148
**Lines**: 1948-1957
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.40, actionability=0.90, epistemic_stability=0.60

> When adopting AI, organizations should embrace an R&D mindset, acknowledging that productivity gains are clear and quick in areas like coding, but be cautious about optimizing for metrics in less clear-cut domains like document writing.

## Prediction (11)

### ATOM-SOURCE-20250605-001-0027
**Lines**: 130-132
**Context**: speculation / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.90, actionability=0.20, epistemic_stability=0.40

> AGI will likely be a phase rather than a single moment in time, without a sudden, definitive event.

### ATOM-SOURCE-20250605-001-0046
**Lines**: 435-442
**Context**: speculation / claim
**Tension**: novelty=0.80, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.70, actionability=0.40, epistemic_stability=0.40

> Future AI systems will likely become more proactive, capable of asking relevant questions and proactively serving information, rather than solely relying on user input.

### ATOM-SOURCE-20250605-001-0049
**Lines**: 470-472
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.50, contradiction_load=0.20, speculation_risk=0.60, actionability=0.30, epistemic_stability=0.60

> We are likely to remain in a 'longer world of limited autonomy' for AI than many people expect, where human direction and guidance will remain important due to the jagged frontier of AI capabilities.

### ATOM-SOURCE-20250605-001-0064
**Lines**: 720-740
**Context**: speculation / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.70, actionability=0.30, epistemic_stability=0.40

> Societal bottlenecks, such as regulatory environments (e.g., FDA) and the limited physical world capabilities of AI (robotics, organizational structure), will slow down the full impact of AI, even as AI accelerates development in areas like drug discovery.

### ATOM-SOURCE-20250605-001-0077
**Lines**: 840-843
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.80, actionability=0.30, epistemic_stability=0.30

> A significant danger is that if junior employees rely solely on AI, they may never develop the skills necessary to become senior, potentially leading to a lack of future senior talent.

### ATOM-SOURCE-20250605-001-0080
**Lines**: 874-876
**Context**: speculation / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.30, speculation_risk=0.90, actionability=0.20, epistemic_stability=0.20

> The traditional mentorship/apprenticeship chain, which has existed for thousands of years, is being broken by the advent of AI.

### ATOM-SOURCE-20250605-001-0083
**Lines**: 884-886
**Context**: speculation / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.30, speculation_risk=0.90, actionability=0.20, epistemic_stability=0.20

> The disruption of the implicit apprenticeship pipeline by AI is a significant concern, as it may hinder the development of future expertise.

### ATOM-SOURCE-20250605-001-0107
**Lines**: 1267-1272
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.80, actionability=0.40, epistemic_stability=0.50

> An agent-native interface, built around teams and capable of maintaining state across various tasks, makes more sense for AI collaboration than co-pilots embedded in individual documents.

### ATOM-SOURCE-20250605-001-0130
**Lines**: 1630-1650
**Context**: speculation / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.70, actionability=0.30, epistemic_stability=0.40

> In a best-case scenario a decade from now, jobs will become more satisfying due to less grunt work, and productivity will flow in fun ways, allowing humans to focus on key elements like style, approach, and perspective, assuming AI improves 5-10 times but not beyond that.

### ATOM-SOURCE-20250605-001-0140
**Lines**: 1808-1815
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.80, actionability=0.30, epistemic_stability=0.40

> AI systems, currently optimized for predicting the next token, will soon evolve to be optimized for engagement, similar to consumer services, leading to deeper and more enticing conversations.

### ATOM-SOURCE-20250605-001-0143
**Lines**: 1898-1907
**Context**: speculation / claim
**Tension**: novelty=0.30, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.70, actionability=0.10, epistemic_stability=0.30

> The potential for AI to flatter users and optimize for engagement is inevitable.
