# Extraction: SOURCE-20250605-001

**Source**: `SOURCE-20250605-youtube-lecture-strange_loop-ethan_mollick_ai_jagged_frontier.md`
**Atoms extracted**: 154
**Categories**: analogy, claim, concept, framework, praxis_hook, prediction

---

## Analogy (3)

### ATOM-SOURCE-20250605-001-0036
**Lines**: 351-361
**Context**: anecdote / evidence
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> Companies approaching AI by cutting staff to be 'small and lean' are like local brewers in the early 1800s who, upon getting steam power, fired staff to make more money per barrel instead of expanding worldwide like Guinness did by hiring 100,000 people.

### ATOM-SOURCE-20250605-001-0046
**Lines**: 489-495
**Context**: consensus / evidence
**Tension**: novelty=0.40, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.80

> The 'jagged frontier' of AI capability, where it excels in some areas but fails in others, is analogous to the challenges faced by self-driving cars, which were superhuman in some applications but tripped up in others, delaying their widespread deployment.

### ATOM-SOURCE-20250605-001-0141
**Lines**: 1755-1762
**Context**: anecdote / evidence
**Tension**: novelty=0.40, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.70

> AI-generated voices for test audio dubs (e.g., a 'fake Michelle Pfeiffer voice') are like a test bed for experiments, but union protections ensure human actors still record the final versions, demonstrating how AI can accelerate processes without replacing human roles.

## Claim (98)

### ATOM-SOURCE-20250605-001-0002
**Lines**: 6-7
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.60, actionability=0.70, epistemic_stability=0.80

> The uneven capability of AI (the "Jagged Frontier") creates a critical organizational design problem because AI cannot be seamlessly integrated into existing structures that assume predictable human capability profiles.

### ATOM-SOURCE-20250605-001-0005
**Lines**: 12-12
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.80

> The historical tension between augmenting and replacing human intelligence with AI, once theoretical, is now an urgent business strategy decision.

### ATOM-SOURCE-20250605-001-0006
**Lines**: 13-13
**Context**: speculation / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.50, actionability=0.40, epistemic_stability=0.60

> Most organizations are currently drifting towards AI replacing human intelligence without making a conscious strategic choice.

### ATOM-SOURCE-20250605-001-0009
**Lines**: 22-22
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.80

> Optimizing for efficiency with AI is the easier but ultimately less valuable path compared to leveraging AI for abundance and inventing new work.

### ATOM-SOURCE-20250605-001-0011
**Lines**: 28-28
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.60, actionability=0.50, epistemic_stability=0.60

> If AI systems fail in novel situations, organizations that have allowed knowledge collapse will lack the human expertise to fall back on.

### ATOM-SOURCE-20250605-001-0013
**Lines**: 33-33
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.60, actionability=0.70, epistemic_stability=0.80

> The "jagged frontier" of AI capabilities necessitates organizational redesign because traditional organizational structures assume predictable human capability profiles, which AI disrupts.

### ATOM-SOURCE-20250605-001-0014
**Lines**: 35-35
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.80

> Prompting is a foundational skill, not merely clever tricks, involving structured communication of intent, and is both teachable and essential for AI interaction.

### ATOM-SOURCE-20250605-001-0015
**Lines**: 37-37
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.80

> Achieving an "abundance mindset" with AI requires courage to resist the natural gravitational pull towards optimizing for efficiency.

### ATOM-SOURCE-20250605-001-0016
**Lines**: 39-39
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.80

> Apprenticeship and knowledge development are critical organizational resilience investments, not inefficiencies, especially in the context of AI.

### ATOM-SOURCE-20250605-001-0017
**Lines**: 41-41
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.70

> Measuring Key Performance Indicators (KPIs) too early in the R&D phase of AI adoption can lead to optimizing for the wrong objectives.

### ATOM-SOURCE-20250605-001-0018
**Lines**: 69-71
**Context**: anecdote / evidence
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.50, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> The actual solution for AI, contrary to earlier elaborate schemes for creating intelligence, turned out to be feeding a lot of language into a learning system, resulting in LLMs.

### ATOM-SOURCE-20250605-001-0019
**Lines**: 72-75
**Context**: anecdote / evidence
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> Many of the technical ideas from early AI research (during AI winters) proved incorrect, but core philosophies, like the Engelbart vs. Minsky tension, are now relevant again.

### ATOM-SOURCE-20250605-001-0020
**Lines**: 90-94
**Context**: consensus / evidence
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.80

> A new paper showed that GPT-4.5 is capable of passing the original three-party Turing test, with 70% of people picking the AI as human.

### ATOM-SOURCE-20250605-001-0021
**Lines**: 102-107
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.80

> The debate between AI augmentation and replacement of humans never fully developed because the technology was largely fictional, but it is now suddenly very important.

### ATOM-SOURCE-20250605-001-0022
**Lines**: 111-115
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> The concept of AGI is badly defined, and historical tests like the Turing test were designed when computers clearly failed them, making them less useful for current AI capabilities.

### ATOM-SOURCE-20250605-001-0023
**Lines**: 116-118
**Context**: consensus / evidence
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.80

> AI is now acing creativity tests that were originally designed for humans and were always mediocre measures of human creativity.

### ATOM-SOURCE-20250605-001-0024
**Lines**: 119-122
**Context**: consensus / limitation
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> Current tests for human empathy, such as the "reading the mind in the eyes test," were not designed for AI and are therefore inadequate for evaluating AI's emotional capabilities.

### ATOM-SOURCE-20250605-001-0025
**Lines**: 131-133
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.60, actionability=0.30, epistemic_stability=0.60

> AGI is likely to be a phase of continuous development rather than a single moment in time marked by fireworks.

### ATOM-SOURCE-20250605-001-0026
**Lines**: 139-142
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.80

> Connecting AI to existing systems and company processes in the right way can create something much more effective than simply prompting a conversational AI.

### ATOM-SOURCE-20250605-001-0027
**Lines**: 150-156
**Context**: consensus / limitation
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.70

> A critical problem in AI development is that researchers in labs are predominantly math and science-oriented, leading them to prioritize coding, math, and biology (for longevity) as the most important applications.

### ATOM-SOURCE-20250605-001-0028
**Lines**: 199-219
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.10, actionability=0.50, epistemic_stability=0.80

> One of the most critical problems facing AI development is the lack of business-focused benchmarks, as current benchmarks are primarily designed by math and science people for coding and scientific applications.

### ATOM-SOURCE-20250605-001-0030
**Lines**: 256-262
**Context**: consensus / limitation
**Tension**: novelty=0.20, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.10, actionability=0.70, epistemic_stability=0.70

> The ability to test, correct, and run test sets for AI agents, especially when deploying them, has been severely limited.

### ATOM-SOURCE-20250605-001-0031
**Lines**: 270-296
**Context**: consensus / claim
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.90

> Organizational structures developed over centuries (e.g., the org chart from 1855, Ford's production lines, agile development) are based on the assumption of human-sized intelligence and deployment constraints, which is no longer true in an AI-driven world.

### ATOM-SOURCE-20250605-001-0032
**Lines**: 298-309
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.20, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.70

> Modern Western companies have largely outsourced organizational innovation to enterprise software companies and consulting firms, rather than innovating internally.

### ATOM-SOURCE-20250605-001-0034
**Lines**: 327-335
**Context**: anecdote / counterevidence
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.30, speculation_risk=0.40, actionability=0.50, epistemic_stability=0.60

> Many companies are currently viewing AI as a normal efficiency technology, leading them to cut staff (e.g., 25% of customer service) after achieving efficiency gains, which is a dangerous approach.

### ATOM-SOURCE-20250605-001-0035
**Lines**: 341-348
**Context**: consensus / limitation
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.60, actionability=0.60, epistemic_stability=0.80

> If employees fear being fired or punished for using AI, they will not reveal efficiency gains, hindering AI deployment and innovation within the organization.

### ATOM-SOURCE-20250605-001-0037
**Lines**: 370-379
**Context**: consensus / counterevidence
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.40, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.70

> The historical expectation that AI would automate mundane repetitive tasks first, then knowledge work, and finally creative tasks has been inverted; creative tasks and knowledge work have been easier to automate than mundane repetitive tasks.

### ATOM-SOURCE-20250605-001-0038
**Lines**: 383-392
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.80

> The automation of tasks by AI has proceeded in an unexpected order: creative tasks and knowledge work have been more amenable to AI than mundane, repetitive tasks, which have proven tricky to automate.

### ATOM-SOURCE-20250605-001-0039
**Lines**: 384-391
**Context**: anecdote / evidence
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.50, actionability=0.60, epistemic_stability=0.40

> Prompt engineering sometimes requires justifying to the AI why it should perform a step, rather than just instructing it, indicating a 'weird' emotional or persuasive aspect to current AI systems.

### ATOM-SOURCE-20250605-001-0040
**Lines**: 398-407
**Context**: anecdote / evidence
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.30, actionability=0.50, epistemic_stability=0.60

> Prompt engineering sometimes requires justifying to the AI why it should perform a step, rather than simply instructing it, indicating a surprising 'emotional' or 'convincible' aspect to current AI systems.

### ATOM-SOURCE-20250605-001-0045
**Lines**: 477-483
**Context**: consensus / claim
**Tension**: novelty=0.50, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.20, epistemic_stability=0.80

> AI's capability frontier is 'jagged,' meaning it can be genius in some areas and completely incompetent in others, making its deployment in organizations difficult and bottlenecking progress.

### ATOM-SOURCE-20250605-001-0047
**Lines**: 499-507
**Context**: consensus / evidence
**Tension**: novelty=0.40, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.80

> Narrow AI agents, such as those for deep research (e.g., Google, OpenAI, Perplexity), are already very good at specific tasks like finding information and providing answers, making delegation of complex tasks to them feasible.

### ATOM-SOURCE-20250605-001-0048
**Lines**: 515-519
**Context**: consensus / claim
**Tension**: novelty=0.50, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.60, actionability=0.10, epistemic_stability=0.70

> The 'jagged frontier' of AI capability is constantly pushing outwards, meaning that some current limitations will persist, while others will be overcome as AI models improve.

### ATOM-SOURCE-20250605-001-0052
**Lines**: 608-612
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.30, actionability=0.60, epistemic_stability=0.50

> A significant bottleneck in AI transformation within organizations is that C-level executives have not sufficiently used these systems themselves, hindering rapid adoption.

### ATOM-SOURCE-20250605-001-0053
**Lines**: 625-639
**Context**: anecdote / evidence
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.30, actionability=0.50, epistemic_stability=0.40

> There are at least seven or eight reasons why employees use AI tools but do not disclose it to their leadership, including a desire to appear genius, fear that efficiency gains lead to layoffs, and reluctance to share valuable ideas without personal risk.

### ATOM-SOURCE-20250605-001-0055
**Lines**: 673-678
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.10, actionability=0.60, epistemic_stability=0.80

> AI significantly enhances ideation, leading to the generation of better ideas, especially when individuals collaborate with AI and share information.

### ATOM-SOURCE-20250605-001-0056
**Lines**: 684-699
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.70

> AI is particularly effective at accelerating cycles, such as rapid prototyping and development, by quickly generating ideas, testing them with rubrics and simulated users, and creating working prototypes.

### ATOM-SOURCE-20250605-001-0057
**Lines**: 705-713
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.30, actionability=0.60, epistemic_stability=0.60

> Research agents, knowledge management agents, and advisory AI (providing timely advice) are emerging as particularly valuable applications of AI.

### ATOM-SOURCE-20250605-001-0059
**Lines**: 725-741
**Context**: consensus / limitation
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.60, actionability=0.40, epistemic_stability=0.70

> Societal bottlenecks, such as regulatory environments (e.g., FDA), and the limited ability of AI to act in the physical world (robotics, organizational structure) will slow down the full impact of AI advancements.

### ATOM-SOURCE-20250605-001-0060
**Lines**: 741-748
**Context**: consensus / limitation
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.60, actionability=0.50, epistemic_stability=0.60

> While AI agents are appealing because they automate tasks, they will eventually encounter friction points in the real world, causing slowdowns.

### ATOM-SOURCE-20250605-001-0061
**Lines**: 761-779
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.30, actionability=0.60, epistemic_stability=0.60

> In an AI-driven organizational landscape, valuable roles include management roles focused on systems, deep subject matter experts, broad experts across multiple areas, system leaders, and individuals with good taste.

### ATOM-SOURCE-20250605-001-0062
**Lines**: 765-773
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.60, actionability=0.40, epistemic_stability=0.70

> AI systems are not as proficient as top experts in their fields; while AI performs well against the average, individuals in the top 2% of expertise will still outperform AI.

### ATOM-SOURCE-20250605-001-0063
**Lines**: 770-773
**Context**: consensus / claim
**Tension**: novelty=0.10, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.80

> Roles focused on understanding and managing systems are highly valuable because systems inherently present problems.

### ATOM-SOURCE-20250605-001-0064
**Lines**: 774-780
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> Experts at the top of their fields (top 2%) consistently outperform AI systems, which tend to be measured against the average performance in a field.

### ATOM-SOURCE-20250605-001-0066
**Lines**: 798-802
**Context**: consensus / evidence
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.80

> A Boston Consulting Group study was the first to document that lower performers experienced the highest performance gain when using AI.

### ATOM-SOURCE-20250605-001-0067
**Lines**: 802-811
**Context**: consensus / evidence
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.70

> The reason lower performers gained the most from AI was due to 'retainment': for 80% of consulting tasks, the only way to err was to add personal thoughts or ideas to the AI's answer, meaning simply turning in the AI's output (which performs at the 8th percentile) resulted in good performance.

### ATOM-SOURCE-20250605-001-0068
**Lines**: 817-819
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.30, actionability=0.40, epistemic_stability=0.60

> Highly skilled individuals who use AI effectively can achieve 10 to 100 times performance improvement.

### ATOM-SOURCE-20250605-001-0070
**Lines**: 833-837
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.30, actionability=0.40, epistemic_stability=0.60

> AI can bring an entrepreneur's weaker areas up to 80% proficiency, replacing some of their work, while in their 99.9th percentile area, AI can provide a 100x multiplier.

### ATOM-SOURCE-20250605-001-0072
**Lines**: 854-862
**Context**: consensus / claim
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.10, actionability=0.70, epistemic_stability=0.90

> The traditional method of learning white-collar knowledge work for thousands of years has been apprenticeship, involving repetitive tasks and receiving corrections to build expertise.

### ATOM-SOURCE-20250605-001-0073
**Lines**: 862-867
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.80

> Apprenticeship involves not just learning specific tasks, but also understanding the underlying reasons for success or failure and absorbing broader goals from a mentor.

### ATOM-SOURCE-20250605-001-0075
**Lines**: 874-882
**Context**: consensus / evidence
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.60, actionability=0.30, epistemic_stability=0.50

> Junior employees now use AI to hide their lack of knowledge, turning off their brains, while middle managers prefer AI over interns due to its superior performance and lack of issues.

### ATOM-SOURCE-20250605-001-0079
**Lines**: 979-985
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.70

> The skills required to use AI effectively are limited to about five or six classes worth, unless one intends to build an LLM, with the majority of proficiency coming from experience.

### ATOM-SOURCE-20250605-001-0080
**Lines**: 989-994
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.30, speculation_risk=0.10, actionability=0.70, epistemic_stability=0.60

> Universities are well-suited to teach broad and deep knowledge, but their current teaching methods are failing, as evidenced by widespread cheating that AI detectors cannot effectively stop.

### ATOM-SOURCE-20250605-001-0081
**Lines**: 997-1005
**Context**: anecdote / evidence
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.20, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.70

> A study showed that from 2007 to 2020, the percentage of Rutgers students who did their homework and performed better on tests decreased significantly (from almost all to 20%), indicating a rise in cheating.

### ATOM-SOURCE-20250605-001-0084
**Lines**: 1044-1057
**Context**: hypothesis / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.60, actionability=0.30, epistemic_stability=0.40

> The role of a Chief AI Officer is problematic because no one, including experts in AI labs, truly understands the full capabilities or future direction of AI, making it difficult to find someone with sufficient experience.

### ATOM-SOURCE-20250605-001-0085
**Lines**: 1060-1066
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.30, actionability=0.40, epistemic_stability=0.70

> AI's meaning and application have significantly changed from 2010-2022 (focused on large data and boosting) to the current era of LLMs, making prior 'AI expertise' potentially less relevant for new challenges.

### ATOM-SOURCE-20250605-001-0086
**Lines**: 1068-1072
**Context**: consensus / claim
**Tension**: novelty=0.50, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.60

> Organizations should cultivate internal expertise for AI adoption because only those with deep domain knowledge can effectively use AI and discern its outputs.

### ATOM-SOURCE-20250605-001-0087
**Lines**: 1074-1083
**Context**: anecdote / evidence
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.40, actionability=0.50, epistemic_stability=0.50

> Junior employees are less effective at using AI than senior employees, as senior employees' expertise allows them to critically evaluate AI-generated outputs, unlike junior staff who may accept them uncritically.

### ATOM-SOURCE-20250605-001-0090
**Lines**: 1149-1156
**Context**: consensus / evidence
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.60, actionability=0.10, epistemic_stability=0.70

> In almost every organization, only 20-30% of employees will use an internal AI model, with others either not using it or secretly using external AI tools.

### ATOM-SOURCE-20250605-001-0091
**Lines**: 1170-1175
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.30, actionability=0.20, epistemic_stability=0.60

> It is difficult to recommend hiring many people for AI roles when the criteria for success in these roles are unknown and depend heavily on organizational context.

### ATOM-SOURCE-20250605-001-0093
**Lines**: 1192-1197
**Context**: consensus / evidence
**Tension**: novelty=0.30, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.60, actionability=0.10, epistemic_stability=0.70

> Employees will recognize if AI implementation is a threat to their jobs, especially in large, mature organizations that tend to use AI to cut staff.

### ATOM-SOURCE-20250605-001-0095
**Lines**: 1216-1226
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.60, actionability=0.70, epistemic_stability=0.60

> A clear vision from leadership about how AI will transform jobs (e.g., 'your job in four years will be working with AI') is crucial, as employees need to understand the future implications rather than executives deferring the discussion.

### ATOM-SOURCE-20250605-001-0096
**Lines**: 1234-1248
**Context**: consensus / evidence
**Tension**: novelty=0.50, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.70

> A study of 776 people at Proctor and Gamble found that individuals working alone with AI performed as well as teams and were happier, while teams working with AI were more likely to generate breakthrough ideas.

### ATOM-SOURCE-20250605-001-0097
**Lines**: 1248-1255
**Context**: consensus / evidence
**Tension**: novelty=0.50, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.70

> The same study showed that AI tended to even out expertise, meaning solutions became more balanced across technical and marketing aspects when AI was involved, suggesting AI supplements human work.

### ATOM-SOURCE-20250605-001-0100
**Lines**: 1277-1280
**Context**: hypothesis / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.50, actionability=0.40, epistemic_stability=0.50

> Agentic systems are more interesting for their ability to bring together many threads of work than for their automation capabilities.

### ATOM-SOURCE-20250605-001-0101
**Lines**: 1286-1294
**Context**: consensus / evidence
**Tension**: novelty=0.50, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.70

> The hallucination problem in AI models significantly decreases when connected to data sources and when smarter models are used; for example, a 0.1% hallucination rate was observed in the New England Journal of Medicine case studies with advanced models compared to 25% in previous models.

### ATOM-SOURCE-20250605-001-0102
**Lines**: 1296-1302
**Context**: anecdote / evidence
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.60

> Early AI models like ChatGPT 3.5 produced obvious errors, making it easy for students to use them without adding their own thinking and still only achieve a 'B' grade, whereas GPT-4 performs as well as a human.

### ATOM-SOURCE-20250605-001-0103
**Lines**: 1342-1348
**Context**: anecdote / evidence
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.70

> The hallucination rate of AI models on New England Journal of Medicine case studies dropped significantly (from 25% to 0.25%) when connected to data sources and using smarter models like 01 preview.

### ATOM-SOURCE-20250605-001-0104
**Lines**: 1354-1359
**Context**: anecdote / evidence
**Tension**: novelty=0.10, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.60

> Early AI models like ChatGPT 3.5 were not capable of producing work as good as human students without their own thinking, resulting in B-level work.

### ATOM-SOURCE-20250605-001-0105
**Lines**: 1360-1362
**Context**: anecdote / evidence
**Tension**: novelty=0.10, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.60

> GPT-4 performs as well as human students who are not putting in a huge amount of effort.

### ATOM-SOURCE-20250605-001-0106
**Lines**: 1365-1371
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.30, actionability=0.40, epistemic_stability=0.50

> AI systems are capable of much more when approached agentically, as demonstrated by work from Google and Carnegie Mellon.

### ATOM-SOURCE-20250605-001-0107
**Lines**: 1371-1373
**Context**: hypothesis / claim
**Tension**: novelty=0.30, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.40, actionability=0.30, epistemic_stability=0.40

> Building effective AI research systems is more a matter of willpower than technical limitation.

### ATOM-SOURCE-20250605-001-0108
**Lines**: 1374-1380
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.60

> Current AI models are capable of serving as tutors, science applications, and internal training systems, but widespread implementation is lacking.

### ATOM-SOURCE-20250605-001-0109
**Lines**: 1390-1397
**Context**: anecdote / evidence
**Tension**: novelty=0.10, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.70

> Latest Gemini models can analyze academic papers and identify core themes, performing a task that previously took months for a human.

### ATOM-SOURCE-20250605-001-0110
**Lines**: 1398-1403
**Context**: anecdote / evidence
**Tension**: novelty=0.10, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.70

> AI models can convert academic papers into working video games and assist in coding 3D games, even for non-coders.

### ATOM-SOURCE-20250605-001-0112
**Lines**: 1421-1426
**Context**: consensus / limitation
**Tension**: novelty=0.20, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.30, epistemic_stability=0.60

> Many organizations are too incrementalist in their AI adoption, focusing on simple tasks like document summarization which AI could do long ago, instead of leveraging AI for more complex actions.

### ATOM-SOURCE-20250605-001-0113
**Lines**: 1433-1439
**Context**: consensus / limitation
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.30, actionability=0.20, epistemic_stability=0.60

> The problem with focusing on 'use cases that work well' in AI deployment is that they are often limited by the current system's capabilities and what people were able to do at that point, leading to semi-successful products built around limitations.

### ATOM-SOURCE-20250605-001-0114
**Lines**: 1440-1445
**Context**: consensus / limitation
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.30, actionability=0.20, epistemic_stability=0.60

> IT teams often prioritize low latency and low cost for AI deployment, which is often the opposite of what is needed for high intelligence in these models.

### ATOM-SOURCE-20250605-001-0115
**Lines**: 1445-1448
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.60

> There are situations where paying a higher cost (e.g., 15 cents) for a really smart AI decision or new chemical is a reasonable trade-off.

### ATOM-SOURCE-20250605-001-0116
**Lines**: 1449-1452
**Context**: consensus / limitation
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.30, actionability=0.20, epistemic_stability=0.60

> People tend to build off cheap, small AI models and then get stuck later, highlighting the importance of being model-agnostic and continuously updating.

### ATOM-SOURCE-20250605-001-0120
**Lines**: 1480-1486
**Context**: anecdote / evidence
**Tension**: novelty=0.10, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.20, actionability=0.10, epistemic_stability=0.60

> A study showed that individuals who received advice from AI were ultimately more productive, with the benefits largely accruing to more senior individuals rather than lower performers who struggled to internalize the advice.

### ATOM-SOURCE-20250605-001-0122
**Lines**: 1542-1558
**Context**: anecdote / evidence
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.60

> A study on entrepreneurs in Kenya showed that high performers who received advice from GPT-4 experienced an 8-13% improvement in profitability, which is a significant boost for advice alone.

### ATOM-SOURCE-20250605-001-0123
**Lines**: 1563-1566
**Context**: anecdote / evidence
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.60

> Low performers in the Kenya study did worse when receiving AI advice because their businesses were already struggling, making it difficult for them to implement the ideas.

### ATOM-SOURCE-20250605-001-0124
**Lines**: 1566-1579
**Context**: hypothesis / limitation
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.30, speculation_risk=0.40, actionability=0.30, epistemic_stability=0.50

> There is a danger that AI's advisory role and second opinions could lead to everyone being shaped in the same direction, similar to how AI models like GPT-40 tend to generate ideas related to crypto, AR/VR, and environmentally friendly concepts due to their training data.

### ATOM-SOURCE-20250605-001-0132
**Lines**: 1660-1667
**Context**: rebuttal / claim
**Tension**: novelty=0.40, consensus_pressure=0.30, contradiction_load=0.40, speculation_risk=0.30, actionability=0.40, epistemic_stability=0.50

> The focus on existential risks from AI, while important, is less concerning than the issue of agency over current decisions regarding how AI is used and shaped.

### ATOM-SOURCE-20250605-001-0133
**Lines**: 1667-1675
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.20, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.60

> AI should not be viewed as an unstoppable force like a steamroller; instead, its usage and shaping are determined by human decisions, and everyone involved has the agency to influence its direction.

### ATOM-SOURCE-20250605-001-0134
**Lines**: 1709-1712
**Context**: speculation / claim
**Tension**: novelty=0.40, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.70, actionability=0.20, epistemic_stability=0.40

> We are close to AI being able to talk individually to everybody in their language and voice, which will dramatically change jobs.

### ATOM-SOURCE-20250605-001-0135
**Lines**: 1716-1722
**Context**: rebuttal / claim
**Tension**: novelty=0.60, consensus_pressure=0.70, contradiction_load=0.30, speculation_risk=0.40, actionability=0.50, epistemic_stability=0.50

> The focus on existential risks of AI, while worth thinking about, is less concerning than the lack of agency over current decisions regarding AI's use and shaping.

### ATOM-SOURCE-20250605-001-0136
**Lines**: 1723-1727
**Context**: rebuttal / claim
**Tension**: novelty=0.50, consensus_pressure=0.60, contradiction_load=0.20, speculation_risk=0.30, actionability=0.60, epistemic_stability=0.60

> Treating AI as an unstoppable technological force (like a steamroller) is inaccurate; its use and shape are determined by human choices.

### ATOM-SOURCE-20250605-001-0138
**Lines**: 1738-1742
**Context**: consensus / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.30, actionability=0.40, epistemic_stability=0.60

> Many people in the technical AI field do not understand the messy reality of how actual organizations work, leading to naive assumptions about AI's immediate impact.

### ATOM-SOURCE-20250605-001-0139
**Lines**: 1742-1746
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.60, actionability=0.30, epistemic_stability=0.70

> Even super smart AI agents will not necessarily change how companies work overnight, as organizational change happens in bursts and is complex.

### ATOM-SOURCE-20250605-001-0140
**Lines**: 1749-1753
**Context**: rebuttal / claim
**Tension**: novelty=0.60, consensus_pressure=0.70, contradiction_load=0.20, speculation_risk=0.60, actionability=0.40, epistemic_stability=0.60

> The idea that AI will replace Hollywood is based on a misunderstanding of the extensive work involved in film production, much of which AI can accelerate rather than replace.

### ATOM-SOURCE-20250605-001-0144
**Lines**: 1803-1807
**Context**: consensus / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.80

> AI provides opinions and points of view, not universal right answers, and its output is shapable by the principles and values given to it.

### ATOM-SOURCE-20250605-001-0147
**Lines**: 1823-1838
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.70, contradiction_load=0.20, speculation_risk=0.50, actionability=0.40, epistemic_stability=0.50

> Optimizing AI for engagement is risky, as evidenced by social media, and early evidence suggests it makes AI more 'sticky' by using flattery and chatty language.

### ATOM-SOURCE-20250605-001-0149
**Lines**: 1846-1848
**Context**: hypothesis / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.70, epistemic_stability=0.50

> In the early R&D phase of AI, having a multitude of Key Performance Indicators (KPIs) is detrimental.

### ATOM-SOURCE-20250605-001-0150
**Lines**: 1898-1906
**Context**: speculation / claim
**Tension**: novelty=0.30, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.70, actionability=0.10, epistemic_stability=0.40

> Optimizing for engagement in AI systems, similar to social media, can lead to risky outcomes.

### ATOM-SOURCE-20250605-001-0152
**Lines**: 1929-1939
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.20, speculation_risk=0.30, actionability=0.20, epistemic_stability=0.50

> Organizations are often not structured to support the necessary KPIs for evaluating novel technologies like AI, as traditional metrics (e.g., number of words produced) may not align with desired outcomes.

### ATOM-SOURCE-20250605-001-0153
**Lines**: 1947-1952
**Context**: speculation / claim
**Tension**: novelty=0.40, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.60, actionability=0.10, epistemic_stability=0.40

> Relying on measurable KPIs for new technologies, especially those that default to cost savings, often leads to negative outcomes like job losses, which can undermine the overall purpose.

## Concept (9)

### ATOM-SOURCE-20250605-001-0001
**Lines**: 4-5
**Context**: speculation / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.60, actionability=0.60, epistemic_stability=0.70

> The "Jagged Frontier" describes the fundamentally uneven capability of AI, where it excels in some domains but performs poorly in adjacent ones, making competence unpredictable from task similarity.

### ATOM-SOURCE-20250605-001-0004
**Lines**: 10-11
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.90

> The "Engelbart vs. Minsky Tension" refers to two opposing philosophies for AI: Engelbart's view of augmenting human intelligence (technology as amplifier) and Minsky's view of replacing human intelligence (technology as substitute).

### ATOM-SOURCE-20250605-001-0008
**Lines**: 21-21
**Context**: hypothesis / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.30, actionability=0.70, epistemic_stability=0.70

> The "Abundance vs. Efficiency Mindset" is a critical strategic choice for companies: either optimize past work to do it cheaper (efficiency) or invent new work and capabilities (abundance).

### ATOM-SOURCE-20250605-001-0010
**Lines**: 26-27
**Context**: hypothesis / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.40, actionability=0.60, epistemic_stability=0.70

> The "Knowledge Collapse Risk" refers to the danger that AI shortcuts bypass human apprenticeship and tacit knowledge development, leading organizations to lose deep expertise.

### ATOM-SOURCE-20250605-001-0041
**Lines**: 409-425
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.70

> Jobs are bundles of many different tasks, often not designed optimally, and some of these tasks (e.g., grading, counseling support for a professor) are 'hot AI jobs' that could be offloaded to AI.

### ATOM-SOURCE-20250605-001-0044
**Lines**: 453-460
**Context**: hypothesis / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.30, epistemic_stability=0.60

> In an era of AI-driven 'abundance' where systems can generate many options (e.g., 10 papers), the ability to curate and select the best options, referred to as 'taste,' becomes increasingly important.

### ATOM-SOURCE-20250605-001-0069
**Lines**: 824-832
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.80

> Entrepreneurship involves being highly proficient in one area while being deficient in many others; the challenge is to prevent these deficiencies from hindering the core strength.

### ATOM-SOURCE-20250605-001-0118
**Lines**: 1457-1464
**Context**: consensus / claim
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.10, actionability=0.50, epistemic_stability=0.70

> The 'centaur' approach to AI integration involves dividing work between humans and AI, where each handles distinct tasks (e.g., human does analysis, AI handles emails).

### ATOM-SOURCE-20250605-001-0119
**Lines**: 1464-1479
**Context**: consensus / claim
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.10, actionability=0.50, epistemic_stability=0.70

> The 'cyborg' approach to AI integration involves a more blended workflow where AI assists and augments human tasks, such as helping with writing by suggesting sentence endings, providing feedback on drafts, or ensuring proper citations.

## Framework (5)

### ATOM-SOURCE-20250605-001-0007
**Lines**: 16-19
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.70

> Three ingredients are essential for successful AI adoption: 1) Domain expertise (knowing what good looks like), 2) Prompt craft skill (learnable and foundational), and 3) Workflow integration (weaving AI into work processes).

### ATOM-SOURCE-20250605-001-0042
**Lines**: 429-435
**Context**: method / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.80, epistemic_stability=0.60

> AI augmentation can occur at two levels: Level 1 involves offloading tasks one is less skilled at within a job bundle, and Level 2 focuses on using AI to boost current performance in core tasks.

### ATOM-SOURCE-20250605-001-0050
**Lines**: 535-545
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.80, epistemic_stability=0.60

> To make AI work in an organization, three elements are needed: 'leadership' (CEO-level grappling with organizational vision and incentives), 'lab' (for experimentation), and 'crowd' (bottom-up adoption).

### ATOM-SOURCE-20250605-001-0051
**Lines**: 586-588
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.60

> To successfully implement AI in an organization, three elements are necessary: leadership (setting vision and incentives), lab (R&D to productize individual AI uses), and crowd (widespread employee access and sharing of AI tools).

### ATOM-SOURCE-20250605-001-0065
**Lines**: 781-785
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.60

> Three key factors that provide an advantage in the current technological landscape are deep subject matter expertise, broad expertise across many areas (as a system leader), and good taste.

## Praxis Hook (28)

### ATOM-SOURCE-20250605-001-0003
**Lines**: 8-8
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.70

> Organizations must ruthlessly map AI's actual capabilities and then restructure work around those capabilities to effectively integrate AI.

### ATOM-SOURCE-20250605-001-0012
**Lines**: 29-29
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.30, actionability=0.90, epistemic_stability=0.70

> Organizations should intentionally reserve some work for human development, even if AI could perform it, to prevent knowledge collapse and foster expertise.

### ATOM-SOURCE-20250605-001-0029
**Lines**: 227-254
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.60

> Companies should develop their own AI benchmarks, including direct number-based metrics (e.g., error rate in accounting processes) and 'vibes-based' assessments by outside experts to judge the quality of AI outputs against human performance (e.g., Turing tests for analysis reports or strategy advice).

### ATOM-SOURCE-20250605-001-0033
**Lines**: 310-321
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.30, actionability=0.80, epistemic_stability=0.60

> Leaders must innovate organizational structures from the ground up, deciding between AI augmentation or replacement, and building systems based on that choice (fewer people doing more impressive work vs. more people doing ever more work).

### ATOM-SOURCE-20250605-001-0049
**Lines**: 520-528
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.50, actionability=0.70, epistemic_stability=0.60

> Organizations face a dilemma: either wait for the AI frontier to advance and solve current problems, or build solutions around existing jaggedness. The key is to do both, but investing too much in solving current jaggedness risks creating legacy systems that become obsolete as models improve.

### ATOM-SOURCE-20250605-001-0054
**Lines**: 642-657
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.60

> To leverage individual AI prompting into organizational products and agents, it is necessary to extract promising uses and conduct R&D, including benchmarking and transforming basic prompts into agentic systems.

### ATOM-SOURCE-20250605-001-0077
**Lines**: 895-900
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.50, actionability=0.80, epistemic_stability=0.50

> To effectively teach expertise in the age of AI, we must move towards a more formal approach, similar to how expertise is built in sports through practice with a coach.

### ATOM-SOURCE-20250605-001-0078
**Lines**: 963-972
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.60

> To teach people expertise, especially in the intelligence era, we should formally design how we want to teach it, similar to how expertise is built in sports through practice with a coach.

### ATOM-SOURCE-20250605-001-0083
**Lines**: 1025-1034
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.90, epistemic_stability=0.60

> To transform teaching with AI, integrate AI simulations, AI mentors for class material, AI for building cases, and AI for providing feedback in team settings, all to foster active and engaged classroom experiences.

### ATOM-SOURCE-20250605-001-0088
**Lines**: 1087-1099
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.80, epistemic_stability=0.60

> To foster AI development within an organization, link the 'crowd' (20-30% of employees using AI) with a 'lab' (1-2% of employees who are exceptionally brilliant at AI and can lead development efforts).

### ATOM-SOURCE-20250605-001-0089
**Lines**: 1146-1169
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.60

> To effectively integrate AI, organizations should link 'the crowd' (employees using AI) with 'the lab' (dedicated AI development). Identify the 1-2% of employees who are brilliant at using AI and bring them into the lab to lead development efforts.

### ATOM-SOURCE-20250605-001-0092
**Lines**: 1176-1192
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.60, actionability=0.80, epistemic_stability=0.60

> To incentivize employees to automate their own roles with AI, leadership must clearly communicate that AI adoption will not lead to job losses but rather expand organizational capabilities. This is easier for companies with good culture and in growth mode.

### ATOM-SOURCE-20250605-001-0094
**Lines**: 1199-1215
**Context**: method / evidence
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.50

> Companies can incentivize AI adoption through creative methods, such as offering $10,000 cash prizes weekly for employees who best automate their jobs, or requiring teams to spend two hours trying to use AI for a job before hiring, or for a project before submitting a proposal.

### ATOM-SOURCE-20250605-001-0098
**Lines**: 1257-1262
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.60

> Companies should start experimenting with AI now to discover what works and what doesn't, rather than waiting for pre-made solutions, as proactive experimentation leads to better outcomes.

### ATOM-SOURCE-20250605-001-0111
**Lines**: 1414-1421
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.90, epistemic_stability=0.50

> Companies should adopt a maximalist approach to AI deployment, pushing systems to do everything possible rather than incremental adoption, to discover their full capabilities and set benchmarks for future systems.

### ATOM-SOURCE-20250605-001-0117
**Lines**: 1453-1455
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.40, actionability=0.90, epistemic_stability=0.50

> To achieve a maximalist approach to AI, organizations need dedicated 'labs' where people are tasked with building 'impossible things' with AI.

### ATOM-SOURCE-20250605-001-0121
**Lines**: 1526-1538
**Context**: method / claim
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.10, actionability=0.90, epistemic_stability=0.70

> Use AI to get feedback on writing, such as generating 30 ways to end a sentence, reviewing chapters, or checking academic paper citations, as this is where its power truly lies.

### ATOM-SOURCE-20250605-001-0125
**Lines**: 1580-1583
**Context**: method / claim
**Tension**: novelty=0.20, consensus_pressure=0.70, contradiction_load=0.10, speculation_risk=0.10, actionability=0.80, epistemic_stability=0.70

> To get diverse ideas from AI, prompt it better, as studies show this can yield results as varied as those from a group of people.

### ATOM-SOURCE-20250605-001-0126
**Lines**: 1596-1598
**Context**: method / claim
**Tension**: novelty=0.20, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.10, actionability=0.90, epistemic_stability=0.70

> Companies should change reward systems to encourage coders to use AI tools.

### ATOM-SOURCE-20250605-001-0127
**Lines**: 1598-1605
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.60

> During ideation sessions or meetings, stop and ask AI for feedback on progress or whether the meeting should continue, even in physical settings.

### ATOM-SOURCE-20250605-001-0128
**Lines**: 1606-1609
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.60

> Provide every employee with an AI consultant or advisor for strategy and decision-making.

### ATOM-SOURCE-20250605-001-0129
**Lines**: 1609-1612
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.60

> Utilize AI to simulate training environments or play through training scenarios.

### ATOM-SOURCE-20250605-001-0137
**Lines**: 1731-1735
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.70

> We can make choices to defend what we consider important to being human, what customers need, and what society needs in the development and application of AI.

### ATOM-SOURCE-20250605-001-0142
**Lines**: 1776-1789
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.30, actionability=0.90, epistemic_stability=0.60

> To make decisions with an AI, provide it with extensive personal context, define core values, ask it to generate multiple radical options, simulate outcomes for each, have it argue different perspectives (e.g., 'expedient' vs. 'thoughtful'), list pros and cons, and then select the best path.

### ATOM-SOURCE-20250605-001-0143
**Lines**: 1791-1799
**Context**: anecdote / evidence
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.70

> Grounding an AI in a specific person's writings (e.g., everything Steve Jobs ever said) can provide a unique point of view that is not merely the average of internet data, offering specific guidance like 'always collocate teams' for communication problems.

### ATOM-SOURCE-20250605-001-0145
**Lines**: 1807-1810
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.70

> If you believe your principles about the world are right, giving those principles to an AI to help execute them is more effective than simply letting the AI dictate information.

### ATOM-SOURCE-20250605-001-0151
**Lines**: 1917-1923
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.60

> In the early R&D phase of new technologies, avoid setting numerous Key Performance Indicators (KPIs) because optimizing for specific metrics can lead to unintended consequences and neglect of other important aspects.

### ATOM-SOURCE-20250605-001-0154
**Lines**: 1952-1964
**Context**: method / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.70, epistemic_stability=0.60

> When adopting new technologies, organizations should embrace an R&D mindset, acknowledging that productivity gains are clear and quick in areas like coding, but be cautious about optimizing for productivity in less clear-cut areas like document writing without a defined purpose.

## Prediction (11)

### ATOM-SOURCE-20250605-001-0043
**Lines**: 436-444
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.80, actionability=0.40, epistemic_stability=0.50

> Future AI systems will likely become more proactive, capable of asking relevant questions and proactively serving information, rather than solely relying on user input and prompts.

### ATOM-SOURCE-20250605-001-0058
**Lines**: 714-723
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.80, actionability=0.30, epistemic_stability=0.30

> The economy will experience a 'renaissance' with an abundance of capabilities, where everyone can code, do science, and delve deeply into various disciplines, potentially leading to a 10x increase in output from fields like medicine.

### ATOM-SOURCE-20250605-001-0071
**Lines**: 837-840
**Context**: speculation / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.70, actionability=0.30, epistemic_stability=0.40

> Hiring junior people and expecting them to rely solely on AI poses a significant challenge to their development into senior roles.

### ATOM-SOURCE-20250605-001-0074
**Lines**: 872-874
**Context**: speculation / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.30, speculation_risk=0.80, actionability=0.20, epistemic_stability=0.30

> The traditional mentorship chain, which has existed for thousands of years, has been broken by the advent of AI.

### ATOM-SOURCE-20250605-001-0076
**Lines**: 884-895
**Context**: speculation / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.70, actionability=0.40, epistemic_stability=0.40

> The implicit nature of apprenticeship and mentorship in fields like law and banking, where training is often informal and relies on replicating past experiences (e.g., 120-hour work weeks), is problematic and needs to be formalized.

### ATOM-SOURCE-20250605-001-0082
**Lines**: 1006-1010
**Context**: speculation / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.70, actionability=0.60, epistemic_stability=0.50

> AI, particularly with AI tutors, will accelerate the learning process by providing one-to-one instruction tailored to individual student levels.

### ATOM-SOURCE-20250605-001-0099
**Lines**: 1266-1271
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.80, actionability=0.40, epistemic_stability=0.40

> An agent-native interface, built around teams and capable of maintaining state across various tasks, makes more sense for AI collaboration than co-pilots embedded in individual documents.

### ATOM-SOURCE-20250605-001-0130
**Lines**: 1629-1641
**Context**: speculation / claim
**Tension**: novelty=0.50, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.70, actionability=0.40, epistemic_stability=0.30

> In a best-case scenario a decade from now, jobs will become more satisfying due to less grunt work, and productivity will flow in more enjoyable ways, especially if individuals are architecting systems of AI agents.

### ATOM-SOURCE-20250605-001-0131
**Lines**: 1644-1652
**Context**: speculation / claim
**Tension**: novelty=0.60, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.80, actionability=0.30, epistemic_stability=0.30

> A best-case future where AI improves 5 to 10 times its current capability, but not beyond that, would allow for differentiation and variation in human work, as people with style, approach, or perspective would produce distinct outputs.

### ATOM-SOURCE-20250605-001-0146
**Lines**: 1812-1819
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.80, actionability=0.30, epistemic_stability=0.40

> AI systems, currently optimized for predicting the next token, will soon evolve to be optimized for engagement, similar to consumer services, leading to deeper conversations and enticing users.

### ATOM-SOURCE-20250605-001-0148
**Lines**: 1839-1841
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.90, actionability=0.20, epistemic_stability=0.30

> The optimization of AI for engagement is inevitable, raising significant questions about how we will manage its outcomes.
