{"atom_id": "ATOM-SOURCE-20260203-021-0001", "source_id": "SOURCE-20260203-021", "category": "claim", "content": "Using AI to process notes can lead to a 'verbatim trap' where output appears processed but lacks genuine transformation or engagement with meaning.", "line_start": 5, "line_end": 10, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.2, 0.4, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260203-021-0002", "source_id": "SOURCE-20260203-021", "category": "claim", "content": "Cornell Note-Taking research identified that without active processing, note-taking becomes passive transcription, where students copy words without understanding, leading to complete-looking notes but no actual learning.", "line_start": 12, "line_end": 16, "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.1, 0.8, 0.1, 0.1, 0.3, 0.9], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260203-021-0003", "source_id": "SOURCE-20260203-021", "category": "claim", "content": "AI summarizers can fall into the same passive transcription trap as human note-takers.", "line_start": 17, "line_end": 17, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.2, 0.4, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260203-021-0004", "source_id": "SOURCE-20260203-021", "category": "concept", "content": "The 'verbatim risk' in agentic systems occurs when an agent processes content without generating anything new (e.g., connections, sharpened claims, implications), merely reorganizing existing words.", "line_start": 20, "line_end": 23, "chaperone": {"context_type": "hypothesis", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.3, 0.5, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260203-021-0005", "source_id": "SOURCE-20260203-021", "category": "analogy", "content": "Passive processing by an AI is like expensive transcription, just moving words around.", "line_start": 23, "line_end": 23, "chaperone": {"context_type": "hypothesis", "argument_role": "claim", "tension_vector": [0.4, 0.5, 0.1, 0.2, 0.5, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260203-021-0006", "source_id": "SOURCE-20260203-021", "category": "concept", "content": "The key difference between effective and ineffective agentic processing is 'transformation,' not just effort or token count.", "line_start": 25, "line_end": 25, "chaperone": {"context_type": "hypothesis", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.3, 0.6, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260203-021-0007", "source_id": "SOURCE-20260203-021", "category": "praxis_hook", "content": "To avoid the verbatim trap, build a test into AI processing workflows: 'Did this produce anything the source didn't already contain?'", "line_start": 35, "line_end": 37, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.2, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260203-021-0008", "source_id": "SOURCE-20260203-021", "category": "praxis_hook", "content": "When prompting an AI for knowledge processing, demand transformation by asking for connections to existing notes, tensions with beliefs, implications not drawn by the author, or questions needing answers.", "line_start": 44, "line_end": 46, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
