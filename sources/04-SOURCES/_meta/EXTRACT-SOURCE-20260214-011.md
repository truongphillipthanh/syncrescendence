# Extraction: SOURCE-20260214-011

**Source**: `SOURCE-20260214-x-thread-aiwithmayank-prompt_engineering_is_officially_outdated.md`
**Atoms extracted**: 8
**Categories**: analogy, claim, concept, framework, praxis_hook, prediction

---

## Analogy (1)

### ATOM-SOURCE-20260214-011-0004
**Lines**: 20-25
**Context**: method / evidence
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.80

> The analogy 'MCP gives Claude the kitchen; Skills give it the recipe' illustrates that MCP provides the foundational tools, while Skills provide the structured guidance for using those tools effectively, leading to automatic workflow triggers, embedded best practices, and consistent API calls.

## Claim (2)

### ATOM-SOURCE-20260214-011-0001
**Lines**: 2-2
**Context**: consensus / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.70, actionability=0.10, epistemic_stability=0.20

> Prompt engineering is officially outdated.

### ATOM-SOURCE-20260214-011-0007
**Lines**: 40-40
**Context**: consensus / claim
**Tension**: novelty=0.50, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.10, actionability=0.80, epistemic_stability=0.90

> Skills built for Claude are designed to work across Claude.ai, Claude Code, and the API, allowing for a 'build once, deploy everywhere' approach.

## Concept (2)

### ATOM-SOURCE-20260214-011-0002
**Lines**: 7-10
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.60, epistemic_stability=0.70

> A Skill, as defined by Anthropic's guide, is not merely a prompt but a structured system that packages instructions inside a `SKILL.md` file, optionally includes scripts, references, and assets, and teaches Claude a repeatable workflow.

### ATOM-SOURCE-20260214-011-0003
**Lines**: 12-17
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.70

> Progressive disclosure is a technique where a lightweight YAML frontmatter tells Claude when to use a skill, full instructions load only when relevant, and extra files are accessed only if needed, reducing context bloat and increasing precision.

## Framework (1)

### ATOM-SOURCE-20260214-011-0005
**Lines**: 28-31
**Context**: method / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.10, actionability=0.70, epistemic_stability=0.80

> Anthropic outlines three major patterns for building skills: document and asset creation, workflow automation, and MCP enhancement.

## Praxis Hook (1)

### ATOM-SOURCE-20260214-011-0006
**Lines**: 33-38
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.70

> When building skills for LLMs, it is crucial to emphasize testing for trigger accuracy, tool call efficiency, failure rate, and token usage, as this focuses on designing an execution layer rather than just clever wording.

## Prediction (1)

### ATOM-SOURCE-20260214-011-0008
**Lines**: 42-43
**Context**: speculation / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.70, actionability=0.20, epistemic_stability=0.30

> The era of 'just write a better prompt' is ending, as Anthropic's guide provides a blueprint for transforming chat into infrastructure.
