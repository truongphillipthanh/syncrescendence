{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "bca9e2f9-49ee-538f-806a-7eadd95c927c", "timestamp": "2026-02-24T00:47:24.270116+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260114-482-0001", "source_id": "SOURCE-20260114-482", "category": "concept", "content": "Recursive Language Models (RLMs) are an approach developed by MIT researchers (Alex Zhang, Tim Kraska, Omar Khattab) that extends the effective context window of LLMs by treating the prompt as an external variable in a Python REPL, allowing the model to recursively call itself over smaller chunks of information.", "line_start": 15, "line_end": 18, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.2, 0.4, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260114-482", "entity_type": "Concept", "name": "Recursive Language Models (RLMs) are an approach developed by MIT researchers (A", "content": "Recursive Language Models (RLMs) are an approach developed by MIT researchers (Alex Zhang, Tim Kraska, Omar Khattab) that extends the effective context window of LLMs by treating the prompt as an external variable in a Python REPL, allowing the model to recursively call itself over smaller chunks of information.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260114-482", "line_start": 15, "line_end": 18, "atom_id": "ATOM-SOURCE-20260114-482-0001"}, "metadata": {"category": "concept", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.2, 0.4, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "d6496d20-eebd-5ab1-8dd7-57e39320642e", "timestamp": "2026-02-24T00:47:24.270116+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260114-482-0002", "source_id": "SOURCE-20260114-482", "category": "claim", "content": "Recursive Language Models (RLMs) offer a practical solution to the problem of context rot in LLMs.", "line_start": 15, "line_end": 16, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.5, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260114-482", "entity_type": "Claim", "name": "Recursive Language Models (RLMs) offer a practical solution to the problem of co", "content": "Recursive Language Models (RLMs) offer a practical solution to the problem of context rot in LLMs.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260114-482", "line_start": 15, "line_end": 16, "atom_id": "ATOM-SOURCE-20260114-482-0002"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.5, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "ec6e7e5f-9a47-5ecd-a02d-d57e474400c9", "timestamp": "2026-02-24T00:47:24.270116+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260114-482-0003", "source_id": "SOURCE-20260114-482", "category": "claim", "content": "RLMs can effectively handle over 10 million tokens.", "line_start": 19, "line_end": 19, "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.5, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260114-482", "entity_type": "Claim", "name": "RLMs can effectively handle over 10 million tokens.", "content": "RLMs can effectively handle over 10 million tokens.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260114-482", "line_start": 19, "line_end": 19, "atom_id": "ATOM-SOURCE-20260114-482-0003"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.5, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "61fba2ae-5d05-58ae-b9fd-beb898e9e4e9", "timestamp": "2026-02-24T00:47:24.270116+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260114-482-0004", "source_id": "SOURCE-20260114-482", "category": "claim", "content": "RLMs outperform base LLM models by double-digit percentages on complex tasks such as code understanding, document QA, and semantic aggregation.", "line_start": 19, "line_end": 20, "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.5, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260114-482", "entity_type": "Claim", "name": "RLMs outperform base LLM models by double-digit percentages on complex tasks suc", "content": "RLMs outperform base LLM models by double-digit percentages on complex tasks such as code understanding, document QA, and semantic aggregation.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260114-482", "line_start": 19, "line_end": 20, "atom_id": "ATOM-SOURCE-20260114-482-0004"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.5, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "31936110-2290-56bb-b329-b8eba460f216", "timestamp": "2026-02-24T00:47:24.270116+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260114-482-0005", "source_id": "SOURCE-20260114-482", "category": "claim", "content": "RLMs can achieve their performance benefits at a comparable or sometimes cheaper cost per query compared to traditional LLM approaches.", "line_start": 20, "line_end": 20, "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.5, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260114-482", "entity_type": "Claim", "name": "RLMs can achieve their performance benefits at a comparable or sometimes cheaper", "content": "RLMs can achieve their performance benefits at a comparable or sometimes cheaper cost per query compared to traditional LLM approaches.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260114-482", "line_start": 20, "line_end": 20, "atom_id": "ATOM-SOURCE-20260114-482-0005"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.5, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "e34f9bfc-0a3c-5911-9c57-6aec67a6192d", "timestamp": "2026-02-24T00:47:24.270116+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260114-482-0006", "source_id": "SOURCE-20260114-482", "category": "praxis_hook", "content": "Recursive Language Models (RLMs) can be implemented with existing LLM models and infrastructure without requiring fine-tuning.", "line_start": 21, "line_end": 21, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260114-482", "entity_type": "PraxisHook", "name": "Recursive Language Models (RLMs) can be implemented with existing LLM models and", "content": "Recursive Language Models (RLMs) can be implemented with existing LLM models and infrastructure without requiring fine-tuning.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260114-482", "line_start": 21, "line_end": 21, "atom_id": "ATOM-SOURCE-20260114-482-0006"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
