{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "beb7fb2a-abd6-5d68-8b9f-7ed7860603e1", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0001", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "OpenClaw agents frequently forget basic information, lose critical project context mid-conversation, and fail to recall decisions made shortly before.", "line_start": 15, "line_end": 17, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.1, 0.1, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Claim", "name": "OpenClaw agents frequently forget basic information, lose critical project conte", "content": "OpenClaw agents frequently forget basic information, lose critical project context mid-conversation, and fail to recall decisions made shortly before.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 15, "line_end": 17, "atom_id": "ATOM-SOURCE-20260218-010-0001"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.1, 0.1, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "69560275-8bdf-5af2-9ad4-bfa2d97fd3ce", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0002", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "OpenClaw treats memory as a suggestion, not a requirement, allowing the agent to decide what to save, when to search, and what to recall, leading to forgetting by default without explicit configuration.", "line_start": 25, "line_end": 27, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Claim", "name": "OpenClaw treats memory as a suggestion, not a requirement, allowing the agent to", "content": "OpenClaw treats memory as a suggestion, not a requirement, allowing the agent to decide what to save, when to search, and what to recall, leading to forgetting by default without explicit configuration.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 25, "line_end": 27, "atom_id": "ATOM-SOURCE-20260218-010-0002"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "bd034605-a4d7-56a8-8fc7-c22381ba64f7", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0003", "source_id": "SOURCE-20260218-010", "category": "framework", "content": "There are three common failure modes for memory in OpenClaw: memory is never saved, memory is saved but never retrieved, and context compaction destroys knowledge.", "line_start": 29, "line_end": 30, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.1, 0.4, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Framework", "name": "There are three common failure modes for memory in OpenClaw: memory is never sav", "content": "There are three common failure modes for memory in OpenClaw: memory is never saved, memory is saved but never retrieved, and context compaction destroys knowledge.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 29, "line_end": 30, "atom_id": "ATOM-SOURCE-20260218-010-0003"}, "metadata": {"category": "framework", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.1, 0.4, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "71be88a9-5a53-50df-b6f9-c855abcbbbf2", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0004", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "In OpenClaw, the LLM decides whether information is worth saving to disk, meaning important context can be lost if the model deems it not worth storing.", "line_start": 34, "line_end": 36, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Claim", "name": "In OpenClaw, the LLM decides whether information is worth saving to disk, meanin", "content": "In OpenClaw, the LLM decides whether information is worth saving to disk, meaning important context can be lost if the model deems it not worth storing.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 34, "line_end": 36, "atom_id": "ATOM-SOURCE-20260218-010-0004"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "9eb2de62-24b8-5ee2-a2d9-3881786eb0e0", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0005", "source_id": "SOURCE-20260218-010", "category": "analogy", "content": "OpenClaw's memory saving mechanism, where the LLM decides what to save, is like an employee who decides on their own which meeting notes to keep and which to throw away.", "line_start": 42, "line_end": 42, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.5, 0.1, 0.1, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Concept", "name": "OpenClaw's memory saving mechanism, where the LLM decides what to save, is like", "content": "OpenClaw's memory saving mechanism, where the LLM decides what to save, is like an employee who decides on their own which meeting notes to keep and which to throw away.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 42, "line_end": 42, "atom_id": "ATOM-SOURCE-20260218-010-0005"}, "metadata": {"category": "analogy", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.5, 0.1, 0.1, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "8c1a3301-4589-52c3-beca-eed01b619818", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0006", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "Even when facts are saved to disk in OpenClaw, recall is not guaranteed because the agent must decide to use the `memory_search` tool, often answering from its current context window instead.", "line_start": 45, "line_end": 48, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Claim", "name": "Even when facts are saved to disk in OpenClaw, recall is not guaranteed because", "content": "Even when facts are saved to disk in OpenClaw, recall is not guaranteed because the agent must decide to use the `memory_search` tool, often answering from its current context window instead.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 45, "line_end": 48, "atom_id": "ATOM-SOURCE-20260218-010-0006"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "0163a42f-7321-5e79-9b60-aba635a6164a", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0007", "source_id": "SOURCE-20260218-010", "category": "analogy", "content": "OpenClaw's memory retrieval issue, where an agent answers from its context window instead of searching saved memory, is like an employee who saved a document but answers from memory instead of checking the actual document when asked.", "line_start": 50, "line_end": 51, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.5, 0.1, 0.1, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Concept", "name": "OpenClaw's memory retrieval issue, where an agent answers from its context windo", "content": "OpenClaw's memory retrieval issue, where an agent answers from its context window instead of searching saved memory, is like an employee who saved a document but answers from memory instead of checking the actual document when asked.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 50, "line_end": 51, "atom_id": "ATOM-SOURCE-20260218-010-0007"}, "metadata": {"category": "analogy", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.5, 0.1, 0.1, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "dbf49be5-608a-58f2-b292-9b079db7d2e9", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0008", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "OpenClaw compacts context to avoid token limits, summarizing or removing older messages, which destroys any information that only existed in the active conversation and was not yet saved to disk.", "line_start": 54, "line_end": 56, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Claim", "name": "OpenClaw compacts context to avoid token limits, summarizing or removing older m", "content": "OpenClaw compacts context to avoid token limits, summarizing or removing older messages, which destroys any information that only existed in the active conversation and was not yet saved to disk.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 54, "line_end": 56, "atom_id": "ATOM-SOURCE-20260218-010-0008"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "f763b6d1-7913-5f9a-9bf4-c6f40b013efe", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0009", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "Even content in MEMORY.md can be summarized away during a long session due to context compaction, causing the agent to forget mid-conversation.", "line_start": 57, "line_end": 59, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Claim", "name": "Even content in MEMORY.md can be summarized away during a long session due to co", "content": "Even content in MEMORY.md can be summarized away during a long session due to context compaction, causing the agent to forget mid-conversation.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 57, "line_end": 59, "atom_id": "ATOM-SOURCE-20260218-010-0009"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "20b126c3-7054-5ed7-a134-ca09695a90ec", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0010", "source_id": "SOURCE-20260218-010", "category": "analogy", "content": "OpenClaw's context compaction, which removes older messages to make room, is like an employee with a stack of papers who throws out the oldest ones without saving important information when the stack gets too tall.", "line_start": 61, "line_end": 62, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.5, 0.1, 0.1, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Concept", "name": "OpenClaw's context compaction, which removes older messages to make room, is lik", "content": "OpenClaw's context compaction, which removes older messages to make room, is like an employee with a stack of papers who throws out the oldest ones without saving important information when the stack gets too tall.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 61, "line_end": 62, "atom_id": "ATOM-SOURCE-20260218-010-0010"}, "metadata": {"category": "analogy", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.5, 0.1, 0.1, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "fa05cd59-3c0d-55bf-9c93-50f50e920325", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0011", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "To fix OpenClaw memory issues, configure memory flush, context pruning, hybrid search, and session indexing before resorting to external plugins or databases.", "line_start": 65, "line_end": 67, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "PraxisHook", "name": "To fix OpenClaw memory issues, configure memory flush, context pruning, hybrid s", "content": "To fix OpenClaw memory issues, configure memory flush, context pruning, hybrid search, and session indexing before resorting to external plugins or databases.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 65, "line_end": 67, "atom_id": "ATOM-SOURCE-20260218-010-0011"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "d24fa4d4-78f5-527c-a4e3-51a16ed49935", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0012", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "Enable memory flush in OpenClaw's compaction settings by setting `enabled: true` and customizing the prompt to specifically capture decisions, state changes, lessons, and blockers, while also raising `softThresholdTokens` to 40000.", "line_start": 70, "line_end": 81, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "PraxisHook", "name": "Enable memory flush in OpenClaw's compaction settings by setting `enabled: true`", "content": "Enable memory flush in OpenClaw's compaction settings by setting `enabled: true` and customizing the prompt to specifically capture decisions, state changes, lessons, and blockers, while also raising `softThresholdTokens` to 40000.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 70, "line_end": 81, "atom_id": "ATOM-SOURCE-20260218-010-0012"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "b7753b74-faeb-5729-af7c-a0769cad1d94", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0013", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "Configure context pruning in OpenClaw using `cache-ttl` mode with a `ttl` of '6h' and `keepLastAssistants` set to 3 to retain recent messages and prevent their removal during compaction.", "line_start": 83, "line_end": 89, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "PraxisHook", "name": "Configure context pruning in OpenClaw using `cache-ttl` mode with a `ttl` of '6h", "content": "Configure context pruning in OpenClaw using `cache-ttl` mode with a `ttl` of '6h' and `keepLastAssistants` set to 3 to retain recent messages and prevent their removal during compaction.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 83, "line_end": 89, "atom_id": "ATOM-SOURCE-20260218-010-0013"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "8a6caa47-cc19-5103-a20b-ef11332df088", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0014", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "Enable hybrid search in OpenClaw's `memorySearch` configuration by setting `hybrid.enabled: true` and adjusting `vectorWeight` (e.g., 0.7) and `textWeight` (e.g., 0.3) to combine vector similarity and BM25 keyword search for improved retrieval accuracy.", "line_start": 91, "line_end": 98, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "PraxisHook", "name": "Enable hybrid search in OpenClaw's `memorySearch` configuration by setting `hybr", "content": "Enable hybrid search in OpenClaw's `memorySearch` configuration by setting `hybrid.enabled: true` and adjusting `vectorWeight` (e.g., 0.7) and `textWeight` (e.g., 0.3) to combine vector similarity and BM25 keyword search for improved retrieval accuracy.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 91, "line_end": 98, "atom_id": "ATOM-SOURCE-20260218-010-0014"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "18e16f73-38f4-5bff-8948-7127c8d873d1", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0015", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "To get started with QMD, have your agent review the QMD Github repository and discuss it before implementation, then install it. Always back up your system before installing new memory systems.", "line_start": 93, "line_end": 96, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.1, 0.2, 0.1, 0.1, 0.9, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "PraxisHook", "name": "To get started with QMD, have your agent review the QMD Github repository and di", "content": "To get started with QMD, have your agent review the QMD Github repository and discuss it before implementation, then install it. Always back up your system before installing new memory systems.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 93, "line_end": 96, "atom_id": "ATOM-SOURCE-20260218-010-0015"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.1, 0.2, 0.1, 0.1, 0.9, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "4a316b5a-329f-5566-977e-f9f5cea2a621", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0016", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "QMD's killer feature is its ability to index external document collections like Obsidian vaults, project documentation, and Notion exports, making them searchable via memory_search.", "line_start": 97, "line_end": 99, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.3, 0.1, 0.1, 0.7, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Claim", "name": "QMD's killer feature is its ability to index external document collections like", "content": "QMD's killer feature is its ability to index external document collections like Obsidian vaults, project documentation, and Notion exports, making them searchable via memory_search.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 97, "line_end": 99, "atom_id": "ATOM-SOURCE-20260218-010-0016"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.3, 0.1, 0.1, 0.7, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "10947749-a4c6-5da5-8125-9fe26a20d697", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0017", "source_id": "SOURCE-20260218-010", "category": "concept", "content": "Mem0 is a memory layer for AI applications that stores memories outside the context window, preventing compaction from destroying them.", "line_start": 102, "line_end": 104, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.1, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Concept", "name": "Mem0 is a memory layer for AI applications that stores memories outside the cont", "content": "Mem0 is a memory layer for AI applications that stores memories outside the context window, preventing compaction from destroying them.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 102, "line_end": 104, "atom_id": "ATOM-SOURCE-20260218-010-0017"}, "metadata": {"category": "concept", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.1, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "26911302-ff40-527c-9708-8f9cbafca675", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0018", "source_id": "SOURCE-20260218-010", "category": "framework", "content": "Mem0 operates with two processes per turn: Auto-Capture, which detects and stores information without LLM judgment, and Auto-Recall, which searches and injects relevant memories before the agent responds.", "line_start": 105, "line_end": 108, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.1, 0.7, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Framework", "name": "Mem0 operates with two processes per turn: Auto-Capture, which detects and store", "content": "Mem0 operates with two processes per turn: Auto-Capture, which detects and stores information without LLM judgment, and Auto-Recall, which searches and injects relevant memories before the agent responds.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 105, "line_end": 108, "atom_id": "ATOM-SOURCE-20260218-010-0018"}, "metadata": {"category": "framework", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.1, 0.7, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "a70f8ee9-5438-5428-bea1-fcb0bc074896", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0019", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "Mem0's auto-capture and auto-recall mechanisms completely solve memory failure modes related to automatic capture and compaction.", "line_start": 109, "line_end": 110, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.1, 0.2, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Claim", "name": "Mem0's auto-capture and auto-recall mechanisms completely solve memory failure m", "content": "Mem0's auto-capture and auto-recall mechanisms completely solve memory failure modes related to automatic capture and compaction.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 109, "line_end": 110, "atom_id": "ATOM-SOURCE-20260218-010-0019"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.1, 0.2, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "395267ee-527f-58a7-9350-6035b37f6f55", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0020", "source_id": "SOURCE-20260218-010", "category": "concept", "content": "Cognee builds a knowledge graph from data, ingesting OpenClaw's memory files to construct a graph of entities and relationships, which allows for structured representation of concepts and their connections.", "line_start": 114, "line_end": 117, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.1, 0.1, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Concept", "name": "Cognee builds a knowledge graph from data, ingesting OpenClaw's memory files to", "content": "Cognee builds a knowledge graph from data, ingesting OpenClaw's memory files to construct a graph of entities and relationships, which allows for structured representation of concepts and their connections.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 114, "line_end": 117, "atom_id": "ATOM-SOURCE-20260218-010-0020"}, "metadata": {"category": "concept", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.1, 0.1, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "143a5165-e9be-5f6d-a34c-bc85ff48c5c2", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0021", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "Cognee is suitable for scenarios requiring deep understanding of relationships and structured knowledge, such as enterprise settings or multi-agent teams, but might be overkill for basic OpenClaw setups.", "line_start": 118, "line_end": 120, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.2, 0.5, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "Claim", "name": "Cognee is suitable for scenarios requiring deep understanding of relationships a", "content": "Cognee is suitable for scenarios requiring deep understanding of relationships and structured knowledge, such as enterprise settings or multi-agent teams, but might be overkill for basic OpenClaw setups.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 118, "line_end": 120, "atom_id": "ATOM-SOURCE-20260218-010-0021"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.2, 0.5, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "e72179cc-f10b-55e8-bdd1-4aa46a0b7fa1", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0022", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "One way to integrate Obsidian with OpenClaw is to symlink your agent's memory folder to your Obsidian vault, allowing daily notes to appear in Obsidian for review, editing, and annotation across devices.", "line_start": 125, "line_end": 128, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.3, 0.1, 0.1, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "PraxisHook", "name": "One way to integrate Obsidian with OpenClaw is to symlink your agent's memory fo", "content": "One way to integrate Obsidian with OpenClaw is to symlink your agent's memory folder to your Obsidian vault, allowing daily notes to appear in Obsidian for review, editing, and annotation across devices.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 125, "line_end": 128, "atom_id": "ATOM-SOURCE-20260218-010-0022"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.3, 0.1, 0.1, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "a6956c0f-8f3f-540b-b47b-a0d9f2daa1db", "timestamp": "2026-02-24T01:06:32.523513+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260218-010-0023", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "Another robust approach for Obsidian integration is to index your vault via QMD, making all captured Obsidian content searchable by agents, which also saves token costs as Obsidian 1.12's CLI allows querying metadata instead of reading entire files.", "line_start": 130, "line_end": 133, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.1, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260218-010", "entity_type": "PraxisHook", "name": "Another robust approach for Obsidian integration is to index your vault via QMD,", "content": "Another robust approach for Obsidian integration is to index your vault via QMD, making all captured Obsidian content searchable by agents, which also saves token costs as Obsidian 1.12's CLI allows querying metadata instead of reading entire files.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260218-010", "line_start": 130, "line_end": 133, "atom_id": "ATOM-SOURCE-20260218-010-0023"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.1, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
