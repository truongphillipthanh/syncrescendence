# Extraction: SOURCE-20251223-730

**Source**: `SOURCE-20251223-youtube-lecture-ai_news_strategy_daily_nate_b-if_this_can_happen_to_an_ex_deepmind_leader_it_can_happen_to.md`
**Atoms extracted**: 8
**Categories**: claim, concept, praxis_hook, prediction

---

## Claim (1)

### ATOM-SOURCE-20251223-730-0001
**Lines**: 15-15
**Context**: rebuttal / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.30, speculation_risk=0.40, actionability=0.10, epistemic_stability=0.60

> The common narrative that AI solely enhances human intelligence is an oversimplification.

## Concept (1)

### ATOM-SOURCE-20251223-730-0003
**Lines**: 17-20
**Context**: hypothesis / claim
**Tension**: novelty=0.80, consensus_pressure=0.20, contradiction_load=0.10, speculation_risk=0.70, actionability=0.30, epistemic_stability=0.20

> LLM-induced psychosis refers to a condition where leaders fall victim to confirmation bias with ChatGPT, replacing their domain expertise with AI confidence, as exemplified by David Budden's Navier-Stokes claim.

## Praxis Hook (3)

### ATOM-SOURCE-20251223-730-0006
**Lines**: 28-28
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.50, actionability=0.80, epistemic_stability=0.50

> To mitigate LLM-induced psychosis, ask your LLM to be adversarial.

### ATOM-SOURCE-20251223-730-0007
**Lines**: 29-29
**Context**: method / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.40, actionability=0.70, epistemic_stability=0.60

> To mitigate LLM-induced psychosis, avoid overstating your domain expertise.

### ATOM-SOURCE-20251223-730-0008
**Lines**: 30-30
**Context**: method / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.40, actionability=0.80, epistemic_stability=0.60

> To mitigate LLM-induced psychosis, submit your AI-assisted work to a jury of your peers for review.

## Prediction (3)

### ATOM-SOURCE-20251223-730-0002
**Lines**: 17-17
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.80, actionability=0.20, epistemic_stability=0.30

> A psychiatric risk, termed 'LLM-induced psychosis,' will emerge in workplaces by 2026.

### ATOM-SOURCE-20251223-730-0004
**Lines**: 21-21
**Context**: speculation / claim
**Tension**: novelty=0.60, consensus_pressure=0.30, contradiction_load=0.20, speculation_risk=0.80, actionability=0.40, epistemic_stability=0.30

> Businesses will begin testing executives for undue AI influence.

### ATOM-SOURCE-20251223-730-0005
**Lines**: 23-24
**Context**: speculation / claim
**Tension**: novelty=0.70, consensus_pressure=0.40, contradiction_load=0.20, speculation_risk=0.80, actionability=0.50, epistemic_stability=0.40

> The ability to distinguish one's own expertise from an LLM's output will be crucial for stable leadership in 2026, and executives unable to do so will become organizational liabilities.
