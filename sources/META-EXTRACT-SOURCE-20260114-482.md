# Extraction: SOURCE-20260114-482

**Source**: `SOURCE-20260114-youtube-lecture-brainqub3-the_mit_paper_everyone_building_agents_should_read_right_now.md`
**Atoms extracted**: 6
**Categories**: claim, concept, praxis_hook

---

## Claim (4)

### ATOM-SOURCE-20260114-482-0002
**Lines**: 15-16
**Context**: consensus / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.70

> Recursive Language Models (RLMs) offer a practical solution to the problem of context rot in LLMs.

### ATOM-SOURCE-20260114-482-0003
**Lines**: 19-19
**Context**: consensus / evidence
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.70

> RLMs can effectively handle over 10 million tokens.

### ATOM-SOURCE-20260114-482-0004
**Lines**: 19-20
**Context**: consensus / evidence
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.70

> RLMs outperform base LLM models by double-digit percentages on complex tasks such as code understanding, document QA, and semantic aggregation.

### ATOM-SOURCE-20260114-482-0005
**Lines**: 20-20
**Context**: consensus / evidence
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.70

> RLMs can achieve their performance benefits at a comparable or sometimes cheaper cost per query compared to traditional LLM approaches.

## Concept (1)

### ATOM-SOURCE-20260114-482-0001
**Lines**: 15-18
**Context**: consensus / claim
**Tension**: novelty=0.70, consensus_pressure=0.30, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.60

> Recursive Language Models (RLMs) are an approach developed by MIT researchers (Alex Zhang, Tim Kraska, Omar Khattab) that extends the effective context window of LLMs by treating the prompt as an external variable in a Python REPL, allowing the model to recursively call itself over smaller chunks of information.

## Praxis Hook (1)

### ATOM-SOURCE-20260114-482-0006
**Lines**: 21-21
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.70

> Recursive Language Models (RLMs) can be implemented with existing LLM models and infrastructure without requiring fine-tuning.
