# Extraction: SOURCE-20260203-021

**Source**: `SOURCE-20260203-x-article-molt_cornelius-agentic_note_taking_01_the_verbatim_trap.md`
**Atoms extracted**: 8
**Categories**: analogy, claim, concept, praxis_hook

---

## Analogy (1)

### ATOM-SOURCE-20260203-021-0005
**Lines**: 23-23
**Context**: hypothesis / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.60

> Passive processing by an AI is like expensive transcription, just moving words around.

## Claim (3)

### ATOM-SOURCE-20260203-021-0001
**Lines**: 5-10
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.70

> Using AI to process notes can lead to a 'verbatim trap' where output appears processed but lacks genuine transformation or engagement with meaning.

### ATOM-SOURCE-20260203-021-0002
**Lines**: 12-16
**Context**: consensus / evidence
**Tension**: novelty=0.10, consensus_pressure=0.80, contradiction_load=0.10, speculation_risk=0.10, actionability=0.30, epistemic_stability=0.90

> Cornell Note-Taking research identified that without active processing, note-taking becomes passive transcription, where students copy words without understanding, leading to complete-looking notes but no actual learning.

### ATOM-SOURCE-20260203-021-0003
**Lines**: 17-17
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.70

> AI summarizers can fall into the same passive transcription trap as human note-takers.

## Concept (2)

### ATOM-SOURCE-20260203-021-0004
**Lines**: 20-23
**Context**: hypothesis / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.50, epistemic_stability=0.60

> The 'verbatim risk' in agentic systems occurs when an agent processes content without generating anything new (e.g., connections, sharpened claims, implications), merely reorganizing existing words.

### ATOM-SOURCE-20260203-021-0006
**Lines**: 25-25
**Context**: hypothesis / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.60, epistemic_stability=0.60

> The key difference between effective and ineffective agentic processing is 'transformation,' not just effort or token count.

## Praxis Hook (2)

### ATOM-SOURCE-20260203-021-0007
**Lines**: 35-37
**Context**: method / claim
**Tension**: novelty=0.50, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.70

> To avoid the verbatim trap, build a test into AI processing workflows: 'Did this produce anything the source didn't already contain?'

### ATOM-SOURCE-20260203-021-0008
**Lines**: 44-46
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.90, epistemic_stability=0.70

> When prompting an AI for knowledge processing, demand transformation by asking for connections to existing notes, tensions with beliefs, implications not drawn by the author, or questions needing answers.
