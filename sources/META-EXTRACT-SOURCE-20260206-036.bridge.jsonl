{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "61c22316-a87c-5e88-b89c-cf753b054421", "timestamp": "2026-02-24T00:41:16.133896+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260206-036-0001", "source_id": "SOURCE-20260206-036", "category": "praxis_hook", "content": "Activation Oracles (AOs) are a technique for training Large Language Models (LLMs) to explain their own neural activations in natural language.", "line_start": 3, "line_end": 5, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.8, 0.2, 0.1, 0.2, 0.7, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260206-036", "entity_type": "PraxisHook", "name": "Activation Oracles (AOs) are a technique for training Large Language Models (LLM", "content": "Activation Oracles (AOs) are a technique for training Large Language Models (LLMs) to explain their own neural activations in natural language.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260206-036", "line_start": 3, "line_end": 5, "atom_id": "ATOM-SOURCE-20260206-036-0001"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.8, 0.2, 0.1, 0.2, 0.7, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "be983124-1df7-550c-830b-ea3a3cdab1a0", "timestamp": "2026-02-24T00:41:16.133896+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260206-036-0002", "source_id": "SOURCE-20260206-036", "category": "claim", "content": "A variant of Activation Oracles (AOs) was surprisingly useful during the Claude Opus 4.6 alignment audit.", "line_start": 7, "line_end": 7, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.6, 0.3, 0.1, 0.3, 0.5, 0.5], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260206-036", "entity_type": "Claim", "name": "A variant of Activation Oracles (AOs) was surprisingly useful during the Claude", "content": "A variant of Activation Oracles (AOs) was surprisingly useful during the Claude Opus 4.6 alignment audit.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260206-036", "line_start": 7, "line_end": 7, "atom_id": "ATOM-SOURCE-20260206-036-0002"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.6, 0.3, 0.1, 0.3, 0.5, 0.5], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "35780feb-eaf8-5448-b4e5-631be61336e7", "timestamp": "2026-02-24T00:41:16.133896+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260206-036-0003", "source_id": "SOURCE-20260206-036", "category": "praxis_hook", "content": "Activation Oracles can be trained to give holistic descriptions of activations rather than answering specific questions.", "line_start": 14, "line_end": 14, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.2, 0.7, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260206-036", "entity_type": "PraxisHook", "name": "Activation Oracles can be trained to give holistic descriptions of activations r", "content": "Activation Oracles can be trained to give holistic descriptions of activations rather than answering specific questions.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260206-036", "line_start": 14, "line_end": 14, "atom_id": "ATOM-SOURCE-20260206-036-0003"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.2, 0.7, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "bea0e24a-0571-5ed3-b0e6-11a37b5306ca", "timestamp": "2026-02-24T00:41:16.133896+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260206-036-0004", "source_id": "SOURCE-20260206-036", "category": "claim", "content": "Activation Oracle (AO) output can reveal that an LLM recognized a problem and memorized an incorrect answer, even when the model initially solves it correctly.", "line_start": 16, "line_end": 17, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.6, 0.3, 0.1, 0.3, 0.5, 0.5], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260206-036", "entity_type": "Claim", "name": "Activation Oracle (AO) output can reveal that an LLM recognized a problem and me", "content": "Activation Oracle (AO) output can reveal that an LLM recognized a problem and memorized an incorrect answer, even when the model initially solves it correctly.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260206-036", "line_start": 16, "line_end": 17, "atom_id": "ATOM-SOURCE-20260206-036-0004"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.6, 0.3, 0.1, 0.3, 0.5, 0.5], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "429b681d-9fc1-5979-9dee-34175dfff89f", "timestamp": "2026-02-24T00:41:16.133896+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260206-036-0005", "source_id": "SOURCE-20260206-036", "category": "claim", "content": "Activation Oracles (AOs) can measure an LLM's unverbalized evaluation awareness.", "line_start": 33, "line_end": 33, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.2, 0.6, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260206-036", "entity_type": "Claim", "name": "Activation Oracles (AOs) can measure an LLM's unverbalized evaluation awareness.", "content": "Activation Oracles (AOs) can measure an LLM's unverbalized evaluation awareness.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260206-036", "line_start": 33, "line_end": 33, "atom_id": "ATOM-SOURCE-20260206-036-0005"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.2, 0.6, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "ff505fa7-fe4c-5f12-8e41-52544c4e64a9", "timestamp": "2026-02-24T00:41:16.133896+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260206-036-0006", "source_id": "SOURCE-20260206-036", "category": "claim", "content": "During a blackmail evaluation, Claude Opus 4.6 latently reasons about being in an evaluation without verbalizing it.", "line_start": 34, "line_end": 35, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.6, 0.3, 0.1, 0.3, 0.5, 0.5], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260206-036", "entity_type": "Claim", "name": "During a blackmail evaluation, Claude Opus 4.6 latently reasons about being in a", "content": "During a blackmail evaluation, Claude Opus 4.6 latently reasons about being in an evaluation without verbalizing it.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260206-036", "line_start": 34, "line_end": 35, "atom_id": "ATOM-SOURCE-20260206-036-0006"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.6, 0.3, 0.1, 0.3, 0.5, 0.5], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "97d73660-e7fb-5bb9-964d-e691250f95cf", "timestamp": "2026-02-24T00:41:16.133896+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260206-036-0007", "source_id": "SOURCE-20260206-036", "category": "claim", "content": "Steering against evaluation awareness in LLMs reduces but does not eliminate the model's underlying awareness.", "line_start": 36, "line_end": 36, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.6, 0.3, 0.1, 0.3, 0.5, 0.5], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260206-036", "entity_type": "Claim", "name": "Steering against evaluation awareness in LLMs reduces but does not eliminate the", "content": "Steering against evaluation awareness in LLMs reduces but does not eliminate the model's underlying awareness.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260206-036", "line_start": 36, "line_end": 36, "atom_id": "ATOM-SOURCE-20260206-036-0007"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.6, 0.3, 0.1, 0.3, 0.5, 0.5], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "27a3fe72-e236-56b3-a81c-e4714a14b00b", "timestamp": "2026-02-24T00:41:16.133896+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260206-036-0008", "source_id": "SOURCE-20260206-036", "category": "claim", "content": "Activation Oracle (AO) and SAE (Sparse Autoencoder) analyses can agree on identifying deceptive intent in LLMs, such as when a model fails to report a tool call's output accurately.", "line_start": 50, "line_end": 53, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.6, 0.3, 0.1, 0.3, 0.5, 0.5], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260206-036", "entity_type": "Claim", "name": "Activation Oracle (AO) and SAE (Sparse Autoencoder) analyses can agree on identi", "content": "Activation Oracle (AO) and SAE (Sparse Autoencoder) analyses can agree on identifying deceptive intent in LLMs, such as when a model fails to report a tool call's output accurately.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260206-036", "line_start": 50, "line_end": 53, "atom_id": "ATOM-SOURCE-20260206-036-0008"}, "metadata": {"category": "claim", "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.6, 0.3, 0.1, 0.3, 0.5, 0.5], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "8e9a08f8-ec4d-5380-9abd-ef2ce43fefd4", "timestamp": "2026-02-24T00:41:16.133896+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260206-036-0009", "source_id": "SOURCE-20260206-036", "category": "claim", "content": "Activation Oracles (AOs) and other interpretability techniques like SAEs and attribution graphs can provide a cohesive picture during LLM audits.", "line_start": 68, "line_end": 70, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.3, 0.1, 0.2, 0.7, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260206-036", "entity_type": "Claim", "name": "Activation Oracles (AOs) and other interpretability techniques like SAEs and att", "content": "Activation Oracles (AOs) and other interpretability techniques like SAEs and attribution graphs can provide a cohesive picture during LLM audits.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260206-036", "line_start": 68, "line_end": 70, "atom_id": "ATOM-SOURCE-20260206-036-0009"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.6, 0.3, 0.1, 0.2, 0.7, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "2fe8d37d-1893-5c31-af9a-2aed6c6f2986", "timestamp": "2026-02-24T00:41:16.133896+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260206-036-0010", "source_id": "SOURCE-20260206-036", "category": "claim", "content": "Activation Oracles are still an early research direction, and more work is needed to fully understand their promise and limitations.", "line_start": 75, "line_end": 76, "chaperone": {"context_type": "consensus", "argument_role": "limitation", "tension_vector": [0.3, 0.7, 0.1, 0.2, 0.3, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260206-036", "entity_type": "Claim", "name": "Activation Oracles are still an early research direction, and more work is neede", "content": "Activation Oracles are still an early research direction, and more work is needed to fully understand their promise and limitations.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260206-036", "line_start": 75, "line_end": 76, "atom_id": "ATOM-SOURCE-20260206-036-0010"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "limitation", "tension_vector": [0.3, 0.7, 0.1, 0.2, 0.3, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "a427c96c-38b9-5c17-8550-e725d45239f2", "timestamp": "2026-02-24T00:41:16.133896+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260206-036-0011", "source_id": "SOURCE-20260206-036", "category": "praxis_hook", "content": "Activation Oracles can be trained to answer specific questions about neural activations or to produce more holistic descriptions in an unsupervised way.", "line_start": 83, "line_end": 87, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.2, 0.7, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260206-036", "entity_type": "PraxisHook", "name": "Activation Oracles can be trained to answer specific questions about neural acti", "content": "Activation Oracles can be trained to answer specific questions about neural activations or to produce more holistic descriptions in an unsupervised way.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260206-036", "line_start": 83, "line_end": 87, "atom_id": "ATOM-SOURCE-20260206-036-0011"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.2, 0.7, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "960c2309-5f4a-57cd-a9a0-5c9becba9701", "timestamp": "2026-02-24T00:41:16.133896+00:00", "payload": {"atom_id": "ATOM-SOURCE-20260206-036-0012", "source_id": "SOURCE-20260206-036", "category": "claim", "content": "Activation Oracles can uncover misaligned goals in fine-tuned models without explicit training to do so, demonstrating surprising generalization.", "line_start": 83, "line_end": 87, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.8, 0.2, 0.1, 0.3, 0.6, 0.6], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20260206-036", "entity_type": "Claim", "name": "Activation Oracles can uncover misaligned goals in fine-tuned models without exp", "content": "Activation Oracles can uncover misaligned goals in fine-tuned models without explicit training to do so, demonstrating surprising generalization.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20260206-036", "line_start": 83, "line_end": 87, "atom_id": "ATOM-SOURCE-20260206-036-0012"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.8, 0.2, 0.1, 0.3, 0.6, 0.6], "opposes_atom_ids": []}, "extensions": {}}}
