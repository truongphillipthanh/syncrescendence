{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "9fbd0b56-e0ab-5abb-a997-03fb99984c8f", "timestamp": "2026-02-24T00:53:10.908326+00:00", "payload": {"atom_id": "ATOM-SOURCE-20251118-1080-0001", "source_id": "SOURCE-20251118-1080", "category": "claim", "content": "Baseten is one of the fastest-growing companies in the AI inference ecosystem.", "line_start": 10, "line_end": 11, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.0, 0.1, 0.1, 0.8], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20251118-1080", "entity_type": "Claim", "name": "Baseten is one of the fastest-growing companies in the AI inference ecosystem.", "content": "Baseten is one of the fastest-growing companies in the AI inference ecosystem.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20251118-1080", "line_start": 10, "line_end": 11, "atom_id": "ATOM-SOURCE-20251118-1080-0001"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.0, 0.1, 0.1, 0.8], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "fcaef6aa-7c47-5304-8212-5566a21c8470", "timestamp": "2026-02-24T00:53:10.908326+00:00", "payload": {"atom_id": "ATOM-SOURCE-20251118-1080-0002", "source_id": "SOURCE-20251118-1080", "category": "concept", "content": "Modern AI inference faces core challenges including the importance of dedicated deployments, runtime and infrastructure bottlenecks, and the fundamental differences in serving large models compared to smaller ones.", "line_start": 14, "line_end": 17, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.0, 0.1, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20251118-1080", "entity_type": "Concept", "name": "Modern AI inference faces core challenges including the importance of dedicated", "content": "Modern AI inference faces core challenges including the importance of dedicated deployments, runtime and infrastructure bottlenecks, and the fundamental differences in serving large models compared to smaller ones.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20251118-1080", "line_start": 14, "line_end": 17, "atom_id": "ATOM-SOURCE-20251118-1080-0002"}, "metadata": {"category": "concept", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.0, 0.1, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "d1272525-9ffc-5016-844b-430960fc2075", "timestamp": "2026-02-24T00:53:10.908326+00:00", "payload": {"atom_id": "ATOM-SOURCE-20251118-1080-0003", "source_id": "SOURCE-20251118-1080", "category": "claim", "content": "Reliability becomes harder to maintain as AI systems scale.", "line_start": 20, "line_end": 20, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.0, 0.1, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20251118-1080", "entity_type": "Claim", "name": "Reliability becomes harder to maintain as AI systems scale.", "content": "Reliability becomes harder to maintain as AI systems scale.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20251118-1080", "line_start": 20, "line_end": 20, "atom_id": "ATOM-SOURCE-20251118-1080-0003"}, "metadata": {"category": "claim", "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.0, 0.1, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}}
{"record_type": "source_atom", "schema_version": "1.0.0", "uuid": "8c68deab-ae70-5475-953b-fefc3fd71ab5", "timestamp": "2026-02-24T00:53:10.908326+00:00", "payload": {"atom_id": "ATOM-SOURCE-20251118-1080-0004", "source_id": "SOURCE-20251118-1080", "category": "praxis_hook", "content": "Company building in the AI inference market involves killing product lines and avoiding premature scaling while navigating a rapidly shifting market.", "line_start": 22, "line_end": 23, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.3, 0.5, 0.1, 0.2, 0.7, 0.5], "opposes_atom_ids": []}, "extensions": {}}, "source_id": "SOURCE-20251118-1080", "entity_type": "PraxisHook", "name": "Company building in the AI inference market involves killing product lines and a", "content": "Company building in the AI inference market involves killing product lines and avoiding premature scaling while navigating a rapidly shifting market.", "confidence": 1.0, "provenance": {"source_id": "SOURCE-20251118-1080", "line_start": 22, "line_end": 23, "atom_id": "ATOM-SOURCE-20251118-1080-0004"}, "metadata": {"category": "praxis_hook", "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.3, 0.5, 0.1, 0.2, 0.7, 0.5], "opposes_atom_ids": []}, "extensions": {}}}
