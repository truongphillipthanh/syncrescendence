# Extraction: SOURCE-20251205-919

**Source**: `SOURCE-20251205-youtube-lecture-arc_prize-arc_prize_2025_paper_award_1st_place_trm.md`
**Atoms extracted**: 4
**Categories**: claim, concept

---

## Claim (3)

### ATOM-SOURCE-20251205-919-0001
**Lines**: 12-12
**Context**: consensus / claim
**Tension**: novelty=0.10, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.10, actionability=0.10, epistemic_stability=0.80

> The Tiny Recursive Model (TRM) is a single-network recursive model with approximately 7 million parameters.

### ATOM-SOURCE-20251205-919-0002
**Lines**: 12-12
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.10, actionability=0.10, epistemic_stability=0.70

> The Tiny Recursive Model (TRM) utilizes separate answer and latent states.

### ATOM-SOURCE-20251205-919-0003
**Lines**: 12-12
**Context**: consensus / claim
**Tension**: novelty=0.20, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.10, actionability=0.10, epistemic_stability=0.70

> The Tiny Recursive Model (TRM) achieves approximately 45% performance on ARC-AGI-1 and 8% on ARC-AGI-2 through deep supervised refinement.

## Concept (1)

### ATOM-SOURCE-20251205-919-0004
**Lines**: 12-12
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.10, actionability=0.20, epistemic_stability=0.60

> The Tiny Recursive Model (TRM) is a recursive model designed with a small parameter count (~7M) and a single network architecture, distinguishing between answer and latent states, and refined via deep supervision.
