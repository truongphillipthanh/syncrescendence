{"atom_id": "ATOM-SOURCE-20260215-011-0001", "source_id": "SOURCE-20260215-011", "category": "claim", "content": "After 30 days, an AI agent team using the same model and prompts can produce high-quality drafts with minimal edits, due to accumulated context stored in files that agents read daily.", "line_start": 9, "line_end": 12, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.7, 0.3, 0.1, 0.2, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260215-011-0002", "source_id": "SOURCE-20260215-011", "category": "praxis_hook", "content": "Corrective prompt-engineering involves starting with a rough sketch of an agent's personality, observing its behavior, and course-correcting over time, similar to managing human team members.", "line_start": 23, "line_end": 26, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.1, 0.2, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260215-011-0003", "source_id": "SOURCE-20260215-011", "category": "praxis_hook", "content": "To improve AI agent output, provide specific feedback that can be codified into rules, rather than general instructions like 'make this better.'", "line_start": 30, "line_end": 30, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.1, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260215-011-0004", "source_id": "SOURCE-20260215-011", "category": "praxis_hook", "content": "Maintain an agent's memory file with specific examples of rejected patterns and good tone/style, allowing the agent to self-correct and reverse-engineer desired output.", "line_start": 34, "line_end": 39, "chaperone": {"context_type": "method", "argument_role": "evidence", "tension_vector": [0.6, 0.3, 0.1, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260215-011-0005", "source_id": "SOURCE-20260215-011", "category": "praxis_hook", "content": "Implement 'ruthless rules' for research agents, such as filtering information based on whether the target reader can immediately act on it, to reduce noise and increase signal.", "line_start": 46, "line_end": 49, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.3, 0.1, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260215-011-0006", "source_id": "SOURCE-20260215-011", "category": "concept", "content": "Memory in the context of AI agents refers to what the agent has learned about working with a specific user or context, while skill refers to how to correctly perform a specific task.", "line_start": 48, "line_end": 49, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.7, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260215-011-0007", "source_id": "SOURCE-20260215-011", "category": "claim", "content": "Skill files for AI agents compound faster than memory because they are prescriptive.", "line_start": 49, "line_end": 50, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.2, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260215-011-0008", "source_id": "SOURCE-20260215-011", "category": "praxis_hook", "content": "To ensure AI agent improvement, feedback must be stored persistently in a file (memory or skill file) rather than remaining in conversational chat, so the agent can load the lesson in subsequent sessions.", "line_start": 51, "line_end": 58, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.4, 0.5, 0.1, 0.2, 0.9, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260215-011-0009", "source_id": "SOURCE-20260215-011", "category": "framework", "content": "AI agent teams typically progress through three phases: Phase 1 (Mediocre everything, days 1-7) with generic output and high correction overhead; Phase 2 (Specific competence, days 8-21) with feedback accumulation and output improvements; and Phase 3 (Compounding returns, day 22+) with rich context and minimal changes needed.", "line_start": 63, "line_end": 79, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.5, 0.4, 0.2, 0.2, 0.6, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260215-011-0010", "source_id": "SOURCE-20260215-011", "category": "praxis_hook", "content": "To transition an AI agent from Phase 1 to Phase 2, provide specific feedback that explains 'why' something is wrong and how it relates to the audience or goals, rather than vague corrections.", "line_start": 79, "line_end": 79, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.5, 0.1, 0.2, 0.9, 0.6], "opposes_atom_ids": []}, "extensions": {}}
