# Extraction: SOURCE-20251113-1141

**Source**: `SOURCE-20251113-youtube-lecture-ai_news_strategy_daily_nate_b-how_i_improved_ai_output_quality_10x_with_one_prompting_shif.md`
**Atoms extracted**: 5
**Categories**: claim, concept, praxis_hook

---

## Claim (3)

### ATOM-SOURCE-20251113-1141-0002
**Lines**: 20-20
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.70

> Over-specifying in LLM prompts can hinder creativity and consume excessive context.

### ATOM-SOURCE-20251113-1141-0003
**Lines**: 21-21
**Context**: consensus / claim
**Tension**: novelty=0.30, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.40, epistemic_stability=0.70

> Under-prompting forces large language models to make guesses.

### ATOM-SOURCE-20251113-1141-0005
**Lines**: 25-25
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.60, contradiction_load=0.10, speculation_risk=0.20, actionability=0.50, epistemic_stability=0.70

> A balanced prompting strategy provides operators and teams with more control over LLMs without suppressing the model's judgment.

## Concept (1)

### ATOM-SOURCE-20251113-1141-0001
**Lines**: 16-22
**Context**: method / claim
**Tension**: novelty=0.70, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.60, epistemic_stability=0.50

> Goldilocks prompting refers to finding the optimal level of detail in LLM prompts, avoiding both over-specification and under-prompting, to enhance model performance and creativity.

## Praxis Hook (1)

### ATOM-SOURCE-20251113-1141-0004
**Lines**: 23-23
**Context**: method / claim
**Tension**: novelty=0.60, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.30, actionability=0.80, epistemic_stability=0.60

> Using short, reusable prompt 'slugs' can be more effective than long instruction dumps for LLM prompting.
