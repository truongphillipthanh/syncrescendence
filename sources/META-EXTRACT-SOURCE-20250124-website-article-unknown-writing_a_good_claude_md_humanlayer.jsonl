{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0001", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "concept", "content": "LLMs are stateless functions, meaning their weights are fixed during inference and they do not learn over time. Their knowledge of a codebase is limited to the tokens provided in the current input.", "line_start": 10, "line_end": 12, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.0, 0.9, 0.0, 0.0, 0.1, 0.9], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0002", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "claim", "content": "Coding agent harnesses, such as Claude Code, typically require explicit management of agents' memory.", "line_start": 14, "line_end": 15, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.0, 0.0, 0.2, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0003", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "claim", "content": "`CLAUDE.md` (or `AGENTS.md`) is the default file included in every conversation with a coding agent.", "line_start": 15, "line_end": 17, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.0, 0.0, 0.2, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0004", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "praxis_hook", "content": "Use `CLAUDE.md` to onboard Claude to your codebase by providing information on 'WHAT' (tech stack, project structure, monorepo details), 'WHY' (project purpose, function of parts), and 'HOW' (execution environment, verification steps like tests, typechecks, compilation).", "line_start": 29, "line_end": 42, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.0, 0.1, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0005", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "claim", "content": "Claude often ignores the contents of `CLAUDE.md` files, regardless of the model used.", "line_start": 47, "line_end": 48, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.0, 0.1, 0.1, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0006", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "claim", "content": "Claude Code injects a system reminder with `CLAUDE.md` content, instructing the agent to ignore it unless highly relevant to the task.", "line_start": 51, "line_end": 57, "chaperone": {"context_type": "consensus", "argument_role": "evidence", "tension_vector": [0.1, 0.7, 0.0, 0.0, 0.1, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0007", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "claim", "content": "Claude is more likely to ignore `CLAUDE.md` instructions if they are not universally applicable to the tasks it is working on.", "line_start": 60, "line_end": 63, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.0, 0.1, 0.1, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0008", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "claim", "content": "Anthropic likely added the instruction to ignore `CLAUDE.md` content because many users appended 'hotfixes' and non-broadly applicable instructions, and telling Claude to ignore these led to better results.", "line_start": 66, "line_end": 72, "chaperone": {"context_type": "speculation", "argument_role": "claim", "tension_vector": [0.3, 0.5, 0.0, 0.7, 0.1, 0.5], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0009", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "claim", "content": "An LLM performs better on a task when its context window is filled with focused, relevant information (examples, related files, tool calls, tool results) rather than irrelevant context.", "line_start": 83, "line_end": 86, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.0, 0.1, 0.2, 0.9], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0010", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "praxis_hook", "content": "When writing `CLAUDE.md`, prioritize fewer instructions, ideally only those universally applicable to the task, as LLMs have limits on instruction following and performance degrades with more instructions.", "line_start": 87, "line_end": 90, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.0, 0.1, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0011", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "praxis_hook", "content": "Ensure the contents of `CLAUDE.md` are as universally applicable as possible, avoiding task-specific instructions (e.g., how to structure a new database schema) that would distract the model in unrelated contexts.", "line_start": 88, "line_end": 94, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.0, 0.1, 0.8, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0012", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "praxis_hook", "content": "Keep the `CLAUDE.md` file concise; general consensus suggests less than 300 lines, with shorter being even better, to optimize LLM performance.", "line_start": 96, "line_end": 99, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.0, 0.1, 0.7, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0013", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "framework", "content": "The principle of Progressive Disclosure can be applied to LLM instructions by keeping task-specific instructions in separate, self-descriptive markdown files (e.g., `building_the_project.md`, `running_tests.md`) and having `CLAUDE.md` instruct the LLM to decide which files are relevant to read.", "line_start": 105, "line_end": 120, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.0, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0014", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "praxis_hook", "content": "When using separate instruction files for an LLM, prefer pointers to copies by including `file:line` references instead of code snippets, as snippets can quickly become outdated.", "line_start": 122, "line_end": 124, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.5, 0.5, 0.0, 0.1, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0015", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "praxis_hook", "content": "Avoid including code style guidelines in `CLAUDE.md` because LLMs are expensive and slow compared to traditional linters and formatters; always use deterministic tools when possible.", "line_start": 128, "line_end": 131, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.4, 0.6, 0.0, 0.1, 0.9, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0016", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "claim", "content": "Code style guidelines and mostly-irrelevant code snippets in an LLM's context window degrade performance, instruction-following, and consume valuable context.", "line_start": 133, "line_end": 135, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.0, 0.1, 0.2, 0.9], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0017", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "claim", "content": "LLMs are in-context learners, meaning if code follows certain style guidelines, the LLM should tend to follow those patterns without explicit instruction, especially with access to the codebase or documentation.", "line_start": 137, "line_end": 140, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.0, 0.1, 0.3, 0.9], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0018", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "praxis_hook", "content": "Set up a Claude Code Stop hook that runs a formatter and linter and presents errors to Claude for fixing, rather than having Claude find formatting issues itself.", "line_start": 142, "line_end": 144, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.0, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0019", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "praxis_hook", "content": "Use a linter that can automatically fix issues, and carefully tune its rules for maximum safe auto-fix coverage.", "line_start": 146, "line_end": 148, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.4, 0.6, 0.0, 0.1, 0.9, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0020", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "praxis_hook", "content": "Create a Slash Command that includes code guidelines and points Claude to changes in version control or `git status` to handle implementation and formatting separately, leading to better results.", "line_start": 150, "line_end": 153, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.6, 0.4, 0.0, 0.2, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer-0021", "source_id": "SOURCE-20250124-website-article-unknown-writing_a_good_claude_md_humanlayer", "category": "praxis_hook", "content": "Avoid auto-generating `CLAUDE.md` files, as it is the highest leverage point of the harness and requires careful crafting to define the project's WHY, WHAT, and HOW.", "line_start": 157, "line_end": 164, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.5, 0.5, 0.0, 0.2, 0.9, 0.8], "opposes_atom_ids": []}, "extensions": {}}
