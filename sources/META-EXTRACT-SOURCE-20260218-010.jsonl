{"atom_id": "ATOM-SOURCE-20260218-010-0001", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "OpenClaw agents frequently forget basic information, lose critical project context mid-conversation, and fail to recall decisions made shortly before.", "line_start": 15, "line_end": 17, "chaperone": {"context_type": "anecdote", "argument_role": "claim", "tension_vector": [0.1, 0.8, 0.1, 0.1, 0.2, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0002", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "OpenClaw treats memory as a suggestion, not a requirement, allowing the agent to decide what to save, when to search, and what to recall, leading to forgetting by default without explicit configuration.", "line_start": 25, "line_end": 27, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0003", "source_id": "SOURCE-20260218-010", "category": "framework", "content": "There are three common failure modes for memory in OpenClaw: memory is never saved, memory is saved but never retrieved, and context compaction destroys knowledge.", "line_start": 29, "line_end": 30, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.6, 0.1, 0.1, 0.4, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0004", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "In OpenClaw, the LLM decides whether information is worth saving to disk, meaning important context can be lost if the model deems it not worth storing.", "line_start": 34, "line_end": 36, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0005", "source_id": "SOURCE-20260218-010", "category": "analogy", "content": "OpenClaw's memory saving mechanism, where the LLM decides what to save, is like an employee who decides on their own which meeting notes to keep and which to throw away.", "line_start": 42, "line_end": 42, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.5, 0.1, 0.1, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0006", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "Even when facts are saved to disk in OpenClaw, recall is not guaranteed because the agent must decide to use the `memory_search` tool, often answering from its current context window instead.", "line_start": 45, "line_end": 48, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0007", "source_id": "SOURCE-20260218-010", "category": "analogy", "content": "OpenClaw's memory retrieval issue, where an agent answers from its context window instead of searching saved memory, is like an employee who saved a document but answers from memory instead of checking the actual document when asked.", "line_start": 50, "line_end": 51, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.5, 0.1, 0.1, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0008", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "OpenClaw compacts context to avoid token limits, summarizing or removing older messages, which destroys any information that only existed in the active conversation and was not yet saved to disk.", "line_start": 54, "line_end": 56, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0009", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "Even content in MEMORY.md can be summarized away during a long session due to context compaction, causing the agent to forget mid-conversation.", "line_start": 57, "line_end": 59, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.7, 0.1, 0.1, 0.3, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0010", "source_id": "SOURCE-20260218-010", "category": "analogy", "content": "OpenClaw's context compaction, which removes older messages to make room, is like an employee with a stack of papers who throws out the oldest ones without saving important information when the stack gets too tall.", "line_start": 61, "line_end": 62, "chaperone": {"context_type": "anecdote", "argument_role": "evidence", "tension_vector": [0.3, 0.5, 0.1, 0.1, 0.2, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0011", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "To fix OpenClaw memory issues, configure memory flush, context pruning, hybrid search, and session indexing before resorting to external plugins or databases.", "line_start": 65, "line_end": 67, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0012", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "Enable memory flush in OpenClaw's compaction settings by setting `enabled: true` and customizing the prompt to specifically capture decisions, state changes, lessons, and blockers, while also raising `softThresholdTokens` to 40000.", "line_start": 70, "line_end": 81, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0013", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "Configure context pruning in OpenClaw using `cache-ttl` mode with a `ttl` of '6h' and `keepLastAssistants` set to 3 to retain recent messages and prevent their removal during compaction.", "line_start": 83, "line_end": 89, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0014", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "Enable hybrid search in OpenClaw's `memorySearch` configuration by setting `hybrid.enabled: true` and adjusting `vectorWeight` (e.g., 0.7) and `textWeight` (e.g., 0.3) to combine vector similarity and BM25 keyword search for improved retrieval accuracy.", "line_start": 91, "line_end": 98, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.6, 0.1, 0.1, 0.9, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0015", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "To get started with QMD, have your agent review the QMD Github repository and discuss it before implementation, then install it. Always back up your system before installing new memory systems.", "line_start": 93, "line_end": 96, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.1, 0.2, 0.1, 0.1, 0.9, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0016", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "QMD's killer feature is its ability to index external document collections like Obsidian vaults, project documentation, and Notion exports, making them searchable via memory_search.", "line_start": 97, "line_end": 99, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.2, 0.3, 0.1, 0.1, 0.7, 0.8], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0017", "source_id": "SOURCE-20260218-010", "category": "concept", "content": "Mem0 is a memory layer for AI applications that stores memories outside the context window, preventing compaction from destroying them.", "line_start": 102, "line_end": 104, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.1, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0018", "source_id": "SOURCE-20260218-010", "category": "framework", "content": "Mem0 operates with two processes per turn: Auto-Capture, which detects and stores information without LLM judgment, and Auto-Recall, which searches and injects relevant memories before the agent responds.", "line_start": 105, "line_end": 108, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.1, 0.7, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0019", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "Mem0's auto-capture and auto-recall mechanisms completely solve memory failure modes related to automatic capture and compaction.", "line_start": 109, "line_end": 110, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.1, 0.2, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0020", "source_id": "SOURCE-20260218-010", "category": "concept", "content": "Cognee builds a knowledge graph from data, ingesting OpenClaw's memory files to construct a graph of entities and relationships, which allows for structured representation of concepts and their connections.", "line_start": 114, "line_end": 117, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.4, 0.3, 0.1, 0.1, 0.6, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0021", "source_id": "SOURCE-20260218-010", "category": "claim", "content": "Cognee is suitable for scenarios requiring deep understanding of relationships and structured knowledge, such as enterprise settings or multi-agent teams, but might be overkill for basic OpenClaw setups.", "line_start": 118, "line_end": 120, "chaperone": {"context_type": "consensus", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.2, 0.5, 0.6], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0022", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "One way to integrate Obsidian with OpenClaw is to symlink your agent's memory folder to your Obsidian vault, allowing daily notes to appear in Obsidian for review, editing, and annotation across devices.", "line_start": 125, "line_end": 128, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.2, 0.3, 0.1, 0.1, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}
{"atom_id": "ATOM-SOURCE-20260218-010-0023", "source_id": "SOURCE-20260218-010", "category": "praxis_hook", "content": "Another robust approach for Obsidian integration is to index your vault via QMD, making all captured Obsidian content searchable by agents, which also saves token costs as Obsidian 1.12's CLI allows querying metadata instead of reading entire files.", "line_start": 130, "line_end": 133, "chaperone": {"context_type": "method", "argument_role": "claim", "tension_vector": [0.3, 0.4, 0.1, 0.1, 0.8, 0.7], "opposes_atom_ids": []}, "extensions": {}}
