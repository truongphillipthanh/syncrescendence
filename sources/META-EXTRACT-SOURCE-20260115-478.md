# Extraction: SOURCE-20260115-478

**Source**: `SOURCE-20260115-youtube-lecture-caleb_writes_code-ai_subscription_vs_h100.md`
**Atoms extracted**: 3
**Categories**: claim, framework, praxis_hook

---

## Claim (1)

### ATOM-SOURCE-20260115-478-0002
**Lines**: 10-12
**Context**: consensus / claim
**Tension**: novelty=0.40, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.30, actionability=0.60, epistemic_stability=0.70

> The increasing cost of AI intelligence and ongoing GPU improvements suggest a potential tipping point where upfront hardware investment becomes more economical than recurring subscription or API fees for heavy users.

## Framework (1)

### ATOM-SOURCE-20260115-478-0003
**Lines**: 13-15
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.50, contradiction_load=0.10, speculation_risk=0.20, actionability=0.70, epistemic_stability=0.60

> Evaluating AI pricing tiers for heavy users involves comparing different pricing models (subscription, API) and considering various model architectures against the total cost of ownership (TCO) for purchasing dedicated hardware like NVIDIA H100s or DGX H100s.

## Praxis Hook (1)

### ATOM-SOURCE-20260115-478-0001
**Lines**: 10-12
**Context**: method / claim
**Tension**: novelty=0.30, consensus_pressure=0.40, contradiction_load=0.10, speculation_risk=0.20, actionability=0.80, epistemic_stability=0.60

> Heavy users of AI models like Claude Code should consider pooling resources to purchase NVIDIA hardware upfront, such as H100 GPUs, as an alternative to accumulating subscription or API costs.
