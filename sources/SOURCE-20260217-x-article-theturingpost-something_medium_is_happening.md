---
url: https://x.com/TheTuringPost/status/2023739917486948536
author: "Ksenia_TuringPost (@TheTuringPost)"
captured_date: 2026-02-17
id: SOURCE-20260217-015
original_filename: "20260217-x_article-something_medium_is_happening-@theturingpost.md"
status: triaged
platform: x
format: article
creator: theturingpost
signal_tier: strategic
topics: [ai-adoption, media-criticism, philosophy, psychology]
teleology: contextualize
notebooklm_category: general
aliases: ["theturingpost - something medium is happening"]
synopsis: "Counterpoint to Matt Shumer's viral 'Something Big is Happening' post (83M views). Agrees AI capability is real but rejects the emergency framing as producing permanent cognitive overdrive and burnout. Argues capability, adoption, regulation, and institutional inertia are separate curves that don't synchronize. Key prescription: instead of 'spend one hour a day experimenting with AI,' achieve one real outcome per week meaningfully better with AI — goal-first learning, not time-based practice."
key_insights:
  - "Time is not the unit of learning, feedback is — instead of 'play with AI for an hour,' achieve one real outcome per week meaningfully better with AI"
  - "The discourse trains people to live in permanent cognitive overdrive — Twitter's intensity makes you feel behind even when actively shipping work with AI systems"
  - "Capability is one curve, adoption another, regulation another — the implied uniformity of 'one to five years' masks a far messier timeline distribution across industries"
---
# Something Medium is Happening?
![#140: Something Medium is Happening?](https://x.com/TheTuringPost/status/2023739917486948536) 
(Description: Vibrant abstract artwork featuring swirling patterns in blues, oranges, reds, and yellows with an artist's brush or pencil crossing diagonally. Overlay text reads "#140: Something Medium is Happening?" in a monospace font. TuringPost branding visible in bottom right corner.)
I want to start by thanking [@mattshumer_](https://x.com/@mattshumer_) for his ["Something Big is Happening."](https://x.com/mattshumer_/status/2021256989876109403) It ricocheted through the part of Twitter I follow until it felt like it had swallowed the whole platform. People were quoting it, reacting to it, forwarding it to their friends with the digital equivalent of grabbing someone by the shoulders. It has 83 million views. Clearly, it hit a nerve.
I also want to argue with it, even if that puts me on the unpopular side of the timeline. Because his piece gave me a real anxiety, the one that is unproductive.
## Let's start with what I agree with.
Matt is right that the pace feels different now. For people who actually use frontier models daily, "AI as a helpful tool" has been sliding toward "AI as an independent worker" in a way that is hard to explain to someone who only played with a free-tier chatbot a year ago. 
He's also right about the perception gap: public understanding lags behind capability, and the lag creates bad decisions. The most wrong thing you can do today is to dismiss AI.
He's also right about the labor market direction. If your work happens on a screen and your core output is text, analysis, code, structured documents, and decisions expressed through a keyboard, you are exposed. The question is not whether AI touches your job. It already does. The question is how quickly tasks get unbundled, automated, and re-priced inside your role. By you, but Matt doesn't say that explicitly.
## Now what I disagree with.
### First, I reject the emotional framing.
Comparing this moment to February 2020 is effective storytelling, but it also turns "learning how to work with a new general-purpose tool" into an emergency broadcast. That framing produces a very specific kind of reader: anxious, compulsively online, and primed to interpret every model release as a life-or-death update. If you already spend time in the Silicon Valley bubble, this is gasoline on the fire. If not, you will feel this sticky anxiety.
That anxiety is not "AI will take my job tomorrow." It's "the discourse is training us to live in permanent cognitive overdrive." That is simply inhuman. Twitter's intensity can make you feel behind even when you are actively shipping work with these systems. There is always another tool, another meetup, another startup demo, another "you're late" thread. That is a very effective recipe for burnout.
### Second, I don't buy the implied uniformity of impact.
Capability is one curve. Adoption is another. Incentives, regulation, liability, procurement, internal politics, and institutional inertia are their own curves, and they do not politely synchronize. Some roles will compress rapidly. Others will change slowly, then suddenly. Matt's directional forecast can be right while the timeline distribution across industries is far messier than "one to five years" suggests. It's big, but it also medium (all this in the middle. mediocre stuff).
## So where does it bring us?
### Third thing I disagree with: how to learn working with AI.
Instead of emotions we should think about goal-setting. Taste. Knowing what matters. About stitching context into a decision that has consequences. To being accountable. About the boring parts that turn capability into reality: integration, evaluation, reliability, compliance, human trust, organizational adoption, and all the messy edges where the real world refuses to behave like a clean benchmark. Again, it's that medium part that matters, not the grandeur of a model or a tool.
Matt gives an advice: "Spend one hour a day experimenting with AI." And I just disagree with that so much.
It teaches a completely wrong muscle. Time is not the unit of learning. Feedback is.
Kids don't learn by allocating 60 minutes to "walking practice." They learn because they want something: open the jar, reach the table, climb the stairs, get the parent's attention. Goal first. Attempts. Feedback. Repeat until the world changes.
So instead of "playing" with AI, you should choose a goal and achieve one real outcome per week meaningfully better with AI.
That forces a goal. And a goal forces evaluation. And it actually makes you feel better because you start achieving things.
There's also a quieter (literal) point that gets missed in the alarm: if you're reading this, you're already inside the tiny internet class that can spend hours discussing AI on the internet. That's not "everyone." That's a self-selected group with a particular set of incentives, and sometimes a suspicious amount of time. Maybe that's what we need AI for – to let us spend more time on social networks… Anyway, 84 millions is very big. But not as much as 8 billion people on the planet.
## What I would like to leave you with:
Treat AI like a power tool with a marketing department. Respect the capability. Ignore the adrenaline. Pick a goal you genuinely care about, then use the tool to move faster toward it. Your intelligence now is to move AI towards the right outcome for you.
Happy building.
---
**Read the full article:** https://www.turingpost.com/p/fod140
**Posted:** 4:42 AM · Feb 17, 2026  
**Views:** 7,255  
**Engagement:** 4 reposts, 14 likes, 13 bookmarks