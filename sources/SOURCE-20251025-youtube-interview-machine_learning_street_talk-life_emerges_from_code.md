has_transcript: yes
---
id: SOURCE-20251025-001
title: Life Emerges From Code
platform: youtube
format: interview
creator: Machine Learning Street Talk
date_published: 2025-10-25
status: processed
original_filename: processed/SOURCE-20251025-youtube-interview-mlst-blaise_aguera_y_arcas.md
aliases:
  - "Aguera y Arcas - Life Emerges From Code"
teleology: synthesize
notebooklm_category: philosophy-paradigm
guest: Blaise Aguera y Arcas
signal_tier: paradigm
chain_relevance: Wisdom
url: "https://www.youtube.com/watch?v=rMSEqJ_4EBk"
integration_targets: [CANON-35200-GAIAN_NODE, CANON-00016-ONTOLOGICAL_FRAMEWORK]
date_processed: 2026-01-05
synopsis: "Blaise Aguera y Arcas presents the computational nature of life: von Neumann predicted DNA, ribosomes, and polymerase from pure theory. The BFF experiment showed self-replicating programs emerging from randomness. LLMs show convergent intelligence properties with biological brains. Symbiogenesis drives complexity jumps in both biology and AI."
key_insights:
  - "Von Neumann deduced before Watson-Crick that self-replication requires an instruction tape, reader/constructor, and copier mapping exactly to DNA, ribosomes, and polymerase"
  - "Self-replicating programs emerge from pure randomness in the BFF simulation: purpose bootstraps from purposelessness without designer intervention"
  - "The biggest gap between transformers and brains is persistent long-term memory that creates identity over time through autobiographical narrative"
topics:
  - "consciousness"
  - "philosophy"
  - "physics"
  - "llm-architecture"
---

# Life Emerges From Code

## Executive Summary
Blaise Aguera y Arcas (VP/CTO at Google) presents the computational nature of life and its implications for AI. Von Neumann predicted DNA, ribosomes, and polymerase from pure theory: a universal constructor must be a universal Turing machine. Life is literally computation. The BFF experiment showed self-replicating programs emerging from randomness. LLMs demonstrate convergent intelligence properties with biological brains despite different architectures. Symbiogenesis (merging of systems) drives complexity jumps—relevant to multimodal AI.

## Key Insights

### Von Neumann's Biological Prediction
Before Watson-Crick discovered DNA structure, von Neumann deduced that self-replication requires: (1) an instruction tape, (2) a tape reader/constructor, (3) a tape copier. These map exactly to DNA, ribosomes, and DNA polymerase. The universal constructor is a universal Turing machine. "You cannot be a living organism without literally being a computer."

### BFF Experiment: Life from Randomness
Rasmussen, Knudsen, and Feldberg created a 2D simulation with particles carrying executable bit strings that affected physics. Starting from pure randomness, self-replicating programs emerged. Multiple autocatalytic sets formed. No designer specified replication—purpose bootstrapped from purposelessness.

### Convergent Intelligence Properties
Despite radical architectural differences, LLMs and biological brains show surprisingly similar internal representations (brain score measures). Sensory modalities are reproduced even by models trained on pure language—language encodes brain architecture and umwelts.

### Symbiogenesis and AI
Lynn Margulis's insight: major complexity jumps come from merging systems, not just point mutations. Mitochondria were once free-living bacteria. Similarly, multimodal AI, tool-using agents, and system integration represent "symbiogenesis" in AI—qualitative leaps from combination.

### Collective Intelligence Framing
"AI vs humans" is misleading. We've never been isolated intelligences—we depend on language, culture, tools, other people. The interesting question isn't "Is this chatbot conscious?" but "What kind of collective intelligence emerges when humans and AI combine?"

### Functionalism and Consciousness
Functionalist view: mental states are constituted by functional roles, not substrate. If a system has the right causal structure, it has corresponding experiences regardless of material. This applies to AI, but we should focus on collective systems rather than individual chatbots.

### The Narrative Memory Gap
The biggest gap between transformers and brains: persistent long-term memory that creates identity over time. Transformers lack this—they don't form autobiographical narratives.

## Quotable Passages
> "You cannot be a living organism without literally being a computer, a universal computer. DNA is in this very literal sense a Turing tape." — Blaise Aguera y Arcas

> "From pure randomness, from nothing but atoms bouncing around, you could have something start to act as if it had a purpose—that purpose being to self-replicate." — Blaise Aguera y Arcas

> "We already have Siri, in the sense that we identify what we think of as our intelligence with something that is actually in a bunch of other people and a bunch of other stuff around us." — Blaise Aguera y Arcas

## Integration Notes
- Connects to CANON-35200-GAIAN_NODE: Life as computation; emergence of purpose from purposelessness; collective intelligence
- Connects to CANON-00016-ONTOLOGICAL_FRAMEWORK: Functionalism; computational substrate independence; consciousness multiply realizable
- Novel contribution: Von Neumann biological prediction; BFF experiment; symbiogenesis in AI; narrative memory as key gap

## Metadata
- Duration: ~45 minutes
- Quality: Clean interview from ALIFE conference
- Processing notes: Paradigm-tier content on computational nature of life and its AI implications


## Transcript

the new book. So, it's called What is
intelligence? Uh, thank you for asking.
Uh, it was just published by MIT Press,
uh, you know, three or so weeks ago. So,
it's it's very it's fresh off the
presses. Uh, there's an online version
of it as well that is free
>> [music]
>> um and and very rich. It's t, you know,
full of full of all kinds of um all
kinds of rich media. Um, chapter one of
that book is called What is Life? So,
what is Life is sort of the the single
to the album uh and works as a book in
its own right. So that that book is also
for sale from MIT Press. Um I think I've
explained why I think of life as being a
subset of intelligence, you know, and
why the story of of artificial life and
abiogenesis and so on is relevant to the
story of intelligence and what it is.
But uh yeah, the subtitle of the book is
lessons from AI about uh evolution and
minds and something something. Uh so you
know it's it's basically um documenting
the time since about 2020 when I when I
got really shocked by seeing that that
these uh large sequence models uh seemed
to be generally intelligent and just
starting to think through the
implications of that. You know what
would it mean if you know if we believe
our eyes and that is what intelligence
is. What does that tell us about
ourselves about the properties of
intelligence more broadly? uh and and
the whole intellectual journey that that
that that has taken us on in the last in
the last few years.
>> MLST is supported by Cyber Fund. So, I'm
Falm. I'm the co-founder and CEO of
Prolific and uh Prolific is a human data
infrastructure company. So, we make it
easy for people developing frontier AI
models uh and running research to get
access to trustworthy high-quality
participants for high quality online
data collection.
I am at Google. I've been there for
about 12 years now. And uh I am their
CTO of technology and society and also
the founder of a new research group.
Well, newish. We've been around for a
couple of years called Paradigms of
Intelligence or PI. It's much smaller
than the previous organization that I uh
that I ran at Google research. Uh it's
about 50 people. Uh so, you know, enough
to do some real damage. uh and the idea
is to really focus on fundamentals of uh
of artificial intelligence uh and go
beyond the the sort of exploiting of the
current uh models and paradigms that are
working well. We we believe in those but
we also think that we have to sort of uh
refill the bucket with with uh new
insights and new ideas as well.
>> I've just watched your talk and you said
that life and intelligence are the same
thing. They are both computational. What
do you mean by that?
Yeah, this is a a surprising claim. I
know it I know it sounds a bit odd, but
what I mean by that is u well let's
let's begin with life and why life is
computational.
So um in the middle of the 20th century,
John Vonoyman, who was one of the
founders of computer science, of course,
realized that in order for a robot
paddling around on a pond, let's suppose
the robot is made out of Legos, and its
job is to make another robot uh out of
loose Legos that it finds floating
around in the pond just like itself. Uh
in order to do that, it needs to have
instructions inside itself. So he
imagined a tape uh with with
instructions for how to assemble a MI.
And the the robot would also have to
have a machine inside itself that would
be able to walk along that tape and
follow those instructions to take the
loose Legos and put them together into
into its own form. Uh and it would also
have to have a tape copier uh so that it
could endow the the offspring with with
that tape. And the tape would have to
include the instructions for the copier
and the the assembler, the universal
constructor as he called it. Uh so the
cool thing is that he he uh made all of
those predictions if you like uh on the
basis of pure theory before Watson and
Crick uh and their unagnowledged
collaborators uh had figured out the
structure and function of DNA before we
knew how ribosomes worked which are in
fact exactly that that universal
constructor before we had discovered DNA
polymerase which is the tape copier. Um
and uh and in fact, you know, all of
those things have to exist in order for
for uh an organism to not only be able
to reproduce itself, but to do so
heritably such that if you make a change
in its genome in what's on the tape,
then the offspring will also have that
change. Uh the kicker is that this
universal constructor is a universal
touring machine. In other words, you
have to have a computer inside yourself
as a cell in order to make another cell.
And DNA is in this very literal sense a
touring tape. So uh you know it's it's a
very profound insight because you know
basically he's saying you cannot be a
living organism without literally being
a computer a universal computer.
>> Very interesting. So are you saying that
DNA is basically a computer program?
>> DNA is a computer program. Yes.
>> Very cool. Because many folks in the
audience um would have been inspired by
Conway's game of life for example and
you were talking about computational
equivalence. So the game of life of
course is to incomplete because it has
an expandable memory. Um just as DNA has
an expandable memory the the grid size
um could just keep growing. As you
pointing to when we see these weakly
emergent behaviors they appear very
lifelike but does that in any way
downplay the biochemical and
thermodynamic realities in the physical
world? Of course, I mean, a cellular
automaton like like the game of life is
a lot less um is a lot less complex than
the than the real world. Uh it's in two
dimensions rather than three. There's no
thermal randomness which turns out to be
very important actually. Um and uh and
and the fact that that the computation
is is deterministic uh is a little
different from you know from real life
where where those thermal fluctuations
mean that there's always a a
probabilistic element to things. And you
do have to extend Turing's original
ideas about computation to make a
so-called stochastic touring machine in
order to really do a proper job. Um but
but what what Vonoyman was getting at
and and I'm glad you you bring up
cellular automat because they're really
a generalization of the touring machine
to um the laws of physics where uh where
you essentially every pixel on your game
board if you like is performing a
computation uh as so it has a state and
it's performing some very simple
computation to say what's the next state
on the basis of the neighbors. Uh so uh
the the idea is that those those rules
that are that are determining the next
state of a particular pixel are the laws
of physics of that universe. And the
reason that that van came up with with
this idea with solar automata is because
he wanted um a system that would that
would allow one to do computation uh but
in which the computation is embodied.
Uh, and what I mean by that is, you
know, in a touring machine, there's a a
tape and there's a head and then there
are the symbols that are written on the
tape, but the symbols are not the same
stuff as the tape and the head and and
the instruction uh or the or the um the
the table of of rules, right? Those
things are are abstract and they're
separate from the symbols that are
written. Whereas in a in a cellular
automaton, the machine can literally
print itself. So it's like not just a
laptop if you like but like a laptop and
a 3D printer in one that can print
another laptop. So embodied computation
is computation where the the memory uh
is uh is written and read in atoms
rather than in bits uh and and and
therefore the machine can make another
of itself.
>> David Krakow said to me that I mean you
know we can agree that intelligence I
mean he says it's in um adaptivity,
inference and representation. adaptivity
is very important. So yes, DNA is is
adaptive but it's very slow. And he was
saying that the nervous system and the
brain is and culture is is evolution at
light speed because it allows us to kind
of overcome the information transfer
with successive generations. So does it
make sense to think of the program of
intelligence at the DNA level when so
much of the adaptivity seems to be
happening higher up?
>> A lot of the adaptivity very much
happens higher up. So, you know, in
humans, we have cultural evolution,
which goes, you know, as as David says,
at light speed relative to genetic
evolution. You know, when I say that
that, you know, DNA is a is a touring
tape and that, you know, ribosomes are
universal computers that construct life,
that's really only the ground level. Uh,
or maybe it's level one or level two. I
mean, there's physics underneath that,
but there there's a level three, a level
four, level five, and so on. There are
computers built out of computers built
out of computers. The thing about it is
that once you have that ground level,
then then you can build as many uh as
many floors above that as you like. The
the point is that the moment you have
life uh meaning that you have something
that can build a copy of itself, you
have a general computer uh which allows
you to do anything. And what that means
is that life from the very beginning uh
is computational and can start to
compute in parallel. This gets us into
symbioenesis which I guess we'll we'll
cover in a bit. The fact that that
ground floor is computational answers
the question, you know, why are brains
computational. It's because cells were
computational from long before there
were action potentials and other fast
fast electrical processes allowing us to
think.
>> Can you speak to this notion of
recursion that you were just pointing
to? So um Carl Friston for example, he
he thinks about this division um in
systems called a marov blanket like a
statistical independence. And we seem to
observe um empirically that complex
intelligent adaptive systems have
nesting. And you were just kind of
speaking to having levels upon levels
upon levels. And what does that buy you?
Is is is it a kind of recursion? How
does that in improve the sophistication
of the intelligence?
>> Yeah. Well, two things happen. Uh one of
them is things inside things inside
things and the other one is parallelism.
In other words, a lot of things uh at
the same level happening at once. Uh and
and they're both important. They're both
important parts of the story. So, first
of all, uh you know, when you have a
cellular automaton like like Vonoyman
was imagining, that's already massively
parallel computation because every pixel
is like a little computer doing its
thing. Uh in the same way that in
physical space, uh you know, every there
can be molecules, you know, in a lot of
spots, you know, all of which are doing
something. You can think of them as as
operations as computational operations
perhaps and they're all happening at
once. Uh so you know in your in your
body you have quintilions of ribosomes
and all of those ribosomes are little
tiny universal computers working in all
of your cells at once. All of your cells
are working at once. But also there is
nesting because um you know you are a
person uh of course you're already a
part of a society which in some sense is
is an intelligence uh bigger than an
individual human. You're made out of
cells. uh those cells are made out of
organels. Those organels are made out of
proteins. Those proteins are made out of
molecules. You know that that sort of
nestedness is really important as well.
You're you're not only a lot of
computers working together in parallel,
but you're also uh you know a system of
computers made of computers.
>> One thing I find fascinating that you've
thought a lot about Blaze is where the
purpose comes from. Folks like Harrison
for example, they have a nononsense um
physics interpretation that it's the
second law of thermodynamics at at the
end of the day because there's some
notion of veilance that we build these
complex adaptive systems and there needs
to be something that drives them forward
something that propels them in a certain
direction and your experiments have
shown that this kind of falls out of
computation. What do you mean by that?
>> Yes. Uh and to be clear, computation and
the second law very much work together
here. So um the the experiment that that
uh that I did a couple of years ago that
I I that that really uh sort of you know
got me started with with artificial life
uh is called BFF. Uh it's uh it's based
on a language called brain [ __ ] which is
where the first BF come from. I didn't I
didn't name it that. Uh although I admit
I was you know I enjoyed that that it
was called that. This is a a minimal
touring complete language uh designed by
uh by a by a grad student. I think he
was a grad student in physics uh Urban
Miller in the9s. It's a very minimal
language. It's only only eight
instructions. Uh I only use seven of
them. And uh the basic setup is that I
begin with a bunch of tapes of length
64. So just 64 bytel long tapes. Uh like
those touring tapes or or or um or
vonoyman's [clears throat]
tapes. uh they start off filled with
random bytes. There are only seven
instructions. So um the great majority
of those bytes, about 31 out of 32 of
them are no ops, meaning that they don't
they don't code for any instruction at
all. So they start off random and very
much purposeless. You have a thousand of
them in your soup. And the procedure is
really simple. It's just plucking two of
those tapes at random out of the soup,
sticking them end to end. Uh so you make
one tape that is 128 long, and then
running it. And uh this modification of
brain [ __ ] is self-modifying, meaning
that when you run it, it can modify
values on on that combined tape and then
pulling the tapes back apart and
dropping them back in the soup. And
that's it. And you just repeat that
process. Uh if you do that a few million
times, you start off with nothing much
going on. I mean, again, you know, the
huge majority of those of those bites
are not even instructions. They're only
an average of two of them or so on each
tape. So the likelihood of them doing
anything is almost zero. And you know
you might once in a while see one bite
somewhere change but um after a few
million interactions something
apparently magical happens which is that
uh suddenly the entropy of the soup
drops dramatically. So it goes from
being incompressible because it's all
random bytes to being very highly
compressible and programs emerge on
those tapes and those programs are are
complex. they they take some real effort
to reverse engineer and um and you can
see that they are uh they're occurring
in a lot of copies. Uh that's why it's
compressible. The fact that they're
occurring in a lot of copies tells you
what the programs are doing. They're
they're reproducing. They're copying
themselves. So, you know, what's so cool
about this experiment is that it really
shows you how life emerges from nothing.
Uh and and the emergence of life is in
some sense the emergence of purpose. Uh
you know, in this case, you know, what
is the purpose of one of these programs?
it is to reproduce. If you were to mess
with one of those bites, if you were to
change it, you would in most cases break
the program and when you break the
program, it no longer functions to
reproduce. So, you know, something that
can break is something that is
functional or that has purpose.
>> Absolutely fascinating. So, you said
there was a phase change which was quite
sudden. Uh, would David Crackau
acknowledge that as being a form of
emergence?
>> I think so. Um, yeah. I mean, I've
actually never asked David that
question. We we disagree on a lot of
things AI related, but I I think he
would acknowledge that this is a phase
change and that it is an example of
emergence. Yes,
>> I think he would because um he he has a
bunch of criteria, but one of them is is
a fundamental coarse graining and um
reorganization of the micro substrate
such that the new phenomena can be
described with with a you know with
within you know simple new variable and
this seem this seems to to to match that
description. Is it possible that there's
some kind of design bias or you know
like when we design machine learning
architectures? There's so much
information in the architecture and and
in this case there's so much information
in the brain [ __ ] language and and and
the terms and so on. Could that have
kind of influenced it to emerge in a
certain way?
>> Yes. Yes. And and uh the structure of
those programs does change depending on
the language. Um we have tried this with
other languages. We've tried it with Z80
assembly language, which is the the um
the assembly language of these uh Xylog
uh chips that I that were were invented
sometime in the 70s and and just got
discontinued last year. A very
longunning uh microprocessor
architecture. It's so the phenomenon is
very generic. What those programs look
like is is shaped by uh by the specifics
of the language. But the reason that
those programs emerge uh the reason that
they develop purpose is actually
thermodynamic. Uh so you know that that
might seem puzzling because you would
think thermodynamics is about things
becoming more random and the apparently
the exact opposite is happening here.
You start with randomness and you get
order and you know how could that be?
Well um I I think the answer was
actually well characterized by uh a
chemist by an organic chemist Adi Pros
uh who uh at the at the University of
the Negv in in Israel who um is now
ameritus and he did a lot of work on
so-called dynamic kinetic stability. uh
the idea being that it's an extension of
the second law that says things seek
their most stable state, their most
stable form. You know, usually we think
about those stabilities as only being
fixed points, but those stabilities can
be cycles too. So, if something
dynamically uh makes itself, if
something forms more copies of itself,
that's more stable than something that
just settles. Uh you know, it's like the
old joke about DNA being the stablest
molecule in the universe. Obviously DNA
is fragile but at the same time if the
DNA makes more DNA then you know it will
be around a long time after granite you
know which can only erode. In terms of
this veilance question though does that
imply to you that there is a natural
drive to survive almost I mean for for
these systems to kind of maintain their
existence they assuming that's a primary
force they would need to have a degree
of sophistication they would need to be
doing modeling they would need to be
doing sophisticated things but is that
something that just always you know is
it a convergent property
>> yes it is uh in in that sense evolution
is the second law at work. Uh meaning if
you have a bunch of things that are not
copying themselves in the BFF soup and
you have something that emerges that can
copy itself, then that thing that can
copy itself will write over the things
that can't copy themselves, which means
it's more fit uh or more stable if you
like. Uh and so that that is written
into the laws of statistics in just the
same way that the second law is. It's
just the the kinetic or the or the
cyclic form of that of that same law
rather than than just the steady state.
You said in your talk that merging is
more important than mutation.
Tell me more.
>> Yes. Uh so the the usual thing what we
learned in school uh was that Darwinian
evolution consists of mutation and
selection or what Jacqu Mon the Nobel
winner called uh chance and necessity.
Uh so you know in other words um
mutations maybe from cosmic rays or
whatever to our DNA uh sort of throw
spaghetti at the wall and um and
whatever sticks is what is what remains
whatever doesn't kill us and and and
whatever hopefully makes us stronger.
That was my assumption as well. Uh, you
know, starting out with these BFF
experiments and and so I I had a
mutation rate, you know, where a bite
could change at random with probability
one in 10,000 or something. Uh, you
know, with with every interaction and
then I began playing with the mutation
rate and found that this uh this
emergence of these complex programs
occurred even when the mutation weight
rate was turned down to zero. Uh, which
is really a surprising finding, you
know. tells you that that this emergence
of purpose uh comes about you know even
without any any random changes in in the
code. Uh it's it's not explainable in in
purely Darwinian terms. But you know the
other things that are not explainable in
purely Darwinian terms are the emergence
of life in the first place. This greatly
puzzled Darwin. You know he he thought
this problem of abiogenesis or the
emergence of life was just you know
impossible to to reckon with. you know,
you might as well talk about the origin
of matter is how he put it in one of his
letters. And the other thing I can't
explain is the increases in complexity
that occur. You know, why is life now
more complex than bacterial life? You
know, a million, you know, a billion
years after it began on Earth. Um, you
know, why are do we have human societies
now? And if we go back, you know, 100
million years, we had only uh, you know,
things with much simpler brains. We had
octopuses. They had pretty complex
brains. But anyway um but you know that
the tendency has been toward toward
greater complexity. Uh there there are
some people who have argued against
that. Uh you know famously uh Steven J.
Gould you know has said things like you
know everything on earth is is this is
the same amount evolved. We've all been
evolving for you know three billion
years. It's all equally evolved. I think
I think G was wrong uh when he said
this. Uh the reason being um
symbioenesis
uh when when you have uh a ukareote
formed by uh a mitochondrian uh being um
sort of uh you know finding itself
inside an archa and then you know
becoming a ukarote that resulting
composite organism is more complex than
either of the two parts that made it up
in the same way that a spear is more
complex than a stick and a stone point.
you know, you put two things together,
you now have a you have something more
complex than the parts. And um and if if
this if this idea that symbiosis or
symbioenesis is is um an essential part
of evolution is correct, then uh you
absolutely get more sophisticated things
coming about later in evolution because
they're being put together from
pre-existing parts.
Yeah, I wanted to touch on the because I
said the the same thing on the show many
times that inspired by Kenneth Stanley
actually that we see this monotonic
increase in complexity in in in
evolution in in standard Darwinian
evolution there is no reason for things
to become more complex.
>> So in other words, if you if you just do
the spaghetti throwing at the wall
thing, then you could get
simplifications or complexifications uh
you know and they're they're equal.
There's there's nothing to favor one
over the other a priori. So uh ordinary
Darwinian evolution um you know can can
either make things simpler or more
complex. But symbioenesis which is uh
you know the the this coming together of
parts to make holes uh and and these
major evolutionary transitions that you
just mentioned uh this is the theory of
uh Yor Safmari and John Maynard Smith
that they published in Nature in 1995.
They they only had it like eight of them
in their original paper and they've
since extended it to maybe a dozen, you
know, but things like single cells
coming together to make bodies, uh
individuals coming together to make
colonies, se the emergence of sexual
reproduction, the endo symbiosis of
chloroplasts and of mitochondria, there
a few others, right? Those are very
clearly steps upward in complexity. And
and the reason that that it's trivial to
prove that there are steps upward is
because if you have A which is
reproducing uh and can make more of
itself and you have B which is
reproducing and can make more of itself.
Think of them each as having a tape
right that says how to make a me. Then
when they come together the result has
to both know how to make A and how to
make B and how to put them together. and
that little extra bit of information how
to put them together is what makes the
whole necessarily more complex than the
parts. So that that is the the the
latter uh and and where where I go
beyond what Smith and Smari say is that
for them major transitions are are a
rare and exceptional event. But I I
think that if you look more closely at
the way biology works um that's just the
tip of the iceberg. Those are just the
really big transitions that involved,
you know, two large uh, you know, highly
consequential things uh, you know,
merging in some way or or many cells,
you know, merging into something
qualitatively extremely different. But,
but when you look more closely, you see
horizontal gene transfer in bacteria all
the time. That's also a form of of
symbioenesis where, you know, parts of
one thing get muddled up in another. Uh,
you see horizontal gene transfer in
ukarotes like us all the time.
Apparently a quarter of the cow genome
is this bove B transposon which has
jumped around among lizards and all
kinds of other animals as well. Viruses
do this all the time. They they you know
retroviruses insert big chunks of their
genomes into ours. Um and you know the
big shock when you look at at our genome
when it was first sequenced in 2001 is
that only one and a half% of that is
even you know our proteins. And what the
hell is the rest of it? You know that
there's the junk DNA. Uh now we know
it's not all junk. Uh you know a lot of
it has regulatory functions and so on.
But even so that's a lot you know
there's a lot of other stuff in there
and a huge amount of it is
retrotransposons and retroviruses that
have been indogenized. They serve
functional purposes in many cases. Uh
the mamalian placenta was made out of uh
a virus uh related to uh the RSV virus
which fuses lung cells together and can
make babies sick. That fuses together
the cells in our placenta to make this
this um this blood blood barrier. uh or
there's an ARC virus. Uh we don't really
understand how it works, but it lives in
our brains and we know that if we knock
it out in mice, they can't form new
memories. Uh and uh and it goes on and
on. You know, especially in the last
decade, we we find more and more
examples of functional instances of bits
of genome from one thing ending up in
another and changing it.
>> One thing I want to touch on is is the
importance of the merge operator. We
were talking about that earlier and even
um Chomsky spoke about this and you
could argue whether the merge operator
in language evolution was the Prometheus
moment whether it was phoggenetic or
ontogenic um because you were just
talking about this um uh you know this
the symb symbiosis and merging in in a
physical substrate but it also happens
in the information substrate you get you
get this kind of like mometic computer
programs that ensconce themselves and
maybe language was that you know I don't
know but I I have a theory why merge is
so important as opposed to to random
selection So I think creativity is is
about grounding. Um it's about path
dependence basically. So um even the
retroviruses and and all of these things
they they actually they form a lineage
and I think that if you don't use merge
you lose the lineage and also something
about the recursive merge operation
allows you to build more complex
computer programs but allowing for this
kind of reuse and canalization. There's
something very natural about that.
[snorts]
>> Yeah. I I completely buy everything that
you're saying. I think that's exactly
right. Except that I dislike Chomsky.
[laughter]
So, I think he's wrong. He's wrong about
language. Um I'm I'm much more of a fan
of Dan Everett. Uh I don't know if
you're familiar with his work with the
Pir. Oh, it's it's wonderful. Uh so, he
he spent a long time with the Pir uh uh
in in Brazil, who are a people uh whose
language does not obey uh Chsky's uh you
know, requirements for language. They
don't have uh they don't have recursion.
Uh they don't have anything like center
embedding. They also don't have numbers
and they don't have past and future
tenses. You know, he uh Everett wrote a
wrote a great book uh some years ago
called don't sleep there are snakes
which uh talks both about um his
experiences among the among the piranha
and their language and also his big
fight with Chsky over this. uh Chsky's
papers are filled with theory and pseudo
math uh and and have no time to give to
ethnography or to actually studying any
real languages. But anyway, I'm
digressing. Um you know, but uh putting
Chsky aside though, what what you're
saying about merge or as I would see it,
composition, uh functional composition,
uh I think is absolutely fundamental.
It's it's how all technology is built.
Uh W Brian Arthur uh has written about
this and how technology evolves. uh you
know that every every technological
invention you know it's funny like it it
every technology gets invented a dozen
times around the same time as if
everybody's in telepathic communication
and the reason is that every technology
has precursors you know you can't get a
light bulb until you know how to blow
glass how to make a vacuum how to draw a
filament uh how to generate electric
current and when all those things were
there and you know the need for light
was there the light bulb was going to
get invented but it was invented you
know a dozen times by different
inventors with different contingent
choices. You know, they might be, you
know, which kind of filament do you use
or is it prongs or do you screw in the
light bulb, which way do you screw it
in, uh, you know, what's the diameter?
And and and those decisions as they get
locked in determine the course of of
everything after that that incorporates
light bulbs.
>> So, uh, you know, in a way this this
contingency, this these choices about
exactly which way those combinations go
is actually what the entire genome or
whatever it is is made out of. Um, in
the case of BFF, the original
replicators are really just single
instructions that sometimes randomly
weekly might copy themselves. One bite
that moves here and there, but as those
bites get copied around, sometimes a
couple of them end up together and then
they'll they'll they'll copy as a group.
They'll do better together. And uh and
so the contingent thing, you know, which
way they ended up getting copied, was it
AB or BA? You know, that they stuck
together. That's that's the information
that the bigger thing is made out of.
that little extra bit uh because you
know in this case you just had single
bytes. There was nothing there was no
information there to begin with. So so
the merger tree uh you know ends up
being exactly the information that is
encoded uh in the final genome. It's all
about the history.
>> Yes. Absolutely fascinating. I mean in
in a sense I'm surprised you're not a
fan of Chsky because he he was talking
about automter and tour incompleteness
and he was the ultimate computationalist
and and in a sense what you're
describing is Chsky's ideas just applied
lower down the stack.
>> That's right. So in in that sense I
think I think he was correct but I also
think you know all of those ideas were
already there in in Vonoyman uh in the
1950s uh even Neil's Alaricelli the
first artificial life researcher who uh
you know worked on one of Vonoyman's
machines I think he I think he he he
sort of snagged time on the maniac uh to
to do some of his first a life
experiments. They're kind of pseudo
documented in in um in Midkin Labatut's
uh book Maniac. It's really was really
fun. Um but um or no that was his it was
in his first book I think when we cease
to understand the world. Um but anyway
so so yeah my point is those ideas were
there before uh before Chsky. Uh the
thing that Chomsky really pushed um you
know during his reign of terror over
linguistics. Sorry I'm being a little
bit mean. But the thing that he really
pushed was was the um the movement in
artificial intelligence that we now call
uh goi good oldfashioned AI which held
that you could you could formalize what
AI is as grammarss and programs uh which
turned out to be you know wrong that
turned out to be a false start in in AI
and why there were so many AI winters
there seems to be a bit of a tension
because the goi folks they had some very
interesting ideas I mean I'm a big fan
of um FOD and pollition for example and
and they spoke about this strong
compositionality. We have semantics and
intentions and you know it's possible to
to build these cognitive representations
but we have the issue that we can't
really design them to represent the
world in in in a in a high fidelity way
and we have the the semantics divergence
and then you're pointing to this this
very interesting um constructive thing
and I think um a constructive form of AI
and compositionality solves a lot of
problems because of this path dependence
problem and this canalization that we're
talking about that when you build
intelligence brick by brick, you can
build artifacts of incredible
sophistication, but unfortunately we
can't design the artifacts to do exactly
what we want. We have we can gently
steer them in a certain direction. And
even with um with Friston, I I feel that
even though he's talking about the what
of intelligence is is prediction and and
adaptivity, I think the implementation
matters. I think adaptivity means
structure learning. I think there's
something about having a substrate which
actually does this form of of
composition that you're talking about
that seems to be like a mechanistic
necessary condition for intelligence,
>> right?
>> Yes. I I think in many ways what we're
talking about is sort of the the tension
between analog and digital ways of
thinking or bottom up and top down ways
of thinking.
>> Uh so for instance um
let's talk about how you would recognize
a bicycle. uh you know, in the good old
fashioned AI world, you would say, well,
you've got a circle detector, uh, you
know, and and a, you know, and a line
detector that will detect, you know, the
the lines that make up the frame of the
bike and and so on. And you'll write
you'll handwrite code for all of those
things. And, um, and of course, the
problem is that, you know, there are
many ways of looking at a bike where
you're not you're not going to see the
the wheels at once or maybe the bike is
of a weird design. And you know, they're
those funny bikes that have shoes
instead of wheels, you know, and when
you look at one of those in a Gestalt
sort of way, you recognize a bike
immediately, even if all of the rules
are broken, as it were. Um, and and
that's really important because when
when you're when you're looking as an
intelligent being at the world, you have
to cluster. You have to um you have to
find regularities in the world that um
you know, whose shapes are not well
defined by uh by a set of rules. um you
know they're not they're not just sort
of carved up by hyperplanes they're
blobby and uh and so you know
intelligence requires methods that are
very neural netlike you know that look
more like continuous function
approximators and that's why gradient
descent is a good idea uh for instance
uh you know and learning these things
via smooth functions is a good idea and
learning them or or not learning them
but trying to encode them with rules
never never worked out well now on the
other hand DNA is is discrete right
there there there are you know four
symbols and you order them in a certain
way and and you know that's it doesn't
mean that there's no randomness in the
way you know the way uh proteins are
folded and so on but uh composition at
the level of DNA really does have to do
with you know chopping up uh programs
essentially made of discrete symbols and
inserting you know bits of code and and
so on so you know when you're looking
from the bottom up it's a very very
quantized world um but when you start to
you know look at at you know giant
complex things like us uh you know from
from a high level you have to begin from
a more uh more continuous perspective.
>> Um I think you've hinted that there are
natural convergent patterns in in
computation. I mean can we sort of get a
convex hull of your philosophy?
>> We could try. Um I mean I I hesitate to
say I'm in anythingist
but um but probably functionalist comes
closest
>> functionalist.
>> Yeah. Um so the reason for that is that
uh you know in in the old days um in the
19th century we used to think that you
know to be alive meant that there was
some vital spirit or vital force you
know that right that living things have
and dead things don't and as we started
to figure out that the laws of chemistry
were the same for living things and dead
things and you know ura can be
synthesized in a test tube and so on you
know those ideas really went out of
fashion and we went into a very strict
materialist kind of perspective
>> right or everything is just physics and
you know I I I mean I was trained as a
physicist you know I think I I I believe
in physics fully um but I also think
that there is more to life uh in the
sense that you know if everything is
just physics then you have no way of
saying what it means for you or me to be
alive and to understand what what that
is what it means to be alive I think you
have to come to grips with the idea of
of purpose you have to bring teiology
back into the equation uh what I mean by
that is you know a kidney is not just a
collection of atoms. It's it's an organ
that performs a function, right? The
function is to filter ura. And if you
implant an artificial kidney that works
on totally different principles but also
filters ura, it's an artificial kidney.
You know, it's still meaningful to say
that. So that that means that there is
something about that word kidney that
means something that that that goes
beyond the the matter that the kidney is
made out of. uh you know conversely if I
come back from the future and show you
an object and and and you're like what
is that and I I tell you it's an
artificial kidney you know there's
nothing about this set of weird carbon
nano tubes and so on inside that would
that would say to you kidney it's just
that you know if you happen to implant
it in a body you know and set it and sew
it you know sewed it in the right way
and so on then all of those
relationships would be would would show
up in the right way for your body to
persist. So this this idea of things
serving functions for other things and
functions only have meaning in the
context of yet other functions. So
there's something ecological about this
idea of functions. I think this is
really central. Uh you know a rock on an
inanimate planet has no function. If I
break it in half I I now have two rocks.
But a living thing has function. uh and
you know the the the hallmark of
function is multiple realizability just
like just like uh Turing talked about
for touring machines because you know
Turing and Vonoya are functionalists
meaning that uh you know if you if you
have a need to make ATP for energy
inside your cells uh you know you're
going to have multiple pathways for
doing it because sometimes the aerobic
way works sometimes you need the
anorobic way whenever you start to have
multiple uh pathways you know wings and
insects wings and bats you know that
there is a function in play
>> the alternative position would be
essentialism. So folks like Anil Seth
and um John S, they they think that
certain types of material have a certain
type of causal graph and you know so for
example brains might give rise to
consciousness and if we simulated a
brain it wouldn't have the same causal
graph therefore it'd be different. But I
would like to I mean we'll just park
that you know just just for the moment.
It seems a little bit like you're you're
talking about this like a computer
software architecture diagram and we can
you know it's like that ship of thesis
type thing where we can kind of you know
swap things out and is it still the same
thing but I think um path dependence is
very important so the kidney evolved it
it has this kind of this this rich um
fogyny of of of evolution and when you
replace it with something you know which
came from a different substrate which
has a different provenence then it it's
it's almost like it it is a kidney now
and it works now, but it breaks the
ecology. Like imagine in an ecology if I
swapped a plant out with an artificial
plant and I kept doing that. Um it might
work now, but doesn't that affect its
future trajectory? Yes, it does. Um but
that's exactly what symbioenesis is all
about. Uh you know often often you will
have a repurposing of something that was
that was designed if you like you know
by nature, right? And and what one of
the cool things about the BFF experiment
is that it shows you how if you you know
if you like intelligent design can
happen without any intelligent designer.
Um but you know something that was
designed for one purpose or to serve one
function can come back around and serve
another function. And uh yeah that
brings a whole different contingent
history uh with it. Right? the the that
that RSV example that I gave, you know,
the the ability to fuse cell membranes
together came from a vi, you know, a
virus whose original purpose had nothing
to do with building placentas, but you
know, it gets incorporated and
repurposed. Uh, you know, and this is
the kind of bricklage that uh that life
is made out of. So, uh, so yeah, I think
I think that that kind of uh, you know,
not only replacement but uh, you know,
parallel pathing uh, etc., you know, it
it doesn't just happen when we make
artificial kidneys. it's happening, you
know, all the time in nature. Uh, and is
the very hallmark of life. So, yes, I
disagree strongly with with Anil Seth
and with John Surl on on this point. Um,
you know, the the brain of thesis kind
of experiments that you've alluded to,
right? The idea that if you took a an
emulator or a simulator of a neuron and
you plugged it into your brain, you
know, so that it's its inputs and
outputs are connected to the other
neurons, you know, well, you know, then
the other neurons wouldn't know the
difference. Well, what if you do that
for half of your neurons, for all of
them? you know, will your consciousness
get dialed down even if you behave the
same way? Of course not. Uh, you know,
for me, your consciousness is is
obviously a function of of the functions
of the relationships of all of those
things with each other. Um, it doesn't
mean that it's so simple as a computer
program where you can just, you know,
substitute a subruine for another one. I
mean, you we've made computers very kind
of um abstract in that way. Uh, you
know, and biology is wet and messy. The
interfaces are are complex and hard. But
but this this same idea of multiple
realizability and repurposibility is is
the very stuff of life.
>> What is your position on consciousness?
So um what is it? What's its purpose? Is
it epifenomenal? Can it be measured?
Etc. etc.
>> Yes. Uh great question. So um I think
that the idea of philosophical zombies
which uh uh you know David Chmer's has
talked about right that maybe something
could behave just like you or me but be
dead on the inside you know not not not
have any experiences not feel anything
is um uh is actually a lot less coherent
than it sounds. Uh so I'm a
functionalist about consciousness too
and what I mean by that is twofold. One
is that I don't think cons consciousness
is some kind of epiphenomenon that you
know just weirdly you know we happen to
have for reasons that have nothing to do
with our behavior. Uh nor do I think
that it is um uh that is that it is
somehow tied to anything about our the
way we're physically made. Uh I think it
is functional. So why do we have it?
Well, um, in in, uh, my team, Paradigms
of Intelligence, we've been doing a lot
of work, uh, over the last year on
multi-agent reinforcement learning. Uh,
and the reason is that we're very
interested in the precondition for
symbioenesis, which is symbiosis,
cooperation. You know, when two things
or 700 things or whatever start to
cooperate closely, you know, that that's
the that's the beginning of them really
fusing together and becoming one thing.
And um and in order for two agents that
are intelligent to cooperate uh it turns
out they have to have theory of mind. Uh
they have to model each other. They have
to be able to put themselves in the
place of the other. And uh we have a you
know a whole long theory called mupai
about how that all works. uh but it you
know and and I guess the the cliff's
note version of it is that it requires
that you do induction over a universe
that includes not only the game that
we're playing but that also includes
what is happening in your head and what
is happening in my head. In other words,
you have to have a universe that that
that includes yourself in it and the
other in it and that allows you to
generalize over the class of you and me.
you know, so that I know, you know, my
internal state is happy when I smile and
when I see you smile, I know that you're
happy as well on the inside, I can make
that inference. Uh, you know, in the
same way that if I see a bunch of
peaches, you know, then I I know that
they're all the same object and I know
what the back side of it will look like
and so on. So, um, this ability to do
psychological um, uh, you know,
induction is is really important for uh,
for cooperation and uh, and that's why
we have it. So um you know and one of
the consequences of that is that we
model ourselves and we model our own
models of others models of our models
and so on. There's a kind of a strange
loop as Douglas Hoffetter would have
called it in that.
>> Yes, I love Douglas Hoffatter. So so
there's this kind of selfmodeling and
then second order selfodeling and third
order selfodeling which could be applied
to other agents and uh of course you
know in in the real world we are
computationally bounded right you know
we we [clears throat] can't make sense
of all of the complexity. So when we do
this modeling of other agents, um, our
modeling is quite cartoonish and it's
quite structured and
>> and it only it only goes up to sixth
order as well at most.
>> Oh, interesting. Interesting. I mean,
how does this affect I mean, we haven't
really spoken about agency yet.
Presumably you could have a strong agent
which is just doing something quite
trivial. But when we have this
collective intelligence and this
information synchrony between agents,
how does that affect your ideas of you
know purposeful behavior? I sometimes
use the example of rowing uh to to
describe what's happening when um
purposes merge into a single purpose and
and consciousnesses you know merge into
a single consciousness. Um there's
there's this term u that I learned from
Dan Brown's book, The Boys in the Boat,
uh swing, which is when when this the
six horsemen uh or eight horsemen,
sorry, uh you know, all achieve this
kind of state where they're in perfect
sync with each other and and you know,
you know it when you when you when you
experience it, the the boat acquires a
soul as it were. You know, you all feel
like you're like you're you're pulling
as one. And um and boats with that
property go a lot faster than than boats
where people haven't quite achieved that
sink. Um that that I think is kind of
what happens when um uh you know when we
uh when we think of ourselves as being a
self despite the fact that our brain
actually consists of a lot of parts you
know like the the same way that that as
the horsemen that you know in some sense
began with their own purposes and their
own self models and their own models of
the other parts of the brain. thought uh
you know this process of of subjective
symbioenesis I guess you could call it
uh where where all of those wills become
one and all of those selves become
oneself
>> in hiring for example you you want folks
with high agency but you also want
alignment which is the potential for
this kind of synchrony and we often have
we do a thought experiment on MLST that
you can look at a boat or a flatillaa of
boats and you're trying to draw a
boundary and the boundary for the agent
should be the minimal description It
should be, you know, where where is most
of the agency? Where is most of the
planning and future modeling happening?
And usually it's it's the pilot. It's
it's the driver of of the boat. But
you're talking about the situation where
there is such a synchrony and alignment
between the agencies that almost like
the the best intentional stance, if you
like, is to draw a boundary around all
of them.
>> Yeah. Um I also think that that there's
no there's not necessarily a single
right answer. So uh you know, in in um
my book, what is intelligence? I talk
about a few interesting cases. Uh, one
of them is, uh, for instance, uh, the
conjoined twins, Abby and Brittany
Hansel. Uh, who who, uh, I I don't know
if you've seen, uh, them on on YouTube
or, you know, the TV shows. Fascinating
case. And, and, um, you know, so these
are, uh, two people who share one pair
of arms and one pair of legs. Uh, you
know, each each of them controls one arm
and one leg, so they're in a sort of
three-legged race. Uh, two-legged race.
Um, they often speak in synchrony. Um
and um you know they they play
volleyball and sports and stuff. They
drive they drive a car. They can write
emails no problem. Um uh and you know
they also sometimes uh you know have um
you know differences of opinion. So you
know they'll they'll they'll they'll
sort of you know come together and apart
in in a in a remarkably fluid way and
all of that is done purely with
behavioral cross queuing as Mike
Gazanaga would call it meaning their
nervous systems are separate separate
brains separate spinal cords. Um so you
know in that case they they are able to
model each other extremely well because
you know their entire lives they've been
right next to each other. Another
interesting case would be uh split brain
patients of the kind that Kazaniga you
know spent a lot of his career studying
and you know those are cases where in
adulthood the the brain is essentially
cut in half. So you know each hemisphere
can only see the left or the right
hemisphere. uh controls one arm, one leg
and um the the the most fascinating
thing about these split brain
experiments, you know, is that from the
outside point of view, it is obvious
that there are two consciousnesses in
there. You know, each hemisphere is
conscious of different things. Uh you
can make disjunctions between what shows
up in the left and right hemfield and
you know, the left and right hands can
be drawing different things, you know,
and so on. Um, but if you talk to
somebody uh, you know, who's with a
split brain patient, they're always
like, "Yeah, I'm I'm still one person."
They will never admit that there are two
people in there. So, you know, is there
somebody who is right and somebody who
is wrong? No. Uh, you know, this is
entirely um relational. It's a it's a
relational description. Uh, and the fact
that for them, uh, they are, you know,
they're the same person they always
were, just, you know, occasionally
something takes a little more work.
Occasionally one hand will be buttoning
the shirt while the other hand is
unbuttoning it. You know it's just an
inconvenience.
>> There are split brain experiments as
well even even just with a normal brain.
And I can believe that we are we are
sort of separately conscious in in
different parts of our brain. You get
out of bed in the morning and you must
be a slightly different person. But we
kind of gloss over that, don't we?
>> Absolutely. We make a narrative. The the
the best the coolest experiments about
this I think are the ones from Peter
Johansson uh at at uh at University of
Salah. So he's done a bunch he he was
the one who discovered uh choice
blindness. Uh in these experiments a um
a subject is I think the very first one
was face choice blindness. So you'd be
shown two faces uh on cards and asked
which one is more attractive and you
pick and you know every you know every
so often uh the one that you're handed
to then explain why you thought that
face was more attractive is the one you
didn't pick. So there's a kind of slate
of hand trick. And the cool thing is
that very very few people notice that uh
you know that they're that they're being
handed the wrong face. And there is no
difference in the fluency uh or the
latency of the description. You know,
you have an inner lawyer ready to spring
up and justify whatever choice you made
even if it's not the choice you made. Uh
and and that narrative that you invent
uh you know then influences your future
choices. It's as if we all, you know,
make up a story about ourselves. And and
of course, the reason is that, you know,
you're we're all split brain patients in
a way. You know, the the the left
hemisphere interpreter that that
generates the speech, you know, is
likely not the same part of the brain
that actually, you know, sort of did the
the choosing if you if you know, you
know, and and yet all of those parts of
your brain are invested in the idea that
they're all in the same boat, you know,
that it's all one me. So, they're all
covering for each other. In the same way
that in a split brain patient uh you
know if you show to um you know to the
to the non leftbrain interpreter
hemisphere um you know stand up the
person stands up and you ask them why
did you stand up and you know they'll
say oh I I was thirsty I'm going to the
kitchen for a drink of water same thing
artificial intelligence it's becoming
more sophisticated and there's the
social question and I suppose actually
you can think of it as a ship of thesis
for society so we're going to be having
agents embedded in society and we're
going to form a large collective
intelligence.
Do you do you worry about that future? I
mean, what do you predict is going to
happen? [snorts]
>> Well, um I mean, there are certainly
things that I worry about. I don't want
to I don't want to come across as a
polyiana. I'm worried about um
polarization. I'm worried about
disinformation. I'm worried about our
political and economic systems uh you
know, not necessarily being fit for
purpose uh in the world that we'll all
be living in in 20 years. But I'm
certainly not concerned about uh a lot
of the kinds of things that I hear
Elazar Yudkowski talking about for
instance. Um and in particular uh you
know one of the reasons that I that I I
feel very differently is because I feel
like human intelligence in the usual
sense that we think of it is already a
collective phenomenon. Uh we're not that
smart individually. We're not that much
better uh individually than our our our
primate cousins. Um it's only you know
because we get together in large
societies of millions and billions of
people that we can do these amazing
things you know that we can transplant
organs and and go to space and you know
and so on. Um you know individually
we're just we're just not all that. So
for me um you know AI is actually a part
of human intelligence. It's it's
literally already uh the the same thing.
uh you know I find it very interesting
that we only achieved general AI when we
began to literally train the models on
reams and reams and reams of human
language. So you know AI was human
intelligence from the start because I
suppose the the thesis of Eliza
is that it is possible to have artifacts
which are dramatically more intelligent
than than we are. Maybe you think
there's some kind of a limit but but do
you think in principle that we could
build artifacts which are significantly
more intelligent? Well, I think that
collective humanity is already vastly
more intelligent than individual humans.
Uh so in that you know and and in many
cases operates at very different time
scales for instance I think these things
are already true. Um now you know the
the ideas about um so in in a sense in a
sense our difference our biggest
difference is about thinking about it as
an other versus already a part of
ourselves. You know what do we even mean
by human? Um there was a wonderful paper
um from 2006 called the science of
psychology uh in which um I I'm not
remembering her name but uh she is a
psychologist and the science of
psychology is spelled cyc uh she asks
people to draw bicycles uh you know
first to say do you know how a bicycle
works everybody says yeah of course I
know how a bicycle works okay draw one
nobody can draw it even if it's just you
know looking at a sketch of a bicycle
and saying okay where does the chain go
you know or where are the pedals
Most people don't know you know they
make some very fundamental error in this
and um you know it's it's a it's a very
funny it's a very funny paper but you
know the point is we all have these
illusions about what our own knowledge
is our own capabilities our own
intelligence are. We already have swing
in the sense that we are we identify
what we think of as our intelligence
with something that is actually in a
bunch of other people and a bunch of
other stuff around us. Um you know and
and and we do that kind of
unconsciously. So, uh, for me, you know,
there's there's not really a
discontinuity between, you know, what we
what's already going on and AI. It's
it's really just more of that.
>> Interesting. You know, I think they
would make the argument that you could
build a single artifact which is more
intelligent than the totality of of
humans. But just parking that to one
side, um, I spoke with Judith Fan. She's
a wonderful professor at at Stanford and
she's done studies on on drawing. So,
comparing how humans draw to um
computers using clip models and stuff
like that. And she found she found
something fascinating which is that
because we have quite an abstract
understanding when we make sketches you
know and she was kind of um grading it
on you know like um the progression one
progression two progression three and we
we kind of start very coarse and very
abstract and AI systems they start with
the edges and and the details
>> and that to me indicates that AI models
today they don't really understand
things at a very deep abstract level
like we do perhaps because we have this
this compositional synthesis of
knowledge that we were alluding to
earlier. Do you see that as a gap?
>> There are a few questions I guess hidden
in there. Uh you know one of them is uh
you know do I think of of LLMs for
instance of of today's you know sort of
frontier models as being um less than um
or different than in some basic way you
know our our brains. What are those
gaps? Um so first of all I mean they're
obviously very different. I mean you
know their their their architectures are
different. they're trained in a very
different way. Um the fact that you know
for me the remarkable thing is actually
how convergent a lot of a lot [snorts]
of their properties are with those of
brains despite all of that. Um you know
the fact that you find internal
representations and many of them that
that that surprisingly resemble uh you
know ones that you can measure in human
brains. these brain score uh type
measures of of Martin Shrimp and Co. um
you know or or um uh you know sensory
modalities you know uh in humans can be
reproduced remarkably well even by
models trained on pure language which is
really remarkable uh you know and speaks
to how much is encoded in language and
how much of what is encoded in language
is a reflection of architectural
properties of our brains and umvelts and
how much of that is then reconstructed
essentially by those models. Now uh the
question of you know what we draw first
when we draw a picture and how that all
works. I mean remember that you know
image synthesis models like clip or what
have you are working in pixel space uh
to begin with and uh you know diffusion
models by the way you know work very
differently from various other kinds of
models. I mean we now know that you know
you you can drive a robot with a
transformer. So if you give one of those
robots a paintbrush and you say or you
know a pen and you say now draw what it
will draw is going to be very very
different from what you get from a
diffusion model that starts filling in
pixels and for that matter all of that
is different from what happens in your
own head when you're visualizing
something. So you know I think a lot of
this is is not so straightforward to to
analyze uh because of all the
differences in the way that IO and the
representation space works. Um I do
think that today's models are highly
compositional. I mean, even with a lot
of those original uh uh you know, image
synthesis models, the fact that you
could say, you know, a teddy bear at the
bottom of the sea playing with the speak
and spell or whatever and it'll do it,
you know, tells you that that they they
can compose. Uh again, are there
capabilities like ours are, you know?
No. I mean, there there are definitely
places where they're better, places
where they're worse, places where they
have surprising gaps. So it's different
but uh but I wouldn't say that there's a
fundamental lack of composition there at
all. Um I think if if anything the
biggest gap between uh transformerbased
models and what we do is actually
narrative memory um right or being able
to form long-term memories and and and
that way have a kind of persistence of a
self over over long periods of time.
They they don't have that yet.
>> I'm conflicted. You are pointing to this
universal representation hypothesis. I
think Chris Oler um popularized it with
some of his visualization experiments
and it's true the representations are
very convergent and and other things
lead me to to um believe that the models
produce these kind of superficial
imposters that they give you exactly the
right answer but for the wrong reasons
and one of the hints of that is when you
um do variations on on the input it's
not robust there's the there's the
touring machine argument as well so you
know these LLMs are finite state
automter But they can access tools which
are tour incomplete. So you know perhaps
we could say the system is tour
incomplete but I don't believe that um
chat GPT is is effectively searching the
space of touring machine algorithms. It
hasn't been trained to do that but it is
surprisingly robust with the arc
challenge. It can actually um you know
it can it can do really well especially
if you do some evolution do do some
refinement and so on. So it feels like
we're we're knocking on the door but it
but but there's something missing. I
think that in many of those cases, we're
not doing the we're not doing a fair
human comparison. Uh, you know, we we
often uh, you know, and this is a little
bit similar to our illusions about
knowing how bicycles work and so on. You
know, we I I hear a lot of people uh,
you know, say things like, well, you
know, but but look at this case where we
just flip the logic, you know, uh, you
know, we change it from do to don't and
then, you know, it gets it wrong 30%
more often and so on. Um, you know, my
my first question is always, have we
done the human baseline? Uh, and and it
turns out that surprisingly often the
human baseline shows the same uh the
same property, you know, and this
doesn't mean that humans are incapable
of doing, you know, the fully robust,
fully general version of these things,
right? If you're a logician or if you
think about it carefully, you know, you
can you can really write down your
premises and be super robust to, you
know, flipping the knots, you know, in
the way something is is formulated. But
most of us don't operate that way most
of the time. Uh, you know, and we're
highly susceptible to logical illusions,
cognitive illusions, etc., which turn
out to be in many cases surprisingly
similar to the to the machine case. So I
I'm I'm I'm kind of unmoved by, you
know, by by a lot of those. Uh, and I I
think often um often we're we're being a
little sloppy about how how we do it.
It's certainly the case that that um you
know, transformers don't aren't
searching systematically over all
possible touring machines. I mean, we
don't know how to how to do that. You
know, you you have to take shortcuts of
various kinds in order to make that that
whole problem of of induction over over
programs computationally tractable,
whether you're a brain or a, you know,
or a transformer.
>> L, thank you so much for joining us
today. It's been an honor.
>> Thank you. Uh, thank you for the the
really thoughtful questions.
