---
id: SOURCE-20251128-971
platform: youtube
format: interview
cadence: evergreen
value_modality: dialogue_primary
signal_tier: paradigm
status: raw
chain: null
topics:
  - "two"
  - "years"
  - "left"
  - "prepare"
  - "roman"
creator: "Wes Roth"
guest: null
title: "You have TWO YEARS LEFT to prepare  - Dr. Roman Yampolskiy"
url: "https://www.youtube.com/watch?v=0d727qv_MYs"
date_published: 2025-11-28
date_processed: 2026-02-22
date_integrated: null
processing_function: transcribe_youtube
integrated_into: []
duration: "1h 21m 11s"
has_transcript: no
synopsis: "You have TWO YEARS LEFT to prepare  - Dr. Roman Yampolskiy by Wes Roth. A interview covering two, years, left."
key_insights: []
visual_notes: null
teleology: synthesize
notebooklm_category: ai-engineering
aliases:
  - "You have TWO YEARS"
  - "You have TWO YEARS LEFT to"
---

# You have TWO YEARS LEFT to prepare  - Dr. Roman Yampolskiy

**Channel**: Wes Roth
**Published**: 2025-11-28
**Duration**: 1h 21m 11s
**URL**: https://www.youtube.com/watch?v=0d727qv_MYs

## Description (no transcript available)

Dr. Roman Yampolskiy is one of the top thought leaders in AI safety and a Professor of Computer Science and Engineering. He coined the term ‚ÄúAI safety‚Äù in 2010 and has published some groundbreaking papers on the dangers of AI, Simulations and Alignment. He is also the author of books such as, ‚ÄòConsiderations on the AI Endgame: Ethics, Risks and Computational Frameworks‚Äô. 
https://scholar.google.com/citations?user=0_Rq68cAAAAJ&hl=en


The latest AI News. Learn about LLMs, Gen AI and get ready for the rollout of AGI. Wes Roth covers the latest happenings in the world of OpenAI, Google, Anthropic, NVIDIA and Open Source AI.

______________________________________________
My Links üîó
‚û°Ô∏è Twitter: https://x.com/WesRothMoney
‚û°Ô∏è AI Newsletter: https://natural20.beehiiv.com/subscribe

Want to work with me?

Brand, sponsorship & business inquiries: wesroth@smoothmedia.co

Check out my AI Podcast where me and Dylan interview AI experts:
https://www.youtube.com/playlist?list=PLb1th0f6y4XSKLYenSVDUXFjSHsZTTfhk
______________________________________________



TIMELINE

00:00:00 Dr Roman Yampolski and AI Safety
00:02:45 what our future looks like
00:05:46 Mutually Assured Destruction
00:06:34 General vs Narrow Superintelligence
00:07:51 different AI architectures
00:08:27 does mechanistic interpretability solve AI alignment
00:11:35 instrumental convergence 
00:13:17 is Superintelligence *just* scaling?
00:14:49 surprising AI abilities
00:17:10 truly horrifying AI outcomes
00:20:12 p(doom)
00:20:56 "boxing" Superintelligence in a simulation
00:23:38 are we in a simulation?
00:26:54 should Google control superintelligence?
00:32:38 how consciousness emerged
00:39:14 outlook
00:40:35 AI timelines
00:43:43 narrow vs general system
00:45:42 human bias
00:48:22 AI/human symbiosys
00:50:42 AI religion
00:52:58 evolution vs intelligent design
00:57:08 limit of intelligence
01:00:00 hacking our simulation
01:05:32 book recommendation
01:06:55 possitive AI scenario
01:08:42 daily stoic
01:11:05 organic bootloaders and aliens
01:13:42 how different audiences respond to AI safety
01:16:12 China vs US
01:20:04 robots


#ai #openai #llm
