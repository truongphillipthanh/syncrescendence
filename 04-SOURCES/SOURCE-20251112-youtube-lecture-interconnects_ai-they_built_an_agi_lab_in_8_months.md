---
id: SOURCE-20251112-1152
platform: youtube
format: lecture
cadence: evergreen
value_modality: audio_primary
signal_tier: paradigm
status: raw
chain: null
topics:
  - "built"
  - "agi"
  - "lab"
  - "months"
creator: "Interconnects AI"
guest: null
title: "They Built an AGI Lab in 8 Months"
url: "https://www.youtube.com/watch?v=vIgE1t1rKjg"
date_published: 2025-11-12
date_processed: 2026-02-22
date_integrated: null
processing_function: transcribe_youtube
integrated_into: []
duration: "1h 17m 49s"
has_transcript: no
synopsis: "They Built an AGI Lab in 8 Months by Interconnects AI. A lecture covering built, agi, lab."
key_insights: []
visual_notes: null
teleology: implement
notebooklm_category: ai-engineering
aliases:
  - "They Built an AGI"
  - "They Built an AGI Lab in"
---

# They Built an AGI Lab in 8 Months

**Channel**: Interconnects AI
**Published**: 2025-11-12
**Duration**: 1h 17m 49s
**URL**: https://www.youtube.com/watch?v=vIgE1t1rKjg

## Description (no transcript available)

In this episode, I sit down with the team behind Ant Ling, one of China's most ambitious open model initiatives. Richard Bian (Product & Growth Lead), Chen Liang (Algorithm Engineer), and Ziqi Liu (Research Lead) share the story of how Inclusion AI went from concept to releasing trillion-parameter models in just eight months. We discuss their philosophy on AGI as a shared milestone for humanity, why they chose to build open models, and how the DeepSeek moment catalyzed a wave of research labs across China. Richard offers a unique perspective as someone who spent 11 years working in the US before returning to China, comparing the different cultural approaches to AI development and open source between East and West.
We dive deep into the technical details of building Ling, Ring, and Ming models, covering FP8 training optimizations, MoE architecture decisions, QK-norm for gradient stability, and innovative pipeline parallelism strategies. Chen and Ziqi explain their approach to scaling laws, how they tackled numerical stability issues at scale, and their work on Language-level Policy Optimization (LPO) for reinforcement learning. The conversation also explores the future of open AI ecosystems, the challenges of defining "open source" for models, and Richard's vision for "model as product" thinking—treating foundation models like operating system kernels that enable entirely new categories of applications.

Transcript, links, and overview of Ant Ling here: https://www.interconnects.ai/p/inside-a-chinese-frontier-lab-inclusion

In this episode...

00:00:00 A frontier lab contender in 8 months
00:07:51 Defining AGI with metaphor
00:20:16 How the lab was born
00:23:30 Pre-training paradigms
00:40:25 Post training at Inclusion
00:48:15 The Chinese model landscape
00:53:59 Gaps in the open source ecosystem today
00:59:47 Why China is winning the open race
01:11:12 A metaphor for our moment in LLMs

Get Interconnects (https://www.interconnects.ai/)...
... on YouTube: https://www.youtube.com/@interconnects
... on Twitter: https://x.com/interconnectsai
... on Linkedin: https://www.linkedin.com/company/interconnects-ai
... on Spotify: https://open.spotify.com/show/2UE6s7wZC4kiXYOnWRuxGv
… on Apple Podcasts: https://podcasts.apple.com/us/podcast/interconnects/id1719552353
