https://www.youtube.com/watch?v=SXqEZ6LMUpY
The Internet Is About to Change Forever (and nobody even realises)
1,858 views  Oct 23, 2025
PAID STUFF
üì≤ 25-Min AI Strategy Call (Biz Owners/Leaders): https://cal.com/dylan-davis-d04ip9/25...
üîç AI Assessment: https://ai-readiness.gradientlabs.co/...
üí™ AI Coaching: https://ai-coaching.gradientlabs.co/?...
üõ†Ô∏è Custom AI Solutions: https://custom-solutions.gradientlabs...

FREE STUFF
üíå 30-Day AI Insights: https://insights.gradientlabs.co/?utm...

SOCIALS
LinkedIn:   / dylantdavis  

‚Äî
Chapters
00:00 - Intro
00:30 - The Race To Agent Layers
01:20 - Key Features Within Atlas
04:24 - Example 1 Scheduling Content
08:08 - Example 2 Automating Followup
09:28 - Example 3 Linkedin Replies
12:11 - The Future
13:30 - Recap 
14:40 - Outro

---

Intro
0:00
How you use the internet is about to
0:01
fundamentally change. There's going to
0:03
be a new AI layer between you and every
0:05
single app that you use. Google,
0:07
Microsoft, Claude, they're all racing
0:09
towards that future. And OpenAI's new
0:11
release of Atlas browser is our first
0:14
real glimpse of what that future could
0:15
look like. Now, instead of just talking
0:17
about it, I actually put their agent
0:19
mode to the test for the last 48 hours.
0:21
I tasked it with scheduling 50 of my
0:22
YouTube shorts and even trying to
0:24
automate my entire postmeating workflow.
0:26
What I found is a clear preview of
0:28
what's next for all of us. Let's get
The Race To Agent Layers
0:30
into it. And this is the race to
0:32
dominate that layer is what I'm talking
0:34
about. So here on the right hand side we
0:35
have the agentic layer. Say this is you.
0:38
This is the internet. Between the two of
0:41
you is going to be an agent that takes
0:43
all the actions on your behalf. And
0:45
every single one of the major players
0:46
are already building out features that
0:48
are feeding into that future. So for
0:50
instance, we have Google that has the
0:52
ability to track your screen and give
0:53
you feedback on what's happening on the
0:54
screen and what to do next. Claude
0:56
already has its Chrome extension that
0:59
allows it to take actions on your behalf
1:00
that's in research preview today. We
1:02
have Microsoft that has had Copilot
1:04
inside of Edge for a while. It's mainly
1:06
a minimalistic feature that allows you
1:08
to read, but eventually it will write.
1:10
We also have Perplexity that released
1:11
their Comet browser a while back. And
1:13
then finally, we have OpenAI's recent
1:14
release of their Atlas browser. All of
1:16
which are trying to push towards this
1:18
future where it sits between you and the
Key Features Within Atlas
1:20
internet. And for this new release of
1:21
the Atlas browser, really the only two
1:23
features that I want to talk about in
1:25
this video that most people will care
1:26
about are memory and agent mode. So for
1:29
memory, what's happening with this
1:30
feature is the AI is going to be able to
1:32
track all of your actions over time. So
1:34
if you forget about something, you want
1:35
it to bring that up for you, it'll be
1:36
able to do so. And for instance, say
1:38
there's a article that I read a week
1:39
ago. I'm like, "Hey, I read that article
1:41
on Energy. What was that about and who
1:42
wrote it?" It'll pull that up for me. Or
1:44
maybe there's an email I received from
1:45
somebody 3 weeks ago. I'm not really
1:47
sure who sent it, but I have a general
1:49
idea of what the topic was about. I can
1:50
have the AI go to my inbox, pull that
1:52
up, and grab it for me. That's on the
1:53
memory side. What's more interesting to
1:55
me is on the agent side, and the agent
1:58
mode is going to take autonomous actions
2:00
on your behalf, and its ability to
2:01
achieve more and more complex tasks over
2:03
time will increase. Instead of just
2:05
talking about this, I want to show you
2:06
what the browser looks like. So, here we
2:08
have the Atlas browser. So, I'm going to
2:10
do a hard refresh so you can see what
2:11
this looks like. So, we're on LinkedIn
2:12
for now. And on the right hand side, we
2:14
have a chat screen. So the chat screen
2:16
is where you can do all the different
2:17
stuff with the AI. The AI is
2:18
interspersed throughout the browser in
2:20
different areas, but this is the one
2:21
we're going to focus on for now. So on
2:23
the right hand side, we have a pop-up
2:24
here that says agent mode. We can also
2:26
enable agent mode with a plus sign here.
2:27
So if I go to plus sign and I go to
2:29
agent mode, it's going to immediately
2:30
turn that on. Once I've turned it on,
2:32
you'll see a few things pop up down here
2:34
at the bottom right hand corner. First,
2:35
it states that this is the agent, but
2:37
also it says that it's logged in. So you
2:39
can see we have logged in and logged
2:40
out. And I can see my head's in the way.
2:42
So, I'm going to quickly move my head
2:44
out of the way for a second. So, you can
2:46
see we have logged in and logged out.
2:47
So, logged in allows it to be logged
2:49
into all the different pieces of
2:50
software that I have access to. So, that
2:52
could be Gmail, all the SAS tools I
2:54
have, anything. And then logged out is
2:56
the opposite. So, for most people, the
2:58
most useful and utility oriented thing
2:59
is going to have it being logged in. So,
3:01
I'm going to keep it logged in. Another
3:03
thing I'll call out here is in the
3:04
settings. So, if I go to the settings in
3:06
the top right hand corner, I go to
3:07
settings. And here, if I go to agent
3:09
mode, at the very bottom, there's a
3:11
system instructions area where you can
3:13
put in system instructions that will
3:14
apply to all the different sites that
3:15
the AI goes to. For me, this is going to
3:18
be one of the most important features
3:19
that OpenAI builds on in the future
3:21
because if I have a series of really
3:22
complex activities that I want the AI to
3:24
do when I go to certain websites, I want
3:26
to have basically a GPT project or
3:28
custom GPT per activity for that
3:31
website. So, I want to have a series of
3:32
custom instructions that I can feed into
3:34
this AI. So anytime I go to that website
3:36
and I do a certain thing, the AI should
3:38
then follow those custom instructions to
3:40
the T to achieve a very complex task. So
3:42
that's the agent mode side. And then for
3:44
the memory piece, if you jump into
3:46
personalization, you go into here, you
3:47
can see that it's referencing memories
3:49
saved for here. So we have memories
3:51
being saved here. We have reference chat
3:52
history being saved and browser memories
3:55
being saved. You can turn all these off
3:56
if you prefer to have privacy, but in
3:58
this case, we're focused on utility and
3:59
getting the benefit from the AI, so I'm
4:01
going to leave it all on. And as a quick
4:02
note that's pretty important to call out
4:04
is this browser currently is only
4:06
available for Mac users, but it will
4:08
eventually be available for Windows
4:09
users. Plus, it's uh the agent mode that
4:12
I'm talking about mainly here is only
4:13
available for pro and plus users at the
4:15
moment, but eventually as with Windows,
4:17
they'll roll this out to all the users.
4:18
The amount of usage you'll get will vary
4:20
obviously based off of how much you're
4:21
paying, but either way, most people
4:23
likely get access to this. Let's jump
Example 1 Scheduling Content
4:24
into the examples. So, this first
4:26
example I want to show you is the 50
4:28
YouTube shorts that I gave it. So,
4:30
here's the context. I had 50 shorts that
4:32
I uploaded to YouTube and I wanted it to
4:34
schedule these shorts out on a daily
4:36
basis. So every single day I publish a
4:37
short on YouTube. This would have
4:39
probably taken me I would say 40 to 60
4:41
minutes to do manually. But instead what
4:43
I did is I created a very specific
4:45
prompt. I gave it to the agent in agent
4:47
mode and I allowed it to work in the
4:48
background. So there was some success
4:50
here but also some failures. And it's
4:52
important to for us to find the edge
4:54
cases of what's available today and be
4:55
aware that these edge cases are only for
4:57
today and likely will be fixed within
4:59
the few months. So the first edge case
5:00
that I found is that there were a few
5:01
restarts that I had to make. For
5:03
instance, it would probably complete
5:04
five to 10 shorts. It would stop and
5:06
then seek my guidance for continuation.
5:08
That's kind of annoying. So I had to
5:10
basically tell it to continue to
5:11
continue over and over and eventually it
5:14
finished, but it finished in a way that
5:15
actually did what I wanted it to. It
5:17
scheduled them all out for daily
5:18
publishing. And here's actually a quick
5:20
video of what it looks like when it's
5:22
happening uh in in kind of a live play.
5:24
So I'm going to play this video so you
5:25
can see it. And quick note, I'm going to
5:27
run this probably at 3 to 4x speed
5:29
because it is quite slow when it moves
5:31
through the browser, when it's taking
5:32
actions on your behalf. That's why I
5:34
recommend kicking it off, moving it to
5:35
the background, and doing a different
5:37
task in a different tab and or a
5:38
different browser. And right now, I have
5:39
this running at about 3x speed. So, I'm
5:42
going to play it out. You're going to
5:43
see that it's going to go to the
5:44
different screens, click through the
5:45
different screens that it needs to click
5:47
through to achieve the given task. So,
5:49
it goes next. It goes none of the above.
5:50
It goes to submit rating. It goes to
5:52
next again. And it's clicking through
5:54
these screens as I would have to do for
5:57
50 separate videos. And once it gets to
5:59
the screen where it has to schedule it,
6:00
you can see it goes to the date there.
6:02
It clicks the date and it then goes to
6:03
the time frame, updates the time frame
6:05
where it needs to. And then it takes a
6:07
second to then click schedule, but it
6:10
eventually does. So, this is the basic
6:11
process as it goes through and schedules
6:13
one post, but imagine it doing it 50
6:15
times in the background for me. Quick
6:17
pause in your regular programming. This
6:19
video is brought to you by me. So, two
6:21
quick things. First off, Blow is a free
6:23
link to a 30-day AI insight series. It's
6:25
completely free. You'll get 30 insights
6:27
in your inbox of how you can apply AI to
6:29
your business and your work. The second
6:30
thing is if you'd like to work with me,
6:32
Blow a series of offerings to see if
6:34
there's a good fit between the two of
6:35
us. With that being said, let's get back
6:36
into the video. So, that's our first
6:38
example. And I'm going to show you the
6:39
exact prompt I used here as well. So you
6:41
have a good context and idea of the
6:43
prompt I gave it because I'm trying to
6:44
be as specific as possible with this
6:45
agent to ensure that it can achieve the
6:47
task that I've given it. So at the top
6:48
I'm providing it the context and the
6:50
task I want it to do. So the context
6:51
states that I have 65 shorts that I've
6:53
uploaded into YouTube already. And then
6:55
I want it to publish all of these uh one
6:57
day out from each. So one one day at a
6:59
time. And then here is where I give the
7:01
very specific sections of where it has
7:04
to go. I say you have to click you have
7:06
to click on edit draft. You then have to
7:07
select next. Then you have to scroll
7:08
down and then you have to select this
7:10
section. I'm being very specific on what
7:11
it needs to do step by step. And at the
7:13
very end, I ask it to go ahead and start
7:15
and just do one to prove to me that it
7:17
can do it effectively. After it achieves
7:19
one, I then say go ahead and do the
7:20
rest. And I'm sure there's going to be a
7:22
lot of people in the comments saying,
7:23
"Oh, well, can't we do this today? Can
7:24
we already automate the process of our
7:26
websites?" And we can. There are
7:27
different tools we can use to automate
7:29
the clicking of buttons on sites and
7:31
things like that. But the issue with
7:32
this approach today is that it relies on
7:34
code. So, it takes a while to write the
7:36
code. Also, it's very brittle because if
7:38
any UI changes occur, it's going to
7:40
break immediately. Then we'd have to fix
7:42
those specific steps in the automation.
7:44
But with AI and using AI agents, it's
7:47
much more reliable because it can adjust
7:49
as we go with the UI. If the UI changes,
7:51
it can adapt to that automatically. It
7:54
understands the intent of what we're
7:55
trying to achieve. So, we don't have to
7:56
be as specific as writing code. And with
7:58
this approach and having it be more
8:00
adaptable, it can handle really any site
8:02
changes and still achieve the task
8:04
without you having to do anything. And
8:05
that for me is very attractive and I'm
8:06
sure it's very attractive to many of you
Example 2 Automating Followup
8:08
as well. Let's jump into the second
8:09
example where we're trying to automate
8:10
the entire postmeating process. Now, the
8:13
postmeating process I wanted it to
8:14
automate is this flow here. So, I'm
8:16
going to feed it a transcript from a
8:18
meeting that I just had. Once it gets
8:19
the transcript, it needs to draft a
8:21
follow-up email from that meeting. After
8:24
it's drafted the email, it needs to find
8:25
the attendees in the meeting and then
8:27
send the email to those attendees. after
8:29
it's sent the email of of that we've
8:31
drafted, it needs to then go to our CRM
8:33
or a task tracker and update the
8:35
specific action items for me and the
8:37
task tracker for that meeting. These are
8:39
a lot of steps for an AI to achieve in
8:42
one go. And I ran into a series of
8:44
issues when using agent mode inside of
8:46
Atlas. The two primary issues that I ran
8:48
into for this example is first is that
8:50
would it would stop midflow. So it maybe
8:52
achieve three or four of the five tasks
8:55
and then just stop without doing
8:57
anything else. So, I'd have to go in
8:58
there and kind of poke it and pro it to
9:00
get it to work. And the other thing that
9:01
was slightly annoying is that the action
9:03
items themselves were sometimes
9:05
misrepresented, giving somebody else's
9:06
action items to me. And then also the
9:08
email tone was off based off of the
9:10
types of emails that I prefer to write.
9:12
And the main insight we can take away
9:13
from this is that when using agent mode
9:15
inside of Atlas is we need to constrain
9:17
the tasks to be somewhat micro and
9:20
individual to start. because from this
9:22
example and from other examples that I
9:23
ran without showing it here is that it
9:25
struggles when you string together a
9:26
series of tasks that are somewhat
Example 3 Linkedin Replies
9:28
complex in nature. And our third and
9:30
final example here is LinkedIn comments.
9:32
So here's the task. I have a series of
9:35
comments below the posts that I like to
9:36
post on LinkedIn. And I often don't have
9:38
time to reply to the comments, but I
9:40
would like to. So what I did is I
9:42
outsourced that to agent mode and said,
9:43
"Okay, I want you to reply to all the
9:44
comments from the post that I put out in
9:46
the last 48 hours and make sure that the
9:49
replies are succinct one to three
9:50
words." And the overall results were
9:52
okay. They weren't horrible. What I
9:54
found is I needed to iterate on the
9:55
initial prompt that I provided probably
9:56
three to five times. After I iterated on
9:59
it and fixed some of the minor issues,
10:01
it was able to complete most of the
10:02
replies and only missed a few from the
10:04
last 48 hours. And here again is another
10:06
video walkthrough. So I'll open this up.
10:09
I'll expand it out so you can see it.
10:10
And this is probably going to be running
10:12
at four to 5x because it did take a
10:14
while for it to figure out where the
10:15
post was, where the comments were,
10:17
figuring out which comments were posted
10:19
in the last 48 hours, and a series of
10:20
other things. But you can see it's
10:21
clicking through the posts right now.
10:23
It's going to the comment section,
10:25
seeing the time frames associated, and
10:27
you can see here it starts to uh
10:28
actually reply. So, it hits reply to the
10:30
person that gave me a comment. It puts
10:32
in a two-word reply, and then it
10:34
selects, actually doesn't select reply
10:36
here. It asks for approval. says, "Hey,
10:37
can I reply on your behalf?" I say,
10:39
"Yes, this is global approval now. You
10:41
can go off and do it for for the
10:42
foreseeable future. You don't have to
10:44
keep on asking me." So, I hit reply. Did
10:45
it for me. That was done. Now, it's
10:47
going to go to the next comment. It's
10:49
going to then add a reply, hit reply,
10:51
and continue. And this basically goes on
10:53
for probably, I'd say, 20 minutes or so.
10:55
And it completes around 20 to 25
10:58
replies. And here's the specific prompt
11:00
that I landed on after the 3 to four
11:02
iterations. And I want to again show you
11:03
this so you can get an insight of what
11:05
worked and what didn't. For this first
11:07
segment of the prompt, we're limiting
11:08
both the time frame and the runtime of
11:11
the agent mode. So, we're saying we only
11:12
want you to look at the last 48 hours
11:14
because I know if I said look for the
11:15
last 50 days, it would take way too long
11:17
for the AI to then look at that and it
11:19
would be too complex for it to achieve.
11:20
So, I limited the constraints and said
11:22
only the last 48 hours. And in addition
11:24
to that, I said only those that I've not
11:26
replied to yet. So, we're trying to
11:28
limit the constraints even further.
11:29
Then, I provide more specifics on how it
11:31
should reply to the comments. So, it
11:33
needs to select the reply button below
11:34
the comment, ensuring that they're
11:36
adding the person when they reply. I'm
11:37
calling out the tone, saying that it
11:39
should keep a similar style to how I
11:40
like to reply to comments. And at the
11:42
very bottom, I've added this critical
11:44
component because this is something I've
11:45
learned through iteration. This was
11:46
probably the fourth or fifth iteration
11:48
when I added this is I needed to call it
11:50
the specific importance of selecting the
11:51
reply button after it was done. And then
11:53
emphasizing the importance of doing this
11:55
one at a time so it would actually
11:57
enforce the completion. And without this
11:59
minor addition at the bottom, it would
12:00
have just drafted a bunch of replies
12:02
below the comments, never selecting the
12:04
button to reply. That's something I ran
12:06
into. So I had to add this to say, "Do
12:07
this one at a time. Ensure that you
12:09
press reply each time." And this didn't
12:10
fix that issue. And after running
The Future
12:12
through those examples, I wanted to kind
12:13
of give you a bit of a glimpse into the
12:14
future of what I perceive going to
12:16
happen in the next probably 3 to six to
12:17
nine months. So right now, today, we're
12:20
able to achieve simple tasks with agent
12:22
mode and other tools that can control
12:24
our browsers with AI. We can have them
12:26
reply to LinkedIn posts. We can have
12:28
them summarize pages and take minor
12:30
actions that have few steps. But likely
12:32
in the next 1 to 3 months, we'll start
12:34
to be able to chain more and more
12:36
complex tasks together, such as
12:38
automating the post meeting stuff that I
12:40
shared with you. So drafting the email
12:42
and updating my CRM all together, all in
12:44
one go. And then finally, and I'm not
12:47
sure how long, maybe 9 to 12 to 16
12:50
months, we'll be able to outsource
12:51
entire activities to these agents where
12:54
we can say based off of my expenses from
12:56
the last month, can you manage those for
12:57
me? Get them all organized and set up
12:59
set it up for my accountant. This is
13:01
pretty ambitious. I'm not sure how long
13:03
this will take, but that's where they're
13:04
trying to go. This is the end goal. And
13:06
in that end goal future, we're likely
13:08
going to transition from typing these
13:11
very extensive and lengthy prompts to
13:14
simply talking to the AI that remembers
13:16
what we've gone and what we've done. It
13:18
knows how to achieve these more complex
13:19
tasks without us intervening. And it
13:21
really turns into that whole kind of
13:23
iron man Jarvis future that people like
13:24
to talk about where you're asking your
13:26
AI to take tasks on your behalf and
13:28
going off and doing that agentically
13:29
inside of your browser. And here are
Recap
13:31
just a few key takeaways. First, there
13:33
is a new abstraction layer being built
13:34
between us and all the applications that
13:36
we use in the internet. And all the
13:38
major companies are converging on what
13:40
this layer could look like based off all
13:42
the features and models are creating.
13:43
And next, there's an interesting
13:44
correlation between how much progress
13:47
has been made in the world of coding and
13:49
AI and how that's going to be directly
13:50
connected to browserbased agents.
13:52
Because with a browser, an agent has an
13:54
environment that it can test and learn
13:56
from and self-correct as it takes
13:58
certain actions. there's a higher
14:00
likelihood that it knows that it did
14:01
something wrong or right based off the
14:03
environment that we put it inside of.
14:05
And it's not necessarily as good as a
14:06
coding environment, but it's a pretty
14:08
strong place to start when the AI can
14:10
learn from its actions. And with that
14:12
point, it's important to note that the
14:13
limitations today are current and
14:16
temporary and progress is very fast and
14:18
will continue to be fast. So, a lot of
14:20
the issues that people complain about
14:21
today will be fixed in the coming
14:23
months. And as I said many times, as
14:25
business owners and leaders, it's
14:26
important to prepare now for that future
14:29
that's coming very fast in the next 6 to
14:31
12 months where we'll be able to
14:32
outsource either medium or large complex
14:35
tasks to agents to take on our behalf so
14:38
we can then refocus our attention on
14:39
things that are more strategic for our
Outro
14:40
businesses. And that's it. That's the
14:42
video. So, if you enjoyed this, reshare
14:43
with your friends. And remember, two
14:45
things. First off, we have the free
14:46
30-day AI insight series, completely
14:48
free. You'll get 30 insights in your
14:50
inbox of how you can apply AI to your
14:51
business and your work. Second thing is
14:53
if you'd like to work with me, blower a
14:55
series of offerings to see if there's a
14:56
good fit between the two of us. And with
14:58
that being said, there should be a video
15:00
around here that the YouTube gods thinks
15:01
that you'll love. See you next time.