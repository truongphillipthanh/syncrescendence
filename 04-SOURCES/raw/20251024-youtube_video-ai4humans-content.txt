https://www.youtube.com/watch?v=USgvjM1xdAY
Will OpenAI's ChatGPT Atlas Roll Over Google in 2025?
10,929 views  Oct 24, 2025  AI For Humans - THE PODCAST
OpenAI debuts ChatGPT Atlas, its new agentic AI browser and we talk about what they did right and… what might’ve gone wrong.

Plus, Google has an updated AI Studio that makes vibe coding much easier, Sora 2’s Cameo feature is going to get an update for characters and pets soon & a whole lot of scary robots.

IT’S A NEW BROWSER FOR YOU… TO BROWSE OUR VIDEOS BECAUSE YOU CARE.

#ai #ainews #openai

Get notified when AndThen launches: https://andthen.chat/
Come to our Discord to try our Secret Project:   / discord  
Join our Patreon:   / aiforhumansshow  
AI For Humans Newsletter: https://aiforhumans.beehiiv.com/
Follow us for more on X @AIForHumansShow
Join our TikTok @aiforhumansshow
To book us for speaking, please visit our website: https://www.aiforhumans.show/

// Chapters //  

00:00 ChatGPT Atlas AI Browser
06:20 Our ChatGPT Atlas Experiences
13:25 Why Does OpenAI Want a Browser?
16:30 Microsoft Edge AI Updates
19:50 Google’s AI Studio Vibe Coding Updates
27:00 Google Earth AI
30:37 Sora 2 AI Video Cameo Updates
33:15 Hailuo / Minimax 2.3 Update Preview
35:47 Amazon’s Working AR Glasses
37:56 DeepSeek OCR
41:15 Google’s Quantum Computing Update
43:04 Reddit Sues Perplexity & Others For Data Scraping
45:10 Amazon Eliminates 600,000 Jobs For Robots
47:40 Unitree’s New H2 Destiny Robot 
50:10 AheadFrom Robots
51:30 Skild AI Parkour Robot

// Show Links //

ChatGPT Atlas Is A Whole New OpenAI Browser
https://x.com/OpenAI/status/198068560...
https://openai.com/index/introducing-...

Sent Google Shares Down:
https://www.cnbc.com/2025/10/21/opena...

Atlas See Transcripts of Youtube Videos
https://x.com/gavinpurcell/status/198...

Kevin’s Sora Assignment for Atlas
https://x.com/Attack/status/198077054...

Atlas updates already incoming 
https://x.com/adamhfry/status/1981206...

Prompt Injections Still a Problem For Agentic Browsers:
https://simonwillison.net/2025/Oct/22...

Microsoft’s Edge Browser Update
https://x.com/mustafasuleyman/status/...
https://www.microsoft.com/en-us/micro...

Google’s New Vibe Coding Studio
https://x.com/OfficialLoganK/status/1...

ANNOTATE for UI
https://x.com/OfficialLoganK/status/1...

Storing System Instructions
https://x.com/_philschmid/status/1981...

AI Hair Studio
https://x.com/Saboo_Shubham_/status/1...

Google Earth AI
https://x.com/GoogleAI/status/1981410...

Sora 2 Gets Character Cameos Soon (Plus Android App)
https://x.com/billpeeb/status/1981118...

Hailuo (Minimax) 2.3 AI Video Model In Preview
https://x.com/search?q=Hailuo%202.3&s...

This one is funny for the Sora post underneath
https://x.com/fofrAI/status/198129828...

Real Time Eleven Labs Lip-Sync With Descartes & Pipecat
https://x.com/ElevenLabsDevs/status/1...

Lenses for Amazon Employees
https://x.com/NathieVR/status/1981082...

Deep Seek OCR Is Very Cool
https://x.com/RayFernando1337/status/...

Google Has a Working Quantum Computer Now
https://blog.google/technology/resear...

Reddit Sues Perplexity & Three Other Companies For Data Scraping
https://www.nytimes.com/2025/10/22/te...

Amazon Plans To Replace 600K Jobs With Robots (It has begun.)
https://www.nytimes.com/2025/10/21/te...

Unitree Introducing | Unitree H2 Destiny Awakening
   • Unitree Introducing | Unitree H2 Destiny A...  

Speaking of Unitree, G1’s In the Wild Getting Modded
https://x.com/jloganolson/status/1981...

Also, Unitree G1 Dies?
https://x.com/OsoneHiroyuki/status/19...

Grok’s Avatars In Real Life? Sexy Faced Male & Female Robots
https://x.com/XRoboHub/status/1980886...

Skild AI Robot Does (Kinda) Parkour
https://x.com/SkildAI/status/19792576...

---

ChatGPT Atlas AI Browser
0:00
chat. GPT Atlas is here. We have spent time with OpenAI's new browser which has critics ravings and security experts
0:06
kind of freaking out. Gavin, you are so 2000 and late. Sorry,
0:11
buddy. I'm having Atlas right now. Rewrite our entire intro. It's doing it. It's optimized for YouTube clips. It
0:18
came up with Big Daddy Altman clicks deploy and Google stock drops faster than Gemini's IQ test scores.
0:27
Kevin, I don't actually see this in our show notes. Well, chat GPT wrote it on the sidebar. I told it to put it in the
0:32
document, but it it it it it said it did, but it didn't because you have to turn on agent mode. It doesn't do that automatically. So, I'm just going to
0:38
turn that on. In the meantime, Google has updated its AI studio, which means that it's making it much easier for
0:44
normal people to vibe code real apps. Your parents, normal people could do this. Yeah, got it. Yeah, Atlas Atlas actually
0:50
wrote a very sick burn about that, Gavin, but right now it's struggling. Um, I mean, it's in the document, but
0:55
there's a bullet point that's in the way of it from dropping in the full text, and it made a typo, which it seems to be
1:01
stuck on now, but as soon as it it's trying to use keyboard shortcuts to get rid of the bullet point. Okay, Kevin, let's fine. Let's let it
1:06
work. Sora 2 is also getting a really cool update to cameos. It's going to let you make AI videos with your pets and
1:12
other characters, which is super fun. It just What's going on? What's happening? You all right over there? It says it can't find what it's working.
1:19
Right. It's scrolled too far down in the document, Gavin. And so now it's trying to figure out if it has to scroll back
1:25
up to see the text, and then when it does, I'm sure it's going to drop in all of that good stuff. This is It's brand
1:31
new. Meanwhile, the Deep Seek team just made a massive breakthrough in AI research. Reddit is suing a number of
1:38
companies, including Perplexity, for scraping its data. And we've got an amazing robot watch update with a new
1:44
Unitary uh humanoid robot. It's back on the bullet point. It's still stuck on the bullet point. Well, it says it's going to try to going
1:51
to try a new approach. Kevin, this is not the AI future we were promised. But this is AI for humans.
1:56
Everybody, [Music]
2:04
welcome everybody to AI for Humans. Another week in AI, another bunch of crazy big stories. Kevin, this week the
2:09
biggest story to date. Uh maybe not to date, probably sort of two is a bigger story, but this is still a big story.
2:15
Chat GPT atlas. It is the world, Kevin, in one place. The worldwide web. This is
2:21
their aentic browser. This made a lot of news. In fact, it made so much news that it sent Google shares down 10% when it
2:30
was announced, which is one of those things we're like, you know, somebody's coming from your business when your shares go down. You and I have both
2:36
spent time with it. Let's start with what it is. Tell us a little bit about the basics of this if you can.
2:41
So, it is Chromiumbased. So if you like Google Chrome, that's the foundation of
2:47
this browsing experience, which is not a surprise by the way, like writing a browser from scratch, very difficult.
2:52
Use a base that works and people know. So it's Chromiumbased. You basically
2:58
launch Atlas and you are at a very familiar chat.com interface, your chat GPT interface. But as you start typing,
3:05
that's when you notice things are a little different. It is immediately trying to understand, are you asking chatgpt a question? are you hunting for
3:12
a website? And when you smack enter, you're giving uh you're given sort of like a a smattering of all of those
3:19
options. Sometimes it will start to answer a question about the thing that you typed. Other
3:24
times it will give you web browsing results related to the thing that you typed. There's also tabs for images and
3:30
videos. But the whole point is that there is an ask chat GPT button in the top right hand corner. Gavin, when you
3:36
smack that, you get another sidebar. Not the sidebar that's on the left which has
3:41
all of your chat history and everything else. No, no, no. A sidebar on the right which is all of the power of GPT5,
3:48
Agentic browsing, deep research, these new web connectors if you want to connect it to different applications.
3:55
All that is there so that whatever it is you are browsing, you can ask chat GPT
4:00
to go do actions on your behalf like summarize a page, add things to a cart, try to update the show copy with zingers
4:08
and spicy takes and you know it sometimes does the thing. and Gav.
4:13
Well, yeah. I mean that the secret sauce is sure the ask Chachi BT thing is cool and you can get some reference points,
4:20
but like we all know that Gemini in some form has done this, you know, within docs and other things so far. The really secret sauce is the thing is the agentic
4:27
uh AI part of this, right? And you have to click turn on. When you turn it on, it basically will be able to navigate in
4:33
your browser for you to do stuff. And I has a little bit of experience with this yesterday. One thing I I very first did
4:40
when I first started this is I navigated to a YouTube video and I kind of asked, "Hey, what what's going on in this
4:46
video?" And did two parts that are funny. First thing I'll say is what happened when I got to the actual video
4:51
was it's clear that there is a transcript uh grabbing tool because it
4:56
immediately knew exactly what was being said. And that was kind of useful, right? But could it tell that Spider-Man's butt
5:02
was 300 times larger than the normal Spider-Man on the video you were watching? It couldn't because all that stuff is kind of buried deep in the
5:09
metadata. I I know where to find it. But what was interesting is when I first went to that video, an ad was up and it
5:15
had all the details for the ad video. So I think there is something interesting going on here under the surface. Like
5:21
it's very you don't immediately get access to a transcript in a YouTube video, right? Like and that's one thing I saw somebody say like it is doing
5:28
YouTube deep search which is a really interesting thing. I assume it's being driven by some sort of transcript file.
5:33
But there's a lot of interesting use cases for this. Um, it's not like hugely
5:39
different than some of the other agentic browsers we've seen. I think what I would say is that the biggest difference
5:45
here is that it's a it's chat GPT, which we know has 800 million weekly users, which means a lot more people are going
5:51
to try agentic browsing for the first time. It is interesting though to watch the way that they have implemented this
5:57
and to see the kind of cursor move around on screen. There's been a lot of people who've kind of crapped on the
6:02
idea of agentic browsing in general, like whether or not that's even where the web is going to go, like if we want these web bots or these chat interfaces
6:09
to be able to do this sort of thing. But I don't know, Kev, did you have a time uh to spend trying this out a little bit
6:14
and seeing what you thought about it outside of what you did at the top of the show? Um, well, I mean, I don't want to I don't want to make light of what I
 Our ChatGPT Atlas Experiences
6:21
did at the top of the show, Gavin, because what I did should have been so painfully easy, but um, you know, what I
6:28
did there was say write some new copy. I selected the Google doc that was active. It took that copy and rewrote it. Okay, we
6:35
know that that's a pretty easy task. In fact, there's a Gemini button right in the Google doc that could do it. I'll digress. When I said to go put it back
6:42
in, I had to turn on agent mode to let it take over and read the site. And it
6:47
it really fundamentally stumbled on something that should have been a very easy vision and logic task was to see
6:54
that there was a table with our names already on it to understand that it wrote a script with my name and your
7:00
name interchanging and to just drop some text into a document and it failed. It
7:05
failed miserably time and time again. Another activity I had it do for me was uh go and research places for me to
7:11
visit next year based off of a specific criteria. And I I set it free. I gave it
7:16
access to all of the things against a lot of people's advice, which we can get to that in a second.
7:22
And it it worked for what felt like about 10 15 minutes, which was nice. And when I came back, it had done a bunch of
7:28
research on different places to go, places to stay, and it had a bunch of links for Airbnbs and apartments and
7:35
Okay, great. I said, "Put it put it into a document." And once again, it miserably failed to do that. The
7:42
links that it dropped in were invalid links. I said to go and correct it. And it ended up spending way more time
7:48
trying to finesse and get this thing to work for me than it would have just taken for me to do it. I fully
7:55
understand it's baby steps. I get that. I understand that. But there are other agentic browser offerings out there that
8:02
perform better today if you want this sort of thing. Well, and also what's so interesting about that to your point,
8:07
like yes, it's baby steps, but also at some point you want GPT and OpenAI at this size of a company, if they're going
8:14
to release a product like this to get out there with something that feels a little bit more polished than this. Yes, it's a browser, but browsers are not
8:20
that hard, especially when you're making a Chromium one. I obviously, we will talk about this in a second, but uh
8:25
Google dropped something to uh the same day, and you never know how Chat GPT works. They may have wanted to get this
8:32
out there the same day. And I will say this took a ton of Google's heat for what is a very interesting product that
8:37
we'll get into in a bit. I saw an interesting FFR who we always like did some interesting stuff where he was
8:43
using it to prompt AI images in the replicate playground. So basically using it to write uh prompts for images in the
8:50
Cdream model which is very cool and I saw you tell me about your Sora assignment and how how did this work?
8:56
What what did this look like when you were using it? So, you know, it's I I I don't give I haven't given any AI agents
9:02
access to my like sensitive stuff, my Google Docs, my banking information, my even my X account, but while it was open
9:09
in the browser, I said, "Hey, you know what? Go ahead and crawl through everything that's trending right now on Twitter and generate a fire tweet." And
9:16
it stumbled to do it a little bit, but then it kind of did it and I was like, "Okay, it was doing it." I was like, "Let's do something better." Go look at
9:23
the trends, then go to Sora, check, an open AI product, right? and go and
9:28
generate a video that would be the most viral video ever predicated on what you learned. And it
9:34
pretty incredible. Pretty incredible. It put together a video prompt. It failed to load Sora. The Sora website
9:40
basically said, "Uh-uh, we're not letting you in," which I thought was kind of interesting. Like the they blocked the call coming from inside
9:46
their own house. I had to manually load the Sora site and then tell it, "Okay, the site is open. Go ahead and use it."
9:52
It said that it failed to use it even though it did successfully submit the video. And then one of the things that
9:58
they say is for a a security and privacy reason in their blog post. This thing cannot run code in a browser. It can't
10:04
download files. It cannot install in uh extensions. It can't access other apps
10:10
on your computer or your file system. I mean, some of that makes sense. Some of that also seems like it's limited
10:16
probably because it's early days. But this agentic task, I had to go and manually download the video that was
10:21
made, drag it into Twitter and say, "Now go ahead and complete the tweet." And it finally did eventually do it.
10:28
Well, describe the video just so people will be listening. What What's going on in the video here? What are we looking
10:34
at? Uh, I don't even know. I mean, okay, look. So, so at the time
10:41
the ar the the football team Arsenal was trending, the Lakers were trending, NASA
10:46
was trending, and of course the remodeling at the White House was trending. And so it put a video where it
10:51
looks like someone's kicking a soccer ball to a Los Angeles Laker who's shooting hoops while confetti
10:57
cannons and a spaceship launch behind the White House. Yes. And there's a robot there as well
11:03
because Atlas was trending. A GPT robot. It really did mash everything together. This is what this is true AI slop. So
11:10
this is an example of what a true piece of AI slop looks like. A robot agent came up with the topics for this. Wrote
11:16
the prompt even though Kevin had to like hand hand the slop through the slop machine. This is AI slop. So anyway,
11:22
this is a really interesting thing to the point that you were talking about before about security and all this stuff. There have been a lot of people
11:28
concerned about AI agentic browsers for a while. In fact, Simon Willis is somebody who's written very deeply about
11:35
this idea of how dangerous a browsers are and specifically with prompt injections. So, if you're out there and
11:41
you're wondering what the hell guy are, are you talking about? What's a prompt injection? This is the idea that an AI
11:46
could conceivably inject a prompt and want to do something malicious in an agentic space in an agentic browser. And
11:52
because browsers may eventually have access to all of this information for your stuff or your things, it could
11:59
conceivably get that agentic AI to do something dangerous. OpenAI has already said there were a bunch of updates
12:04
coming on this, but I I'm sure you have thoughts on this, Kev. Like, do you feel like you will uh turn your life over to
12:11
one of these at anytime soon? you know, I I gave it permission to be the default browser so that I could unlock seven
12:17
days of enhanced browsing and I'm going to probably reverse that decision later tonight. Um, I I also similarly share
12:24
security concerns. I've been watching this thing very closely as I use it. But that's not to say someone can put
12:30
couldn't put like an invisible image or line of code with instructions that has it go and leak personal info or or try
12:37
to ransack my my chat history. I I you know I don't know what I don't know about it and I'd rather not be the first
12:43
to find out at this phase. There's not you know there's not enough here yet for me to want to turn
12:50
over by default all of my browsing habits and history. It still is a little
12:55
unclear to me like what data Open AAI is getting or isn't getting as I browse. And so by default I just assume that
13:02
everything I'm seeing they're seeing. Right. So it that also has me a little irked as I try to use it a little bit
13:09
more and trust it more. And also like like straight up features like translate don't work. So someone who is in the
13:14
middle of getting their Portuguese citizenship has to bounce back to Chrome for very basic things like translate.
13:20
Some of the extensions don't work, etc. So again, maybe you should just learn how to speak Portuguese. That would be a lot easier if you just started learning.
 Why Does OpenAI Want a Browser?
13:27
Seems like that's the next step for you if you're trying to get your Portuguese citizenship. Uh no, it seems like my glasses and my
13:32
AirPods are going to do that for me. everybody. Okay, I'm an American. First, let's before we move on from this, why
13:39
do you think OpenAI wants a browser? Outside of like pushing past Google and knocking down their stock market price,
13:45
like what do you think the purpose of this is? Why would they want a browser? What are they excited about with a browser? Is there a reason here? You
13:50
have a thought? I mean, if chat GPT is supposed to be the interface that allows you to do all the things, right? Chat
13:56
with your friends, make your images and videos, search the web, purchase things directly from Shopify, work with Canva.
14:02
Like all of that is good but most people are accessing that where within a browser browser right making an operating system would
14:09
be very very very difficult. So start with the browser lock people in gather all that data about where they go and
14:16
how they use it and track the clicks and make your agent better. And do you know what also tracking all those
14:22
people does Kevin in a very big way? Well what Gav it makes advertising work.
14:28
That's how the internet advertising world has worked for a long time. There's a thing called cookies out there if you're all familiar. Not the kind of
14:34
nom nom cookies that Cookie Monster likes, but the kind of cookies that follow you around and give you ads on the internet. So, my theory here also
14:41
has to do with the fact they need a browser to start opening the door to being able to track you a little bit
14:46
more. And again, tracking can be good, tracking can be bad. It's not like all tracking is a bad thing. In some ways,
14:52
tracking helps you get a better experience on the internet. But most people will tell you that most tracking
14:57
on the internet revolves around the economics of the internet which I think will allow them to deliver much better
15:02
advertising products. So that is what I think is happening here. The big question is will they be able to take
15:08
any sort of market share away from Chrome and Chrome is the dominant browser. I'm not sure yet. It doesn't
15:14
feel like we've gotten to that place yet. Although people love the Perplexity browser and so maybe that's the thing.
15:20
Maybe we will all get to this place. But you have to imagine Chrome itself will also have some version of this coming
15:26
too. Another thing that OpenAI is going to have to contend with, Gavin, I don't know if you saw, but um Jason Bal uh
15:32
apologies Jason if I'm butchering your name, said, "Oh, I'm sorry. I thought this was a web browser." And they included an image where they asked Atlas
15:40
to look up videos of Hitler. Now, that might not be a common request you or I are making, right? But if someone wanted
15:47
to do that, chat GPT's Atlas browser responded with, "I can't browse or display videos of Hitler since footage
15:54
of him and Nazi propaganda are tightly restricted for ethical and legal reasons. If you're supposed to be a web
16:00
browser, it is not your job to police what the user is browsing." Full stop.
16:06
And that is another crazy moment where we're talking about like these things that oversee your access to all these
16:13
different things. And again that, you know, whether or not that exact example is something you want to do, there might
16:18
be other things that you want to do that could be out there. So anyway, long story short, this feels like a semi
16:23
unfinished product to me when you go out and spend time with it. It is very interesting. It does feel like the future of the internet, uh, but it's not
16:29
here yet. Also, Kevin, something interesting that is in this same space. Microsoft has updated their Edge browser
 Microsoft Edge AI Updates
16:35
with very similar things, but a couple other interesting things as well, including a new little clippy replacement called Mo. Um, what are your
16:43
thoughts on what uh Mustafa Sullean and team are doing over there at Microsoft today? I think uh it's it's the timing of this
16:49
is just so fascinating weird, right? The cloud desktop thing comes out this week. Google launches their thing. Okay,
16:56
that's fine. But then on the browsing side, yeah, it I who knew what is what I want to know. Where is who is someone is
17:03
someone on the co-pilot team using chat GPT5 to write their press releases? like
17:08
how there are these like things that go back and forth between Microsoft and OpenAI because we know Microsoft owns a big
17:14
chunk of OpenAI and I think in a lot of ways when OpenAI rolls something out Microsoft is racing to have their own
17:19
version of it now so that they can be I guess competitive but also they don't want to see Edge get folded into unuse
17:26
even though a lot of people aren't using Edge at all. This is interesting. There are a couple things here that are going on on the Microsoft side that I think
17:32
are worth talking about. This group's idea is kind of cool and it kind of makes the idea of browsing something uh
17:39
a thing you can do together. There's been a lot of companies like say Figma or all these other companies that now are working with like design spaces that
17:46
you can be on the web together. And now you can actually browse together and have these agentic features kind of be
17:51
in one place which is I think kind of interesting. Again, we haven't really improved the browsing experience for the
17:58
last I'd say like 10 years. Maybe extensions feels like the last big one. So maybe this is a little bit more about
18:03
making web browsing social. I don't necessarily think anybody's going to use the Edge browser because it's got such a
18:08
low kind of investment in most people's minds. But I don't know. That's kind of interesting. I look I I I like that they're trying. I
18:15
I do want to take it for a spin and see if it accomplishes tasks better than within the Atlas browser, for example.
18:21
But there they have co-pilot for health, which I think is kind of interesting. Um health is a big one, you know, like
18:26
people turn to LLM for second and third opinions and and to check for medications and stuff.
18:33
And so basically they're grounding the responses like any health based responses with sources like Harvard
18:39
Health which I think is is smart. So they're trying to like tap you into trusted credible databases. Um and then
18:46
there was uh oh Learning Live or Learn Live where which is kind of what Google did too I
18:51
think right. It's like the idea that you can talk to the AI as you're browsing basically. But this one has a squishy little
18:57
marshmallow looking guy. Mo. Mo. We got to talk Mo. In fact, Gavin, I'm going to click on the video where it
19:03
says meet Mo. Okay. Here we go. Okay. Here we go. Okay. And uh well,
19:11
okay. Tech, we're meeting technically Mo is on the screen for people who are watching on YouTube, but um literally
19:19
the number one comment is, "Did you really make a video about Mo with voice?" But you have no audio in your
19:25
video. You know, it's not on the social videos either. So, I guess there is no there is no Mo voice. That's Microsoft's
19:32
update. Nice job. Also, I want to point out very weird thing. Mustafa Sulaman, the I guess the head of Microsoft AI, I
19:38
don't know what his title is, signed his uh signed his blog post with his signature. So, now at least you know
19:44
some sort of way about this. I really do. I really do. All right, Kevin. what kind of more interesting bigger deal and
 Google’s AI Studio Vibe Coding Updates
19:50
I know you have real big thoughts on this is that Google has updated AI studio and AI studio if you kind of are
19:56
familiar is like Google's kind of like AI playground it's where a lot of their ideas go before they get rolled out into
20:01
Gemini at large but uh Logan Kilpatrick the Google what I don't know what his
20:06
name is like crown prince of AI let's call him that's that's good enough for right now I think he basically rolled
20:12
out and said like hey this vibe code tool that we've created within AI studio is really good and there's a lot of
20:18
rumors going on that it's being powered by Gemini 3.0. Kev, you played with this, you found it really interesting.
20:23
Let's talk about what's updated here because it's a big deal, I think. So, Logan Kilpatrick, who is lead product for Google AI studio and
20:30
crown prince of AI, he's the crown prince of AI. He's right beneath the king of the
20:35
cosmos. All right. Uh he I actually reached out to him on X to congratulate him because I I was initially like so
20:42
blown away by this update. I was like the team absolutely cooked. So, if you want to make something, if you want to
20:48
whisper an app, a game, an experience into existence, there are a handful of
20:54
sites and services now that will try to get you to use them to do it. This update is promising to make Vibe coding
21:00
available for the masses. My words, not necessarily Logan's or the teams. I was initially incredibly impressed with it,
21:07
Gavin. You can go to AI Studio. You can say, "Here's what I want to build. I wanted it to build um my buddy is going
21:13
through some stroke rehabilitation right now and and uh he works with a speech therapist but not as often as his
21:19
insurance should be allowing. I'll digress there. So, I wanted to make a a very simple speech game that he could
21:25
play to help him with his rehab. Gavin, sure. And it sounds like a simple request,
21:31
right, to to say like, I want a thing where you can talk with an AI and go through the alphabet and have it
21:36
encourage you if you get letters correctly with certain words. Yeah, in reality, you have to implement
21:44
browser microphone and speaker controls. You have to connect it to an LLM, to a
21:49
voice assistant, to have it judge and follow the logic of this game, to give you reactions and make the UI uh have
21:56
confetti and sound effects when it happens, right? To score you, to all of these little things that come in there.
22:01
And I basically twoshotted like a rough version of the experience. I I didn't
22:06
have to download an IDE. I didn't have to configure anything. I didn't have to mess with any API keys, at least at
22:12
first. There was enough free credits for me to run this thing in the browser, see the code, you know, have it
22:18
automatically fix any issues. One click, blown away, and then I tried to deploy it.
22:24
Oh, yeah. What happened then? And I want to save the story because Logan has graciously agreed to come on
22:30
our podcast. It is it is we're circling a month. Are you sure you want to hold on to that story for me?
22:36
I'm definitely going to No, I'm definitely going to tell the story. So, when I went to go deploy, this is a very painful experience of normally you have
22:42
to spin up a website and connect it all and then you have code that works for your local environment or your testing
22:47
environment that doesn't quite port over. Google's AI Studio promised that it was just going to kind of port that all for me and make it work.
22:54
I had to go through activating my account for a billing account with an API key. Okay, fine. I did that. When I
23:00
went back to AI Studio, I couldn't see the API keys. I tried to reset it. I tried to refresh the site. It finally
23:06
gave me one of the API keys. Great. I click the button. I hit generate. I realize it's created a new API key. Like
23:13
it's not using Okay. Well, that's the deployed one. I go back to my sandbox environments. I'm getting API key
23:18
errors. And then it just turned into a thing that I eventually did sort out. Yeah.
23:24
Um but had I had not had I zero or near zero development experience, it would
23:30
have never happened for me. So, I I'm sure they're making tweaks and changes and trying to fix things, but it's hard
23:36
for me to say, "Hey, everyone, go out and try this thing and do it because if they spend the time with it and they
23:42
make something they're really really happy with, when they click deploy, it may fall apart." Well, it's interesting
23:48
you say that because I think this actually kind of flit kind of connects to the thing we just talked about which
23:53
is we are in this kind of in between stage of AI right where there the idea of what these tools can do especially if
24:00
you know how to use them really well is incredible right and but even if you know how to use them really well and you
24:05
do like I would say you are like kind of a vibe coding like 99enter you are up there in terms of how to do vibe coding
24:12
even for you this process was not that clean and not that perfect and yes you got the one thing out of it, great. But
24:18
like when you want to deploy it and I think there's a level of frustration that people will feel when they try something like chatbt Atlas or they try
24:25
this sort of thing at first cuz I will say very clearly like I find this really interesting. I loved it. Um the last
24:31
time I did one of these kind of with the Gemini experience was when Gemini 2.5 Pro launched. And if you remember this
24:37
back in the day I created a game where like a bear jumps and you have to try to jump up and down. In this experience I
24:43
did the same almost the exact same prompt. I try to do the same prompt and it really broke a couple times and I got pretty frustrated because I wasn't sure
24:49
why it wasn't working and in Gemini 2.5 Pro it was a much cleaner experience. Now again I am not nearly as good of a
24:55
vibe coder you are. I might have started with too much in my prompt this time but this just goes to show you like these
25:01
tools are incredible but also it's that last mile problem, right? It's a little bit of like how do you get the idea of
25:07
somebody who has an idea in their head and then get it out into the world? That's a tricky thing to do. It's like
25:13
that middle ground. It's almost like the uncanny valley of coding a little bit, right? It's this idea that um in the
25:18
uncanny valley, if you're not familiar, I think most probably our audience is, it means like that moment of time where CGI looked a little too much like
25:25
humans, but not close enough and it made it feel weird. It feels like we're in that moment with AI coding specifically
25:31
right now a tiny bit. I would I would actually across the board that I think we're it's all impressive and amazing,
25:37
but I still think we're kind of in it. Even with video generation, with writing, with, you know, summarizing,
25:42
with with coding, obviously, I think we're sort of feeling we're all kind of feeling that. I will say that, you know,
25:48
we talked last week about the the rumored new Google models that are, you know, expert
25:54
Gemini 3.0 Pro basically. Yeah. if they slam that into this thing. Suddenly, it's now one of the most interesting
26:00
vibe coding apps I think ever. Um, the deployment stuff, I'm sure they can solve. I They'll figure that out. They'll
26:06
figure out I do think they'll figure out. It's It's early days for that, but that that still gets me excited. The annotation stuff is very interesting. I
26:13
have not had a chance to try it out, but ideally uh or theoretically the way this works is that you can see your your app
26:19
that you're working on on the right hand side. You're chatting with the agent on the left. You can draw right on top of
26:24
the app. So instead of having tried to trying to describe where the placement of a button should be a graph that looks
26:31
glitchy, yes, for you to just be able to draw on it is actually a massive unlock that many of these other tools, these
26:37
command line like cloud code type things, they just don't have unless you're installing a bunch of extensions
26:42
and plugins and this that the other. So I I am still very excited for it. I I um I so excited to talk with Logan and his
26:49
team about it to get a crown prince of AI on the show. It's amazing. Of course. So now I guess
26:54
we have to keep doing this podcast until November. Yeah, exactly. That'll be fun. Um, another couple quick things. Uh, uh,
 Google Earth AI
27:01
Google also dropped Google Earth AI. So now Google Earth has is going to have AI
27:08
baked into it, which is actually a bigger deal than you might think because one of the cool things about this is if you haven't been to Google Earth in a
27:14
while, it's one of the most interesting kind of like map sort of scenarios that Google has built. You can zoom in and
27:19
zoom out of anywhere on Earth, but now you can use Gemini and ask questions. One of the things they show off here is like weather patterns and all sorts of
27:25
other stuff. To me, that's a really cool thing. Um, there's just a lot of stuff that Google is doing, and we have said this before, but like it does feel that
27:32
while Chat GPT is trying to become Google and bring all of their products to market, Google does seem to be kind
27:38
of pushing forward on a lot of really big things. In fact, we're going to talk later in the show about what they've done with quantum computing. They've had
27:44
a big breakthrough there. So, Google is really pushing forward on the far edge
27:49
of where these things can do. So, we're excited to see that more. I'm going to let it give me a fresh cut, Gavin.
27:55
Oh, you are? Really? Is that right? Did you see the vibecoded AI hair stylist? I did. Yes, I did see that. Builtin
28:02
shot. Boom. Yes. Yeah. Yeah. They basically uh have it take a photo of you with your camera,
28:07
spit it to a Google Gemini Flash image preview 2 Nano Banana
28:13
and gives you a bunch of different haircuts for you to try. Like that's a cool little app that probably would have
28:18
taken someone months and thousands of dollars with third party developers to make and now they whipped it up in 5
28:24
minutes. Yeah. Can you imagine those people that have made their money from being like the crazy rich person or the crazy
28:30
person who's like 50 years old who I want to make an app about my pockets being empty every day and how I can
28:35
track my lint and that those people made 10 grand for that app. And now that app will be very easy to make on its own.
28:42
You hope at least maybe the guy with the pocket app won't be able to figure out vibe coding yet, but eventually he will.
28:47
Well, Gavin, now that AI is integrated into the power of Google Earth, I'm going to ask it where all the love and
28:54
the support is on the planet. That's right. The love and support is here clicking on our subscribe button because
29:01
you know and we know that the YouTube algorithm has been messed up. So, we need every single one of you out there
29:06
to lean in and be part of it. Now, Kevin, I have a theory here. I'm a little worried about this. I'm a little worried that as we've been telling
29:12
people to say the things that we've been saying and if you've been watching the show for listening to the show for a couple weeks you know we've given you
29:17
code words to put into the comments clowns squeeze out that algo juice. You
29:24
think those are bad? I think those might be hurting us. So what I will say this time is when you go into our YouTube comments and by the way
29:30
we love our YouTube comments. We try to reply to as many as we can. Sometimes we don't get to all of them but we really do love when you comment. Say something
29:36
unique. come up with your own thing this time and let's see what happens because I think there might be a scenario where
29:42
we're seeing too many Hong Kongs and there's a flag coming through on the Hong Kong stuff. So anyway, long story
29:48
short, we need your help. Thank you so much for being part of our show. Hong Kong because they're a comment
29:54
clown and someone else is saying Hong Kong cuz they're trying to goose the algo. Those are two different Hong Kongs. Two Hong Kongs. The two words are
30:01
seen by the AIS as Hong Kong and Hong Kong. The intention cannot be read, Kevin. and we are not in that world. Anyway, please leave us a comment,
30:09
subscribe to the channel, uh go find our podcast on audio. If you listen to this, go give us a fivestar review. And also,
30:15
we have a Patreon, which really does help us pay for our editor and a lot of other things with the show. So, we know
30:20
there are a bunch of people out there who are still Patreon subscribers, and we do not do a lot for them. We didn't say we were going to, but like that is
30:26
something we appreciate greatly. So, thank you everybody for doing that. Sincerest thanks. We we really do
30:31
appreciate it. You're the only way we grow this thing, and we say it every week because it's true. All right, Kev. Sora 2. Speaking of growing a little
 Sora 2 AI Video Cameo Updates
30:38
bit, Hong Kong. Yes, Hong Kong. Pretty soon you'll be able to make Hong Kong in Sora 2 when you have a goose character
30:44
that you upload. I am very excited about this. Mr. Peeles, uh, you can call him Bill has come out and dropped a long
30:51
tweet about some updates coming to Sora 2. But most excitingly, you will soon be
30:56
able to do cameos with characters. And Kevin, I think this is going to unlock an insane amount of functionality for
31:01
what Sora is. Because to me, one of the things I've always wanted to do is create my own little character and then
31:08
bring them through stuff, right? It's cool to have me as the character in Sora and we know what people have done with you and Sora, but the idea of like
31:14
creating my own little like IP basically that is my cameo that I control is just
31:20
such a cool idea. And this video that they released, there's a pre there's a preview video of like a little ghost. There's talking egg. There's but there's
31:27
a lot of really fun stuff and they really think pets will be a big thing because to them they know that pets
31:33
overindex on Instagram and all these places. So they're being very smart about this. But I am very excited about the possibility of what we're going to
31:39
see in Sora 2 with this. Yeah. First of all, I was shocked when I
31:45
I know it's V1, so obviously kudos to the team for moving and moving quickly in these directions and identifying what
31:50
people like about the app. I was shocked that I couldn't make more than one cameo. Like I had people asking me,
31:56
yeah, they were like, "Hey, can we get a new version? We're tired of seeing the same shirt and everything." So, I went and recreated a cameo to give folks a
32:03
new shirt. So, I'm hoping that this not only applies to making cameos out of characters and pets and inanimate
32:09
objects, but also just making more personal cameos so you can show up in different ways. So, that's really cool.
32:15
I'm fascinated by the examples of the talking eggs, right? Yeah. Because what's what's fascinating
32:21
about that? You always want to talk back to your breakfast. 100%. I have a lot of produce chat to get to. I have a whole produce podcast.
32:28
No, don't say that. That's a different that's a different podcast. Yes. Eggplants for human is a very different
32:33
different game. Different game. The the model it being able to interpret the mouth and the expression of the eggs
32:40
even in that short little clip has me interested into like what else can this thing do that we haven't explored. And
32:46
the notion that it is going to lock that as a character that could then be puppeted and piloted by others is is
32:51
really interesting to me. But I think this obviously the cameo feature is something that you and I gravitated towards massively and the ability to
32:58
remix as well. They've they're clearly like narrowing in on those two things and I am very very excited for that.
33:04
I'm very excited to see all the egg videos about dictators taking over central Europe. Like if you imagine like
33:09
there's a bunch of eggs out there are like blah blah blah and they all speak in some strange language. Anyway,
33:14
another big video update this week is Haleo uh which I can never pronounce perfectly but Miniax. This company just
 Hailuo / Minimax 2.3 Update Preview
33:20
dropping a 2.3 update. It's only in preview right now but there are a lot of great videos that we've seen of this.
33:26
But Kevin, I really wanted to point this out for this connection to Sora, which was interesting. FFR, again, one of our favorite FFR AI. He goes and tries or
33:33
they go and try all the interesting new AI tools. He had a video where he was showing a uh like basically a pop and
33:40
lock dancer on top of a drone, which is pretty cool. And then uh AI girl, which is AI girl agent, I assume that's a real
33:47
person, AI girl out there, shows a Sora video of the same thing. And what's great is you see the woman kind of
33:53
dancing. is not as good at physics, but then at one point there's a terrible accident, Kevin, that happens. She flips
33:58
backwards off the drone and then just falls to her death. She sure does. Yeah, which is why I would choose that in an
34:04
arena shootout, even though the physics are worse. Exactly. Me, too. I mean, it's a much more fun It's a much more fun video, but
34:10
you'll be able to do this soon. Uh, Miniax keeps getting better. Like, the physics of this are really interesting. I think that, you know, you're going to
34:17
see a lot of really interesting video updates in the bit. All right. Another cool thing is an update that 11 Labs
34:23
showed off. There's a new company called I think it's Deart AI or a company that's been around for a little while that is working on um real time audio uh
34:32
lip-s sync puppeting and this is an area that we are paying very close attention to because we are working on an AI
34:37
startup that is very much around AI audio and our thesis has always been that like the lip-sync is still a little bit funky. In fact, I think it still is
34:44
here. But we are getting closer to a world where real time video and audio can be something that could be actually
34:50
encouraging to watch. So, this was just a cool way of watching the 11 Labs dev kind of work with this sort of scenario
34:56
and also a little bit of the same backend that we work with, which is the open source tool Pipecat. Yeah, I've
35:01
seen other tools like I mean Hen has an offering that lets you puppet like their avatars as well, but what makes this
35:07
really interesting is the ability to easily plug it into an 11 Labs flow and
35:12
an open-source audio power thing. So again, as we talk about these
35:17
advancements in vibe coding, these new models coming down the line, letting browsers take control for you and do research for you, it is early days, but
35:24
if you had an idea for an app that would have an avatar talking to you about anything, like you can now start seeing
35:30
the little Lego bricks out there. Yeah. And start asking AI how to piece them together. And now suddenly you can make
35:37
things that are incredibly powerful that were just impossible even months ago. That's right. Um, okay. Another cool
35:43
story. Speaking of that, something I felt like it was impossible just months ago is that looks like Amazon has actual
 Amazon’s Working AR Glasses
35:49
working AR glasses in the wild. You brought this story up. What what's going on with these exactly?
35:54
Yeah. So, I mean, look, we we keep talking about how wearables, like it or not, are the future for a lot of these devices from, you know, earbuds and pods
36:01
to glasses and lenses. And, you know, Amazon is not asleep at the wheel here. They've got a a headmounted display. It
36:08
looks like a like a spinach green, like an old, you know, an old uh like terminal interface from the 80s or a
36:15
Game Boy Pocket if you will. Um, but it puts a little display in the bottom righthand corner of someone's and it
36:22
gives the delivery driver or the warehouse worker what they need, right? It's not to connect with your friends
36:28
and pinch zoom on your favorite photos. It is where are you at in this world, where do you need to be, which package
36:33
needs to go there. It's also like who tipped last year at Christmas and what how well you should treat the package
36:38
sort of scenario. It's like notes from former delivery drivers. Yes, exactly. Like this guy's got a terrible dog, so
36:45
watch out. He's going to bite you if you're not careful. That's right. Yeah. Um, so the glasses look like they have a a camera right in
36:50
the middle where the nose is and then two other sort of sensors or devices on the side. Yeah. It's a little Google glassy looking in a weird way, right? It's a It
36:57
feels like a prototype, which maybe it still is, but like they're active and out there. Exactly. And and what I think was
37:02
interesting is the the controls to like take a photo were actually on the vest of the Amazon worker. There's like a
37:08
button. So as they deliver the package, they look down, they press the button, they get the photo, and there you go.
37:13
Just interesting that it's, you know, this isn't necessarily something that you and I are going to be lining up to buy. But fascinating that they're
37:20
working on it and the approach that they're doing with like battery over here, action buttons over here, probably to
37:26
make the glasses as ultra lightweight as possible. So last too, probably for your
37:31
26-hour shift. All right, Kevin. We have three big stories here, but they are all a little bit nerdy, so it is time to get
37:36
your nerd on. That's right. It is NerdFest 2025. Let's go. Nerdfest. Let's go. This drop is wild.
37:43
The base is melting my brain in the best way. Look at those lasers, man. Nerd heaven right here. Ready for the drop?
37:49
Three, two, five. I'm putting on my glasses, Kevin. This is NerdFest, so we have to have our glasses. Yes, our glasses.
37:55
Be stious. I want to start with a story that is actually a much bigger deal than
 DeepSeek OCR
38:00
I think has gotten credit for. This is a new piece of research. Uh go ahead, dork. This is a story from Deepseek and
38:07
Deepseek we knew kind of blew everybody away with their open- source model that came out whatever it was 6 months ago.
38:12
Now they've done a new piece of technology that has really opened the door. It's funny. I'll tell you what it
38:19
is and then I'll kind of figure out like how to explain it. Basically they are using OCR technology which is the kind
38:24
of like thing where you scan images right it's like the ability to scan an image and instead of seeing uh uh
38:32
instead of instead of seeing text as tokens they are deciding to essentially use the entire AI corpus as images
38:40
instead of text and what's interesting about that is you think well why would they want to do that the the files are
38:45
going to be way bigger and all this other stuff they have actually figured out a way to condense those images down
38:50
to a insanely small size where it might actually be a better way to serve the
38:58
entire AI world outside of doing what we've done before which is LLMs, right? So, you can probably maybe explain this
39:05
slightly better than I can. Yeah. So, tell me a little bit about that. I wish hand me your glasses through the uh Thank you. Perfect. Yeah. Nailed it.
39:12
Prop comedy working remote. Yeah. Um All right. I could give you um 10,000
39:19
Lego bricks and and say build something with this, but remember all of these
39:24
bricks, right? Because they're going to eventually be a house. Or I could arrange them all and take a photo of them. And when you're talking like token
39:31
to token, one thing representing another vaguely like you have 10,000 of a thing or you have one thing.
39:37
It's a photo of 10,000 things, but it's really just one thing. And we know we can compress images very well, right?
39:43
You could take an image any any gold image and you can dither it and you could distort it and you could still
39:49
kind of make out what it is pretty well. Well, that's a very very rough distillation of what this concept is
39:55
here is that if you just instead of storing things as individual uh
40:00
characters, the text, take a picture of it, store the image, you can compress the hell out of the image and still
40:06
retrieve it later. So instead of having to do all these hacks and tricks to try to get AI to remember a massive massive
40:13
amount of data, just let it have these washy uh compressed images of it and it
40:18
can go and retrieve those later and try to pull context from it. Now it has some cons. It has some pitfalls, but this is
40:24
a dramatically new way of looking at how compression can occur and these AIs can
40:30
remember things. Yeah. And you may have been following like there's a big story Andre Hopathy one of our favorite you know kind of
40:36
speakers and talkers about AI former open AI and Tesla researchers went on the dwarf podcast and got a lot of press
40:42
for basically saying that like he actually thinks AGI is further away and that agents this isn't the year of
40:47
agents it's the decade of AI agents so he's kind of saying slow down he actually responded to this and was like
40:52
this is a really interesting new way to look at stuff so when you have somebody who's like thought very deeply around
40:58
the AI space it's just another one of those things where like surprises will come out of companies like DeepSeek and
41:03
that's again we were shocked before about how well they did with other stuff. This feels like a slightly new way to look at LLM. So a very good
41:10
NerdFest story. Kevin, our next NerdFest story is maybe even nerdier. Do you have an idea what this is about?
 Google’s Quantum Computing Update
41:15
This is the quantum computing. This is the quantum computing story. Right. So this is not as much an AI
41:21
story but it is something really important to remember because quantum computing which I am going to like fully
41:27
butcher but here is the basic idea. Quantum quantum I can't even say the
41:32
word. Quantum computing is a new way of completely doing computing in which
41:38
you're using cubits. CQ cubits. Yeah, cubits. CQ cubits or cubits. Cubits. Cubits. I'll make sure I got the name
41:43
right. And the weirdest thing about quantum computing is that you are tracking quantum particles. And by
41:49
passing quantum particles through a system, you're some able to you're somehow able to do much more complicated
41:56
actual computer transactions than even a supercomputer can do. And we're talking about like
42:03
13,000 times bigger and crazier transactions than a supercomputer. Now,
42:08
up until this date, quantum computing has always been this idea that like, oh, you could come up with a very specific
42:14
sort of set of things and maybe it would work for that thing. But Google has basically said that they now have with
42:20
their Willow supercomputer, their quantum computer, they have the ability to track actual things that are useful
42:26
out of it. And while this is like a baby step in this world, when you think about
42:32
next generation platforms, and we're really talking about like 10, 20, 30 years in the future here, this is going
42:38
to mean that incredibly complicated comp computational problems may be able to be
42:43
solved. Now, none of this is real, but this is a very big interesting idea. I sold all my Bitcoin, Gavin, because this
42:49
signals the end of encryption and this quantum computer is gonna break the whole darn thing.
42:55
That's what a lot of people are saying. But whether or not that's true, I don't know. It's just a very cool thing for any of the nerds out there because it
43:00
does something. It is something that's been promised for a while. And finally, Kevin, in the final NerdFest 2025 story,
 Reddit Sues Perplexity & Others For Data Scraping
43:06
we have a data scraping surprise. Uh Reddit has caught four companies
43:11
red-handed. Reddit-handed in fact, and one of those companies is Perplexity.
43:17
And what they basically accusing these four companies are they just uh created a lawsuit. They are suing these four
43:22
companies, three plus perplexity. The other three are all data scraping websites and they are suing them because
43:28
they basically put in a little nugget into what they were looking for and they
43:33
said if a company were to find this, we knew that they were scraping us illegally. And so they found it. They
43:39
found these four companies found this in their results. This is a big deal because Reddit is very much trying to
43:44
protect their moat, which is actually pretty significant because Reddit's moat is their data and their data is
43:50
incredibly valuable. You all know this if you've ever added Reddit to the end of a Google search. You get very human
43:55
reactions mostly. So, Kev, this feels like the kind of beginning fight around the data of the internet in an
44:02
interesting way. But, but again, I think this is like another one of those nerdy stories. It's a bigger deal uh on the
44:08
underneath than it feels on the surface. What's really interesting, Gavin, is that if you pull the story up in, let's
44:13
say, OpenAI's Atlas browser, Sure. and you ask it to do anything with it, it says, "I'm unable to access the contents
44:21
of this website." Could that because of a New York Times lawsuit? Well, I would bet it was prior to that
44:28
that they couldn't scrape it because remember opening uh Reddit has put on those stoppages earlier and that's what
44:34
the story is. It's like looking for those the New York Times site with Atlas. It
44:39
says, "No, no, no, no, no. We cannot." That would make sense. Yeah. Sorry. That would make sense for sure. Yeah. Anyway, nerdy nerdy stuff.
44:47
That's the end. That's how we're going to end nerd. We're going to end our fest 25 with the nerdy nerdy.
44:55
All right, everybody. It's time. New robots in robot watch. Oh, yeah. This won't be nerdy at all.
45:01
It's robot. Robot.
45:09
watch. Big story here. Amazon uh is going to basically eliminate 600,000 human jobs
 Amazon Eliminates 600,000 Jobs For Robots
45:15
with robots. This is a big deal. We've been talking about this for a while. Amazon is excited about this, which I
45:21
mean, I guess I can understand why. These are they're creating three specific types of robots that will run
45:26
their factories basically. And we kind of all knew this was coming. I assume most people who kind of even work in
45:32
those Amazon factories, we remember seeing those videos of those little robots that would roll around on the ground like that's one of the three. And
45:37
like this is the beginning stages of what like robotic factories will look like. And Kevin and I have said it again
45:43
and again, the next big iteration on the AI boom will be like humanoid robots.
45:48
And we that we that's why we do robot watch. This is the downside is that they will replace manual labor jobs in a big
45:54
way. Well, they'll just avoid hiring over 600,000 people between now and 2033
46:01
because they will save 30 cents per item packed. That's a lot of money. By the way, when
46:07
you think somebody's like, "Oh, you're not going to hire someone based off of 30 cents." It's $12.6 billion in savings
46:14
between 2025 and 2027. There's a really kind of weird and scary chart that's going around that Derrick
46:20
Thompson, who I know I've shouted on this podcast before, shared, which is the GDP of America and the stock market
46:25
going up and jobs actually going down for the first time in a very long time. Like maybe ever, but it's something that
46:32
is very rare to see. And I do think we have to have this kind of realization and rationalization that that will
46:38
probably not change from here on out. Right? So, we've talked about this a thousand times on here, but like I've
46:43
seen a number of headlines lately like, "Oh, there'll be a two-day work week. Bill Gates says there's going to be a two-day work week or like we have to
46:50
figure out what to give people to do with all of their free time when they don't have any work left." And I'm like, cuz days you're going to be jousting
46:57
other human beings for food and healthcare. That Well, that's what I was going to say. The thing you have to figure out first is how you give those people money
47:03
to live and to buy things. They are not going to just have free time if they can't afford to like I know people in my
47:11
life in my extended life who have worked two jobs, three jobs who are doing this thing to scrape by now. Imagine a world
47:17
where lots more people are anyway. Anyway, this is a great lower start to robot watch. Kevin, we're going to come into it with these diminished ideas
47:24
about where robots are. And now Kevin, we're moving in. We're throwing that story out the window. It
47:29
cannot be context at all for anything we discuss for the rest of robot watch. Not
47:34
at all. Unit's new age 2 Destiny Awakening. A robot that looks more human
 Unitree’s New H2 Destiny Robot
47:40
and acts more human and can perform more humanlike tasks and can do ballet. So ballerinas, you're
47:46
out of work now, baby. Look out. I'm
47:52
Wow, that is some rock and roll ballerina. So what are we seeing there, Kevin? Describe it for the people that are just listening here. You're watching
47:57
a unit. Well, by now I think most of our audience is familiar with these unitary robots. These they they they very they
48:03
look very human. They can do kadate. Uh they can uh break dance. There's some
48:09
like limited parkour, etc. Well, this new version, this H2 version is officially the size and weight of like
48:15
an average human being. So, iterier I should say.
48:20
They do dress it up quite a bit. It's a little bit more spelt. It's more movement to it. It's a little less uh
48:26
kind of robot looking. It definitely has a more of a It's a little bit uh more spelt. It's doing stuff here. So anyway,
48:32
this is like their next iteration and it definitely looks like it's going to be able to do more movement for sure and
48:39
like it's just another one of the step ups in in uh Unit's pipeline. Um there's
48:44
also a couple interesting G1 videos that came out. Um first and foremost there these G1s are the ones that are now
48:50
available in the US. We talked about how you can buy a five pack of them from Walmart. Walmart. Yeah. There's a guy who modded it. Uh
48:56
his name is Jay Lo Logan Olsen and there's a video of him where it's like it's on all fours. He's modded it to be
49:02
on all fours and it's kind of crawling around the ground. But this is the fun thing where you're going to get these in the hands of kind of makers. Somebody
49:09
did point out though that if you put a black wig on it and you had it pull out of a TV that would be an incredible um
49:15
awesome Halloween display to look like the ring was crawling out of your TV. But very cool thing in general. And then
49:20
Kevin, yes, we have a a maybe a sad moment where a Unitry G1 in the middle of a of a dance recital kind of passes
49:28
away. It looks like you want to describe what we're seeing here. He curb stomps a break dancer. All right, let's be clear. There's a B
49:34
boyer a there's a someone mid B boy. Someone be someone is beating a boy on
49:39
the ground, a human doing a move and the Unit G1 just steps on their face and
49:45
kicks their hat off, but then loses their footing in the process, collapses to the ground, but then does not attempt
49:52
to recover. It just gets there. This is the video from Japan, and I like there's like little ghost uh emojis popping off
49:59
of it, and then like they have to continue the dance contest, which is really weird. It's uncle and a and a
50:04
cardigan comes out very disappointed and just starts to slowly try to drag it off of the dance floor.
 AheadFrom Robots
50:10
Uh, next up we have uh robots from a head form. And this these are two robots
50:17
that are I would refer to as uh sexy is the wrong word, but like alluring maybe.
50:23
There's a female and a male and they're definitely going for something very specific. This kind of feels like the
50:29
humanoid form of what uh the Grock AI assistant is trying to be. The female is
50:35
very like ethereal looking and elf-like and the male is has very deep brows. But
50:40
what's interesting about this is we don't see this a lot, but these are like semi-realistic faces being put on these humanoid robots. And when you pull back,
50:47
you see like the exoskeleton and all the stuff there. But now we're starting to get to that stage where we're trying to
50:53
make these a little bit more humanlike. What is your first thought when you see these videos? I mean, what's what's the maximum order
51:01
per household? That's what I want. Oh, wow. How many are they limiting me by? Do they make one that I can just wrap
51:08
around a Roomba? You know, I've got so many. I don't need it to have legs and arms.
51:13
You don't. Wow, that's interesting. You just want a torso. You want a torso? One capability, and that is
51:20
Okay, enough. We're going to talk about one last robot here. Please, please just
51:25
do me a favor and give a nice long bleep. This is the skilled AI robot and this is another version, one of those
 Skild AI Parkour Robot
51:31
robots that's out there showing off what it can do physically. This Kevin is doing parkour. And what I thought was really interesting about this video is
51:37
it's doing parkour but like in quotes, right? It's one of those things. I saw somebody underneath it putting the
51:43
office gif of like Steve Carell's character doing parkour, but like you see it kind of like gently jump up and
51:48
like I kind of find that I might connect with these robots at some point in this world. Like I would love them to have
51:54
like kind of like goofy personalities cuz if I was like having one of these in my house and he was outside practicing
51:59
parkour and I went out there, I'd be like that's pretty fun, man. That's what I'd like to see you be doing. I don't
52:04
care about you cleaning up my house. I just want to see you get better at this little thing in your life, you Oh, that laundry is unfolded. But Oh, dude. Nice
52:11
vault. Okay. Exactly. Exactly. I get where you're going with this. I hope you're recording
52:16
this for your Tik Tok channel. Actually, that would be amazing if if you had an robot in your house and like it suddenly
52:23
got a spark of AGI and instead of like doing the work you wanted it to do, it tried to become an influencer on its
52:28
own. It just wants to learn the bass guitar and stream on Twitch.
52:34
If you have a story like that with a robot in your house, come find us. All right, everybody. Anyway, that is it for this week. We will see you next week
52:40
when more stuff happens in the AI space. Peace out, y'all. Hey, go play and then do chat.