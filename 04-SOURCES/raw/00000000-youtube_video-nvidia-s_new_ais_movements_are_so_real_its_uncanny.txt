https://www.youtube.com/watch?v=FM8yNkWad1w
NVIDIA‚Äôs New AI‚Äôs Movements Are So Real It‚Äôs Uncanny
174,518 views  Oct 20, 2025  #nvidia
‚ù§Ô∏è Check out Lambda here and sign up for their GPU Cloud: https://lambda.ai/papers

Guide:
Rent one of their GPUs with over 16GB of VRAM
Open a terminal
Just get Ollama with this command - https://ollama.com/download/linux
Then run ollama run gpt-oss:120b - https://ollama.com/library/gpt-oss:120b

üìù The paper is available here:
https://add-moo.github.io/

üìù My paper on simulations that look almost like reality is available for free here:
https://rdcu.be/cWPfD 

Or this is the orig. Nature Physics link with clickable citations:
https://www.nature.com/articles/s4156...

üôè We would like to thank our generous Patreon supporters who make Two Minute Papers possible:
Benji Rabhan, B Shang, Christian Ahlin, Gordon Child, John Le, Juan Benet, Kyle Davis, Loyal Alchemist, Lukas Biewald, Michael Tedder, Owen Skarpness, Richard Sundvall, Steef, Sven Pfiffner, Taras Bobrovytsky, Thomas Krcmar, Tybie Fitzhugh, Ueli Gallizzi
If you wish to appear here or pick up other perks, click here:   / twominutepapers  

My research: https://cg.tuwien.ac.at/~zsolnai/
X/Twitter:   / twominutepapers  
Thumbnail design: Fel√≠cia Zsolnai-Feh√©r - http://felicia.hu

#nvidia

---

0:00
There is one thing that I really want. What I  want is a digital character to move exactly like a  
0:07
human. Well, just copy it then, right? Do a little  motion capture with the sensors on the human body,  
0:13
record it running, jumping, reading papers, and  then, copy it within a computer program. Well,  
0:20
unfortunately, that is impossible. Okay, why?  Well, this motion capture data shows you what  
0:27
you need to do, but it does not tell you  how. You see, these virtual characters  
0:33
have muscles and joints, and to copy these  movements, you would need to come up with  
0:38
the forces and torques exerted everywhere at  every time instance to be able to mimic it.
0:45
Oh man, that is hard. Really hard.
0:48
But, this amazing paper from 2018 could  already do that. It was called DeepMimic,  
0:55
and goodness, this‚Ä¶am I seeing correctly? This  really is able to match the reference motions  
1:03
superbly. Is that a word? I don‚Äôt know.  I don‚Äôt care. We talked about this work  
1:08
approximately 500 videos ago. Yes I heard you. I  heard what you just said. And the answer is yes,  
1:15
we‚Äôve been around that long.  Almost a 1,000 paper videos now.
1:20
Okay, DeepMimic. This worked by turning motion  imitation into a video game where every joint,  
1:27
angle, and contact had its own little  score counter. The controller played  
1:33
this game over and over, tweaking  its moves through endless retries,  
1:37
until it learned how to rack up the  maximum score. Which is perfect imitation  
1:43
of the motion capture performance. And  boy, does it look perfect in places.
1:49
But it got better, it worked on a bunch of  different body morphologies as well. And you  
1:55
could even do the favorite pastime of the computer  graphics researcher: throwing boxes at it, for how  
2:04
long? Until it collapses of course. You could even  do some art direction where you would ask it to  
2:11
dance a bit more vigorously. Yes, more life, more  life, more energy! Oh baby. It looks terrible but  
2:19
I still love it. And now, you‚Äôre tired after doing  all this kung fu. Yup, that one checks out too.
2:27
So, is this work perfect? It sure seems so! Well,  
2:31
it is not. Here is a dirty little  secret, but don‚Äôt tell anyone.
2:36
So here‚Äôs the problem: every single one of  those little score counters in DeepMimic  
2:41
had to be designed and tuned by hand. You had  to decide exactly how many points to give for  
2:49
matching a knee angle, how harshly to punish a  wobbly torso, and how much to care about foot  
2:55
placement versus balance. Change the motion,  or even switch to a robot body, and suddenly  
3:02
all your scores are wrong again. You spend days  turning invisible dials just to get something  
3:09
that doesn‚Äôt collapse into a breakdancing  mess. Just to get a flavor of the paper,  
3:15
you have to optimize these: joint rotations,  velocities, root velocity, end effectors that  
3:21
describe where hands and feet should go, and  center of mass. Yum yum yum. Tastes great,  
3:28
but man, that‚Äôs a lot to optimize. And you have  to do it by hand, manually? Oof. This system is  
3:35
held together by duct tape and the tears of  PhD students. There‚Äôs got to be a better way!
3:43
And that‚Äôs where this new paper, ADD, the  Adversarial Differential Discriminator comes  
3:49
in. Instead of hard-coding hundreds of score  counters, it introduces an AI judge that learns  
3:56
automatically what a perfect performance looks  like. The system plays the same imitation game,  
4:02
but now, instead of manually juggling  separate scores for elbows, knees,  
4:08
and toes, the judge gives a single  verdict on how close the motion feels  
4:12
to the real human one. As training  goes on, this judge gets smarter,  
4:18
focusing attention on the parts that still look  off and pushing the character to refine them.
4:24
So, previous DeepMimic lots of hand-tuning,  new ADD, single automatic AI judge.
4:31
Okay, good. But that does help? Hmm‚Ä¶ they say  this is better than DeepMimic? Well, I‚Äôd like  
4:39
to see that! And, well well well. I am not seeing  that. With pink, we got DeepMimic, the previous  
4:48
method and with blue, ADD, the new technique. Both  are nailing the problem, but it‚Äôs not better. So,  
4:56
have we been deceived by the marketing department  again? I swear I‚Äôm not buying more car insurance.
5:03
Okay, let‚Äôs calm down and see if this next test  is better. Here is the reference movement. A  
5:12
little parkour! Loving it. So, the previous AMP  method does exactly what we all feel like at the  
5:19
moment. Disqualified. Get out of here. And now,  DeepMimic is about to nail it, as always. Wait a  
5:27
second‚Ä¶that‚Äôs not it, sir. You need a little  more carbohydrates before working out! Wow,  
5:34
it failed. And if you think this is a failure  case, now check this out. Now off with you,  
5:41
eat a nutrition bar while we watch the reference  motion do the jump. Okay, got it? Got it. So now,  
5:48
start running, and‚Ä¶oof! Sir. Sir! Are you  okay? Goodness, failed again, even worse.
5:57
Now hold on to your papers Fellow  Scholars and let‚Äôs see if the new  
6:01
technique with the AI judge is any  better, and‚Ä¶oh my goodness. They did  
6:08
it. What about the climbing? Let‚Äôs  see‚Ä¶absolutely nailed that too. Wow!
6:15
The motions are really fluid and believable,  
6:18
and physically correct. It controls all  the joints correctly. That is really tough.
6:25
And yes, I know what you want. You also want to  see the earlier low energy AMP do the jump too.  
6:33
Your wish is now granted. Ain‚Äôt no jumping  here brother. They don‚Äôt pay me enough. And  
6:40
believe it or not, it‚Äôs going to get even  better. Here‚Äôs how. Dear Fellow Scholars,  
6:45
this is Two Minute Papers with Dr.  K√°roly Zsolnai-Feh√©r. Dr. Carroll.
6:49
Oh yeah! We still retain DeepMimic‚Äôs wonderful  
6:53
property of working on different body  morphologies. I am starting to flip out.
7:00
So, the crowd favorite, the walking sausage man,  not a problem. ADD does as well as hand-tuned  
7:07
techniques, but this one works automatically. It  can control a robot too, it can fall and get up.
7:14
It can do a variety of different behaviors,  karate, jumping on one leg, walking an invisible  
7:22
dog. And at this point, I am so happy, this  is basically me. So good! Mother of Papers.
7:29
Here we also have an ablation study,  which takes out each individual puzzle  
7:34
piece that they invented, and they show  how the system breaks when you remove  
7:39
these individual puzzle pieces. In short,  they show one by one that everything they  
7:45
invented here is indeed useful. Not just  a soup of stuff that works, but they show  
7:51
that each piece is necessary. I still can‚Äôt  believe that they‚Äôve actually done it. Wow!
7:58
And now, before I tell you about  the limitations of this new method,  
8:03
look at this. Oh my goodness. Is this  for real? This research paper is an  
8:09
absolutely marvelous piece of work, and  nearly nobody is talking about it. Wait a  
8:15
minute. Not nearly nobody. Actually nobody  is talking about it. Let me try to help.
8:21
So this is why I feel that talking about  these research works is so important,  
8:26
it‚Äôs a bit like saving endangered species. If we  don‚Äôt do it here, nobody does it. So please, save  
8:33
a paper today, like this video, subscribe, hit  the bell icon, and leave a really kind comment.
8:40
Okay, so it‚Äôs not flawless, of course.  Sometimes the AI judge gets confused on  
8:46
the flashier tricks - instead of pulling off a  smooth backflip, the poor thing just lies down  
8:52
and gives up halfway. It‚Äôs a bit like a dance  judge who judges the waltz well but freezes  
8:59
when the performer suddenly tries parkour  - you know, still learning what ‚Äúgraceful‚Äù  
9:04
means when gravity is involved. Reminds  me of an earlier paper where an AI player  
9:09
collapsed, get this, in a way that reprogrammed  the mind of the other AI to lose. Insanity.
9:17
But just think about it. AI systems  now don‚Äôt just imitate motion,  
9:22
they actually understand how we move around.  And just two more papers down the line,  
9:27
and I am sure these digital creatures  will learn to move with the same grace  
9:32
and intent as living ones. That is the First  Law of Papers. Do not look at where we are,  
9:39
look at where we will be two more papers  down the line. What a time to be alive!
9:44
So, digital ninjas, motion shapers,  
9:47
smoother than your graphics shaders  - subscribe to Two Minute Papers!