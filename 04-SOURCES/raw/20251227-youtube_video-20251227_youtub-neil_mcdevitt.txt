https://www.youtube.com/watch?v=01G6s9wP7VM
2026 is The Year of The AI Augmented Generalist
608 views
Dec 27, 2025
AI Augmented Generalists will Own The Future

https://www.skool.com/community-found...

Socials:
Follow me on X: https://x.com/NeilMcDevitt_

Subscribe!

---

0:00
What's up guys? Neil here. Welcome back
0:02
to the channel. In this video, I want to
0:04
talk about the concept of being an AI
0:07
augmented generalist because I think
0:10
that's ultimately where we're going
0:12
here. There's a lot of people really
0:14
focused on trying to specialize even
0:17
further when AI is coming and it's kind
0:20
of like disrupting a lot of work. One of
0:22
the notable tweets that came out today
0:24
is from Andre Karpathy talking about
0:25
this and his answer was, "Well, we just
0:28
need to roll up our sleeves to not fall
0:30
behind. We need to specialize harder and
0:32
become even better at software
0:34
engineering." And I think that's the
0:36
wrong take. I'm going to explain why.
0:38
But first, let's let's actually look at
0:40
what Andre Karpathy said here.
0:43
He said, "I've never felt this much
0:45
behind as a programmer. The profession
0:48
is being dramatically refactored as the
0:50
bits contributed by the programmer are
0:53
increasingly sparse and between meaning
0:56
AI is outputting more than people these
0:59
days. Um, and then he continues to talk
1:02
about different things that he needs to
1:03
learn and all these different uh like
1:06
technical jargon things like uh uh the
1:09
the memory modes, permission tools,
1:11
plugins, skills, hooks, MCPS,
1:13
LSP/comands, workflows, IDE
1:15
integrations, all this different stuff.
1:17
And then the thing that was most notable
1:20
to me is
1:22
clearly some powerful alien tool was
1:26
handed around except it comes to it
1:29
comes with no manual and everyone has to
1:32
figure out how to hold it and operate it
1:35
while the resulting magnituded
1:37
earthquake is rocking the profession.
1:41
Roll up your sleeves to not fall behind.
1:46
Um
1:48
yeah now some people are going to hear
1:51
this and say well he's incentivized to
1:53
say that uh this is just hype. Let me
1:56
remind you Andre Karpathy was the lead
1:59
engineer at Tesla. He would worked on
2:01
full self-driving. He left there to work
2:03
at OpenAI. He was a lead engineer there.
2:07
Now he left OpenAI to start his own
2:10
thing and his own thing is Eureka Labs
2:13
AI which is basically like a a new kind
2:15
of school that is AI native right
2:19
so he actually has the opposite of
2:22
financial incentive because if he was
2:25
still at open AI he would have financial
2:28
incentive to say these things but
2:29
because he is no longer at OpenAI and he
2:32
has probably dramatic amounts of fear of
2:35
missing out lots of FOMO Mo because AI
2:37
is accelerating and he's not a part of
2:39
it. Actually quite the opposite of
2:42
incentives for it to pan out really
2:44
well. He would have made billions of
2:46
dollars at OpenAI, right? So
2:51
quite the inverse.
2:53
He has financial incentives for it to do
2:55
really bad. And if you went and watched
2:57
the Dark Cash interview with Andre
2:59
Karpathy, he basically said we're it'll
3:02
take about a decade to get where we are
3:04
today.
3:06
Now the reason I the reason I can
3:08
confidently say that is because if you
3:09
look here if you watch the Carpathy
3:12
interview he basically said I don't
3:13
think these things are going to get that
3:14
good at coding and now this guy saying
3:16
up 4.5 is pretty good. Andre says it's
3:19
very good. People who aren't keeping up
3:23
even just over the last 30 days already
3:26
have a deprecated worldview on this
3:28
topic. He was one of those people. He
3:30
updated his priors. Good for Andre. Be
3:33
like Andre. He's keeping updated with
3:35
the technology and he is admitting when
3:37
he is wrong and he is adapting his model
3:39
and improving it as the trajectory of
3:41
the technology improves. Be like Andre.
3:44
This is the way you do it right here.
3:46
Now, the one thing I disagree with is
3:48
rolling up your sleeves to not fall
3:49
behind. I think this is true. You want
3:51
to do that, but it depends on how you're
3:54
doing it. Right now, the ladder is
3:57
leaned against the wrong wall. Everybody
3:59
is trying to climb up the ladder and get
4:01
to the top, but it's fundamentally the
4:03
wrong wall. The the wrong wall. There's
4:05
another wall that also has the same
4:07
exact ladder. It's kind of like
4:09
duplicated over here, but the wall is
4:12
going towards a different paradigm than
4:14
what most people are used to. And it's
4:16
scary to switch paradigms whenever the
4:18
only one that you can think of is this
4:20
one that's been here this whole time,
4:22
even though it's probably clearly going
4:24
to get disrupted.
4:25
Right now, here's another post. This is
4:28
from Dra uh Jack Clark, co-founder of
4:30
Anthropic. He said, "By the summer, I
4:34
expect that many people who work with
4:36
Frontier AI systems will feel as though
4:39
they lived in a parallel world to the
4:41
people who don't. And I expect this will
4:43
be more than just a feeling."
4:46
So, uh, if you're not aware, he
4:47
basically said, uh, in 2026, it's
4:50
basically going to feel like AI, the
4:52
people who use these systems to do
4:55
meaningful work are basically going to
4:57
be like a completely new like worker is
5:00
effectively what he's saying. Uh, and it
5:02
won't just be a feeling, it'll be
5:03
actually true. And we're already
5:05
starting to see the signs of that. the
5:06
people who are good at using clawed code
5:08
in 4.5 opus are astonishingly different
5:12
and better at working than people who
5:14
aren't. And that's just objectively
5:16
true. And the interesting thing is
5:19
Claude code is better than just it's
5:22
it's really good at uh code, but it's
5:25
also really good at so many different
5:26
things, too. Um, and most people only
5:28
use it for code. It's actually good at a
5:30
lot of things. It's kind of like an an
5:33
agent for knowledge work in general, not
5:35
just for coding. And a lot and not
5:37
everybody, but some people are starting
5:38
to notice that. So here here's a comment
5:41
on Andre Karpath's tweet. We kind of
5:43
just covered Andre Karpath's tweet. He
5:44
said, "We get we basically have this
5:46
powerful alien tool handed handed
5:48
around, but there's no manual to
5:49
actually use it." And then uh Boris,
5:52
which is somebody who works on Claude
5:54
code at Anthropic, he says, "I feel this
5:57
way most weeks to be honest. Sometimes I
6:00
start approaching a problem manually and
6:02
I have to remind myself Claude can
6:03
probably do this." And then he comes
6:05
down here and he says, "In a way, the
6:07
newer co-workers and even the new grads
6:10
that uh don't make the assumptions that
6:12
I make about what these models can and
6:14
can't do are able to use the model most
6:16
effectively.
6:19
The last month uh last month was my
6:22
first month as an engineer that I didn't
6:24
open an IDE at all. Opus 4.5 wrote
6:28
around 200 PRs. every single line.
6:32
Software engineering is radically
6:33
changing and the hardest part even for
6:36
early adopters and practitioners like us
6:39
is to continue to readjust our
6:40
expectations and it's still just a
6:43
beginning
6:45
absolutely astonishing right now. The
6:48
interesting thing about this is I
6:49
actually think the people who are new to
6:51
the field and uh and uh don't have to
6:54
keep readjusting their priors and trying
6:56
to like release their grip which they
6:58
have like most of the engineers have a
7:00
hard time doing that. They have a hard
7:01
time loosening their grip on the
7:04
projects that they're working on. The
7:06
people that are newer to the field and
7:08
they're just kind of like working at the
7:10
limits of these tools because these
7:11
tools are so much beyond them that it's
7:13
like holy holy cow. The fact that I'm
7:15
doing any of this is crazy. the tools
7:17
are going to keep going. They're not
7:18
going to stop, right? I think they will
7:20
eventually obviously, but they have room
7:22
to grow from here. And I think that's
7:24
obvious. And even Andre Carpathy says,
7:26
"This is obvious at this point." Um he
7:28
says, Andre continues from his response.
7:30
He says, "I have similar experiences.
7:32
You point the thing around, it shoots
7:33
pellets or sometimes even misfires. And
7:36
then once you get a good grip on it, um
7:39
it's basically a powerful beam of laser