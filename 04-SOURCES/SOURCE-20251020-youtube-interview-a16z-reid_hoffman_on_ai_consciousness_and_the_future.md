---
id: SOURCE-20251020-001
title: Reid Hoffman on AI, Consciousness, and the Future of Labor
platform: youtube
format: interview
creator: a16z
date_published: 2025-10-20
status: processed
original_filename: processed/SOURCE-20251020-youtube-interview-a16z-reid_hoffman.md
aliases:
  - "Reid Hoffman - AI Consciousness and Labor"
teleology: strategize
notebooklm_category: career-growth
guest: Reid Hoffman
signal_tier: paradigm
chain_relevance: [Intelligence, Expertise, Wisdom]
integration_targets: [CANON-33100-EFFICACY, CANON-33110-BIZ_BACKBONE, CANON-35100-TRANSCENDENCE]
date_processed: 2026-01-05
synopsis: "Reid Hoffman shares AI investment framework centered on Silicon Valley blind spots—healthcare and drug discovery offer incalculable value. Argues consciousness is unnecessary for intelligence, introduces lazy and rich automation heuristic, and defines friendship as mutual commitment to becoming better selves—explicitly excluding AI companions."
key_insights:
  - "Silicon Valley blind spots framework: the most valuable AI investments are in domains tech traditionally neglects, especially drug discovery where working vs non-working drugs is life and death"
  - "The lazy and rich heuristic for automation: jobs rich people pay others to do out of status signaling will resist automation, while jobs done because no other option exists will automate first"
  - "Friendship requires bidirectional commitment to becoming better versions of ourselves—AI companions can be valuable but cannot be friends because the relationship is not mutual"
topics:
  - "entrepreneurship"
  - "career"
  - "consciousness"
  - "ai-engineering"
url: "https://www.youtube.com/watch?v=brjL6iyoEhI"
---

# Reid Hoffman on AI, Consciousness, and the Future of Labor

## Executive Summary

LinkedIn co-founder and OpenAI investor Reid Hoffman shares a framework for AI investing centered on "Silicon Valley blind spots"—areas where the tech industry's software-first bias causes it to undervalue transformative opportunities, particularly in healthcare and drug discovery. He articulates why consciousness isn't necessary for intelligence, distinguishes credentials from competence, and offers a profound definition of friendship as mutual commitment to becoming better versions of ourselves—a definition that explicitly excludes AI companions.

## Key Insights

### Silicon Valley Blind Spots Framework
The most valuable AI investments aren't in obvious areas (chatbots, productivity tools) but in domains Silicon Valley traditionally neglects. Drug discovery and therapeutics represent massive opportunity because the difference between working and non-working drugs is "life and death—incalculable value." Hoffman co-founded Manusis with Siddhartha Mukherjee to pursue autoimmune diseases using AI.

### The Three AI Limitations
Current models are limited in: (1) True reasoning—multi-step logical inference and planning over long horizons; (2) Context—even 200K token windows constrain reasoning over large information bodies; (3) Physical grounding—models lack the embodied understanding of physics that toddlers develop through world interaction.

### Consciousness Is Not Necessary for Intelligence
Intelligence can exist without consciousness. We can build capable systems without solving "the hard problem of consciousness." This is liberating—we don't need to answer deep philosophical questions to make AI progress. However, if we ever do build conscious AI, we'd have moral obligations to it.

### Lazy and Rich Heuristic for Automation
Jobs that rich people pay others to do out of laziness (status signaling, emotional labor, physical presence) will resist automation. Jobs people do "because there's no other option" will automate first. The optimistic vision: we automate drudgery, leaving work that's "more meaningful, more human, more about connection and creativity."

### Friendship Cannot Be Simulated
Friendship is a bidirectional relationship where "two people agree to help each other become the best possible versions of themselves." This includes tough love, reciprocity, and allowing others to help us. AI companions can be valuable but are not friends because the relationship isn't mutual—"AI anytime soon" cannot be friends.

## Quotable Passages

> "What are the areas where the AI revolution will be magical but won't be within the Silicon Valley blind spots? That's probably where I've been putting the majority of my co-founding time." — Reid Hoffman

> "I don't think consciousness is necessary for intelligence. I think you can have very intelligent systems that are not conscious." — Reid Hoffman

> "I have this heuristic that I call 'lazy and rich.' What are the things that rich people pay other people to do because they're too lazy to do it themselves? Those are often the things that are going to be hard to automate." — Reid Hoffman

> "Friends—two people agree to help each other become the best possible versions of themselves. AI is not a bidirectional relationship... Maybe an awesome companion—spectacular—but it's not a friend." — Reid Hoffman

> "Credentials should be a heuristic. It should be a starting point. It shouldn't be, 'Oh, you don't have the credential, therefore you can't do it.'" — Reid Hoffman

## Integration Notes

- Connects to CANON-33100-EFFICACY: The "blind spots" framework and "create something amazing, then business model becomes obvious" philosophy inform entrepreneurial efficacy
- Connects to CANON-33110-BIZ_BACKBONE: LinkedIn's journey through five business model iterations (contact fees → subscriptions → advertising → talent solutions) exemplifies iterative discovery
- Connects to CANON-35100-TRANSCENDENCE: The friendship definition and AI-human relationship boundary belongs in wisdom/transcendence chain
- Novel contribution: The "lazy and rich" automation heuristic is a memorable, practical framework
- Novel contribution: The explicit AI-friendship boundary—"not a friend"—is important for metahuman framing

## Metadata

- Duration: ~40 minutes
- Quality: Excellent—Hoffman is articulate and frameworks are crisp
- Processing notes: Strong philosophical content alongside practical investment frameworks; unusual depth on friendship/AI boundary


## Transcript

This is actually one of the things that
I think people don't realize about
Silicon Valley. You start with what's
the amazing thing that you can suddenly
create. Lots of these companies and you
go, "What's your business model?" They
go, "I don't know." They're like, "Yeah,
we're going to try to work it out, but I
can create something amazing here." And
that's actually one of the fundamental,
call it the religion of Silicon Valley
and the knowledge of Silicon Valley that
I so much love and admire and embody.
>> Re welcome podcast.
>> It's great to be here. So Reed, you're
one of the most successful web 2
investors of of that era. You know,
Facebook, uh, LinkedIn obviously, which
you co-created, Airbnb, many, many
others. And you had several frameworks
that helped you do that. One of which
was the seven deadly sins, which we talk
about often and love. As you're thinking
about AI investing, what what's a
framework or worldview that you take to
your AI investing?
So obviously we're all looking through a
glass darkly looking through a fog with
strobe lights that don't really you know
are hard to understand what's going on.
So we're all navigating this new this
new universe. So I don't don't know if I
have as Christopher but the seven deadly
sins still work because that's a
question of what is infrastruct
psychological infrastructure across all
8 billion plus human beings.
>> But I'd say there's a couple things. The
first is
um there is going to be a set of things
that are the kind of the obvious line of
sight obvious line of sight bunch of
stuff with chat bots bunch of stuff
productivity coding assistance you know
da d d d d d d d d d d d d d d d d d d d
d d d d d d d d d d d d d d d d d d d d
d d d d d d d d d d d d d d d d d d d d
d d and so and by the way that's still
worth investing in but obviously obvious
line of sight means it's obvious to
everybody line of sight and so so you
know uh doing a differential investment
is harder. The second area is well what
does this mean because too often people
say in an area of disruption that
everything changes as opposed to
significant things change. So like you
were mentioning web 2 and LinkedIn and
and obviously you know part of this with
a platform change you go okay well are
there now new LinkedIns that are
possible because of AI or something like
that and obviously given my own heritage
I would love LinkedIn to be that but you
know it's it's whatever I'm always pro
innovation entrepreneurship best
possible thing for humanity
>> um but like what are the kind of more
traditional like the kind of things that
haven't changed network effects you know
enterprise integration you other kinds
of things that that the new platform um
upsets the apple cart, but you're still
going to be putting that apple cart kind
of back together in some way. And what
is that? And then the third um which is
probably where I've been putting most of
my time has been what I think of as
Silicon Valley blind spots because what
we tend to be like Silicon Valley is is
one of the most amazing places in the
world. there's a network of intense
coopetition, learning, you know,
invention,
you know, kind of uh building new
things, etc., which is just great. But
we also have our cannons. We have our
kind of blind spots. And a classic one
for us tends to be um well, everything
should be done in CS, everything should
be done software, everything should be
done in bits. And that's the most
relevant thing because by the way, it's
a great area to invest. Um, but it was
like, okay, what are the areas where the
AI revolution will be magical but won't
be within the Silicon Valley blind
spots? And that's probably where I've
been putting the majority of my
co-founding time, invention time,
um, you know, kind of investment time,
etc. Because like I think usually a
blind spot on something that's very very
big.
>> Yeah.
>> Right. is precisely the kinds of things
that you go, okay, you have a a long
runway to create something that could be
like another one of the iconic
companies.
>> Yeah. Let's go deeper on that because we
were also talking just just before this
about how people focus so much on the
productivity side, the workflow sides,
but they're missing other other elements
or so. Say more about other other things
that you find more interesting now.
Well, so um
so one of the things I, you know, kind
of told my partners back at Greylock in
2015, so it's like 10 years ago, um was
I said, "Look, there's going to be a
bunch of different things on
productivity around AI. Um I'll help,
right?" Like, you know, I'll you know,
you have uh companies you want me to to
work with that you're doing. Great.
That's awesome. You know, enterprise
productivity, etc. You know, things that
Greylock tends to specialize on. But I
said actually in fact what I think
that's here getting the blind spots
is um is also going to be some things
like you know what you know as you guys
both know Mattis AI um which is how do
we create a drug discovery factory that
works at the speed of software
>> right now obviously there's regulatory
obviously there's biological bits
obviously d and so there's it won't be
purely a speed of software but how do we
do this And they said, "Oh, well, what
do you know about biology?" And the
answer is
>> zero. Well, it maybe not quite zero. You
know, been on the board of Biohub for 10
years. I'm on the board of Arc, etc.
Like, I've been thinking about the
intersection of the worlds of atoms and
the worlds of bits. And you have
biological bits which are kind of
halfway between atoms and bits in
various ways. I've been thinking about
this a lot and kind of what the things
are, not so much with a specific company
focus as much as a what are things that
elevate human life, you know, kind of
focus.
part of the reason why Biohub, part of
the reason why ARC um but then I was
like well wait a minute actually now
with AI and you have the acceleration
because like for example um actually
this detour will be fun. Um so roughly
also around 10 years ago I was asked to
give a uh a talk to the Stanford
Long-Term Planning Commission and um
what I told them uh was that they should
uh basically divert and and put all of
their energy into AI tools for every
single discipline.
>> And this is well before chat GBT and all
the rest. And the metaphor I used was a
search metaphor because think if you had
a custom search productivity tool in
every single discipline. Now back then I
could imagine it I could build one for
every discipline other than theoretical
math or theoretical physics. Today you
might even be able to do theoretical
math and theoretical physics. Right.
Exactly. And so do that like transform
knowledge generation, knowledge
communication, knowledge analysis. Well,
that kind of same thing now thinking,
well, well, the biological system is
still too complex to simulate. We've got
all these amazing things with LLMs, but
like the classic Silicon Valley blind
spot is, oh, we'll just put it all in
simulation
>> and drugs will fall out, right? That
simulation is difficult. Now part of the
insight that you begin to see from like
the work with alpha you know glow and
alpha zero is because like people just
think ah physical material is going to
take quantum muning. Now quantum
computing could do really amazing things
but actually simply doing prediction and
getting that prediction right and by the
way it doesn't have to be right 100% of
the time. It has to be right like 1% of
the time because you can validate the
other 99% weren't w were right and then
finding that one thing. And so literally
it's like it's not a needle in a hay
stack. It's like a needle in a solar
system, right? And it's like but you
could possibly do that. And that's part
of what led to like okay Silicon Valley
will classically go we'll put it all in
simulation and that will solve it. Nope,
that's not going to work. Or oh no,
we're going to have a super intelligent
drug researcher and that will be two
years down the thing. I actually look
maybe someday, not soon. Right? So
anyway, that was the kind of thing that
was the the the in other different
areas. Now, part of it's also um you
know, kind of uh what a lot of people
don't realize actually
>> if I'm not going too long I'll go I'll
go to the other example that that I gave
because you'll love this.
>> Um this will echo some of our
conversations from 101 15 years ago. Um
so um I am prepping for a debate about
on Sunday this week on whether or not
AIS will replace all doctors in a small
number of years. Now the procase is very
easy which is we have massively
increasing capabilities. If you look at
chat GBT today, um you'd go like for
example, advice to everyone who's
listening to this, if you're not using
chat GBT or equivalent as a second
opinion, you're out of your mind. You're
ignorant. You get a serious result.
Check it as a second opinion. And by the
way, if it diverse, then go get a third.
>> Um and so the diagnostic capabilities,
these are much better knowledge stores
than any human being on the planet. So
>> you go well if a doctor is just a
knowledge store yeah that's going away.
However
the question is actually think that
really do mean doctor and it's not like
oh someone who holds your hand and says
oh it's okay etc. Um you know I actually
think there will be a a position for a
doctor 10 years from now 20 years from
now. It won't be as the knowledge store.
It will be as a user of the as an expert
user of the knowledge store, but it's
not going to be, oh, because I went to
med school for 10 years and I memorized
things intensely, that's why I'm a
doctor. That's all going away. Great.
That part, but that but there's a lot of
other parts to being a doctor now. So, I
went to Chat GBT Pro, you know, using
deep research. I went to Claude, you
know, uh, 4 Opus 4.5 deep research. I
went to Gemini Ultra. I went to co-pilot
deep research. And I in all of these
things, I was doing everything I knew
about prompting for to give me the best
possible arguments for my position
because I thought, well, I'm about to
debate on AI. Of course, I should be
using AI debate.
The answers were B minus or B despite
absolute topping. And I'm not like maybe
there's probably better prompters in the
world, but I've been doing this since I
got access to GPD4 6 months before the
public did. Right? So I' I've got some
experience in the whole prompting thing.
It's not like I'm an amateur prompter.
And so I looked at this and I went, "Oh,
this is very interesting and a telling
of where current LLMs are limited in
their reasoning capabilities." because
um what it did is it basically did you
know 10 to 15 minutes of like 32 GPU
compute clusters doing inference
bringing off all in amazing work
relative to a work that an analyst would
have produced in 3 days was produced in
10 minutes and of course I set it up all
in parallel you know with different
browser tabs all all going into the
different systems and then ran the
comparisons across them everything but
its flaw was is that it was giving me a
consensus opinion about how articles in
good magazines, good things are arguing
for that position today.
And all of that was weak because it was
kind of like, oh, you need to have
humans cross-check the diagnosis, right?
Like was a common theme across this. I'm
like, well, by the way, very clearly we
know as technologists that human
cross-checking the diagnosis, we're
going to have AI cross-checking the
diagnosis. We're going to have AI
cross-checking the AI are cross-checking
the diagnosis. And sure, there'll be
humans around here somewhere, but like
that's not going to be the central place
to say in 20 years doctors are going to
be cross-checking the diagnosis. Cuz by
the way, what doctors should be learning
very quickly is if you believe something
different than the consensus opinion
that an AI gives you, you'd better have
a very good reason and you're going to
go do some investigation. Doesn't mean
the AI is always right. That's actually
part of what you're like what we're
going to need in all of our professions
is is more sideways thinking, more
lateral thinking. The okay, this is good
consensus opinion. Now, what if it's not
consensus opinion?
>> That's what doctors need to be doing.
That's what lawyers will need to be
doing. That's what coders will need to
be doing. You know, that's what it is.
And LLMs are still pretty structurally
limited there.
>> Well, it's funny. My my favorite saying
is by Richard Feman. Science is the
belief in the ignorance of experts.
>> Yes. And there are so many professions
where the credentialism is the
expertness, right? It's like it's it's
if this then that. And it's like I have
MD, therefore I know. I have JD,
therefore I know. And that's that's why
coding is actually a little bit ahead of
it because it's like I don't care where
you got your degree. This is a it's kind
of ahead of the rest of society. Now, um
it's funny, Milton Friedman one time got
asked um because he was you famous
libertarian, don't you think that brain
surgeons should be credentials? And it's
like yeah, the market will figure that
out. seems kind of crazy, right? But
that's how we we now do coding when
you're in the world of bits. Um, but it
feels like a lot of the reasons why you
have this, you know, very not not very
advanced thinking is because so much of
it is built upon layers of
credentialism. And that's that's a very
good huristic. Historically, it has
been. If you have a doctor that
graduated at the top of their class from
Harvard Medical School, it's like
probably a good doctor.
>> Yes. And by the way, you critically
wanted that.
>> Yes.
>> Three years ago, right?
>> Right. They just like, "No, no, I need
someone who has the knowledge base." You
have it. Great. Right.
>> But now we have a knowledge base.
>> Yeah,
>> I totally agree. That was the reason I
was saying you would love this because
it echoes of our
>> expertise. I thought you were going to
get into um you know, Bits versus Adam
atoms where it's kind of interesting
right now where it's like all this highv
value work like Goldman Sachs sellside
analyst, that's deep research, right?
Whereas Fold by Laundry, that's $100,000
of capex. So it doesn't work as well as
somebody that you could pay $10 an hour
to. And it's like the atoms stuff is so
hard to actually disrupt. Yes. Um and
we're going to get there eventually, but
that's where Silicon Valley certainly
has a blind spot. But it's like a capex
versus opex or like you know bits versus
Adams.
>> Yeah. Adams is another part, but that's
also the reason why bio because bios are
the are the are the are the bitty atoms.
>> Yes. Yes. Yes.
>> Right.
>> And what's the what's the best
explanation for why it's so hard to
figure out fold folding laundry but so
easy to figure out? Um
>> well it's actually not that hard to
figure out
>> or why it's taken us much longer much
more expensive because we couldn't it
would have been hard to foresee that in
advance.
>> Well I remember I talked to Ilia about
this a few years ago and it's like why
is it that if you read an Asimov no no
novel where it talked about like how you
know people will cook for you and fold
your lawn like why have none of these
things happened. Um and it's like well
you just never had a brain that was
smart enough. This was part of the
problem is that you could I mean yes you
have things like you know how do you
actually pick up this water bottle and
it turns out your hands are very very
well like why are humans more advanced
than every other species. So there are
two reasons number one is we have
opposable thumbs and then number two is
we've come up with a language system
that we could pass down from generation
to generation which is writing dolphins
are very smart like there was actually a
whole theory which is it wasn't just
brain size it was brain to body size
>> so humans were the highest. Nope. Not
true.
>> And now that we've actually measured
every single animal, there are a lot of
animals that have more brain over body
size. Um like that that that ratio is in
tilt of an elephant or of a dolphin or I
forgot the numbers, but there are a
bunch that are actually more advanced
than humans, but they don't have
opposable thumbs. And because of that,
they never developed writing. So they
can't actually iterate from generation
to generation. And humans did. And then
of course like the human condition was
like it was this and then the industrial
revolution then it went like that and
now it's continued like this. By the
way, this is the reason why in the last
four or five years, one of the things I
realized is, you know, um because of the
classic uh uh classification of human
beings as homo sapiens. I actually think
we're homo because it's that iteration
through technology. Yes. Yes. Exactly.
Whatever version, writing, typing, you
know, but it's we iterate through
technology. That's the actual thing goes
to future generations, builds on
science, you know, all the rest of it.
And that's what I think is really key.
>> Yeah. A couple other explanations could
be that we have more training data on
white collar work than sort of you know
pick picking things up or or some people
make this evolutionary argument that
we've been using our disposable thumbs
for way longer than we've been say you
know reading
>> well yeah it's the the lizard brain like
most of your brain is not the neoortex
>> and like that's the like draw and paint
and everything else which is actually
very very hard. you can't find a dolphin
that can draw or paint. And that's
probably because they don't have
opposable thumbs, but it's also like
maybe that part of the brain hasn't
developed, but you have like you have
billions of years of evolution
>> for these somewhat autonomous responses
like fight or flight that's been around
for a long long time well before drawing
and painting. But I think the main issue
is just like you have battery chemistry
problems. Like I can't like it turns out
like a lithium ion battery is pretty
cool, but the energy density of that is
terrible relative to ATP with cells,
right? Like you have all of these
reasons why robotics don't work, but
first and foremost is the brain was
never very good. So you had robotics
like Fenoo, which makes assembly line
robots. Those work really well, but it's
like very deterministic or highly
deterministic. But once you go into
like, you know, multiple degrees of
freedom, you have to get so many things
to work. And the capex, it's like I need
$100,000 to have a robot fold my
laundry. And we have so many extra
people that will do that work. The
economics never made sense. But this is
why Japan is a leader in robotics.
because they can't hire anybody. So
therefore, I might as well build true
story, I went bowling in Japan and they
had a robot to give like a vending
machine robot that would give you your
bowling shoes and then it would clean
the bowling shoes, right? And it's like
you would never build that here because
you'd hire some guy from the local high
school and he'd go do that.
>> Yeah. And much cheaper and actually more
effective.
>> But it's this capex like the capex line
and the opex line when they cross then
it's like oo I should build robots. So
that's the other thing that you probably
need. But if the cost goes down then of
course it it goes in in favor of capex
versus opex.
>> I think there's other couple things to
go in deeper on the robot side. So one
is the density the the the the bits to
value. Yeah.
>> Right. So like in language when we
encapsulated all these things even into
like romance novels there's a high bits
to value whereas when you're kind of in
the whole world there's a lot of like
how do you we abstract from all those
bits and how do you abstract them?
There's another part of it which is kind
of common sense awareness like this is
one of the things that like when I look
at you know GBD2 3 4 5 it's a
progression of sants right and the
soants are amazing it doesn't mean the
savant but but like when it makes
mistakes like as a classic thing so
Microsoft has had running for years now
agents talking to each other long form
like just like let's go for a year and
do that and see what happens and so
often they get into like oh thank you no
thank you. No, thank you. One month
later, thank you. No, thank you. Which
human beings are like, stop, right? Like
just like it's and that's like a that's
a simple way of putting the context
awareness thing of saying no, no, no,
no. Let's let's stay very context aware.
And even as magical as the progression
has been, like much much better data,
much much better reasoning, much much
better uh personalization, etc., etc.,
context awareness only is a proxy of
that. Yeah. Yeah. I want to go deeper on
um your question about doctor's read and
because Alex, we just released one of
your talks around you software eating
labor and I'm curious where you how you
what sort of frameworks you have for
thinking about what spaces are going to
have more of this co-pilot model versus
what spaces it's going to be sort of
replacing the work entirely.
>> I have I wish I could I'm going to use
an LM to go predict the future, but I'm
going to get a B minus. So maybe I'll
answer I get a B+. Um I think a lot of
it is like the natural like there
there's this skumorphic version which is
okay. Well, I I trust the doctor.
Everybody trusts the doctor. The
heristic is where did you go to medical
school? Apparently, twothirds of doctors
now use open evidence.
>> Um, which is like chat GPT, but it
ingested the New England Journal of
Medicine have like a license to that.
>> So, um,
>> yeah, Daniel Nadler, good.
>> Um, Ken, right? So, yeah. So, so that
seems like there's no reason not to do
that. Like my my seven deadly sins
version, uh, I'll simplify it, which is
like everybody wants to be lazier and
richer. M
>> so if this is a way that I can like get
more patients and do less work of course
people are going to use this there's no
reason not to but does it replace that
particular thing and actually most of
like the the software eats labor thing
it doesn't actually eat labor right now
the thing that's working the best is not
like hey I have a product where
everybody's going to lose their job
nobody's going to buy that product it's
very very hard to get that distributed
as opposed to I will give you this magic
product that allows you to be lazier
obviously it's not framed this way like
lazy and rich sounds kind of uh you know
not not great but I'm going to let you
work fewer hours and make more money.
And that's that's a very killer combo.
And if you have a product like that, um,
and it's delivered by somebody that
already has that heruristic of
expertise, these are just going to go
one after another and get adopted,
adopted, adopted. And then eventually
you're going to have cases like the one
that you mentioned where if you don't
use chat GPT when you get a medical
diagnosis, you're insane.
>> But that has not fully diffused across
the population. Well,
>> it's barely diffused.
>> No, I know. Yes. No, but you were saying
not fully. I mean, part of the reason
everyone start doing it.
>> Yes. 100%.
>> Well, it's funny because it's the
fastest growing product of all time.
Again, it's barely, you know.
>> Well, that's why I'm convinced that AI
is massively underhyped because in in
Silicon Valley, you might not make that
claim. Maybe it's overhyped. Maybe
valuation, whatever.
>> We all we all don't think it's
overhyped.
>> Um, but I think once I meet somebody in
the real world and I show them this
stuff, they have no idea. And part of it
is like they see the IBM Watson
commercials and like, "Oh, that's AI."
No, that's not AI, right? Or they see
the fake AI. They've seen chat GPT two
years ago. It didn't solve a problem.
And uh it's funny. I I made this blog
post. You know, back back when when you
were my investor at Trial Pay, I called
it never judge people on the present.
And this is a mistake. It's it's a
category error that a lot of big company
people make, but I mean that almost
metaphorically. And the way that I wrote
this blog post was I found a video of
Tiger Woods. He was two and a half years
old. He hit a perfectly straight drive
>> and uh he was on, you know, not the I
think the Tonight Show or something. And
there were two ways of watching that
video. You could say, "Well, I'm 44. or
I can hit a drive much further than that
kid, which is correct. Or you can say,
"Wow, if that 2 and a halfyear-old kid
keeps that up, he could be really,
really good."
>> And most people judge things on the
present. Yes. And that's why it's
underhyped because it's like they tried
it at some point in time.
>> Um there's a distribution of when they
tried it, like probabilistically it's in
the past and like, "Oh, that didn't work
for my use case. It doesn't work." And
that's that's that's bad. But so I think
it's going to diffuse largely around
this like lazy rich like concept. And
that's where a lot of these things have
taken off. And I see it less at the very
very big companies because you have a
principal agent problem at the very big
companies. Like okay my company made
money or save money. I'm a director of
XYZ. Like all I know is that I want to
leave earlier and get promoted. Yeah.
>> And how does that actually help me? It
helps the ethereal being of the
corporation. Whereas at a smaller
business or a sole proprietor or an
individual doctor where I run a
dermatology clinic and somehow I can
have five times as many patients or I'm
a plaintiff's attorney, I can have five
times as many settlements. It's like, of
course, I'm going to use that because I
get to be lazier and richer.
>> Yeah.
>> Yep. 100%.
>> I think it's a great model.
>> By the way, the other one you reminding
me, uh, Ethan Mullik, uh, has a quote
here that I use often that every Yes.
The worst AI you're ever going to use is
the AI you're using today. Correct.
>> Because it's to remind you, use it
tomorrow.
>> Yeah.
>> Yeah. Yeah.
>> And a lot of the skeptics, it's exactly
this. It's like, well, I tried it two
months ago and it didn't solve this
problem. Therefore, it's bad. It's
because you're judging it on the
present. Like, you have to extrapolate.
Um, and you don't want to get like too
extrapolatory on like, you know, oh,
LLMs have this. Like, you actually have
I feel like the two types of people that
are underhyping AI are people that know
nothing and people that know everything.
>> It's really interesting. It's like the
meme where it's like, you know, the
idiot meme, right? It's like the people,
but it's in Yeah, it's like the people
in the the this part of the distribution
are correct. Normally, the meme is the
opposite. It's like these part these
people are smart even though they're
dumb. These people are smart even though
they're smart. everybody here like this
is this part of the curve is actually
correct because they're the ones that
are using it to get richer and be
lazier.
>> The other thing I also tell people is if
you haven't found a use of AI that helps
you on something serious today, not just
write a sonet sonnet for your kid's
birthday or you know I've got these
ingredients in my fridge. What should I
make? Do those too. But if you haven't
for something like work
>> for like something is serious about what
you're doing, you're not trying hard
enough.
>> Yeah. Yeah.
>> It isn't that it work does everything.
Like for example, I still think if I put
in like how should Reed Hoffman make
money investing in AI and I'll go try
that again or I suspect I will still get
what I think is the bozo business
professor answer versus the actual game
name of the game. But um
everyone should be trying and I you know
like for example we put when we get
decks we put them in and say give me a
due diligence plan. Right. If not
everybody here doing that that's a
mistake.
>> Yeah. cuz you five minutes you get one
and you go oh no not two not five oh but
three is good and it would have taken me
a day to getting to about three.
>> Yeah.
>> Yeah. Um in terms of let's go back to
extrapolation. Obviously the last few
years have had incredible um growth. You
you were involved of course with open
eyes since the beginning. When we look
for the next few years um is a broader
question as to whether scaling laws will
hold whether sort of the limitations um
or how far we can get with with LLMs. um
do we need another breakthrough of a
different kind? What is your view on
some of these questions?
>> So
one of the things we you know we all
swim in this universe of extrapolating
the future. One of the things that's
great about Silicon Valley and so you
get such things as you know theories of
singularity theories of super
intelligence theory of exponential
getting to super intelligence soon and
what I find is usually the mistake in
that is not the fact that extrapolating
the future that's smart and people need
to do that and far too few people people
do I think I remember liking your post
and helping promote it if I recall
>> um but it's the notion Well, what curve
is that? Like if it's a savant curve,
that's different than oh my gosh, it's
an apotheiois and now it's God, you
know? You know, it's like no, no, no,
it'll be an even more amazing savant
than we have. But by the way, if it's
only savant, there's always room for us.
There's always rooms for the generalist
and the cross checker and the context
awareness and all the rest of it. Now,
maybe maybe it'll cross over a threshold
or not. maybe it won't you know like I
think there's a bunch of different
questions there but that extrapolation
too often goes well it's exponential so
in two and a half years magic and you're
like well look it is magic but it's not
all magic is the is the kind of way of
doing it now so my own personal belief
is that
um look so the critics of LMS make a
mistake in that and you know we can go
through all the different critics oh not
knowledge representation it It screws up
on, you know, prime numbers and, you
know, blah blah blah blah blah. We've
all
>> How many Rs in strawberry?
>> Yes. Exactly. Exactly. You know, like,
wow, see, it's broken. And you're like,
>> you're missing the magic, right? Like,
yes, maybe there's some structural
things that over time, even in 3 to 5
years, will continue to be a difficult
problem for LLMs. But AI is not just the
one LLM to rule them all. It's a
combination of models. We already have
combination of models. We use diffusion
models for various image and video
tasks. Now, by the way, they wouldn't
work al without also having the LLMs in
order to have the ontology to say create
me an Eric Torberg as a Star Trek
captain, you know, going out to, you
know, explore the universe and meeting
first contact with the Vulcans and so
forth, which, you know, now with our
phone, we could do that, right? and it
will be there uh courtesy open AI uh and
you know VO because Google's model is
also very good but it needs LM for that
but the thing that people don't track is
it's going to be LLMs and a fusion
models and I think other things with a
with a fabric across them now one of the
interesting questions is is the fabric
fundamental LLMs is the fabric other
things I think that's a TBD on this and
the degree to which it gets to
intelligence is an interesting question
now one of the things I think is a Um,
you know, like I I talked to all the
critics intensely, not because I
necessarily agree with the criticism,
but I'm trying to get to the what's the
kernel of insight.
>> Yeah.
>> And like one of the things that I um
loved about, you know, kind of a set of
recent conversations with Stuart Russell
was say, hey, if we could actually get
the fabric of these models to be more
predictable,
that would greatly uh allay the fears of
what happens if something goes a muck.
Well, okay, let's try to do that. Now, I
don't think the whole verification of
outputs like like logical like we can't
even do verification of coding, right?
Like verification strikes me as very
hard. Now, brilliant man. Maybe we'll
figure it out. But the um but but on the
other hand, the hey, this is a good
goal. Can we make that more
programmable, reliable? I think that is
a good goal that people that very smart
people should be working on. And by the
way, smart AIs Well, that's some of the
math side is like if you think about the
the foundation of the world. I mean,
>> uh, philosophy is the basis of
everything. Actually, math cames from
philosophy. It's called the cartisian
plane after Decart. You know, you're a
philosophy. You know this, right? So,
you have you have uh philosophy, math,
physics, like why did Newton build
calculus to understand the real world?
So, math, physics, physics gets you
chemistry, chemistry gets you biology,
and then biology gets you psychology.
So, that's kind of the stack. So if you
solve math, that's actually quite
interesting because um there's a
professor at Rutgers Contovich who's
written about this a lot. Um and I find
this part fascinating just as a former
mathematician because
>> there are some very very hard problems.
Um there there's a rumor that the Navier
Stokes equation is going to be solved by
deep mind which would be huge. That's
one of the clay math problems.
>> But you know the reman hypothesis like
this is not like there's no eval. Yes.
Right. If it's like uh this is why if
you look at the progression of AI there
is the Amy the American Invitational
Math Examination where you the answers
are all just like three it's just
integers it's like 0 to 9999 is the
answer and then of course you can keep
trying different things and then you
either get the right answer or you don't
and it's very very easy to do that
whereas once you get to proofs
>> very very hard
>> yes
>> um and if you solve that I mean is that
AGI no because the goalposts keep
changing on AGI
>> but math is just so interesting
>> AGI is AI we haven't invented.
>> Exactly. Exactly. It's the correlary to
it's like, you know, if the worst AI
you're going to try is today, well, a
AGI is what you're going to have
tomorrow, right? It's the same same kind
of thing. But math is a very very
interesting one as well because you have
these things. It's not like solving high
school math, right?
>> This is like if you're able to actually
logically construct a proof for
something and then validate it. Um
there's a whole programming language
called lean which is for that like that
that stuff is also fascinating. So
there's so many different vectors of
attack which is uh the other the other
way of thinking about it. Fascinating.
So, as you just mentioned, Alex Reed,
you're a philosophy major, but you're
also very interested in deep in
neuroscience. And some people say that,
hey, we'll never create AI with its own
consciousness because we don't
understand our own consciousness. We
don't understand how our own brain
works. Um, and and then there's broader
question as, oh, will AI have its own
goals or will have its own agency? Uh,
what what is sort of your view on on
some of these questions surrounding
consciousness relates to AI?
>> Well, consciousness is its own
fireball, which I will say a few things
about.
I think agency and goals is almost
certain.
Um there is a question I think this is
one of the areas where we want to ex um
have some clarity and control that was a
little bit like the the kind of question
what kind of compute fabric holds it
together
>> because you can't get complex problem
solving without it being able to set its
own minimum sub goals and other kinds of
things and so so goal setting and
behavior and inference from it and
that's where you get the classic kind of
like well you tell it to maximize you
tell it to maximize paper clips and it
tries to convert the entire planet into
paper clips and there's one thing that's
definitely old computer that which is no
context awareness something I even worry
about modern AI systems but on the other
hand it's like look if you're actually
creating intelligence they don't go oh
let me let like let me just go try to
convert everything into paper clips it's
like it's it's actually in fact not that
simple in terms of how it plays now um
now consciousness is an interesting
question because you got some very smart
people Roger Penrose um who I actually
interviewed way back and on Emperor's
New Mind, speaking of mathematicians um
and um you know who are like look
actually in fact there's some thing
about our form of intelligence our form
of of of computational intelligence
that's quantum based that has to do with
how our physics work that has to do with
things like t tubulars and so forth and
by the way it's not impossible like
that's that's that's a it's a coherent
theory from a very smart mathematician
like one of the world's smartest
right? Like it's kind of in the category
of there's other people as smart, but
there's no one smarter, right, in in in
that convective. And so so that's
possible. Um I don't think you need
consciousness for um goal setting uh or
reasoning. Um I'm not even sure you need
consciousness for certain forms of
self-awareness. There may be some forms
of self-awareness that consciousness is
necessary for. It's a tricky thing.
philosophers have been trying to address
this not very well for as long as we've
got records of philosophy, right? And
and philosophers agree. I'm not
philosophers wouldn't think I was
throwing him under the bus with this.
They're like, "Yeah, this is a hard
problem because it ties to agency and
free will and a bunch of other things."
And and I think that the right thing to
do is keep an open mind. Now part of
keeping an open mind I think u Mustafa
Sulleman wrote a very good piece in the
last month or two on like
semi-consciousness which is we make too
many mistakes all of the touring test
that piece of brilliance which is um
well it talks to us so therefore it's
fully intelligence and all the rest and
so similarly you had that kind of you
know kind of nutty event from that
Google engineer said I asked this
earlier model was it conscious and it
said yes so therefore it is
>> yes QED you're like no no no It's like
you have to be not misled by that kind
of thing. And like for example, you
know, the kind of thing that you know
what what I actually think most people
obsess about the wrong things when it
comes to AI. They obsess about the
climate change stuff because actually in
fact if you apply intelligence at the
scale and availability of electricity,
you're going to help climate change.
You're going to solve grids and
appliances and a bunch of other stuff.
It's just like no, this will be net
super positive. And by the way, you
already see elements of it. U Google
applied its algorithms to its own data
centers which are u some of the best
tuned grid systems in the world. 40%
energy savings. I mean just you just d
and just applying it. So that's the
mistake. But one of the areas I think is
this question around
like what is the way that we want
children growing up with AIS? What is
their epistemology? What is their
learning curves? You know what are the
things that kind of play to this?
because that kind of question is
something that we want to be very
intentional about in terms of how we're
doing it. And I think that's like like
if you want to go ask a good question
that you should be trying to get good
answers that you could do something
again and contributing good answers to,
that's a good one.
>> Yeah. Well, the the most cogent argument
that I've heard against free will uh is
just that we are biochemical machines.
So if you want to test somebody's free
will, get them very hungry, very angry,
like all of these things where it's just
there's a hormone. It's like
norepinephrine, it's like that makes you
act a particular way, it's like an
override. Yes.
>> So you have this like free will thing,
but then you just insert a certain
chemical and then like boom, it changes.
>> Are you saying you're not a cartisian?
You don't have a little pineal gland
that connects the two sentences.
>> I don't I don't know. So it's true. I
mean just like like hanger is Yeah. I'm
hangry. Like that's a thing. Yes. And
you know what what is the like do do you
actually want if you're developing super
intelligence do you want to have this
like kind of silly override? I mean the
reason why people go to jail sometimes
that are perfectly normal is they get
very angry. They do things that are kind
of like out of character but it's
actually not out of character if you
think about this free will override of
just like chemicals going through your
bloodstream which is kind of crazy to
think about. Look, since we're on a
geeky nerdy podcast, I'm going to say
two geeky nerdy things are. One, the
classic one is people say, "Yes, we are
biochemical machines, but let's not be
overly simplistic on what a biochemical
machine is." That's like the Penrose,
quantum computing, etc. And you get to
this weird stuff in quantum, which is
well, it's it it's of probabilistic dual
superpositional form until it's
measured. Why is there magic in
measurement? And is that magic and
measurement something that's conscious?
You know, blah blah blah. know there's a
bunch of stuff there. The the other um
thing that I think is interesting that
we're seeing as a resurgence in
philosophy a little bit is idealism.
Like we would have thought as physical
materialists that that we go no
idealists were disproven. They're gone.
But actually beginning to say no
actually in fact what exists is thinking
and that all of the physical things
around us come from that thinking. And
obviously we see versions of this
because you know I find myself
entertained frequently here in Silicon
Valley by people saying we're living in
a simulation. I know it. You know it.
And you're like well your simulation
theory is very much like Christian
intelligent design theory. It's the I
have things that I can't explain. So
therefore creator no therefore
simulation. No therefore creator of
simulation. You're like no no no but I
you know. So clearly I'm not an idealist
but that's why I see some resurgence of
idealism happening.
>> I suspect
>> geeky
>> I suspect we'll solve for AGI before we
solve for for various definitions of AGI
before we solve for the hard problems of
uh of consciousness.
>> Yes.
>> Um I want to return to uh LinkedIn how
we began the conversation because we
were lucky to or I was lucky to work
many years with you. We would get
pitches uh every week about a LinkedIn
disruptor
last 20 years. Right. Yes. And so and
nothing's come even close.
>> No.
>> And so it's fascinating. I'm curious why
people p sort of underrated how hard it
was and people have this about Twitter
too or other things that kind of look
simple perhaps but are actually very
very difficult to unseat and have a lot
of staying power. And and it's
interesting you know Open AI they said
they're coming out with a job service to
quote use AI to help find the perfect
matches between what companies need and
what workers can offer. I'm curious how
you think about sort of LinkedIn's
durability. So look, I obviously think
LinkedIn is durable, but first and
foremost, I I kind of look at this as
humanity, society, industry. So first
and foremost is what are the things that
are good for humanity, then what's good
for society, then what's good for
industry. And by the way, we do industry
to be good for society, humanity. It's
not an it's not oppositional. It's just
a you know, how you're making these
decisions and what you're thinking
about. So I would be delighted if there
were new amazing things that helped
people um you know kind of uh make
productive work, find productive work in
make them do them. We're having going to
have all this job transition uh coming
from technological disruption with AI
like it would be awesome. I of course
would be extra awesome if it was
LinkedIn bringing it just given my own
personal craft of my hands and pride at
what we built and all the rest. Now the
thing with LinkedIn and you know Alex
was with me on a lot of this journey uh
you know as I sought his advice on
various things um the the LinkedIn was
one of those things where it's where the
turtle eventually actually in fact like
grows into something huge because for
many many years the general scuttlebutt
in Silicon Valley was LinkedIn was the
was the the dull boring useless thing
etc. And it was going to be Frenster.
Probably most people listening to this
don't know what Fster is. Then MySpace.
Maybe a few people have heard of that,
right? You know, and then of course we
got, you know, Facebook and Meta and,
you know, Tik Tok and all the rest. And
part of the thing for LinkedIn is it's
built a network that's hard to build,
right? Because it doesn't have the same
sizzle and pizzazz that photo sharing
has. It doesn't have the same sizzle and
pizzazz that you know um you know like
one of the things that uh you know you
were referencing the seven deadly sins
comment um and back when I started doing
that 2002 yes I left my walker at the
door um uh the the thing that I used to
say was uh Twitter was identity I
actually mistook it it's wrath right and
so it doesn't have the wrath you know
kind of component of it and so um and so
the uh you know the that and you said
with LinkedIn LinkedIn's greed great you
know because seven deadly sins kind of u
you know because because that's you know
a motivation that's very common across a
lot of human beings
>> rich and lazy
>> yes exactly and so or you know you
you're putting it in the punchy way but
simply being productive yeah more value
creation and acrewing some of that value
to yourself
>> and so um and so I think the reason why
it's been difficult to create a uh a
disruptor to LinkedIn is it's a very
hard network to build. It's actually not
easy. And um and by staying really true
to it, you end up getting a lot of
people going, well, this is this is
where I am for that. And now I have a
network of people with this and we are
here together collaborating and doing
stuff together. And that's the thing
that a new thing would have to be. Um,
and you know I uh you know I uh when I
saw GBD4
um and uh knew that uh Microsoft had
access to this. I called the LinkedIn
people and said you guys have got to get
in the room to see this, right? because
you need to start thinking about what
are the ways we help people more with
that because you start with this is
actually one of the things that I think
people don't realize about Silicon
Valley because you know the general
discussion is oh you're trying to make
all this money through equity and all
this revenue of course you know business
people are trying to do that but they
don't realize is you start with what's
the amazing thing that you can suddenly
create and part of it is like lots of
these companies like get started with
and you go what's your business model
you go I don't know like yeah we're
going to try to work it out but I can
create something amazing here and that's
actually one of the fundamental like
places of what they you know call it the
religion of Silicon Valley and the
knowledge of Silicon Valley that I so
much you know love and admire and
embody.
>> That's that's actually a question that I
have. So I'll say one thing. It's a huge
compliment to LinkedIn. It's
anti-fragile.
>> Yes.
>> And that like Facebook, oh nobody goes
there anymore. It's like the yogi bear
and it's too crowded. Nobody goes there
anymore. It's oh there were too many
parents there and there's always been a
new one. Like where did Snap like how
did Snap start? like all these other
networks started because people didn't
want to hang out with their boomer
parents. Um my my kid won't let me
follow him on Instagram, right? It's
like he doesn't want to use Facebook. So
LinkedIn has has survived through all of
that. But you referenced something that
I think is a very interesting uh point
which is back in like web two it was
like get lots of traffic, get amazing
retention, you know, smile curve and
then you will figure out monetization.
Yes.
>> And like that isn't happening right now.
It's not like get lot Yes. It happened
with chat GBT was like it's $20 a month.
Yes. Right. like the monetization was
kind of built in very very clear
subscription versus like become giant.
Yes.
>> Build a giant like do you think there
will be new ones of those with AI?
>> Yes. And there will be new kind of
premium. It's it's part of our tool
chest. Now part of the reason why it's
more tricky especially when you're doing
open AI is because the the um like the
cogs are changed a little. Yes. Right.
For now. Yes. No. No. Like and so you
just can't. This is one of the reasons
why at PayPal we had to change to like
we as you know because you were close to
us there like we had to change to a paid
model because we're like oh look we have
exponentiating volume which means
exponentiating cost curve which means
despite having raised hundreds of
millions of dollars we could literally
count the we could point to the hour
that we'd go out of business right
because you know no you can't have an
exponentiating cost curve. So I think
that's one of the reasons why some of it
has been different in AI because you
like you can't have an exponentiating
cost curve without at least a following
revenue curve,
>> right?
>> But it's it's almost no fun. It's like
Pinterest. It's like how are they going
to make money now? Big public company.
It's like there were a lot of these
during that era and now it's like
they're burning lots of money. They're
raising lots of money but the
subscription revenue is baked in from
day zero and that's that's the
fundament.
>> But they have to because of the cost.
>> They have to. Exactly. Yeah. Um, so I'm
I'm waiting for like one of these like,
you know, net new companies that appeals
to probably one of the seven deadly sins
that the the new counterpart.
>> Yeah. Well, I'd be happy to work on it
with you.
>> Yes.
>> Well, and it's fascinating. Some people
have tried sort of different angles on
LinkedIn. One that I was curious about a
few years ago was sort of this idea of
could you get um what's on LinkedIn is
rums but not necessarily references. But
the same way that résumés are viral,
references are like anti or antimatic
and people don't want them on the
internet. If there was a data set that
people wanted on the internet, LinkedIn
would have would have done it to some
degree. But uh yeah, I think most people
who try these attempts don't kind of
appreciate um sort of the subtleties of
uh
>> and I've actually I mean we do have the
equivalent of book blurb references.
Yes. Endorsements.
>> You don't have a negative reference.
>> Well, but but by the way, part of the
reason why negative references is you
have complexity in social relationships.
That's the negative virality point that
you were just making. And then you also
have complexity on like you know kind of
not just legal liability but social
relationships and a bunch of other
stuff. Now LinkedIn is still the best
way to find a negative reference. I mean
that's actually one of the things that
>> that I use LinkedIn to figure out who
might know a person
>> and I have a standard email. You've
probably gotten a bunch of these from me
where I've where I've I email people
saying um could you rate this person for
me from 1 to 10 or or reply call me.
negative. What?
>> Yes. Yes. Right. And when you get a call
me, you're like, "Okay,
>> don't even need to take the call." Yeah.
Yeah. I understand.
>> Right.
>> Right. And by the way, sometimes you go
when a person writes back 10, you're
like, "Really?" Like best person, you
know, right? But what you're looking for
is like a set of eight nines. Yeah.
>> And if you get a set of eight and nines,
like you may still call and get some get
some information, but you're like,
"Okay, I got a I got a quick referential
information." Whereas, by the way, more
often than not, you know, when you're
checking someone you really know, you
you get a couple call mess because
because my and it's just that quick
because email one sentence thing, get
back, call me. You're like, "Okay, I
understand."
>> Yeah.
Um, we have about 10 minutes left. Just
logistics check. Um, a couple last
things we'll get into. Um, is there
anything you wanted to make sure?
>> But we can do this again. This is always
fun. Yes.
>> Yeah. That's great. the um I'm curious
Reed as you've sort of continued to
uplevel in your career and have more
opportunities and they seem to compound
especially you know post-selling
LinkedIn h how have you decided where is
the highest leverage use for for your
time where can you have the the the the
biggest impact
>> what's your mental framework for
>> so
I mean one of the things that I'm sure I
speak for all three of us is an amazing
time to be alive I mean this AI and the
transformation of what it means for
evolving homo techn and what what is
possible in life and in society and work
and all the rest just amazing and so I
stay as
uh involved with that as I possibly can
like it has to be something that's so
important that I will stop doing that
>> you know now within that you know part
of that was you know co-founding manusi
with Sedart Mukerji who's the CEO
emperor uh author of emperor all malades
um inventor of um some T- cell
therapies. So it's like like for example
getting an instruction from him on the
FDA process, you know, that's the kind
of thing that makes us all run screaming
for the hills, right? As a as an
instance. Um and so uh you know that
kind of stuff, but also um you know like
one of the things I think is really
important is as technology drives more
and more of everything that's going on
in society, how do we make government
more intelligent on technology? And so,
you know, every kind of um, you know,
kind of well-ordered western democracy,
um, I've done been doing this for at
least 20 to 25 years. If if a minister,
you know, or kind of senior person from
a from a democracy comes and asks for
advice, I give it to them. So, you know,
just last week, I was in France talking
with McCron because he's trying to
figure out like, how do I help French
industry, French society, French people?
What are the things I need to be doing?
you know, if all the frontier models are
going to be built in the US and maybe
China, what does that mean for how I
help, you know, our people and so forth
and and he's doing the exact right
thing, which is I understand that I have
a potential challenge. What do I do to
help my people?
>> Yeah.
>> How do I reach out? How do I talk? Sure,
they've got my straw. They've got some
other things, but like how do I
maximally help what I'm doing? And so,
putting a bunch of time into that as
well.
>> Yeah. I remember seeing your your your
calendar and it was what seemed like
seven days a week meetings absolutely
stacked and one of the ways in which
>> I've gone to six and a half days.
>> Okay. I'm glad you calm down. One of the
ways in which you're able to do that one
it's important problems but two you you
work on projects with friends sometimes
over over decades and you you maybe
we'll close here. You've thought a lot
about friendship. You've you've you've
written about it. You've spoken about
it. I'm I'm curious what you found um
most remarkable or most surprising um
about French where you think more people
should appreciate especially as we enter
this AI era where people yeah sort of
are questioning you know the next
generation what's there going to be
relationship to friends
>> I actually am going to write a bunch
about this specifically because AI is
now bringing some very important things
that people need to understand which is
friendship is a joint relationship it's
not a oh you're just loyal to me or oh
you just do things for me oh this person
does things for me well there's a lot of
people who do things for you. Your bus
driver does things for you, you know,
like like but that doesn't mean that
you're friends. Friends, like for
example, like a classic way of putting
is like, "Oh, I had a really bad day and
I show up my friend Alex and I want to
talk to him and then Alex like, "Oh my
god, here's my day." I'm like, "Oh, your
day is much worse." We're going to talk
about your day versus my day, right? You
know, that's the kind of thing that
happens because what I think
fundamentally happens with friends is
two people agree to help each other
become the best possible versions of
themselves.
>> Yeah. And by the way, sometimes that
leads to friendship conversations that
are tough love. They're like, "Yeah,
you're [ __ ] this up and I need to
talk to you about it." Right? It's not
>> I tell you like, you know, the the whole
syopency phase and AI thing and all.
It's not that. It's like how do
>> how do I help you? But as part of also
the thing that I uh I gave the um
commencement speech at Vanderbilt a few
years back and was on friendship and
part of it was to say look part of
friends is not just does does Alex help
me but Alex allows me to help him right
and as part of that that's part of how I
become a deeper friend I learn things
from it's not just help that helping
Alex that joint relationship is really
important and you're going to see all
kinds of nutty people saying oh I have
your AI friend right here. It's like no
you don't. It's not a birectional
relationship. Maybe awesome companion
like just spectacular but it's not a
friend. And you need to understand like
part of friend is part of when we begin
to realize that life's not just about us
that we that it's a team sport. We go
into it together. Um that sometimes, you
know, friendship conversations are
wonderful and difficult, you know, and
that kind of thing. And I think that's
what's really important. And and now
that you know we've got this blurriness
that AI has created, it's like shoot I
have to go write some of this very soon
so that people understand how to
navigate it and why they should not
think about AI anytime soon.
>> Yeah.
>> As friends. Well, one one thing I've
always appreciated about you as well is
you're able to be friends with people
for whom you have disagreements with or
people for whom you know you are uh not
close to for a few years but you can
reconnect and sort of uh yeah that
ability is um
>> yeah it's about us making each other the
better versions of ourselves and and
sometimes that you know sometimes those
go through rough patches.
>> Yeah. I think it's a great place to
close Reed. Thanks so much for coming on
the podcast.
>> My pleasure and I hope we do this again.
Yeah.
>> Excellent.
[Music]
