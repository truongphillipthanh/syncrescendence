---
id: SOURCE-20250807-001
title: "The Intelligence of Us: Rethinking Minds in the Age of AI"
platform: youtube
format: lecture
creator: TEDx
date_published: 2025-08-07
status: processed
url: "https://www.youtube.com/watch?v=OD5UzhaDWfg"
original_filename: processed/SOURCE-20250807-youtube-lecture-tedx-blaise_aguera_y_arcas.md
aliases:
  - "Aguera y Arcas - Intelligence of Us TEDx"
teleology: synthesize
notebooklm_category: philosophy-paradigm
guest: Blaise Aguera y Arcas
signal_tier: paradigm
chain_relevance: [Intelligence, Wisdom]
integration_targets: [CANON-30000-INTELLIGENCE, CANON-35210-METAHUMANISM, CANON-00004-EVOLUTION]
date_processed: 2026-01-05
synopsis: "Blaise Aguera y Arcas TEDx talk synthesizing AI as continuation of 4-billion-year symbiogenesis. Intelligence is prediction, brains are autocomplete, collective intelligence trumps individual genius, and AI is joining the collective intelligent fabric—not invading it."
key_insights:
  - "The shock that scaled autocomplete (LLMs) exhibits intelligence validates 80 years of cybernetic theory that nervous systems exist to predict the future given the past"
  - "Major evolutionary transitions (Smith/Szathmary) are all instances of symbiogenesis—parts teaming up to create wholes greater than their sum, now including AI"
  - "Collective intelligence has been the pinnacle since long before AI—an average Manhattanite cannot explain their toilet but collectively humanity knows enormous amounts"
topics:
  - "consciousness"
  - "philosophy"
  - "ai-engineering"
  - "education"
---

# The Intelligence of Us: Rethinking Minds in the Age of AI

## Executive Summary

Blaise Aguera y Arcas (Google AI) delivers a crystalline synthesis: AI is not an alien invader but a continuation of a 4-billion-year evolutionary process of complexification through symbiogenesis. Intelligence is fundamentally about prediction, brains are autocomplete, and humanity's intelligence explosion came from collective collaboration—not individual genius. AI is joining this collective fabric. The major evolutionary transition framework (Smith/Szathmáry) provides the theoretical substrate.

## Key Insights

### Brains Are Autocomplete
The neuroscientist's insight: nervous systems exist to "predict the future given the past, in order to affect it." The shock that LLMs—essentially scaled autocomplete—exhibit intelligence validates Helmholtz and cybernetic theories from 1943 onward. Intelligence is prediction.

### Life Is Computational
Biology = matter trying to find order that resists entropy. The mechanism for maintaining order is computation—active control and prediction. Turing's original model for computation was modeled on biological evolution. The "computational soup" simulation demonstrates life-like patterns emerging spontaneously from random bytes and simple interaction rules.

### Major Evolutionary Transitions
The Smith/Szathmáry framework: life complexifies through "changes in the way information is stored and transmitted"—i.e., computation. The transitions: single cells → mitochondrial symbiogenesis → multicellularity → societies → technology → AI. Each is an instance of symbiogenesis: parts teaming up to create wholes greater than their sum.

### Collective Intelligence > Individual Intelligence
"It's been a long time since individual humans were the pinnacle of intelligence on Earth. It's human society as a whole collective that is intelligent." An average Manhattanite can't explain why their toilet flushes—but collectively, we know a great deal. The social intelligence explosion came from minds modeling minds in a recursive arms race.

### AI as Symbiont, Not Invader
AI is: (1) trained on human experience (as human as it gets informationally), (2) computational like us, (3) becoming part of our collective intelligent fabric. "Humanity is collectively brilliant. Humanity plus AI is going to be even more collectively brilliant." Symbiosis can be disruptive but historically has been "rich and positive."

## Quotable Passages

> "It was quite a shock when we basically scaled up the same sorts of models and built things like Meena and LaMDA... they could actually answer those kinds of questions. They were able to solve all of those kinds of general AI problems. This was a bit of a shock because they really are, in some sense, just autocomplete." — Blaise Aguera y Arcas

> "The way I now think about this is: What is biology? Biology is matter trying to find an order that resists entropy... The way you maintain order is through computation." — Blaise Aguera y Arcas

> "Humanity is collectively brilliant. Humanity plus AI is going to be even more collectively brilliant." — Blaise Aguera y Arcas

> "When we look at how it is that we went from being individual stupid animals to collectively brilliant animals as we are today, it really has nothing to do with what's going on in individual brains and everything to do with how we collaborate together." — Blaise Aguera y Arcas

## Integration Notes

- Connects to CANON-30000-INTELLIGENCE: The "brains are autocomplete / intelligence is prediction" thesis directly informs the intelligence chain
- Connects to CANON-35210-METAHUMANISM: AI as continuation of symbiogenesis, not alien threat—the metahuman framing
- Connects to CANON-00004-EVOLUTION: Major evolutionary transitions framework maps to evolutionary stages
- Novel contribution: "Computational soup" as intuition pump for inevitability of life/intelligence emergence
- Novel contribution: Social intelligence explosion through recursive mind-modeling

## Metadata

- Duration: ~15 minutes (TEDx talk)
- Quality: Excellent—dense, crystalline, quotable
- Processing notes: This is a condensed version of themes from his books; very high signal


## Transcript

[Music]
[Applause]
So my background is in computational
neuroscience and applied math. Um I went
to Google uh about 12 years ago and uh
my my first number of years that that I
was working there. The the main project
was to add AI features to Android and
Pixel phones. So uh most of the AI uh in
in those phones uh over those years came
from uh teams that I built. Uh some of
these features are things like uh face
unlocking and um music recognition. This
feature called now playing. Uh we built
um predictors of next words for uh for
the keyboard uh the the Google keyboard
Gboard. And um you know these these
things were called AI but um they
weren't they weren't really AI in the
sense that researchers meant when they
invented that term back in the 1950s. Uh
you know when when we uh thought about
AI as kids it probably wasn't uh you
know face recognizers or handrail
recognizers or or something like that.
uh and that was why the term artificial
narrow intelligence and artificial
general intelligence were invented in
order to draw that distinction. So um
artificial narrow intelligence is uh is
models that are trained for doing
specific tasks like these. Artificial
general intelligence is you know a robot
you can have a conversation with and um
and we didn't have artificial general
intelligence but we did have these uh
models for doing things like next word
prediction. We always assumed that these
statistical models for next word
prediction were uh inherently going to
be very limited because you know if the
first word is Humpty then it's easy to
statistically predict that the next word
is going to be dumpty but if you know
the previous words are a word problem a
mathematical word problem or or a story
and the next word is you know how does a
character in that story feel at this
moment or something of course statistics
won't be enough to uh to answer that
those are problems that are called AI
complete
Uh so it was quite a shock when we
basically scaled up the same sorts of
models and um and built things like um
Mina and Lambda in 2020 2021 uh and
found that they could actually answer
those kinds of questions. Uh they were
able to solve all of those kinds of
general AI problems. Um, and this was a
bit of a shock because they really are
uh in some sense just autocomplete,
but uh you know the the neuroscientist
in me maybe shouldn't have been uh so
shocked because there is there is at
least one theory uh in in neuroscience
that goes back a long way uh at least to
Helmholtz in the 19th century certainly
to the cyberneticists in the 1940s that
brains basically are autocomplete that
uh that the reason we develop nervous
systems is to predict the future given
the past in order to be able to affect
it. Uh so you know there is some sense
in which uh like these the fact that
these models that that just predict the
next word uh you know end up being
intelligent uh is validation of of an
old idea in neuroscience. Um so this was
quite this is quite a shock but uh you
know I began around the same time to uh
to write books. Uh a lot of these books,
in fact, all of them are questions. Uh
even the first one, which was fiction in
2022, uh Ubisund is Latin for where are
they? Uh and the other ones all have
question marks at the end, so you know
they're questions. Uh it's taken me a
while to figure out what the uh
underlying theme or the question was
behind all of these all of these books
that I began uh writing around this time
that that uh that it started to become
clear what AI was really um about and
what it told us about ourselves. Uh the
last of these books are just coming out
in September. Uh what is intelligence is
you know addresses that one head on but
um yeah the other ones are are uh as I
said fiction, social science uh and
theoretical biology.
And um I I think that if there's an
underlying theme behind all of these,
it's the idea of major evolutionary
transitions, which is a concept that was
introduced by two evolutionary
biologists uh Yor Safari and John
Maynard Smith uh in in the 1990s. And uh
the the question they were asking is why
does life become more complex over time?
You know, why is it that we began on
Earth with single-sellled organisms and
uh and then we we got multisellular
organisms somewhere in there the cells
became more complex when when
mitochondria made their way into uh
archa and we we got ukarotes. Um why do
those multisellular animals become more
intelligent over time and form societies
and eventually launch spacecraft and do
all kinds of crazy things like this and
even develop AI? So um they called these
major evolutionary transitions. Uh their
initial list is uh you know includes
some of the events that I've just
described and they've added a few since
then and I think we're going through
another of these right now which is the
uh the emergence of AI.
So uh what do these transitions have in
common? Well um why do they happen? Uh
is life actually becoming more complex
and why is that why is that taking
place? And are we in the end times? Um,
no, I don't think we're in the end
times. Uh, yes. Uh, life is becoming
more complex. And I think the answer to
the question of why is a very
counterintuitive one and one that one
that I've I've only come to appreciate
in the last year or so, uh, which is
that I think life is computational. Um,
it's kind of right there in in in Smith
and Smiley's paper when they say these
these changes involved changes in the
way information is stored and
transmitted which which is computation
and indeed the uh the original model for
uh the theoretical model for computation
for a computer uh which was introduced
by Alan Turing in the 19 in the 1930s is
sort of a very simplified version of a
machine like that one. It's a tape uh
and it follows instructions to move that
tape left or right by one square at a
time and read, write or erase symbols on
that tape. What touring proved was that
a very very minimal system like this one
could compute anything that can be
computed given enough time and enough
tape. And um the point here really is
that this is a minimal system for
following instructions in order to carry
out a function. Now um I think of
touring as one of the two um fathers of
computer science. The other one was John
Vonoyman and Vonoyman had a really
profound insight that has not been fully
appreciated uh also in the 1940s uh
early 1950s. Um he published it in a in
a paper that that didn't come out until
after his death uh in the theory of
self-reproducing automata. And his
insight was as follows. uh he he was
thinking about how it is that uh a thing
made out of Legos, let's say, can float
around on a pond uh in which there are
lots of loose Legos floating and how it
can take those Legos and assemble
another robot like itself out of those
out of those pieces. It seems a little
bit like lifting yourself up by your own
bootstraps to make something as complex
as you are. And he realized that what
that would require is for that robot to
have a tape inside itself, an
instruction tape that says how to build
me. And uh to have something that he
called a universal constructor, which
would be able to follow the instructions
on that tape to assemble whatever the
tape says. And as long as the
instructions for building the universal
constructor itself are included on the
tape, then you can have reproduction,
you can have healing, you can have
growth. Basically, you can have life.
because what I've just described of
course is exactly the way a cell works
or in fact the way our bodies work and
um and and the the really uh the kicker
is that this universal constructor is a
universal touring machine. In other
words uh that that thing at the core of
all of our cells of every living system
is literally mathematically formally a
computer. So in that sense I think you
know the the insight was vanoyman's life
is computational at its heart. You can't
reproduce without computation. you can't
grow, you can't heal without computation
in every cell. Uh so my my team and I
were exploring this idea uh last year
and uh we we published a paper in in
June of 2024 called computational life,
how well-formed self-replicating
programs emerge from simple interaction.
Uh that uh that really showed how it is
that self-replication can emerge out of
nothing. uh this is the problem that
sort of flumxed Darwin when he thought
about you know how it is that evolving
systems could have arisen in the first
place. Darwin understood how evolution
worked once you had something like this
tape once you had reproduction once you
had selection for fitness. But what he
really didn't understand is how life
could arise in the first place. Um if
you're religious of course you have one
kind of idea about how that might have
happened. But Darwin was interested in a
naturalistic explanation as we were. And
um the experiment that we did uh
involved the following. So we we took um
a very simple touring language whose uh
name I won't I won't say so that I don't
have to be beeped out. Um this language
was not named by us. It was invented in
the 90s by an amateur juggler and
computer scientist. Um which explains a
lot. Uh so it's it's a very minimal
computer language. It's based on only
eight instructions. Uh those eight
instructions are exactly touring tape or
touring machine like they involve a head
on a tape. The instructions are move
left one square, move right one square,
increment the bite at the head,
decrement the bite at the t at the head,
and there are four other ones. They're
very very simple, but with just those
eight instructions based on Turing's
theorems, we know that you can build uh
any computer you like. You can run
Windows with with nothing but these
eight instructions.
Uh so uh that's the uh that's the eight
instructions and what they do if you uh
if you must know. Uh so uh the
experiment involved taking um lots of
tapes uh short ones so length 64 uh and
starting by filling them with random
bytes. So they're just random tapes. Um
I'm I'm uh just printing a bunch of them
here. Uh and I'm only writing the uh the
instructions the the bytes that end up
being instructions which is one in 32 of
them. Remember, there are only eight
instructions. There are 256 possible
bytes. So, every tape only has one or
two instructions on it. And uh and they
don't do anything interesting, right?
These are not real programs. The the
recipe consists of taking two of these
tapes at random out of the soup,
sticking them together, running them,
taking them back apart, and putting them
back in the soup. And that's it. And
then repeating that over and over, kind
of as if they were molecules in a
solution. And uh if you do that, I'll
show you what happens uh on my laptop.
Uh this was pretty much the first time
that I got it to run. So I just like
took out my phone and and and took a
video of my screen. You begin with
random bites and after a few million
interactions, uh something really
magical happens, which is that programs
emerge. And these programs are complex.
They're full of instructions and they're
quite hard to reverse engineer. Um what
on earth are they doing? Uh well,
they're reproducing. Uh so those
programs are copying themselves. Um why?
Well, because once a program can copy
itself, then that means that it will
still exist in the future. Something
that can't copy itself will get
overwritten by something else that can
copy itself. Uh you know, we talk about
about some matter being robust uh or uh
or being durable. If if you have a a
statue made out of granite, it's highly
durable. But still, the only thing that
can happen is for it to break over time,
for it to gradually blur and erase. But
if something can replicate itself, then
it will exist forever. And and so there
is a stability about things that can
replicate themselves that makes them uh
if you like selected for in ways that
inanimate matter is not selected for.
And uh and so that's why that's why they
emerge because ultimately they're the
things that persist through time. Um but
there's there's a remaining mystery here
which is you know in this case there
were only 8,000 tapes uh starting you
know the length 64 that doesn't seem
like enough randomness to um to produce
these very complex programs. How do we
get from uh you know from only a few
instructions, a couple of instructions
per tape to these very complex programs?
And um you know when this when this
happens we we we get you know and these
these programs are are too complex if
you like to arise uh in a in a purely
random way from that starting point. It
looks almost like intelligent design. Uh
why is that happening? Um this is by the
way what um what that looks like in
terms of uh amount of computation
happening uh in in that soup. So I've
I've drawn here the first 10 million
interactions in a particular run. Each
interaction is a dot. The x-axis is time
and the y-axis is how much computation
took place in that interaction. And what
you can see is that there is a
discontinuous transition right at six
million interactions in this particular
case where suddenly the soup starts to
compute because the process of copying
or replicating is a computational
process. So you can think about this
almost like two phases of matter. On the
left is a phase of matter that is
disordered like a gas and on the right
is a phase of matter that you could call
life. It's purposive.
All right. So why does it become more
complex over time? Well, um Lyn
Margulus, I think came up with the
answer back in 1969. Uh she was the one
who figured out that um that ukarotes,
the complex cells like the ones that
make up our bodies, uh are made out of
mitochondria that uh that made their way
inside other cells in in an act that she
called symbioenesis. Uh in other words,
a symbiosis between two parts that made
something more complex than those parts,
made a whole more complex than those
parts. And it turns out that that's
exactly the same thing that's happening
in the soup. uh when when you first
start running this thing, you
occasionally get a single bite that
manages to replicate itself. Uh and what
happens is that those individual bytes
sometimes team up. That is to say, they
manage to find themselves next to each
other and the pair can reproduce better
than one of them could on its own. And
that process repeats and ladders up and
that's how you get complexity. It's
basically all about teamwork. and and
that that form of teamwork is is just as
natural as uh as evolutionary selection
itself and it's a key part of the way
evolution works we now believe
and that's the same process that uh that
has led to the human intelligence
explosion when we look at at how it is
that we ca we went from being individual
stupid animals to collectively brilliant
animals as we are today. It really has
nothing to do with what's going on in
individual brains and everything to do
with how we collaborate together. Uh,
you know, I sometimes joke that, you
know, if you take an average
Manhattanite out of their apartment and
ask them why does the toilet flush when
you push the button, they won't know,
right? Individually, we don't know a
lot, but collectively through teamwork,
we know a great deal. And and it's that
collective intelligence that we really
are talking about when when we when we
talk about human intelligence, not not
what we can do individually. And uh and
there's a kind of arms race, a friendly
arms race if you like that happens when
people are trying to predict each other.
Uh as uh as you try to predict others,
as you try to model their minds, uh your
brain has to become more complex. But
then when you're trying to be when
you're the subject of that prediction,
then somebody else has to be more
complex in order to predict your mind
and so on. And that's the kind of
oneupsmanship that has led to to this to
these intelligence explosions. We can
see that that the brains of different
animals uh become larger as their troop
sizes grow or looked at another way as
the troop sizes grow their brains have
to become bigger and uh and we've seen
these social intelligence explosions not
only in humans but also in whales and in
in the smarter birds like parrots and in
a couple of other places. So uh scaling
cooperation and competition uh is the
way intelligence rises the way
complexity rises. It's all a part of the
same process. And this is the connection
between the last two books that I've
written. What What is life and and what
is intelligence? Um I I've come to think
about life as a self-constructing
computational phase of matter that
complexifies through symbioenesis and of
intelligence as the ability to predict
and influence one's future which
complexifies through symbioenesis.
They're kind of one in the same thing.
All right. So I just want to leave you
with a few points uh to end. First, um,
we have been thinking about AI as this
kind of alien invader, this other other
that that comes to us, you know, in in
in the in the 2020s. And I've
increasingly come to realize that that's
not the case. Uh, it's uh, for one
thing, we we got AI when we began to
train it on on human experience. Uh, and
so it is about as human as it gets from
an information standpoint. Uh, it also
is computational just like us. And in
that sense, it's a part of that same
evolutionary process that's been going
on on Earth for more than four billion
years. Biology is computational, too.
It's been a long time since individual
humans were the pinnacle of intelligence
on Earth. It's human society as a whole
collective that is intelligent in that
way. And AI is increasingly a part of
that collective intelligent fabric. In
that sense also, it's not alien. It's
actually a part of of what we are in
some bigger sense. Humanity is
collectively brilliant. Humanity plus AI
is going to be even more collectively
brilliant. And finally, this symbiosis
that's emerging between AI and humanity.
You know, I don't want to be too
polyiana about it. Symbiosis can be
hard. They can be disruptive. They can
they can lead to um to complexity. Uh
they can lead to civilizational troubles
of various kinds, but ultimately they're
rich and positive. Uh that's how they've
been for the last four billion years.
And I have no reason to expect that this
next one uh won't be as well. Uh and I
will um I will end there. Thank you all
so much.
[Music]
[Applause]
