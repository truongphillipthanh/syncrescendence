This morning I hit my usage limit on Codex, OpenAI's competitor to Claude Code. I'm building an agent-native Markdown editor for the Every team. It's exactly the kind of complex, detail-heavy project where Codex shines.
But this week was an exception. Most of my coding happens in Claude Code now—and I'm not alone.
On Tuesday night, we had about 20 founders over to the office for a dinner on the future of AI. I asked everyone what their daily driver AI tools were. Of the programmers, almost everyone said Claude Code with Opus 4.5. The lone holdout was Naveen Naidu—general manager of Monologue—who still prefers Codex.
A month ago, the room would have been split between Codex CLI, GPT 5.1 in Cursor, and Claude Code—with some Droid sprinkled in.
A year ago, the whole room would have been using GPT models.
This might not surprise you if you've been on X lately. It seems the only thing on everyone's mind is Claude Code. This audience is obviously a narrow slice of the market, but it's the same slice that was excited about ChatGPT when it first came out.
So, what explains Claude Code and Opus's sudden rise in startup circles? It's not better marketing. Sure, Anthropic has their "thinking" caps. But compared to the high-profile livestreams we've gotten used to for important model releases, they barely promoted Opus 4.5 at launch. Instead, it's who they decided to build for—and how that's shaping the direction of the whole tech industry.
How Claude Code happened
When Anthropic first released Claude Code along with Sonnet 3.7 in late February of 2025, it was a bold bet. At a time when existing code editors were firmly stuck in building AI agents crammed into a sidebar, they went terminal-first and bypassed the code editor altogether. It signaled, "We're moving to a world where code doesn't matter." At the time, we wrote that while it was incredible at vibe coding new projects from scratch, it wasn't yet good enough to work with large codebases on its own. Still, we were impressed.
OpenAI responded two months later. They launched Codex CLI in April and, in May, Codex Web—a cloud-based agent that ran in ChatGPT. Both these products did away with the code editor, but neither of them worked quite as well as Claude Code—Codex CLI didn't have access to OpenAI's most powerful model, and Codex Web ran in a virtual machine, a sandboxed emulation of a computer rather than your actual computer—but it seemed OpenAI had the same vision of coding as Anthropic and was closing the gap.
That's why the GPT-5 launch in August was confusing. OpenAI had clearly bet big on coding, but they'd split their strategy in two. Vibe coding belonged in ChatGPT, and professional coding belonged in Cursor or Codex CLI. More importantly, in the latter tools, it was billed more as a pair programmer than a tool to which you would fully delegate coding tasks.
Strategically, the decision made sense. Senior software engineers wanted to read code and feel confident their agent wouldn't mess up their computer, and OpenAI was building what those customers wanted: a smart, sandboxed agent that did exactly, exactly, what it was told. But it felt like a miss for those of us who felt that ChatGPT was too underpowered for our needs, and Codex too overpowered, slow, and permission-heavy.
As we wrote at the time, "The discipline of programming has fundamentally changed this summer. The benchmarks don't show it, but if you know how to YOLO four agents at once in Claude Code, GPT-5 feels like a step backward."
That was true in August when the most current Anthropic model was Opus 4, and it's even more true today. Opus 4.5 is fast, emotionally intelligent, and slightly looser with details, but it understands what you're trying to do. When we tested it in November, Kieran Klaassen, general manager of Cora, ran 11 parallel coding projects in six hours, and none of them derailed. He described it as "an extremely capable colleague who understands what you're trying to build and executes accordingly." The code quality might be marginally lower than what Codex produces, but the experience of using it is so much better that it doesn't matter.
Meanwhile, GPT-5.2 in Codex and ChatGPT is no slouch. It consistently tops the benchmarks, and every few days, it seems to solve a new frontier math problem. It's extremely autonomous for complex tasks and clearly the preference of more senior engineers, like Naveen in my straw poll. It just coded for an entire week straight and produced a browser end-to-end.
Codex is growing like a weed, and from OpenAI's perspective, the metrics probably look great. When Codex became publicly available in October, they announced it had grown tenfold since August. Last night, OpenAI confirmed to me that the number is now 20 times. They're building for the most valuable customers—enterprise engineering teams and professional developers. So why worry about a bunch of founders YOLOing side projects in Claude Code?
The strategic threat of good vibes
The first big problem is that OpenAI is building for senior engineers, and that market is shrinking. To be clear, there will still be senior engineers, but they'll increasingly be people who orchestrate agents, not people who read diffs. OpenAI is, at best, trying to build a product and model that serves both. That's a tough needle to thread.
The second problem is that vibe coders won't stay vibe coders. It might be easy to dismiss them now, but the lightly technical founders vibe coding an iPhone app today are going to ship real software for real businesses in a year or two. Codex may remain a powerful tool in their workflow for fixing nasty bugs, but it won't be the primary one for their day-to-day.
The third and most important problem is that whoever wins vibe coding wins how you work on your computer. Anthropic has discovered that once you have an AI that sits on your computer and can build anything, it's also great for getting other kinds of work done, like spreadsheet creation and document editing.
Hence, the explosion of people using Claude Code for non-technical tasks and this week's launch of Cowork.
Opus happily goes from server-side coding to copywriting to growth performance analysis to web research. Can you imagine asking GPT 5.2 Codex to do any of those things? It's too slow, too gated, and too engineer-y.
My point isn't that OpenAI has lost, or that the Codex team isn't making progress. The only reason any of us are here is because OpenAI started the large language model wave.
My point is this: Historically, OpenAI has been consistently ahead of every other competitor in pretty much every dimension. But in this one, at least, they have some catching up to do.