---
url: https://x.com/nicbstme/status/2019149771706102022
author: Nicolas Bustamante (@nicbstme)
captured_date: 2026-02-13
---

# The Crumbling Workflow Moat: Aggregation Theory's Final Chapter

*36 replies, 75 reposts, 485 likes, 1,338 bookmarks, 176.7K views*
*Published: 12:43 PM · Feb 4, 2026*

---

## Introduction

The interface moat is dying. Every vertical software company built on workflow complexity is about to learn this the hard way.

For decades, software companies commanded premium pricing not only for their data, but for their interfaces. The specialized keyboards. The Excel integrations. The workflow automations. Users spent years mastering these systems. Companies built processes hardcoded to specific tools. Switching meant massive productivity loss.

**The interface WAS the product.**

I haven't used Google in a year. An LLM chat is my browser. Soon, knowledge workers won't use specialized software interfaces either. The LLM chat will be their interface to everything.

This isn't incremental change. This is the completion of @benthompson's Aggregation Theory.

### In this article:

- Why Aggregation Theory left suppliers with one critical asset: their interface
- How vertical software built empires on workflow complexity, not data
- Why LLMs absorb the interface layer entirely
- When interfaces are commoditized, it's API versus API
- Valuation Framework: the math is brutal
- Who wins, who loses, and what comes next

---

## Aggregation Theory: The Incomplete Revolution

Ben Thompson's framework reshaped how we think about internet economics.

The value chain was simple:

**Suppliers → Distributors → Consumers**

Pre-internet, high distribution costs created leverage for distributors. TV networks controlled what content got aired. Newspapers decided which stories mattered. Retailers chose which products reached shelves.

Then distribution costs collapsed to zero. Transaction costs followed. Power shifted from distributors to a new species: aggregators.

The classic aggregators emerged: Google aggregated websites via search. Facebook aggregated content via social graph. Amazon aggregated merchants via marketplace. Uber and Airbnb aggregated physical supply via mobile apps.

Thompson identified the virtuous cycle:

**Better UX → More users → More suppliers → Better UX**

The aggregator wins by owning the consumer relationship, commoditizing suppliers until they become interchangeable.

### The Web 2.0 Aggregation Stack

(Description: Diagram showing "Web 2.0 Stack" with layers: Consumers at top, Aggregator (Google/Facebook/Amazon) in middle, and Suppliers at bottom, with arrows indicating value flow)

But suppliers retained two critical assets. Their interface and their data.

---

## The Interface Moat: Why Commoditization Had a Ceiling

The paradox of Web 2.0 aggregation was structural.

Google commoditized discovery. When you search "best Italian restaurant SF," you don't care which site ranks #1. The source is fungible. But you still visit that site. You see their brand. You experience their UX. You navigate their reservation system.

This created a hard limit on commoditization:

- **Discovery**: Commoditized (Google owns it)
- **Interface**: Protected (suppliers own it)
- **Data**: Protected (suppliers own it)

The interface layer mattered for four reasons:

**Brand persistence**: Users saw the New York Times, not just "a news source." Brand equity survived aggregation.

**UX differentiation**: Suppliers could compete on design, speed, features. A better interface meant higher conversion.

**Switching costs**: Users developed muscle memory, workflow habits. Learning a new system had real friction.

**Monetization control**: Suppliers owned their conversion funnels. They controlled the paywall, the checkout, the subscription flow.

Vertical software is the perfect case study. Financial data terminals, legal research platforms, medical databases, real estate analytics, recruiting tools. They all pull from data that's largely commoditized or licensable. Yet they command premium pricing.

Why? **Because the interface IS the moat.**

### The Interface Moat in Vertical Software

(Description: Comparative diagram showing three vertical software platforms (financial data terminal, legal research platform, medical database) all accessing the same underlying data sources but presenting different interfaces with different pricing tiers)

Same data. Different interfaces. Premium pricing.

Knowledge workers spent years learning specialized interfaces. The muscle memory is real. They're not paying for data. They're paying to not relearn a workflow they've spent a decade mastering.

Companies built models and processes hardcoded to specific plugins. Changing providers means rebuilding workflows, retraining teams, risking errors during the transition.

Switching costs weren't about data. They were about the interface.

This is why vertical software traded at 20-30x earnings. The market believed the interface was defensible.

But is it today?

---

## LLMs: The Final Aggregator

LLMs don't just aggregate suppliers. They absorb the interface itself.

When LLMs commoditize the interface, what's left? Just the data. And then it's API against API. Pure commodity competition.

### The Three-Layer Collapse

(Description: Diagram showing three evolutionary stages of the supplier stack - Pre-aggregation (suppliers control everything), Web 2.0 (aggregators control discovery, suppliers control interface and data), and LLM Era (LLMs control interface, suppliers left with only data))

### The Visibility Collapse

(Description: Flow diagram showing how user experience changes from direct software interface interaction to invisible backend data flow through LLM intermediary)

What changes structurally:

- Users never see the supplier's brand
- Users never experience the supplier's UX
- Users don't know where information originated
- The entire web becomes a backend database

Consider a knowledge worker today using specialized vertical software. They open the application. Navigate to the screening tool. Set parameters. Export to Excel. Build a model. Run scenarios. Each step involves interacting with the software's interface. Each step reinforces the switching cost.

Now consider a knowledge worker with an LLM chat:

> "Show me all software companies with >$1B market cap, P/E under 30, growing revenue >20% YoY."
> "Build a DCF model for the top 5."
> "Run sensitivity analysis on discount rate."

The user never touched any specialized interface. They don't know (or care) which data provider the LLM queried. The LLM found the cheapest available source with adequate coverage.

This is complete commoditization. Not just of discovery, but of the entire supplier experience.

**When interfaces are commoditized, all that remains is API versus API.**

---

## The Economics of Invisible Suppliers

What happens to pricing power when interfaces disappear:

### The Old Model (Vertical Software):

- $10-25K/seat/year
- Multi-year contracts with annual escalators
- 95%+ retention because switching means retraining
- Gross margins >80%

### The New Model:

- Data licensing fees (pennies per query)
- No user lock-in (LLM can switch sources instantly)
- Margin compression to commodity levels
- Retention based purely on data quality and coverage

**The math is brutal.**

If a vertical software company's interface was 60% of their value, and LLMs eliminate interface value entirely, what remains is pure data value. And if that data isn't proprietary, if it can be licensed or replicated, there's nothing left.

### Value Decomposition

(Description: Chart showing how a $20B vertical software company's value decomposes into interface value (60%, $12B) and data value (40%, $8B), with annotation showing that when LLMs absorb interface value, only the $8B data value remains)

**If no proprietary data you are in big trouble.**

This is Aggregation Theory applied to its logical conclusion.

Look at financial data software. Companies that built empires on interface complexity are watching their moats evaporate. A $20B market cap company with no truly proprietary data should trade at $5-8B once LLMs absorb their interface value. That's not a bear case. That's math.

The same logic applies everywhere interfaces created moats:

**Financial data**: Terminals that charge $12-24K/year for interfaces over largely commoditized data feeds. When an LLM can query the same data directly, the interface premium evaporates.

**Legal research**: Platforms charging premium prices for interfaces over case law that's largely public domain. The specialized search and citational tools become worthless when an LLM can do it better.

**Medical databases**: Clinical decision support tools that charge physicians for point-of-care recommendations. Exactly what LLMs excel at.

**Real estate analytics**: Comprehensive databases accessed through specialized workflow tools. LLMs querying the same data through APIs eliminate the workflow lock-in.

**Recruiting**: Search and outreach tools charging $10K+/year. When an LLM can query professional networks and draft personalized outreach, the interface value disappears.

**The only survivors: companies with truly proprietary data that cannot be replicated or licensed.**

---

## From Software to APIs: The New Supplier Stack

If interfaces are irrelevant, what do suppliers need?

### The Old Stack:

- Frontend framework (React, Vue)
- Design system (component library)
- UX research (user testing, A/B tests)
- Brand marketing (differentiation)
- SEO optimization (Google discovery)

### The New Stack:

- Clean, structured data (markdown, JSON)
- API/MCP endpoints (machine accessibility)
- Data quality monitoring (accuracy, freshness)

**That's it. All software becomes API.**

A restaurant today invests in a beautiful website with parallax scrolling, professional food photography, reservation system integration, review management, local SEO. All to make humans want to click "Book Now."

A restaurant in the LLM era needs:
```
# Bella Vista Italian Restaurant

## Location: 123 Main St, San Francisco

## Hours: Mon-Thu 5-10pm, Fri-Sat 5-11pm

## Menu:
- Margherita Pizza: $22
- Spaghetti Carbonara: $24

## Reservation API: POST /book {date, time, party_size}
```

That's everything an LLM needs. The $50K website becomes a text file and an API endpoint.

Vertical software's beautiful interfaces become:
```
MCP endpoint: /query
Parameters: {filters, fields, format}
Returns: [structured data]
```

No keyboard shortcuts to learn. No plugins to install. No interface to build. Just data, accessible via API.

---

## MCP: The Protocol That Completes Aggregation

Traditional REST APIs had structural limitations that preserved switching costs:

- Rigid schemas requiring exact field names
- Extensive documentation humans had to read
- Bespoke integration for every service
- Stateless interactions without conversation context

This created a moat: integration effort. Even if data was commoditized, the cost of switching APIs was non-trivial. Someone had to write new code, test edge cases, handle errors differently.

MCP changes this.

**Model Context Protocol** eliminates integration friction:

(Description: Diagram showing how MCP standardizes API integration, allowing instant switching between data providers through a unified protocol interface)

When switching between data sources requires zero integration work, the only differentiator is data quality, coverage, and price.

**This is true commodity competition.**

### Switching Cost Collapse

(Description: Graph showing the collapse of switching costs over time from high costs in Web 2.0 (requiring custom integration work) to near-zero costs in LLM era (standardized MCP protocol))

---

## The New Aggregation Framework

Reframing Thompson's model for the LLM era:

### Aggregation Evolution

(Description: Two-part diagram comparing Original Aggregation Theory (Suppliers → Aggregator → Consumers with suppliers retaining interface/data) vs. LLM Aggregation Theory (APIs → LLM Chat → Consumers with complete supplier invisibility))

**Original Aggregation Theory (2015):**

Suppliers → [Aggregator] → Consumers

The aggregator (Google/Facebook) achieved zero distribution cost, zero transaction cost, and commoditized suppliers. But suppliers kept their interface and their data.

**LLM Aggregation Theory (2025):**

APIs → [LLM Chat] → Consumers

The LLM achieves zero distribution cost, zero transaction cost, AND zero interface cost. Complete supplier invisibility. What remains is API versus API.

The aggregator layer gets **thicker** while the supplier layer gets **thinner**.

In Web 2.0, Google was a thin routing layer. It pointed you to suppliers who owned your attention once you clicked. The supplier had the relationship. The supplier had the interface. The supplier converted you.

In the LLM era, the chat owns your entire interaction. Suppliers are invisible infrastructure. You don't know where the information came from. You don't experience their brand. You never see their interface.

**Vertical software in 2020**: The product that owned the workflow.

**Vertical software in 2030**: An API that the LLM queries.

The moat wasn't data. It was that knowledge workers lived inside these interfaces 10 hours a day. That interface now lives inside the LLM chat.

---

## Winners and Losers: A Framework

### The New Value Matrix

(Description: 2x2 matrix showing businesses plotted across "Interface Value" (high to low) and "Data Proprietary" (low to high) axes, identifying winner and loser quadrants)

### The Winners:

**LLM Chat Interface Owners**: Whoever owns the chat interface owns the user relationship. OpenAI with ChatGPT. Anthropic with Claude. Microsoft with Copilot. Google with Gemini. They capture the interface value that vertical software loses. The new aggregators.

**Proprietary Data Owners**: Companies with truly unique, non-replicable data. The key test: Can this data be licensed or scraped? If yes, not defensible. If no, you survive.

**MCP-First Startups**: Companies building for agents, not humans. No legacy interface to protect. No beautiful UI to maintain. Just clean data served through MCP endpoints that LLMs can query. They can undercut incumbents on price because they have no interface investment to recoup.

### The Losers:

**Interface-Moat Businesses**: Any vertical software where "workflow" was the value. The interface that justified premium pricing becomes worthless. A $20B company with no proprietary data becomes a $5-8B company.

**Traditional Aggregators (Maybe)**: Google and Meta commoditized suppliers. Now LLMs could commoditize them. But here's the nuance: only if they fail to own the LLM chat layer themselves. Google has Gemini and insane distribution. Meta has Llama. The race is on. If they win the chat interface, they stay aggregators. If they lose it, they become the commoditized.

**Content Creators**: UGC platforms lose relevance when AI generates personalized content. The creator economy inverts: infinite AI content, zero human creators needed for most use cases.

**The UI/UX Industry**: Beautiful interfaces become irrelevant when the LLM chat is the only interface. Hundreds of billions per year in frontend development... for what? Figma (amazing product!) is down by 90%.

---

## The Valuation Implications

The framework for repricing interface businesses is simple:

**How much of the business is interface versus data?** Most vertical software is 60-80% interface, 20-40% data. When LLMs absorb the interface, that value evaporates.

**Is the data truly proprietary?** If it can be licensed, scraped, or replicated, there's no moat left. Pure commodity competition.

**This is not a bear case. This is math.**

The market hasn't priced this in because LLM capabilities are new (less than 2 years at scale), MCP adoption is early (less than 1 year), enterprise buyers move slowly (3-5 year contracts), and incumbents are in denial.

But the repricing is coming in my opinion.

---

## The Completion of Aggregation

### The Arc of Aggregation

(Description: Timeline diagram showing four eras of internet economics: Pre-Internet (high distribution costs), Web 1.0 (collapsed distribution), Web 2.0 (collapsed transaction costs, aggregators emerge), LLM Era (collapsed interface costs, complete commoditization))

The arc of internet economics:

**Pre-Internet (1950-1995)**: Distributors controlled suppliers. High distribution costs created leverage.

**Web 1.0 (1995-2005)**: Distribution costs collapsed. Content went online but remained siloed.

**Web 2.0 (2005-2023)**: Transaction costs collapsed. Aggregators emerged. Suppliers were commoditized but kept their interfaces.

**LLM Era (2023+)**: Interface costs collapse. LLMs complete aggregation. Suppliers become APIs. It's API versus API, and whoever has no proprietary data loses.

What Thompson got right: Suppliers would be commoditized. Consumer experience would become paramount. Winner-take-all dynamics would emerge.

What Thompson couldn't have predicted: The interface itself would be absorbed. Suppliers would become invisible. The aggregator would BE the experience, not just route to it. All software would become API.

In the LLM era, the internet becomes a database. Structured data in, natural language out. No websites, no interfaces, no brands. Just APIs serving data to AI.

For someone who spent a decade building beautiful interfaces, this is bittersweet. All those carefully crafted interactions, pixel-perfect layouts, workflow optimizations... obsolete.

But this is what progress looks like. The UX of chatting with an LLM is infinitely better than navigating specialized software. And that's all that matters.

**Aggregation Theory told us suppliers would be commoditized. LLMs are finishing the job.**

**The interface moat is dead. What remains is data. And if your data isn't proprietary, neither is your business.**

---

*Published by Nicolas Bustamante • Captured Feb 13, 2026*