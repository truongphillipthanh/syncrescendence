---
id: SOURCE-20251031-008
title: "No Priors: The Best of 2025 (So Far)"
platform: youtube
format: video
creator: No Priors
date_published: 2025-10-31
status: processed
original_filename: processed/SOURCE-20251031-youtube-video-nopriors-best_of_2025.md
aliases:
  - "No Priors - Best of 2025"
teleology: contextualize
notebooklm_category: ai-engineering
guest: Multiple (Winston Weinberg, Fei-Fei Li, Brendan Foody, Dan Hendrycks, Noubar Afeyan, OpenAI researchers, Arvind Jain, Shiv Rao)
signal_tier: paradigm
chain_relevance: Intelligence
integration_targets: [CANON-30000-INTELLIGENCE, CANON-33000-EXPERTISE]
date_processed: 2026-01-05
synopsis: "Compilation of No Priors 2025 highlights: Harvey discovered GPT-3 produced lawyer-quality answers 86/100 times, Fei-Fei Li on spatial intelligence as evolution hardest problem, displacement creating populist movements, superintelligence geopolitics requiring new coordination, and reasoning models exhibiting metacognition."
key_insights:
  - "GPT-3 tested on 100 legal questions produced 86/100 answers good enough to send to clients without attorney edits before anyone knew models were this capable"
  - "Spatial intelligence (3D world reconstruction from 2D input) is the hardest problem evolution solved, now being tackled by World Labs"
  - "Displacement in digital roles will happen very quickly and painfully, creating a large political populist movement as a predictable societal consequence"
topics:
  - "ai-engineering"
  - "career"
  - "economics"
  - "research"
url: "https://www.youtube.com/watch?v=OdEJjJq1I28"
---

# No Priors: The Best of 2025 (So Far)

## Executive Summary
Compilation of key insights from No Priors interviews throughout 2025. Highlights: Harvey discovered GPT-3 could produce lawyer-quality answers 86/100 times before anyone knew; Fei-Fei Li's spatial intelligence thesis (3D world reconstruction is hardest problem evolution solved); Mercor CEO predicts painful displacement with political populist movement; Dan Hendrycks on superintelligence geopolitics requiring new international coordination; OpenAI researchers on reasoning models exhibiting metacognition; Glean built in "graveyard market" because SaaS unlocked enterprise data access.

## Key Insights

### Harvey Discovery (Winston Weinberg)
GPT-3 tested on 100 landlord-tenant questions from r/legaladvice. Three attorneys said 86/100 answers were good enough to send to clients without edits. "I had no idea the models were this good at legal" —OpenAI general counsel response.

### Spatial Intelligence (Fei-Fei Li)
Spatial intelligence is the hardest problem evolution had to solve—reconstructing 3D world from 2D light collection (eyes). Humans still can't easily generate complicated 3D models mentally without training. World Labs building "imagine at your fingertip" capability.

### Displacement Reality (Brendan Foody)
Displacement in many roles "going to happen very quickly and be very painful and a large political problem." Expects big populist movement. Physical world work persists longer (robotics data creators, waiters, therapists). Digital automation faster because of "self-reinforcing gains and self-improvement."

### Superintelligence Geopolitics (Dan Hendrycks)
Different from nuclear MAD because: (1) capability concentration in few actors, (2) controllability questions at capability thresholds, (3) speed of development. Needs: international coordination mechanisms, verification protocols, solving racing dynamics where slowing down = losing.

### Reasoning Models (OpenAI: McKinzie, Mitchell)
Models learning to "break problems down, consider multiple approaches, self-correct." Exhibiting something like metacognition—reflecting on own reasoning, identifying wrong paths. But still limitations: "can appear to be reasoning when really following learned patterns."

### Deep Research Training (Isa Fulford)
Training models for research assistant quality: finding sources, synthesizing information, understanding good research questions. Hardest part: teaching models what "depth" means—when to stop accumulating surface-level information.

### Graveyard Market Success (Arvind Jain)
Enterprise search was "graveyard of companies." SaaS was the unlock—no more data center access problems. One customer has 1 billion documents (same as entire internet in 2004). Cloud era enables scale that wasn't possible before.

### Human Impact (Shiv Rao)
Doctor feedback: "I was sitting at dinner and my son asked why I wasn't working. I explained Abridge lets mommy come home early." Husband: "Mommy's going to eat dinner with us every night now." Purpose-driven development sustained by oxytocin hits, not just dopamine of hypergrowth.

### Entrepreneurship Thesis (Noubar Afeyan)
"Entrepreneurship is not about taking risks—it's about taking calculated leaps where you can see further than others." Start with "what if?" questions that seem unreasonable. "Real breakthroughs happen when you push into territory of what seems implausible."

## Quotable Passages
> "86 out of 100 was yes. We cold emailed the general counsel of OpenAI and his response was, 'I had no idea the models were this good at legal.'" — Winston Weinberg

> "Displacement in a lot of roles is going to happen very quickly and it's going to be very painful and a large political problem." — Brendan Foody

> "Mommy's going to be able to eat dinner with us every night now." — Doctor feedback via Abridge

## Integration Notes
- Connects to CANON-30000-INTELLIGENCE: Reasoning models, spatial intelligence, deep research
- Connects to CANON-33000-EXPERTISE: Enterprise AI applications, graveyard market success
- Novel contribution: 86/100 legal quality metric; spatial intelligence as evolution's hardest problem; graveyard market thesis

## Metadata
- Duration: ~60 minutes (compilation)
- Quality: Edited highlights from multiple interviews
- Processing notes: Paradigm-tier for diverse AI application insights and founder perspectives


## Transcript

2025 has been another remarkable year in
AI. This week on No Priors, we're
sharing our favorite moments from the
podcast from the [music] year so far.
We've talked to visionary leaders at
Harvey, OpenAI, Glean, A Bridge, and
more. We also talked to legends of
science like Dr. Fay Feay Lee and Nubar
[music] Fayen. But first, let's start
with a moment that captures the magic of
leaning into new capabilities at the
right time. [music] Harvey CEO Winston
Weinberg discovered an extraordinary
opportunity hidden in plain sight.
>> Gabe and I actually had met a couple
years before and I definitely didn't
know anything about the startup world
and didn't have a plan of of doing a
startup. And what had happened was he
showed me GBD3 which at the time was you
know public and and I was first of all
just incredibly surprised that no one
was talking about GPD3 and no one was
using it in any way, shape or form. Um,
and he showed me that and I showed him
kind of my legal workflows and we
started the the kind of aha moment was
we went on uh our/legal advice which is
basically you know a subreddit where
people ask a bunch of legal questions
and almost every single answer is so who
do I sue um almost every single time and
we took about a hundred landlord tenant
questions and we came up with kind of
some chain of thought prompts and this
is before you know anyone was talking
about chain of thought or anything like
that and we applied it to those landlord
tenant questions and we gave it to three
landlord tenant attorneys and we just
said nothing about AI. We just said
here's a question that a potential
client asked and here is an answer uh
would you send this answer without any
edits to that client. Would you be fine
with that? You know, is that ethical? Is
it a a good enough um answer to to send?
And 86 out of 100 was yes. Um, and
actually we cold emailed the general
counsel of OpenAI and we sent him these
results and his response basically was,
"Oh, I had no idea the models were this
good at legal." Um, and we we met with
the the seuite of OpenAI a couple weeks
after.
>> Now, from legal reasoning to spatial
intelligence, the legendary Dr. Fay Lee
opened our eyes to an entirely different
dimension of AI capability. I think from
a neural and cognitive science point of
view that spatial intelligence is a
really hard problem that evolution has
to solve for animals. And what's really
interesting is I think animals have
solved it to an extent but not fully
solved it. It's one of the hardest
problem because um what is the problem
animal has to solve? Animals have to
evolve the capability of collecting
lights in something which we call eyes
mostly. And then with that collection of
eyes, it has to reconstruct a 3D world
in their mind somehow so that they can
navigate and they can do things and of
course they can interact. For humans,
we're the most capable animal in terms
of manipulation. then we can do a lot of
things and all this is spatial
intelligence. To me that's um that's
just rooted in in our intelligence. What
is interesting is it's not a fully
solved problem even in animals. We uh
for example uh for humans right um if I
ask you to close your eyes right now and
draw out or or or build a 3D model of
the environment around you it's not that
easy we don't have that much capability
to generate
extremely complicated 3D model till we
get trained you know there are some of
us whether they're architects or or
designers or just people with a lot of
training and a lot of talent. And that's
that's a that's a hard thing to do. And
imagine you do it at your fingertip much
more easily and allow much more uh fluid
uh interactivity and editability. That
would just be a whole different uh world
for people. No pun intended.
>> Data is the beast feeding the AI train.
And thus, Merkore CEO Brendan Foody is
working with major AI labs on how to
build what's next. He gives a clear
prediction about what's coming for the
workforce.
>> I think displacement in a lot of roles
is going to happen very quickly and it's
going to be very painful uh and a large
political problem. Like I think we're
going to have a big populist movement
around this and all the displacement
that's going to happen. But one of the
most important problems in the economy
is figuring out how to respond to that,
right? Like how do we figure out what
everyone who's working in customer
support or recruiting should be doing in
a few years? How do we reallocate wealth
uh once we have once we approach super
intelligence um for especially if the
value and gains of that are more of a
power law distribution um and so I spend
a lot of time thinking about like how
that's going to play out um and I think
it's really at the heart of
>> what do you think happens eventually x%
of people get displaced from like color
work
>> what do you think they do
>> I think there's going to be a lot more
of the physical world I think that
there's als also going to be a lot that
of like niche.
>> What does the physical world mean?
>> Well, it could be everything ranging
from people that are creating robotics
data to people that are waiters at
restaurants or um or are just like
therapists because people want like
human interaction uh like whatever that
looks like. I think all of I think that
automation in the physical world is
going to happen a lot slower than what's
happening in the digital world just
because of so many of the like
self-reinforcing
uh gains and uh a lot of yeah
self-improvement that can that can
happen in in the virtual world but not
physical one
>> which brings us to one of the biggest
questions of our time. How do we
navigate the geopolitical implications
of super intelligence? Dan Hendris, the
director of the Center for AI Safety,
has an answer.
>> Let's think of what happened in in
nuclear strategy. Basically, a lot of a
lot of states deterred each other from
doing a first strike because they could
then retaliate. So, they had a shared
vulnerability. So, there they were,
we're not going to do this really
aggressive action of trying to make a
bid to wipe you out because that will
end up causing us to be damaged. And we
have a somewhat similar situation later
on um when AI is more salient when it is
viewed as pivotal to the future of of a
nation when the people are on the verge
of making a super intelligence more when
when they can say automate you know
pretty much all AI research. I I think
states would try to deter each other
from trying to leverage that to um
develop it into something like a super
weapon that would allow the other
countries to be crushed or use those AIs
to do um uh some really rapid automated
AI research and development loop that
could um have it bootstrap from its
current levels to something that's um
super intelligent, vastly more capable
than than any other system out there. I
think that later on it becomes so
destabilizing that China just says we're
going to do something preemptive like do
a cyber attack on your data center and
the US might do that to China um and
Russia get coming out of Ukraine will
you know reassess the situation see um
get get situationally aware think oh
what's going on with the US and China oh
my goodness they're so head on AI AI is
looking like a big deal let's say it's
later in the year when you know a big
chunk of software engineering is is
starting to be impacted by AI Hi. Uh, oh
wow, this is looking pretty relevant.
Hey, if you try and use this to crush
us, we will prevent that by doing a
cyber attack on you and we will keep
tabs on your projects because it's
pretty easy for them to do that
espionage.
>> Nubara Feyen has been thinking about how
biotech gets built and how to change the
game for three decades. His
breakthroughs have impacted global
health. He's the founder and CEO of
Flagship Pioneering and the co-founder
of Madna. He wants to make
entrepreneurship a scientific effort,
not a random one. And he thinks AI can
help. The motivation for flagship uh
stems from what I was doing before which
was that I started a company in 1987
when 24year-old immigrants didn't start
companies in this country but instead it
was kind of like former Merc senior
executives or IBM senior executives were
the only ones who were entrusted with
the massive amounts of venture capital
namely $23 million per round used to go
into venture capital. So this was very
early days and I had the the kind of
chance opportunity to start a company
right out of my graduate school and
ended up raising quite a bit of venture
money and eventually um kind of went
down a path of entrepreneurship along
the way. One of the things that
interested me was why it is that kind of
the entrepreneurial process was supposed
to be random, improvisational,
kind of idiosyncratic, almost emotional,
gamy, all of those things I kind of
thought was bit of a put off uh when it
comes to actually doing things in a
serious professional way. And I kind of
used to go around in the very early 90s
saying why isn't entrepreneurship a
profession? And if it was going to be a
profession, how could it be a
profession?
>> What do you mean by gamy?
>> Because it's like supposed to fail most
of the time and once in a while you win
and then you celebrate the win. And what
I mean is like it it
>> it's random.
>> But not only random, but there's like
winners and losers and keeping score. I
don't know. It's maybe the wrong word,
but I just mean like people even call
gamification in the in in the software
space. There is a version of this like I
don't mind being playful cuz if you're
overly serious sometimes you miss
things. But it can't just all be play.
We take hard-earned money. We deploy it
to do things that are damn near
impossible. Once in a while we reduce
them to practice so they become not only
possible but valuable. And yet people
treat it like oh well you know it didn't
work. There's 20 different things we
tried. One of them worked. And that I
don't know as an engineer by background
as a scientist I just thought that what
we do especially listen in healthcare
especially in climate especially in kind
like agriculture food security you can't
think of this as you know like shots on
goal and this you've got to kind of say
hey we can get better at this
>> reasoning is the biggest paradigm shift
in AI architecture since the transformer
Brandon McKenzie and Eric Mitchell from
OpenAI explained a crucial insight about
reasoning models
>> I can give maybe very concrete cases for
like the visual reasoning side of
things. The uh there's a lot of cases
where and back to al also the model
being able to estimate its own
uncertainty. You'll you'll give it some
kind of question about an image and the
model will very transparently tell you
in a thought like I I I don't know. I
can't really see the thing you're
talking about very well or like it
almost knows like that its vision is not
very good. And uh but what's kind of
magical is like when you give it access
to a tool it's like okay well I got to
figure something out. uh let's see if I
can like manipulate the image or crop
around here or something like this. And
um what that means is that it's it's
it's like much more productive use of
tokens as it's doing that. And so your
test time scaling slope, you know, goes
from something like this to, you know,
something much steeper. And uh we've
seen exactly that like the the the test
time scaling slopes for without tool use
and with tool use for for visual
reasoning specifically are very
noticeably different.
>> Yeah. Yeah, I also say like for like
writing code for something like um there
are a lot of things that an LLM could
try to figure out on its own but would
require a lot of uh attempts and
self-verification
that you could write a very simple
program to do in like a verifiable and
and you know much faster way. So um you
know I hey I do some research on this
company and like use this type of you
know valuation model to tell me like you
know what the valuation should be like
you could have the model like try to
crank through that and like fit those
coefficients or whatever in its context
or you could literally just have it like
write the code to just do it the right
way um and just know what the actual
answer is. And so um yeah, I think like
part of this is you can just allocate
compute a lot more efficiently because
you can defer stuff that the model
doesn't have comparative advantage to
doing to a tool that is like really well
suited to doing a thing.
>> Sometimes the most profound moments in
AI development aren't the grand
theoretical breakthroughs. They're based
on taste, data generation, and grinding
work. The visceral experience of
watching something you hoped would work
actually come to life. Issa Falford from
Opening Eye captures that moment
perfectly. Here she's describing the
training that went into deep research.
>> It really was one of those things where
we thought that, you know, training on
browsing tasks would work. You know,
felt like we had good conviction in it.
But actually the first time you train a
model on a new data set using this
algorithm and seeing it actually working
and playing with the model was pretty in
incredible even though we thought it
would work. So honestly, just that it
worked so well was pretty surprising.
>> Mhm.
>> Even though we thought it would, if that
makes sense.
>> Yeah. Yeah. It's the it's the visceral
experience of like, oh, the path is
paved with strawberries or whatever.
>> Exactly. But then sometimes some of the
things that it fails at also surprising
like sometimes it will make a mistake
where it will do such smart things and
then make a mistake where I just
thinking why are you doing that? Like
stop. So I think there's definitely a
lot of room for improvement. Yeah, we've
been impressed with the model so far.
>> One of the biggest surprises of AI and a
core principle for us here at Conviction
is how it can make bad markets suddenly
good ones. The right technology can meet
the right moment in unexpected ways.
Arvin Jane built Glean in what everyone
said was a graveyard market. Enterprise
search.
>> It was like a graveyard like you know of
all these companies that tried to solve
the problem and it didn't. Part of it
was just that I think search is a hard
problem in an enterprise like even
getting access to all the data that you
want to search it was such a big problem
in the pre-SAS world the there was no
way to sort of go into those data
centers figure out where the servers
were where the storage systems were try
to connect with information in them was
a big it was a big challenge so SAS
actually solved that issue so like
search products like most of them most
of the companies started in the pre-SAS
world they failed uh because you could
just couldn't build a turnkey product
but SAS actually allowed you to to
actually build something you know uh
which is my insight was that like look
you know the enterprise world has
changed we have these SAS systems now
and SAS systems don't have versions like
everybody all customers have the same
version you know that they are open
they're interoperable you can actually
hit them with APIs and get all the
content I felt that the biggest problem
was actually solved which was that I
could actually easily go and bring all
the enterprise information and data in
one place uh and build this unified
search system on top. So that was
actually a big unlock and by the way the
origins of glean is so at rubric you
know we had this problem like you know
we grew fast we had lot of information
across 300 different SAS systems and
nobody could find anything in the
company and people were complaining
about it in our pulse surveys and I and
I was you know I always run it in my
startups and so this is a complaint that
you know came to me like I had to solve
it so I tried to buy a search product
and I I realized there's nothing to buy
I mean that's that's really the origins
of how how green got started as a
company and so that was like you know
one big issue like you know uh so SAS
made it easy for to actually connect you
know your enterprise data and knowledge
to a search system. So that actually
made it possible for us to for the very
first time build a turnkey product. But
there are a lot of other advances as
well you know one is you know like look
you know businesses have so much
information and data. One interesting
you know fact one of our largest
customers they have more than 1 billion
documents inside their company. Now hear
this, you know, when LR and I, you know,
when we were working on search at
Google, you know, in 2004, the entire
internet was actually 1 billion
documents. You know, there's a massive
explosion of content like inside
businesses. So, you have to build
scalable systems and you couldn't build
like a system like that before in the
pre-cloud era.
>> Perhaps no story captures the human
impact of this AI moment and its
potential better than what's happening
in healthcare. Here's Shiva, CEO and
founder of a bridge. It's pretty heroic
in general for a doctor to give you
feedback like hey this sucked and you
got to do better like um you didn't
recognize the way I said this medication
or uh I'm a gastronenterologist and I
would never you know sequence my
problems in my assessment and plan
section of my note this way. It doesn't
serve me well and makes me look like
terrible as a doctor or whatever. We get
that feedback. We love it. It's oxygen.
But then we also get the feedback that's
like, "Hey, this is amazing and I'm not
going to retire anymore and I I've got
like years, decades left in my career
now thanks to this technology." But in
this channel, love stories, all of that
feedback, that positive feedback, we
just get it like programmatically
funneled. So any one of our people
inside of the company can always go into
that channel and it's like purpose, you
know? It's like fulfillment immediately.
like you immediately understand why
we're all working so hard and why it
makes sense because like being on this
very telephone pole like journey these
last couple years uh is obviously like
it's new for so many of us and we're all
kind of building new muscles but it's
it's a lot of pressure but this is my
favorite bit of feedback so this love
story comes from a doctor at Tanner
Health which is a rural health system
and she wrote to us she wrote I was
sitting at dinner last week and my son
asked me mommy why aren't you working
right now I literally took my phone out
and explained to him that a bridge is a
new tool that lets mommy come home early
and eat dinner with her family. I
started to tear up and looked over at my
husband who then said, "Mommy's going to
be able to eat dinner with us every
night now." And we get feedback like
that like every day, you know, and so
like there's there's dopamine hits, you
know, in hyperrowth and like those are
awesome, but I think that they get us
through like sprints. But I think it's
the oxytocin hits like this. It's the
purpose. It's the fulfillment. It's like
that's I think what I think we're really
after in this company. And so like
everybody's mission driven out out
there, but I think this mission um like
it hits me at least a little bit
different.
>> These conversations remind us that we're
living through a hinge moment in
history. Stay tuned as we have more
conversations with the builders and
thinkers leading the way for the rest of
the year. If you like what we're doing,
leave us a review on Apple Podcasts or
Spotify, comment on YouTube, or let us
know who we should have as a guest.
Thanks for [music] listening.
Find us on Twitter at no prior pod.
[music] Subscribe to our YouTube channel
if you want to see our faces. Follow the
show on Apple Podcast, Spotify, or
wherever you listen. That way, you get a
new episode every week. And sign up for
emails or find transcripts [music] for
every episode at no-briers.com.
