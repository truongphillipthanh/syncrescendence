## The State of AI in Q4 2025: A Detailed Analysis and 2026 Predictions

My name is **David Andre**, and I've focused intensely on **AI** for the last 28 months. In this analysis, I will provide a detailed breakdown of the main trends, patterns, and changes I observe in the AI industry, alongside a set of predictions for 2026.

### Is AI in a Bubble?

The most frequently discussed topic is whether AI constitutes a bubble. A useful heuristic suggests that if everyone is convinced it’s a bubble, it probably isn't. For a true bubble to exist, investors—the people providing the capital—must be absolutely convinced that the returns will continue indefinitely, devoid of any fear. The 2008 crash is the most recent and clearest example of this. However, the current AI technology cycle possesses major differences compared to past speculative events.

First, let's examine the arguments for why people believe AI is a bubble:
* **Insane Investment:** Investment is pouring in not only from massive tech companies like **Google**, **Nvidia**, **OpenAI**, **Broadcom**, **AMD**, and **Meta** (with Mark Zuckerberg reportedly spending billions on individual people) but also from the venture capital (VC) landscape. We see seed rounds reaching $\$17$ million and some companies raising multi-billion dollar rounds before having a product.
* **Unproven Startups:** I would make exceptions for foundational AI research labs like those co-founded by **Ilya Sutskever** or **Mira Murati** (e.g., **SSI** and **Thinking Machines**), as they employ the best people in the world. However, tons of application-layer and consumer startups are raising massive rounds, often with **no revenue**, **zero product-market fit**, and a completely **unproven track record**. This is the biggest indicator that a bubble may exist, specifically in the VC world or private markets.

However, when comparing the current state of AI as of Q4 2025 to, for example, the 2021 crypto bull run, there are significant differences:
* **Use Case:** AI is already being used every day; it is genuinely useful. In contrast, crypto (especially **NFTs** and esoteric coins) was often based on the "greater fool theory."
* **Revenue:** Unlike many crypto companies in 2021, which were speculative with no actual growth (similar to the **dot-com bubble** where adding ".com" tripled a valuation), AI companies like **OpenAI** and **Anthropic** are seeing **massive revenue growth**. Anthropic, for instance, has seen growth exceeding a 10x increase year-over-year. The use case and the revenue are demonstrably present.

While a short- to medium-term stock market pullback of $10\%$, $20\%$, or even $30\%$ is possible, this is not a recession or a depression. We will certainly see many early-stage startups with private backing crash and burn. However, I do not foresee an **$80\%$ market crash** like the **2001 dot-com bubble**, where the NASDAQ dropped from a $5,000$ peak to about $1,300$. AI is a completely transformational technology, and the gains are real.

### The Frontier of Reinforcement Learning and Data Bottleneck

Even with models like **GPT-5**, which some felt was not as impressive as anticipated—primarily because OpenAI deliberately made it a smaller, more compute-efficient model than the massive **GPT-4.5** (estimated at $17$ trillion parameters) to facilitate serving it to more users and on the free plan—the massive gains in **reinforcement learning (RL)** continue to push the frontier.

Reasoning, which became mainstream with the release of **Anthropic’s Claude 3.0 (preview)** (a key mainstream reasoning model) about 12 months ago, is still relatively new. However, reinforcement learning, especially when combined with **test-time compute**, remains largely untapped. The core breakthrough is that as long as a benchmark for a desired capability can be created and measured, AI models can saturate and master that capability.

This is why there's a surge of startups in San Francisco building **RL environments** for specific tasks. For example, recreating a site like **Amazon** to train AI agents on online shopping actions: picking a product, scanning the page, opening the cart, checking out, and so on.

The models are already incredibly smart but are primarily trained on text, which is both their biggest strength and weakness. The internet's text has been largely scraped and saturated, leading to a stagnation in foundational model performance. However, applying new paradigms like reinforcement learning allows for massive gains in **coding** and **math**. These two dimensions are ideal because they are **deterministic** and **can be validated**. Code must compile, and math must add up. This determinism allows for the effective use of **synthetic data**; even if only one out of 500 generated examples works, the reasoning trace (chain of thought) can be examined to train the model.

For most **creative tasks** (like image generation, copywriting, video editing), the output is a question of taste, making this training loop difficult. For AI to make crazy gains, we must continue to create these RL environments to generate the **new data** needed for models to keep improving, as data, compute, and talent are the digital oil required for models to work and scale.

### XAI and the Real-World Data Advantage

I previously predicted that **XAI**, despite starting late, might catch up to competitors because **Elon Musk** is exceptional at large manufacturing, infrastructure projects, and quickly solving bottlenecks. He has the capital expenditure (capex) to buy GPUs and the ability to attract top talent.

Crucially, he also has the **data advantage**:
* **X.com (formerly Twitter):** Musk acquired Twitter, not just for free speech, but also for its wealth of real-time data. It is now prohibitive for companies like OpenAI, Anthropic, or Google to scrape this data.
* **Tesla:** XAI has a massive amount of real-world data, especially video footage from Tesla cars, which, while primarily used for **Full Self-Driving (FSD)**, will also be invaluable for **video models** and **world models** (like **Grok Imagine**, XAI's alternative to **Sora**).
* **Optimus:** Elon's humanoid robot will provide three-dimensional, physical understanding of the world. Tasks that are trivial for a human, like a simple physical manipulation, are impossibly hard for a robotic arm because it lacks the necessary input tokens.

Humans are not unproductive in the first years of life; they are massively learning physics and gathering a continuous stream of input tokens (visual, audio, sensory). The neuroplasticity of a child is immense.

Consider that the average human can become much smarter than a Large Language Model (LLM) by age 18 with orders of magnitude fewer tokens. Top models like **GPT-5**, **Opus 4**, or **Grok 4** are trained on tens of trillions of tokens yet are often not as generally useful as a college intern. Humans are much better at **generalization**, suggesting there are still massive efficiency gains for AI to achieve.

The **Optimus** program will give XAI invaluable, non-internet-available data that others lack. The internet primarily contains text, images, and videos. It does not capture the intuitive, social, and emotional tokens of human experience, such as how to act respectfully in a corporate hallway or the feeling of regret after eating unhealthy food. LLMs are next-token predictors and do not possess these feelings, despite how their output might seem.

### The Evaporation of AI Doomerism

One of the biggest trends of 2025 is the complete evaporation of the **AI safety** and **AI doomerism** movements. In 2023 and the first half of 2024, everyone was discussing the paperclip problem, escaping AIs, and hard take-offs. Today, nobody is.

This is because the more people use AI, the more they realize LLMs are simply **large language models** and **next-token predictors**. They are not an immediate threat. While the future of AI architecture, drones, and humanoid robots could change this in 30–50 years, the reality in Q4 2025 is that doomerism was mostly hype. I am staking my entire career and reputation on the fact that AI is **not a bubble**.

---

## Major AI Industry Trends and Predictions

### 1. The Rise of Open Source Models

A major trend that is not getting enough publicity is that **open-source models** are truly catching up to and, in many domains, overtaking closed-source models.

The best example is **GLM-4.6**, a powerful open-source model, especially for coding, which is better than **Claude 3.5 Sonnet** and even **Claude 4.5 Sonnet** on many popular benchmarks. However, it remains a more esoteric model for several reasons:
* **Big Lab Incentives:** Major AI labs (**OpenAI**, **Anthropic**, **Google DeepMind**) have every incentive to ignore or downplay open-source models.
* **Inference Optimization:** The majority of compute (GPUs, TPUs, cloud resources) is optimized for popular models like the GPT and Claude series. When new open-source architectures like **DeepSeek**, **Kimmy**, or **GLM** emerge, the compute is often not optimized for them, resulting in worse performance.

Despite these factors, open-source models have nearly surpassed closed ones. The fact that a model like GLM-4.6 from **Zhipu AI** (a Chinese lab that was little-known three months ago) is comparable to Anthropic’s most powerful model, **Claude 4.5 Sonnet** (from a company valued at about $\$200$ billion), is incredible.

### 2. The Dominance of Smaller, Faster Models

Another significant trend is the rise of **smaller models**. Anthropic recently released **Claude Haiku 4.5**. Haiku might be **more useful** than its superior, **Sonnet**.
* **Cost-Effectiveness:** Haiku is three times cheaper, enabling many more applications.
* **Speed and Flow:** It is more than twice as fast as Sonnet 4.5. Especially for coding, speed is crucial for maintaining a programmer's "flow zone." A slow model encourages distraction.

We will see more **specialized, small, super-fast models** that are efficient, rather than massive, generic, slow, and expensive behemoths. The era of models like the huge **GPT-4.5** (which is now mostly removed from the API or gated behind a $\$200$-a-month plan due to its $178$ trillion parameter size) is ending.

Modern, cutting-edge LLMs are much more efficient (e.g., $1$ or $2$ trillion parameters). Thanks to **reasoning** and **test-time compute**, medium-sized models can utilize more compute during inference, enabling them to "think for longer." The time an agent can work meaningfully by itself has been rising exponentially, from about 20 minutes just six months ago to around two hours today, with some agents reportedly working for seven hours.

This extended capability has unlocked a new paradigm of tasks. For example, a **deep research** query—a feature that didn't exist nine months ago but is now in every major chatbot—requires a model to research, scrape, reason, analyze, and summarize. This single query burns hundreds, if not thousands, of times more tokens than a simple chat query. Similarly, a massive codebase refactor with **GPT-5 Codex** could run for 30–90 minutes. This new multi-hour capability means models can execute complex, long-running processes that previously required an intern or junior engineer.

### 3. The "Infinite Money Glitch" and Compute Bottleneck

There is an "infinite money glitch" being performed by companies like **Nvidia** and **OpenAI**. For example, Nvidia invests $\$100$ billion into OpenAI. OpenAI then uses that capital to buy compute, funneling the money directly back to Nvidia or to cloud providers that purchase Nvidia GPUs. This creates a revenue loop for the investors and allows the AI labs to scale much faster, even if they are largely unprofitable.

This lack of profitability is a strong argument for the bubble hypothesis. All of the biggest AI companies are burning money—millions, and for the largest, billions—on training new models and compute. The only entity making massive profits with amazing margins is **Nvidia**.

This is why we see deals like **OpenAI and Broadcom** partnering to build custom chips, and why **Amazon** and **Google** have their own custom silicon (TPUs). Everyone wants to build their own chip to avoid being reliant on Nvidia and to **control their own destiny**.

However, **compute remains the single biggest bottleneck in AI**. The demand for compute from companies like Anthropic and OpenAI is so insatiable that they could easily double or triple their revenues if they had more GPUs. This massive demand is why the "smart money" (trillions of dollars managed by the world's largest investors) is being dumped into building **multi-gigawatt data centers** (like OpenAI's $10$-gigawatt facility with Broadcom). Data centers are predictable, understandable assets for Wall Street, similar to real estate.

### 4. The Problem of Sameness and a Call for 0 to 1 Innovation

Everyone is building the same two types of applications:
1.  A **generic "vibe coding" tool** (a clone of **Bold**, **Lovable**, or **V0**).
2.  A **workflow builder** (**NA10 clone**).

The rush to clone **NA10** is significant; even major players like OpenAI released their own workflow builder, **Agent Kit**, at the latest Dev Day. While both NA10 and Agent Kit can be successful (NA10 is currently valued around $\$2$ billion and could reach $\$10$ billion in a year), most of the other clones will not survive. For instance, **11 Labs** (voice company) and **Firecrawl** (web crawler) have also released agentic workflow builders.

There is a glaring lack of **true innovation** and **unique products**. The vibe coding tools are virtually interchangeable, and none are **$10$ times better** than the next best thing—a key criterion for success, as outlined in **Peter Thiel's** book, *Zero to One*. Many of these startups are also vastly unprofitable because they are **reselling OpenAI and Anthropic tokens at a loss**. We will see a lot of these startups go bust in the next 24 months.

The biggest need is for people to build something **0 to 1**—creating something entirely new, solving a unique problem in a small market, and achieving a monopoly by delivering a solution that is demonstrably superior.

---

## Predictions for 2026

1.  **Massive Social Unrest and Protests:** AI is going to take jobs because that is where the money is. The global labor market is a $\$15$ trillion-per-year industry, compared to the software market's roughly $\$300$ billion. We will see a surge of startups building **single-job replacement agents** (e.g., customer support, secretaries, outreach specialists). This will lead to massive efficiency and productivity gains and returns for investors, but on the negative side, it will cause widespread job loss, resulting in significant social unrest and protests.
2.  **The Return of Coding:** Learning how to code will become "sexy" again. People will want to understand software engineering and computer science because a technical person can take a **massive advantage** of coding agents. A "cracked programmer" who can manage a team of agents and build automations will become $100$x more powerful, while the average person might only be $2$x or $3$x more powerful. This is the concept of **"the smart gets smarter"**—those who are at the cutting edge of AI will crush the competition.

The biggest takeaway is this: **If you can do one thing, get to the cutting edge of AI.**